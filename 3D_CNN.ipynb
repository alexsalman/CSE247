{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/3D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7I8NauauE3"
      },
      "source": [
        "####**3D Convolutional Neural Network**\n",
        "######*I am using 3D Convolutional Neural Network to extract the temporal and spatial information which are merged slowly throughout the whole network.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ibtd5HKtZk",
        "outputId": "17903ddf-5b28-42e5-8e89-9d45234c71e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
        "from keras import regularizers\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)\n",
        "# https://bleedai.com/human-activity-recognition-using-tensorflow-cnn-lstm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "8bde9e78-17fa-4964-99fc-8c982bcd2d8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUTeIqzpZc9J"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QRDbHG0TZkYJ"
      },
      "outputs": [],
      "source": [
        "# https://medium.com/analytics-vidhya/video-preprocessor-and-augmentation-for-deep-learning-tasks-12dd3fcce868\n",
        "def load_video(path, resize=(128, 128)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            # frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "609b917f-75ee-43a0-8562-ee79e336f50f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# one_hot_encoded_labels\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-9ykP4ig7IW"
      },
      "outputs": [],
      "source": [
        "def create_3D_CNN_model():\n",
        "    sample_shape = (16, 128, 128, 3)\n",
        "    model = Sequential()\n",
        "\n",
        "    ### 1\n",
        "    model.add(Conv3D(8, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4),\n",
        "                     input_shape=sample_shape))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 2\n",
        "    model.add(Conv3D(16, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 3\n",
        "    model.add(Conv3D(16, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 4\n",
        "    model.add(Conv3D(32, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(GlobalAveragePooling3D())\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "\n",
        "    # model.add(Dense(12, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.6))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "\n",
        "    model.summary(line_length = 125)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_GxXZBcHlB",
        "outputId": "7cf18d8f-d3cf-47b1-e4b7-a415683089fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_____________________________________________________________________________________________________________________________\n",
            " Layer (type)                                           Output Shape                                      Param #            \n",
            "=============================================================================================================================\n",
            " conv3d (Conv3D)                                        (None, 16, 126, 126, 8)                           224                \n",
            "                                                                                                                             \n",
            " max_pooling3d (MaxPooling3D)                           (None, 8, 63, 63, 8)                              0                  \n",
            "                                                                                                                             \n",
            " dropout (Dropout)                                      (None, 8, 63, 63, 8)                              0                  \n",
            "                                                                                                                             \n",
            " conv3d_1 (Conv3D)                                      (None, 8, 61, 61, 16)                             1168               \n",
            "                                                                                                                             \n",
            " max_pooling3d_1 (MaxPooling3D)                         (None, 4, 30, 30, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_1 (Dropout)                                    (None, 4, 30, 30, 16)                             0                  \n",
            "                                                                                                                             \n",
            " conv3d_2 (Conv3D)                                      (None, 4, 28, 28, 16)                             2320               \n",
            "                                                                                                                             \n",
            " max_pooling3d_2 (MaxPooling3D)                         (None, 2, 14, 14, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_2 (Dropout)                                    (None, 2, 14, 14, 16)                             0                  \n",
            "                                                                                                                             \n",
            " conv3d_3 (Conv3D)                                      (None, 2, 12, 12, 32)                             4640               \n",
            "                                                                                                                             \n",
            " max_pooling3d_3 (MaxPooling3D)                         (None, 1, 6, 6, 32)                               0                  \n",
            "                                                                                                                             \n",
            " dropout_3 (Dropout)                                    (None, 1, 6, 6, 32)                               0                  \n",
            "                                                                                                                             \n",
            " global_average_pooling3d (GlobalAveragePooling3D)      (None, 32)                                        0                  \n",
            "                                                                                                                             \n",
            " dropout_4 (Dropout)                                    (None, 32)                                        0                  \n",
            "                                                                                                                             \n",
            " dense (Dense)                                          (None, 16)                                        528                \n",
            "                                                                                                                             \n",
            " dropout_5 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense_1 (Dense)                                        (None, 8)                                         136                \n",
            "                                                                                                                             \n",
            " dense_2 (Dense)                                        (None, 4)                                         36                 \n",
            "                                                                                                                             \n",
            "=============================================================================================================================\n",
            "Total params: 9,052\n",
            "Trainable params: 9,052\n",
            "Non-trainable params: 0\n",
            "_____________________________________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "model = create_3D_CNN_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYEkaYLoyb_",
        "outputId": "7be3bf4a-a730-4241-ab7b-5f29a3d2baa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "202/202 [==============================] - 9s 35ms/step - loss: 1.5409 - accuracy: 0.4041 - val_loss: 1.3183 - val_accuracy: 0.3566\n",
            "Epoch 2/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.2551 - accuracy: 0.4035 - val_loss: 1.2473 - val_accuracy: 0.4816\n",
            "Epoch 3/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.2129 - accuracy: 0.4171 - val_loss: 1.2002 - val_accuracy: 0.4816\n",
            "Epoch 4/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.1628 - accuracy: 0.4369 - val_loss: 1.1622 - val_accuracy: 0.4816\n",
            "Epoch 5/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.1283 - accuracy: 0.4889 - val_loss: 1.0909 - val_accuracy: 0.6912\n",
            "Epoch 6/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.0732 - accuracy: 0.5223 - val_loss: 1.0483 - val_accuracy: 0.6250\n",
            "Epoch 7/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 1.0380 - accuracy: 0.5755 - val_loss: 0.9977 - val_accuracy: 0.6912\n",
            "Epoch 8/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.0371 - accuracy: 0.5786 - val_loss: 0.9985 - val_accuracy: 0.6250\n",
            "Epoch 9/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.0108 - accuracy: 0.5910 - val_loss: 0.9729 - val_accuracy: 0.6250\n",
            "Epoch 10/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9815 - accuracy: 0.6170 - val_loss: 0.9046 - val_accuracy: 0.7022\n",
            "Epoch 11/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9571 - accuracy: 0.6170 - val_loss: 0.9097 - val_accuracy: 0.7390\n",
            "Epoch 12/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9391 - accuracy: 0.6256 - val_loss: 0.9096 - val_accuracy: 0.7316\n",
            "Epoch 13/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9632 - accuracy: 0.6089 - val_loss: 0.9300 - val_accuracy: 0.7243\n",
            "Epoch 14/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9269 - accuracy: 0.6275 - val_loss: 0.8769 - val_accuracy: 0.7426\n",
            "Epoch 15/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9014 - accuracy: 0.6528 - val_loss: 0.8262 - val_accuracy: 0.7463\n",
            "Epoch 16/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9068 - accuracy: 0.6392 - val_loss: 0.9389 - val_accuracy: 0.6287\n",
            "Epoch 17/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9037 - accuracy: 0.6312 - val_loss: 0.9874 - val_accuracy: 0.6287\n",
            "Epoch 18/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8989 - accuracy: 0.6423 - val_loss: 0.8733 - val_accuracy: 0.7390\n",
            "Epoch 19/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8677 - accuracy: 0.6498 - val_loss: 0.8704 - val_accuracy: 0.7353\n",
            "Epoch 20/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9007 - accuracy: 0.6423 - val_loss: 0.8016 - val_accuracy: 0.7316\n",
            "Epoch 21/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8765 - accuracy: 0.6473 - val_loss: 0.8609 - val_accuracy: 0.7390\n",
            "Epoch 22/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8687 - accuracy: 0.6541 - val_loss: 0.8511 - val_accuracy: 0.7390\n",
            "Epoch 23/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8338 - accuracy: 0.6590 - val_loss: 0.8677 - val_accuracy: 0.7390\n",
            "Epoch 24/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8358 - accuracy: 0.6615 - val_loss: 0.8627 - val_accuracy: 0.7316\n",
            "Epoch 25/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.8403 - accuracy: 0.6553 - val_loss: 0.8133 - val_accuracy: 0.7426\n",
            "Epoch 26/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8230 - accuracy: 0.6646 - val_loss: 0.7700 - val_accuracy: 0.7096\n",
            "Epoch 27/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8081 - accuracy: 0.6801 - val_loss: 0.7852 - val_accuracy: 0.7353\n",
            "Epoch 28/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7947 - accuracy: 0.6757 - val_loss: 0.7996 - val_accuracy: 0.7426\n",
            "Epoch 29/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8237 - accuracy: 0.6714 - val_loss: 0.7419 - val_accuracy: 0.7353\n",
            "Epoch 30/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8119 - accuracy: 0.6634 - val_loss: 0.8317 - val_accuracy: 0.7426\n",
            "Epoch 31/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8176 - accuracy: 0.6547 - val_loss: 0.8701 - val_accuracy: 0.7316\n",
            "Epoch 32/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8024 - accuracy: 0.6671 - val_loss: 0.8322 - val_accuracy: 0.7426\n",
            "Epoch 33/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7927 - accuracy: 0.6689 - val_loss: 0.7717 - val_accuracy: 0.7426\n",
            "Epoch 34/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7848 - accuracy: 0.6801 - val_loss: 0.7894 - val_accuracy: 0.7243\n",
            "Epoch 35/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.7937 - accuracy: 0.6751 - val_loss: 0.8572 - val_accuracy: 0.7022\n",
            "Epoch 36/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7680 - accuracy: 0.6825 - val_loss: 0.8460 - val_accuracy: 0.7390\n",
            "Epoch 37/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7825 - accuracy: 0.6665 - val_loss: 0.8535 - val_accuracy: 0.7206\n",
            "Epoch 38/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7662 - accuracy: 0.6869 - val_loss: 0.7082 - val_accuracy: 0.7096\n",
            "Epoch 39/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7987 - accuracy: 0.6764 - val_loss: 0.9099 - val_accuracy: 0.6618\n",
            "Epoch 40/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7688 - accuracy: 0.6745 - val_loss: 0.7874 - val_accuracy: 0.7426\n",
            "Epoch 41/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7697 - accuracy: 0.6757 - val_loss: 0.8385 - val_accuracy: 0.7353\n",
            "Epoch 42/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7659 - accuracy: 0.6844 - val_loss: 0.8221 - val_accuracy: 0.7206\n",
            "Epoch 43/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7326 - accuracy: 0.6832 - val_loss: 0.7903 - val_accuracy: 0.7426\n",
            "Epoch 44/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7392 - accuracy: 0.6869 - val_loss: 0.8537 - val_accuracy: 0.6838\n",
            "Epoch 45/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.7337 - accuracy: 0.6844 - val_loss: 0.8122 - val_accuracy: 0.7390\n",
            "Epoch 46/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7499 - accuracy: 0.6850 - val_loss: 0.7565 - val_accuracy: 0.7390\n",
            "Epoch 47/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7346 - accuracy: 0.6856 - val_loss: 0.8053 - val_accuracy: 0.7353\n",
            "Epoch 48/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7242 - accuracy: 0.6918 - val_loss: 0.6589 - val_accuracy: 0.7574\n",
            "Epoch 49/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7099 - accuracy: 0.6906 - val_loss: 0.8160 - val_accuracy: 0.7353\n",
            "Epoch 50/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7162 - accuracy: 0.6813 - val_loss: 0.7404 - val_accuracy: 0.7426\n",
            "Epoch 51/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7311 - accuracy: 0.6869 - val_loss: 0.7761 - val_accuracy: 0.7390\n",
            "Epoch 52/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7083 - accuracy: 0.6931 - val_loss: 0.8346 - val_accuracy: 0.6985\n",
            "Epoch 53/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7095 - accuracy: 0.6801 - val_loss: 0.7003 - val_accuracy: 0.7463\n",
            "Epoch 54/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6999 - accuracy: 0.6931 - val_loss: 0.7136 - val_accuracy: 0.7279\n",
            "Epoch 55/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7026 - accuracy: 0.6825 - val_loss: 0.6721 - val_accuracy: 0.7500\n",
            "Epoch 56/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7120 - accuracy: 0.6906 - val_loss: 0.7594 - val_accuracy: 0.7390\n",
            "Epoch 57/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6985 - accuracy: 0.6931 - val_loss: 0.7595 - val_accuracy: 0.7390\n",
            "Epoch 58/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7095 - accuracy: 0.6856 - val_loss: 0.6803 - val_accuracy: 0.7537\n",
            "Epoch 59/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6660 - accuracy: 0.6993 - val_loss: 0.6672 - val_accuracy: 0.7426\n",
            "Epoch 60/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6923 - accuracy: 0.6838 - val_loss: 0.6986 - val_accuracy: 0.7426\n",
            "Epoch 61/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6923 - accuracy: 0.6887 - val_loss: 0.6184 - val_accuracy: 0.7169\n",
            "Epoch 62/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6791 - accuracy: 0.6918 - val_loss: 0.7456 - val_accuracy: 0.7206\n",
            "Epoch 63/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7099 - accuracy: 0.6894 - val_loss: 0.6796 - val_accuracy: 0.7426\n",
            "Epoch 64/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6530 - accuracy: 0.6993 - val_loss: 0.6201 - val_accuracy: 0.7500\n",
            "Epoch 65/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6825 - accuracy: 0.6931 - val_loss: 0.6544 - val_accuracy: 0.7574\n",
            "Epoch 66/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6692 - accuracy: 0.6937 - val_loss: 0.7320 - val_accuracy: 0.7390\n",
            "Epoch 67/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6527 - accuracy: 0.7178 - val_loss: 0.6934 - val_accuracy: 0.7390\n",
            "Epoch 68/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6595 - accuracy: 0.7005 - val_loss: 0.7734 - val_accuracy: 0.7279\n",
            "Epoch 69/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6647 - accuracy: 0.7234 - val_loss: 0.6202 - val_accuracy: 0.7868\n",
            "Epoch 70/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6536 - accuracy: 0.7079 - val_loss: 0.5992 - val_accuracy: 0.7794\n",
            "Epoch 71/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6736 - accuracy: 0.7017 - val_loss: 0.6902 - val_accuracy: 0.7353\n",
            "Epoch 72/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6528 - accuracy: 0.7184 - val_loss: 0.5860 - val_accuracy: 0.8015\n",
            "Epoch 73/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6627 - accuracy: 0.7271 - val_loss: 0.7165 - val_accuracy: 0.7426\n",
            "Epoch 74/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6491 - accuracy: 0.7184 - val_loss: 0.7050 - val_accuracy: 0.7279\n",
            "Epoch 75/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6387 - accuracy: 0.7209 - val_loss: 0.6599 - val_accuracy: 0.7426\n",
            "Epoch 76/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6431 - accuracy: 0.7364 - val_loss: 0.7503 - val_accuracy: 0.6728\n",
            "Epoch 77/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6302 - accuracy: 0.7333 - val_loss: 0.6330 - val_accuracy: 0.7500\n",
            "Epoch 78/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6270 - accuracy: 0.7450 - val_loss: 0.6144 - val_accuracy: 0.7537\n",
            "Epoch 79/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6338 - accuracy: 0.7234 - val_loss: 0.6652 - val_accuracy: 0.7243\n",
            "Epoch 80/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6226 - accuracy: 0.7308 - val_loss: 0.6173 - val_accuracy: 0.7463\n",
            "Epoch 81/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6221 - accuracy: 0.7395 - val_loss: 0.6654 - val_accuracy: 0.7243\n",
            "Epoch 82/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6404 - accuracy: 0.7382 - val_loss: 0.6387 - val_accuracy: 0.7279\n",
            "Epoch 83/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6516 - accuracy: 0.7302 - val_loss: 0.5840 - val_accuracy: 0.7279\n",
            "Epoch 84/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6346 - accuracy: 0.7290 - val_loss: 0.6453 - val_accuracy: 0.7279\n",
            "Epoch 85/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6165 - accuracy: 0.7321 - val_loss: 0.6603 - val_accuracy: 0.7206\n",
            "Epoch 86/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6052 - accuracy: 0.7376 - val_loss: 0.5747 - val_accuracy: 0.7500\n",
            "Epoch 87/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6155 - accuracy: 0.7370 - val_loss: 0.6225 - val_accuracy: 0.7316\n",
            "Epoch 88/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6080 - accuracy: 0.7444 - val_loss: 0.5806 - val_accuracy: 0.7868\n",
            "Epoch 89/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6397 - accuracy: 0.7327 - val_loss: 0.9381 - val_accuracy: 0.5368\n",
            "Epoch 90/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6265 - accuracy: 0.7407 - val_loss: 0.6838 - val_accuracy: 0.7206\n",
            "Epoch 91/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6047 - accuracy: 0.7469 - val_loss: 0.6753 - val_accuracy: 0.6912\n",
            "Epoch 92/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6286 - accuracy: 0.7420 - val_loss: 0.6462 - val_accuracy: 0.7390\n",
            "Epoch 93/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6170 - accuracy: 0.7525 - val_loss: 0.6537 - val_accuracy: 0.7132\n",
            "Epoch 94/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6017 - accuracy: 0.7401 - val_loss: 0.6017 - val_accuracy: 0.7279\n",
            "Epoch 95/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6111 - accuracy: 0.7543 - val_loss: 0.6236 - val_accuracy: 0.7243\n",
            "Epoch 96/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6141 - accuracy: 0.7469 - val_loss: 0.6349 - val_accuracy: 0.7132\n",
            "Epoch 97/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6154 - accuracy: 0.7333 - val_loss: 0.6901 - val_accuracy: 0.6691\n",
            "Epoch 98/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6009 - accuracy: 0.7389 - val_loss: 0.5970 - val_accuracy: 0.7463\n",
            "Epoch 99/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6070 - accuracy: 0.7531 - val_loss: 0.6941 - val_accuracy: 0.6985\n",
            "Epoch 100/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5908 - accuracy: 0.7469 - val_loss: 0.6275 - val_accuracy: 0.7279\n",
            "Epoch 101/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6057 - accuracy: 0.7444 - val_loss: 0.6335 - val_accuracy: 0.7132\n",
            "Epoch 102/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5930 - accuracy: 0.7444 - val_loss: 0.5459 - val_accuracy: 0.7647\n",
            "Epoch 103/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5914 - accuracy: 0.7500 - val_loss: 0.5900 - val_accuracy: 0.7537\n",
            "Epoch 104/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5885 - accuracy: 0.7642 - val_loss: 0.6360 - val_accuracy: 0.7206\n",
            "Epoch 105/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5912 - accuracy: 0.7531 - val_loss: 0.6740 - val_accuracy: 0.7096\n",
            "Epoch 106/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5999 - accuracy: 0.7512 - val_loss: 0.6275 - val_accuracy: 0.7206\n",
            "Epoch 107/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5980 - accuracy: 0.7587 - val_loss: 0.5764 - val_accuracy: 0.7426\n",
            "Epoch 108/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6057 - accuracy: 0.7506 - val_loss: 0.6364 - val_accuracy: 0.7206\n",
            "Epoch 109/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5866 - accuracy: 0.7624 - val_loss: 0.6588 - val_accuracy: 0.7316\n",
            "Epoch 110/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5808 - accuracy: 0.7537 - val_loss: 0.5651 - val_accuracy: 0.7537\n",
            "Epoch 111/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5847 - accuracy: 0.7642 - val_loss: 0.6381 - val_accuracy: 0.7132\n",
            "Epoch 112/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5948 - accuracy: 0.7717 - val_loss: 0.5698 - val_accuracy: 0.7647\n",
            "Epoch 113/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6001 - accuracy: 0.7519 - val_loss: 0.5707 - val_accuracy: 0.7500\n",
            "Epoch 114/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5904 - accuracy: 0.7655 - val_loss: 0.6334 - val_accuracy: 0.7132\n",
            "Epoch 115/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5884 - accuracy: 0.7667 - val_loss: 0.6064 - val_accuracy: 0.7426\n",
            "Epoch 116/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5872 - accuracy: 0.7630 - val_loss: 0.6334 - val_accuracy: 0.7206\n",
            "Epoch 117/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5567 - accuracy: 0.7704 - val_loss: 0.5626 - val_accuracy: 0.7721\n",
            "Epoch 118/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5873 - accuracy: 0.7599 - val_loss: 0.6101 - val_accuracy: 0.7279\n",
            "Epoch 119/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5727 - accuracy: 0.7735 - val_loss: 0.5468 - val_accuracy: 0.7684\n",
            "Epoch 120/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6028 - accuracy: 0.7531 - val_loss: 0.5381 - val_accuracy: 0.7794\n",
            "Epoch 121/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5786 - accuracy: 0.7537 - val_loss: 0.6522 - val_accuracy: 0.6912\n",
            "Epoch 122/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5808 - accuracy: 0.7580 - val_loss: 0.5995 - val_accuracy: 0.7390\n",
            "Epoch 123/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5608 - accuracy: 0.7673 - val_loss: 0.6456 - val_accuracy: 0.7022\n",
            "Epoch 124/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5949 - accuracy: 0.7500 - val_loss: 0.5961 - val_accuracy: 0.7132\n",
            "Epoch 125/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5755 - accuracy: 0.7655 - val_loss: 0.5925 - val_accuracy: 0.7463\n",
            "Epoch 126/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5807 - accuracy: 0.7593 - val_loss: 0.5972 - val_accuracy: 0.7353\n",
            "Epoch 127/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5724 - accuracy: 0.7661 - val_loss: 0.5713 - val_accuracy: 0.7500\n",
            "Epoch 128/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5649 - accuracy: 0.7729 - val_loss: 0.5636 - val_accuracy: 0.7610\n",
            "Epoch 129/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5539 - accuracy: 0.7933 - val_loss: 0.5871 - val_accuracy: 0.7537\n",
            "Epoch 130/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5813 - accuracy: 0.7593 - val_loss: 0.5660 - val_accuracy: 0.7574\n",
            "Epoch 131/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5834 - accuracy: 0.7438 - val_loss: 0.5730 - val_accuracy: 0.7610\n",
            "Epoch 132/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5760 - accuracy: 0.7673 - val_loss: 0.5299 - val_accuracy: 0.7868\n",
            "Epoch 133/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5450 - accuracy: 0.7828 - val_loss: 0.5942 - val_accuracy: 0.7500\n",
            "Epoch 134/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5755 - accuracy: 0.7760 - val_loss: 0.6569 - val_accuracy: 0.7059\n",
            "Epoch 135/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5650 - accuracy: 0.7661 - val_loss: 0.5880 - val_accuracy: 0.7390\n",
            "Epoch 136/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5608 - accuracy: 0.7717 - val_loss: 0.5826 - val_accuracy: 0.7721\n",
            "Epoch 137/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5542 - accuracy: 0.7710 - val_loss: 0.6010 - val_accuracy: 0.7316\n",
            "Epoch 138/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5546 - accuracy: 0.7785 - val_loss: 0.5634 - val_accuracy: 0.7537\n",
            "Epoch 139/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5532 - accuracy: 0.7822 - val_loss: 0.5719 - val_accuracy: 0.7279\n",
            "Epoch 140/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5482 - accuracy: 0.7785 - val_loss: 0.5374 - val_accuracy: 0.7721\n",
            "Epoch 141/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5637 - accuracy: 0.7729 - val_loss: 0.5937 - val_accuracy: 0.7390\n",
            "Epoch 142/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5529 - accuracy: 0.7686 - val_loss: 0.5534 - val_accuracy: 0.7610\n",
            "Epoch 143/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5567 - accuracy: 0.7618 - val_loss: 0.5914 - val_accuracy: 0.7316\n",
            "Epoch 144/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5538 - accuracy: 0.7655 - val_loss: 0.5815 - val_accuracy: 0.7500\n",
            "Epoch 145/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5765 - accuracy: 0.7692 - val_loss: 0.5977 - val_accuracy: 0.7279\n",
            "Epoch 146/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5471 - accuracy: 0.7809 - val_loss: 0.5588 - val_accuracy: 0.7463\n",
            "Epoch 147/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5479 - accuracy: 0.7902 - val_loss: 0.5528 - val_accuracy: 0.7574\n",
            "Epoch 148/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5449 - accuracy: 0.7729 - val_loss: 0.5561 - val_accuracy: 0.7721\n",
            "Epoch 149/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5574 - accuracy: 0.7717 - val_loss: 0.5434 - val_accuracy: 0.7647\n",
            "Epoch 150/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5345 - accuracy: 0.7840 - val_loss: 0.5251 - val_accuracy: 0.7868\n",
            "Epoch 151/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5490 - accuracy: 0.7717 - val_loss: 0.5525 - val_accuracy: 0.7610\n",
            "Epoch 152/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5510 - accuracy: 0.7766 - val_loss: 0.6094 - val_accuracy: 0.7574\n",
            "Epoch 153/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5425 - accuracy: 0.7840 - val_loss: 0.5598 - val_accuracy: 0.7757\n",
            "Epoch 154/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5551 - accuracy: 0.7834 - val_loss: 0.5199 - val_accuracy: 0.7794\n",
            "Epoch 155/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5467 - accuracy: 0.7859 - val_loss: 0.5573 - val_accuracy: 0.7647\n",
            "Epoch 156/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5252 - accuracy: 0.7865 - val_loss: 0.5283 - val_accuracy: 0.7684\n",
            "Epoch 157/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5395 - accuracy: 0.7853 - val_loss: 0.5479 - val_accuracy: 0.7610\n",
            "Epoch 158/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5377 - accuracy: 0.7847 - val_loss: 0.5804 - val_accuracy: 0.7500\n",
            "Epoch 159/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5428 - accuracy: 0.7828 - val_loss: 0.5708 - val_accuracy: 0.7463\n",
            "Epoch 160/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5435 - accuracy: 0.7840 - val_loss: 0.5316 - val_accuracy: 0.7794\n",
            "Epoch 161/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5502 - accuracy: 0.7741 - val_loss: 0.5472 - val_accuracy: 0.7647\n",
            "Epoch 162/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5386 - accuracy: 0.7772 - val_loss: 0.5353 - val_accuracy: 0.7941\n",
            "Epoch 163/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5615 - accuracy: 0.7766 - val_loss: 0.5444 - val_accuracy: 0.7868\n",
            "Epoch 164/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5378 - accuracy: 0.7859 - val_loss: 0.5290 - val_accuracy: 0.7721\n",
            "Epoch 165/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5463 - accuracy: 0.7890 - val_loss: 0.5600 - val_accuracy: 0.7537\n",
            "Epoch 166/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5468 - accuracy: 0.7785 - val_loss: 0.5626 - val_accuracy: 0.7610\n",
            "Epoch 167/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5175 - accuracy: 0.7902 - val_loss: 0.5465 - val_accuracy: 0.7647\n",
            "Epoch 168/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5343 - accuracy: 0.7816 - val_loss: 0.5870 - val_accuracy: 0.7610\n",
            "Epoch 169/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5344 - accuracy: 0.7921 - val_loss: 0.6018 - val_accuracy: 0.7390\n",
            "Epoch 170/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5539 - accuracy: 0.7760 - val_loss: 0.5609 - val_accuracy: 0.7610\n",
            "Epoch 171/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5060 - accuracy: 0.8088 - val_loss: 0.5348 - val_accuracy: 0.7684\n",
            "Epoch 172/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5388 - accuracy: 0.7902 - val_loss: 0.6050 - val_accuracy: 0.7316\n",
            "Epoch 173/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5335 - accuracy: 0.7816 - val_loss: 0.5739 - val_accuracy: 0.7500\n",
            "Epoch 174/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5298 - accuracy: 0.7927 - val_loss: 0.5554 - val_accuracy: 0.7610\n",
            "Epoch 175/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5480 - accuracy: 0.7847 - val_loss: 0.5618 - val_accuracy: 0.7500\n",
            "Epoch 176/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5239 - accuracy: 0.7902 - val_loss: 0.5560 - val_accuracy: 0.7794\n",
            "Epoch 177/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5489 - accuracy: 0.7748 - val_loss: 0.5729 - val_accuracy: 0.7574\n",
            "Epoch 178/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5286 - accuracy: 0.7877 - val_loss: 0.5220 - val_accuracy: 0.7868\n",
            "Epoch 179/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5474 - accuracy: 0.7803 - val_loss: 0.5490 - val_accuracy: 0.7721\n",
            "Epoch 180/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5357 - accuracy: 0.7847 - val_loss: 0.5667 - val_accuracy: 0.7574\n",
            "Epoch 181/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5415 - accuracy: 0.7853 - val_loss: 0.5289 - val_accuracy: 0.7831\n",
            "Epoch 182/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5339 - accuracy: 0.7970 - val_loss: 0.5216 - val_accuracy: 0.7831\n",
            "Epoch 183/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5253 - accuracy: 0.7927 - val_loss: 0.5307 - val_accuracy: 0.7831\n",
            "Epoch 184/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5340 - accuracy: 0.8001 - val_loss: 0.5401 - val_accuracy: 0.7721\n",
            "Epoch 185/500\n",
            "202/202 [==============================] - 6s 32ms/step - loss: 0.5200 - accuracy: 0.8020 - val_loss: 0.5404 - val_accuracy: 0.7794\n",
            "Epoch 186/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5288 - accuracy: 0.7840 - val_loss: 0.5531 - val_accuracy: 0.7794\n",
            "Epoch 187/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5369 - accuracy: 0.7853 - val_loss: 0.5662 - val_accuracy: 0.7647\n",
            "Epoch 188/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5158 - accuracy: 0.8119 - val_loss: 0.5387 - val_accuracy: 0.7831\n",
            "Epoch 189/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5199 - accuracy: 0.7915 - val_loss: 0.5195 - val_accuracy: 0.7721\n",
            "Epoch 190/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5170 - accuracy: 0.8032 - val_loss: 0.4973 - val_accuracy: 0.7978\n",
            "Epoch 191/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5225 - accuracy: 0.7939 - val_loss: 0.5588 - val_accuracy: 0.7574\n",
            "Epoch 192/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5442 - accuracy: 0.7853 - val_loss: 0.5210 - val_accuracy: 0.7831\n",
            "Epoch 193/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5136 - accuracy: 0.8075 - val_loss: 0.5774 - val_accuracy: 0.7500\n",
            "Epoch 194/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5304 - accuracy: 0.7865 - val_loss: 0.5818 - val_accuracy: 0.7500\n",
            "Epoch 195/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5311 - accuracy: 0.7865 - val_loss: 0.6090 - val_accuracy: 0.7316\n",
            "Epoch 196/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5165 - accuracy: 0.7958 - val_loss: 0.5615 - val_accuracy: 0.7500\n",
            "Epoch 197/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5193 - accuracy: 0.7983 - val_loss: 0.5607 - val_accuracy: 0.7684\n",
            "Epoch 198/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5132 - accuracy: 0.8001 - val_loss: 0.5415 - val_accuracy: 0.7610\n",
            "Epoch 199/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5186 - accuracy: 0.8007 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
            "Epoch 200/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4858 - accuracy: 0.8075 - val_loss: 0.5395 - val_accuracy: 0.7610\n",
            "Epoch 201/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5232 - accuracy: 0.7908 - val_loss: 0.5299 - val_accuracy: 0.7721\n",
            "Epoch 202/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5181 - accuracy: 0.7964 - val_loss: 0.6114 - val_accuracy: 0.7059\n",
            "Epoch 203/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5577 - accuracy: 0.7809 - val_loss: 0.5340 - val_accuracy: 0.7721\n",
            "Epoch 204/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5013 - accuracy: 0.7964 - val_loss: 0.5287 - val_accuracy: 0.7610\n",
            "Epoch 205/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5018 - accuracy: 0.8069 - val_loss: 0.5407 - val_accuracy: 0.7868\n",
            "Epoch 206/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5073 - accuracy: 0.8137 - val_loss: 0.5406 - val_accuracy: 0.7831\n",
            "Epoch 207/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5332 - accuracy: 0.7840 - val_loss: 0.5357 - val_accuracy: 0.7757\n",
            "Epoch 208/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5079 - accuracy: 0.7890 - val_loss: 0.5138 - val_accuracy: 0.7831\n",
            "Epoch 209/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5290 - accuracy: 0.7877 - val_loss: 0.5300 - val_accuracy: 0.7537\n",
            "Epoch 210/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5069 - accuracy: 0.7946 - val_loss: 0.5380 - val_accuracy: 0.7610\n",
            "Epoch 211/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5284 - accuracy: 0.7983 - val_loss: 0.5385 - val_accuracy: 0.7721\n",
            "Epoch 212/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5195 - accuracy: 0.7995 - val_loss: 0.5730 - val_accuracy: 0.7500\n",
            "Epoch 213/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5142 - accuracy: 0.8094 - val_loss: 0.6290 - val_accuracy: 0.7096\n",
            "Epoch 214/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5278 - accuracy: 0.7896 - val_loss: 0.5573 - val_accuracy: 0.7574\n",
            "Epoch 215/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5351 - accuracy: 0.7983 - val_loss: 0.5791 - val_accuracy: 0.7463\n",
            "Epoch 216/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5352 - accuracy: 0.7902 - val_loss: 0.5793 - val_accuracy: 0.7574\n",
            "Epoch 217/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5126 - accuracy: 0.7976 - val_loss: 0.5246 - val_accuracy: 0.7647\n",
            "Epoch 218/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5071 - accuracy: 0.7964 - val_loss: 0.5169 - val_accuracy: 0.7757\n",
            "Epoch 219/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5244 - accuracy: 0.7946 - val_loss: 0.5192 - val_accuracy: 0.7831\n",
            "Epoch 220/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5170 - accuracy: 0.7970 - val_loss: 0.5756 - val_accuracy: 0.7757\n",
            "Epoch 221/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5188 - accuracy: 0.7927 - val_loss: 0.5244 - val_accuracy: 0.7831\n",
            "Epoch 222/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4978 - accuracy: 0.8131 - val_loss: 0.5640 - val_accuracy: 0.7500\n",
            "Epoch 223/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5126 - accuracy: 0.7952 - val_loss: 0.5518 - val_accuracy: 0.7537\n",
            "Epoch 224/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5316 - accuracy: 0.7933 - val_loss: 0.5465 - val_accuracy: 0.7868\n",
            "Epoch 225/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5075 - accuracy: 0.8131 - val_loss: 0.4984 - val_accuracy: 0.8088\n",
            "Epoch 226/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5243 - accuracy: 0.7847 - val_loss: 0.5456 - val_accuracy: 0.7574\n",
            "Epoch 227/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5264 - accuracy: 0.7958 - val_loss: 0.5235 - val_accuracy: 0.7831\n",
            "Epoch 228/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5167 - accuracy: 0.8038 - val_loss: 0.5352 - val_accuracy: 0.7684\n",
            "Epoch 229/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5117 - accuracy: 0.8063 - val_loss: 0.5367 - val_accuracy: 0.7647\n",
            "Epoch 230/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5165 - accuracy: 0.7939 - val_loss: 0.5291 - val_accuracy: 0.7794\n",
            "Epoch 231/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5151 - accuracy: 0.7964 - val_loss: 0.5578 - val_accuracy: 0.7684\n",
            "Epoch 232/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5293 - accuracy: 0.7964 - val_loss: 0.5553 - val_accuracy: 0.7868\n",
            "Epoch 233/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5134 - accuracy: 0.8007 - val_loss: 0.5335 - val_accuracy: 0.7610\n",
            "Epoch 234/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5092 - accuracy: 0.7995 - val_loss: 0.5364 - val_accuracy: 0.7647\n",
            "Epoch 235/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5009 - accuracy: 0.8057 - val_loss: 0.5422 - val_accuracy: 0.7610\n",
            "Epoch 236/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4916 - accuracy: 0.8131 - val_loss: 0.5133 - val_accuracy: 0.7831\n",
            "Epoch 237/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5085 - accuracy: 0.8020 - val_loss: 0.5226 - val_accuracy: 0.7941\n",
            "Epoch 238/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5319 - accuracy: 0.7989 - val_loss: 0.5345 - val_accuracy: 0.7610\n",
            "Epoch 239/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5017 - accuracy: 0.8119 - val_loss: 0.5443 - val_accuracy: 0.7647\n",
            "Epoch 240/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5082 - accuracy: 0.8026 - val_loss: 0.5607 - val_accuracy: 0.7500\n",
            "Epoch 241/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5127 - accuracy: 0.8014 - val_loss: 0.5231 - val_accuracy: 0.7794\n",
            "Epoch 242/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4931 - accuracy: 0.8125 - val_loss: 0.5120 - val_accuracy: 0.7794\n",
            "Epoch 243/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4940 - accuracy: 0.8131 - val_loss: 0.5252 - val_accuracy: 0.7647\n",
            "Epoch 244/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4890 - accuracy: 0.8131 - val_loss: 0.5135 - val_accuracy: 0.7794\n",
            "Epoch 245/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4938 - accuracy: 0.8057 - val_loss: 0.5389 - val_accuracy: 0.7721\n",
            "Epoch 246/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4904 - accuracy: 0.8026 - val_loss: 0.5398 - val_accuracy: 0.7647\n",
            "Epoch 247/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5161 - accuracy: 0.7964 - val_loss: 0.5139 - val_accuracy: 0.7647\n",
            "Epoch 248/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4871 - accuracy: 0.8007 - val_loss: 0.5094 - val_accuracy: 0.7904\n",
            "Epoch 249/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5029 - accuracy: 0.8051 - val_loss: 0.5499 - val_accuracy: 0.7684\n",
            "Epoch 250/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5161 - accuracy: 0.8094 - val_loss: 0.5656 - val_accuracy: 0.7647\n",
            "Epoch 251/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5113 - accuracy: 0.7989 - val_loss: 0.5239 - val_accuracy: 0.7831\n",
            "Epoch 252/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5086 - accuracy: 0.8075 - val_loss: 0.5306 - val_accuracy: 0.7794\n",
            "Epoch 253/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4877 - accuracy: 0.8187 - val_loss: 0.5316 - val_accuracy: 0.7831\n",
            "Epoch 254/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5091 - accuracy: 0.7995 - val_loss: 0.5389 - val_accuracy: 0.7868\n",
            "Epoch 255/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5043 - accuracy: 0.8007 - val_loss: 0.5385 - val_accuracy: 0.7574\n",
            "Epoch 256/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5216 - accuracy: 0.7989 - val_loss: 0.5084 - val_accuracy: 0.7904\n",
            "Epoch 257/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4999 - accuracy: 0.8088 - val_loss: 0.5606 - val_accuracy: 0.7794\n",
            "Epoch 258/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4876 - accuracy: 0.8150 - val_loss: 0.5572 - val_accuracy: 0.7684\n",
            "Epoch 259/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4945 - accuracy: 0.8075 - val_loss: 0.5586 - val_accuracy: 0.7757\n",
            "Epoch 260/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4858 - accuracy: 0.8205 - val_loss: 0.5622 - val_accuracy: 0.7610\n",
            "Epoch 261/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5003 - accuracy: 0.8051 - val_loss: 0.5477 - val_accuracy: 0.7610\n",
            "Epoch 262/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4849 - accuracy: 0.8094 - val_loss: 0.5481 - val_accuracy: 0.7647\n",
            "Epoch 263/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5038 - accuracy: 0.8150 - val_loss: 0.5313 - val_accuracy: 0.7757\n",
            "Epoch 264/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5040 - accuracy: 0.8001 - val_loss: 0.5422 - val_accuracy: 0.7721\n",
            "Epoch 265/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5089 - accuracy: 0.8063 - val_loss: 0.5485 - val_accuracy: 0.7757\n",
            "Epoch 266/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5237 - accuracy: 0.7989 - val_loss: 0.5061 - val_accuracy: 0.7868\n",
            "Epoch 267/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4878 - accuracy: 0.8131 - val_loss: 0.5457 - val_accuracy: 0.7574\n",
            "Epoch 268/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5137 - accuracy: 0.8007 - val_loss: 0.5614 - val_accuracy: 0.7684\n",
            "Epoch 269/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4876 - accuracy: 0.8168 - val_loss: 0.5332 - val_accuracy: 0.7868\n",
            "Epoch 270/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4912 - accuracy: 0.8168 - val_loss: 0.5203 - val_accuracy: 0.7757\n",
            "Epoch 271/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4864 - accuracy: 0.8218 - val_loss: 0.5142 - val_accuracy: 0.7794\n",
            "Epoch 272/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5077 - accuracy: 0.8125 - val_loss: 0.5467 - val_accuracy: 0.7574\n",
            "Epoch 273/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4866 - accuracy: 0.8150 - val_loss: 0.5328 - val_accuracy: 0.7721\n",
            "Epoch 274/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4818 - accuracy: 0.8175 - val_loss: 0.5368 - val_accuracy: 0.7684\n",
            "Epoch 275/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5101 - accuracy: 0.8106 - val_loss: 0.5284 - val_accuracy: 0.7794\n",
            "Epoch 276/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4739 - accuracy: 0.8230 - val_loss: 0.5324 - val_accuracy: 0.7610\n",
            "Epoch 277/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5052 - accuracy: 0.7976 - val_loss: 0.5629 - val_accuracy: 0.7500\n",
            "Epoch 278/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4892 - accuracy: 0.8113 - val_loss: 0.5502 - val_accuracy: 0.7574\n",
            "Epoch 279/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4702 - accuracy: 0.8199 - val_loss: 0.5596 - val_accuracy: 0.7390\n",
            "Epoch 280/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4833 - accuracy: 0.8137 - val_loss: 0.5198 - val_accuracy: 0.7831\n",
            "Epoch 281/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4818 - accuracy: 0.8020 - val_loss: 0.5446 - val_accuracy: 0.7794\n",
            "Epoch 282/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4785 - accuracy: 0.8150 - val_loss: 0.5462 - val_accuracy: 0.7647\n",
            "Epoch 283/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4921 - accuracy: 0.8137 - val_loss: 0.5585 - val_accuracy: 0.7721\n",
            "Epoch 284/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4899 - accuracy: 0.8261 - val_loss: 0.5402 - val_accuracy: 0.7684\n",
            "Epoch 285/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4956 - accuracy: 0.8181 - val_loss: 0.5245 - val_accuracy: 0.7757\n",
            "Epoch 286/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4924 - accuracy: 0.8094 - val_loss: 0.5582 - val_accuracy: 0.7574\n",
            "Epoch 287/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4834 - accuracy: 0.8162 - val_loss: 0.5363 - val_accuracy: 0.7831\n",
            "Epoch 288/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5009 - accuracy: 0.8063 - val_loss: 0.5434 - val_accuracy: 0.7574\n",
            "Epoch 289/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4949 - accuracy: 0.8038 - val_loss: 0.5334 - val_accuracy: 0.7684\n",
            "Epoch 290/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5032 - accuracy: 0.8125 - val_loss: 0.6342 - val_accuracy: 0.7353\n",
            "Epoch 291/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4934 - accuracy: 0.8020 - val_loss: 0.5249 - val_accuracy: 0.7831\n",
            "Epoch 292/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4835 - accuracy: 0.8106 - val_loss: 0.5480 - val_accuracy: 0.7574\n",
            "Epoch 293/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4771 - accuracy: 0.8113 - val_loss: 0.5206 - val_accuracy: 0.7684\n",
            "Epoch 294/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4814 - accuracy: 0.8137 - val_loss: 0.5150 - val_accuracy: 0.7794\n",
            "Epoch 295/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4835 - accuracy: 0.8156 - val_loss: 0.5556 - val_accuracy: 0.7537\n",
            "Epoch 296/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4804 - accuracy: 0.8199 - val_loss: 0.5224 - val_accuracy: 0.7721\n",
            "Epoch 297/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4911 - accuracy: 0.8156 - val_loss: 0.5286 - val_accuracy: 0.7647\n",
            "Epoch 298/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4849 - accuracy: 0.8162 - val_loss: 0.5530 - val_accuracy: 0.7757\n",
            "Epoch 299/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5071 - accuracy: 0.7958 - val_loss: 0.5176 - val_accuracy: 0.7831\n",
            "Epoch 300/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5085 - accuracy: 0.8075 - val_loss: 0.5682 - val_accuracy: 0.7537\n",
            "Epoch 301/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4835 - accuracy: 0.8119 - val_loss: 0.5522 - val_accuracy: 0.7610\n",
            "Epoch 302/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4907 - accuracy: 0.8113 - val_loss: 0.5349 - val_accuracy: 0.7721\n",
            "Epoch 303/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4886 - accuracy: 0.8094 - val_loss: 0.5344 - val_accuracy: 0.7610\n",
            "Epoch 304/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4838 - accuracy: 0.8218 - val_loss: 0.5495 - val_accuracy: 0.7574\n",
            "Epoch 305/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4801 - accuracy: 0.8286 - val_loss: 0.5152 - val_accuracy: 0.7831\n",
            "Epoch 306/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5011 - accuracy: 0.8038 - val_loss: 0.5640 - val_accuracy: 0.7647\n",
            "Epoch 307/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4906 - accuracy: 0.8181 - val_loss: 0.5310 - val_accuracy: 0.7904\n",
            "Epoch 308/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4814 - accuracy: 0.8150 - val_loss: 0.5288 - val_accuracy: 0.7647\n",
            "Epoch 309/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4902 - accuracy: 0.8131 - val_loss: 0.5339 - val_accuracy: 0.7574\n",
            "Epoch 310/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4912 - accuracy: 0.8113 - val_loss: 0.5360 - val_accuracy: 0.7757\n",
            "Epoch 311/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5008 - accuracy: 0.8082 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
            "Epoch 312/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4805 - accuracy: 0.8162 - val_loss: 0.5543 - val_accuracy: 0.7610\n",
            "Epoch 313/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4822 - accuracy: 0.8168 - val_loss: 0.5445 - val_accuracy: 0.7610\n",
            "Epoch 314/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4792 - accuracy: 0.8106 - val_loss: 0.5327 - val_accuracy: 0.7721\n",
            "Epoch 315/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4620 - accuracy: 0.8156 - val_loss: 0.5347 - val_accuracy: 0.7647\n",
            "Epoch 316/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4822 - accuracy: 0.8187 - val_loss: 0.5160 - val_accuracy: 0.7831\n",
            "Epoch 317/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4769 - accuracy: 0.8156 - val_loss: 0.5250 - val_accuracy: 0.7757\n",
            "Epoch 318/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4777 - accuracy: 0.8193 - val_loss: 0.5191 - val_accuracy: 0.7794\n",
            "Epoch 319/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4796 - accuracy: 0.8205 - val_loss: 0.5101 - val_accuracy: 0.7794\n",
            "Epoch 320/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4849 - accuracy: 0.8187 - val_loss: 0.5233 - val_accuracy: 0.7831\n",
            "Epoch 321/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4845 - accuracy: 0.8150 - val_loss: 0.5128 - val_accuracy: 0.7868\n",
            "Epoch 322/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4956 - accuracy: 0.8137 - val_loss: 0.5064 - val_accuracy: 0.7831\n",
            "Epoch 323/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4725 - accuracy: 0.8212 - val_loss: 0.5543 - val_accuracy: 0.7574\n",
            "Epoch 324/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4811 - accuracy: 0.8069 - val_loss: 0.5222 - val_accuracy: 0.7721\n",
            "Epoch 325/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4987 - accuracy: 0.8045 - val_loss: 0.5581 - val_accuracy: 0.7794\n",
            "Epoch 326/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4783 - accuracy: 0.8212 - val_loss: 0.5261 - val_accuracy: 0.7868\n",
            "Epoch 327/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4967 - accuracy: 0.8113 - val_loss: 0.5303 - val_accuracy: 0.7390\n",
            "Epoch 328/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4863 - accuracy: 0.8144 - val_loss: 0.5453 - val_accuracy: 0.7463\n",
            "Epoch 329/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5024 - accuracy: 0.8212 - val_loss: 0.5597 - val_accuracy: 0.7500\n",
            "Epoch 330/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5016 - accuracy: 0.8063 - val_loss: 0.5274 - val_accuracy: 0.7794\n",
            "Epoch 331/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4844 - accuracy: 0.8137 - val_loss: 0.5365 - val_accuracy: 0.7868\n",
            "Epoch 332/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4872 - accuracy: 0.8144 - val_loss: 0.5474 - val_accuracy: 0.7647\n",
            "Epoch 333/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4839 - accuracy: 0.8119 - val_loss: 0.5275 - val_accuracy: 0.7721\n",
            "Epoch 334/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4855 - accuracy: 0.8168 - val_loss: 0.5272 - val_accuracy: 0.7831\n",
            "Epoch 335/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4730 - accuracy: 0.8137 - val_loss: 0.5219 - val_accuracy: 0.7868\n",
            "Epoch 336/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4744 - accuracy: 0.8298 - val_loss: 0.5027 - val_accuracy: 0.7868\n",
            "Epoch 337/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4803 - accuracy: 0.8175 - val_loss: 0.5394 - val_accuracy: 0.7794\n",
            "Epoch 338/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4846 - accuracy: 0.8119 - val_loss: 0.5329 - val_accuracy: 0.7757\n",
            "Epoch 339/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4608 - accuracy: 0.8230 - val_loss: 0.5306 - val_accuracy: 0.7757\n",
            "Epoch 340/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4710 - accuracy: 0.8175 - val_loss: 0.5179 - val_accuracy: 0.7757\n",
            "Epoch 341/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4683 - accuracy: 0.8236 - val_loss: 0.5045 - val_accuracy: 0.7831\n",
            "Epoch 342/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4711 - accuracy: 0.8100 - val_loss: 0.5125 - val_accuracy: 0.7721\n",
            "Epoch 343/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4914 - accuracy: 0.8100 - val_loss: 0.5244 - val_accuracy: 0.7757\n",
            "Epoch 344/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4792 - accuracy: 0.8286 - val_loss: 0.5459 - val_accuracy: 0.7537\n",
            "Epoch 345/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4761 - accuracy: 0.8156 - val_loss: 0.5394 - val_accuracy: 0.7684\n",
            "Epoch 346/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4610 - accuracy: 0.8199 - val_loss: 0.5194 - val_accuracy: 0.7868\n",
            "Epoch 347/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4560 - accuracy: 0.8342 - val_loss: 0.5166 - val_accuracy: 0.7831\n",
            "Epoch 348/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4757 - accuracy: 0.8162 - val_loss: 0.5397 - val_accuracy: 0.7721\n",
            "Epoch 349/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4809 - accuracy: 0.8212 - val_loss: 0.5462 - val_accuracy: 0.7610\n",
            "Epoch 350/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5029 - accuracy: 0.8100 - val_loss: 0.5210 - val_accuracy: 0.7757\n",
            "Epoch 351/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4763 - accuracy: 0.8106 - val_loss: 0.5280 - val_accuracy: 0.7794\n",
            "Epoch 352/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4767 - accuracy: 0.8150 - val_loss: 0.5334 - val_accuracy: 0.7684\n",
            "Epoch 353/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4759 - accuracy: 0.8175 - val_loss: 0.5055 - val_accuracy: 0.7831\n",
            "Epoch 354/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4782 - accuracy: 0.8069 - val_loss: 0.5188 - val_accuracy: 0.7721\n",
            "Epoch 355/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4693 - accuracy: 0.8323 - val_loss: 0.5126 - val_accuracy: 0.7868\n",
            "Epoch 356/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4871 - accuracy: 0.8131 - val_loss: 0.5267 - val_accuracy: 0.7794\n",
            "Epoch 357/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4837 - accuracy: 0.8144 - val_loss: 0.5404 - val_accuracy: 0.7610\n",
            "Epoch 358/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4781 - accuracy: 0.8193 - val_loss: 0.5386 - val_accuracy: 0.7721\n",
            "Epoch 359/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4868 - accuracy: 0.8156 - val_loss: 0.5242 - val_accuracy: 0.7610\n",
            "Epoch 360/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4818 - accuracy: 0.8292 - val_loss: 0.5465 - val_accuracy: 0.7757\n",
            "Epoch 361/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4873 - accuracy: 0.8243 - val_loss: 0.5357 - val_accuracy: 0.7757\n",
            "Epoch 362/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4786 - accuracy: 0.8218 - val_loss: 0.5539 - val_accuracy: 0.7537\n",
            "Epoch 363/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4866 - accuracy: 0.8218 - val_loss: 0.5695 - val_accuracy: 0.7537\n",
            "Epoch 364/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4767 - accuracy: 0.8255 - val_loss: 0.5443 - val_accuracy: 0.7390\n",
            "Epoch 365/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4716 - accuracy: 0.8038 - val_loss: 0.5328 - val_accuracy: 0.7831\n",
            "Epoch 366/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4884 - accuracy: 0.8199 - val_loss: 0.5428 - val_accuracy: 0.7684\n",
            "Epoch 367/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4616 - accuracy: 0.8193 - val_loss: 0.5336 - val_accuracy: 0.7647\n",
            "Epoch 368/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4915 - accuracy: 0.8193 - val_loss: 0.5324 - val_accuracy: 0.7721\n",
            "Epoch 369/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4606 - accuracy: 0.8199 - val_loss: 0.5359 - val_accuracy: 0.7757\n",
            "Epoch 370/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4824 - accuracy: 0.8175 - val_loss: 0.5408 - val_accuracy: 0.7757\n",
            "Epoch 371/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4492 - accuracy: 0.8329 - val_loss: 0.5088 - val_accuracy: 0.7904\n",
            "Epoch 372/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4754 - accuracy: 0.8230 - val_loss: 0.5506 - val_accuracy: 0.7647\n",
            "Epoch 373/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4831 - accuracy: 0.8075 - val_loss: 0.5078 - val_accuracy: 0.7904\n",
            "Epoch 374/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4864 - accuracy: 0.8137 - val_loss: 0.5372 - val_accuracy: 0.7757\n",
            "Epoch 375/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4797 - accuracy: 0.8243 - val_loss: 0.5443 - val_accuracy: 0.7647\n",
            "Epoch 376/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4741 - accuracy: 0.8144 - val_loss: 0.5372 - val_accuracy: 0.7757\n",
            "Epoch 377/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4596 - accuracy: 0.8292 - val_loss: 0.5227 - val_accuracy: 0.7831\n",
            "Epoch 378/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4732 - accuracy: 0.8243 - val_loss: 0.5446 - val_accuracy: 0.7647\n",
            "Epoch 379/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4873 - accuracy: 0.8199 - val_loss: 0.5338 - val_accuracy: 0.7721\n",
            "Epoch 380/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4720 - accuracy: 0.8063 - val_loss: 0.5441 - val_accuracy: 0.7721\n",
            "Epoch 381/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4571 - accuracy: 0.8168 - val_loss: 0.5587 - val_accuracy: 0.7610\n",
            "Epoch 382/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4543 - accuracy: 0.8267 - val_loss: 0.5391 - val_accuracy: 0.7647\n",
            "Epoch 383/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4638 - accuracy: 0.8274 - val_loss: 0.5259 - val_accuracy: 0.7794\n",
            "Epoch 384/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4799 - accuracy: 0.8181 - val_loss: 0.5511 - val_accuracy: 0.7316\n",
            "Epoch 385/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4881 - accuracy: 0.8212 - val_loss: 0.5440 - val_accuracy: 0.7390\n",
            "Epoch 386/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4420 - accuracy: 0.8292 - val_loss: 0.5442 - val_accuracy: 0.7721\n",
            "Epoch 387/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4510 - accuracy: 0.8311 - val_loss: 0.5363 - val_accuracy: 0.7794\n",
            "Epoch 388/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4778 - accuracy: 0.8255 - val_loss: 0.5430 - val_accuracy: 0.7757\n",
            "Epoch 389/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4651 - accuracy: 0.8249 - val_loss: 0.5434 - val_accuracy: 0.7684\n",
            "Epoch 390/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4881 - accuracy: 0.8113 - val_loss: 0.5539 - val_accuracy: 0.7390\n",
            "Epoch 391/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4850 - accuracy: 0.8106 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
            "Epoch 392/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4593 - accuracy: 0.8311 - val_loss: 0.5470 - val_accuracy: 0.7463\n",
            "Epoch 393/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4823 - accuracy: 0.8168 - val_loss: 0.5310 - val_accuracy: 0.7721\n",
            "Epoch 394/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4794 - accuracy: 0.8230 - val_loss: 0.5263 - val_accuracy: 0.7757\n",
            "Epoch 395/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4632 - accuracy: 0.8249 - val_loss: 0.5412 - val_accuracy: 0.7757\n",
            "Epoch 396/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4804 - accuracy: 0.8175 - val_loss: 0.5454 - val_accuracy: 0.7721\n",
            "Epoch 397/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4506 - accuracy: 0.8243 - val_loss: 0.5392 - val_accuracy: 0.7794\n",
            "Epoch 398/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4667 - accuracy: 0.8187 - val_loss: 0.5582 - val_accuracy: 0.7610\n",
            "Epoch 399/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4730 - accuracy: 0.8342 - val_loss: 0.5081 - val_accuracy: 0.7904\n",
            "Epoch 400/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4612 - accuracy: 0.8373 - val_loss: 0.5307 - val_accuracy: 0.7757\n",
            "Epoch 401/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4620 - accuracy: 0.8317 - val_loss: 0.5427 - val_accuracy: 0.7684\n",
            "Epoch 402/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4695 - accuracy: 0.8230 - val_loss: 0.5415 - val_accuracy: 0.7684\n",
            "Epoch 403/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4719 - accuracy: 0.8199 - val_loss: 0.5247 - val_accuracy: 0.7868\n",
            "Epoch 404/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4783 - accuracy: 0.8181 - val_loss: 0.5262 - val_accuracy: 0.7794\n",
            "Epoch 405/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4532 - accuracy: 0.8292 - val_loss: 0.5236 - val_accuracy: 0.7757\n",
            "Epoch 406/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4690 - accuracy: 0.8304 - val_loss: 0.5253 - val_accuracy: 0.7831\n",
            "Epoch 407/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4688 - accuracy: 0.8218 - val_loss: 0.5403 - val_accuracy: 0.7757\n",
            "Epoch 408/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4689 - accuracy: 0.8267 - val_loss: 0.5316 - val_accuracy: 0.7757\n",
            "Epoch 409/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4605 - accuracy: 0.8311 - val_loss: 0.5489 - val_accuracy: 0.7757\n",
            "Epoch 410/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4713 - accuracy: 0.8162 - val_loss: 0.5508 - val_accuracy: 0.7647\n",
            "Epoch 411/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4707 - accuracy: 0.8212 - val_loss: 0.5645 - val_accuracy: 0.7279\n",
            "Epoch 412/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4753 - accuracy: 0.8236 - val_loss: 0.5497 - val_accuracy: 0.7279\n",
            "Epoch 413/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4575 - accuracy: 0.8323 - val_loss: 0.5531 - val_accuracy: 0.7500\n",
            "Epoch 414/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4664 - accuracy: 0.8125 - val_loss: 0.5485 - val_accuracy: 0.7463\n",
            "Epoch 415/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4713 - accuracy: 0.8187 - val_loss: 0.5275 - val_accuracy: 0.7721\n",
            "Epoch 416/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4731 - accuracy: 0.8175 - val_loss: 0.5426 - val_accuracy: 0.7390\n",
            "Epoch 417/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4552 - accuracy: 0.8261 - val_loss: 0.5480 - val_accuracy: 0.7647\n",
            "Epoch 418/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4917 - accuracy: 0.8088 - val_loss: 0.5405 - val_accuracy: 0.7721\n",
            "Epoch 419/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4599 - accuracy: 0.8329 - val_loss: 0.5358 - val_accuracy: 0.7684\n",
            "Epoch 420/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4504 - accuracy: 0.8329 - val_loss: 0.5562 - val_accuracy: 0.7647\n",
            "Epoch 421/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4807 - accuracy: 0.8249 - val_loss: 0.5410 - val_accuracy: 0.7500\n",
            "Epoch 422/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4717 - accuracy: 0.8187 - val_loss: 0.5475 - val_accuracy: 0.7794\n",
            "Epoch 423/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4803 - accuracy: 0.8193 - val_loss: 0.5519 - val_accuracy: 0.7647\n",
            "Epoch 424/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4658 - accuracy: 0.8199 - val_loss: 0.5412 - val_accuracy: 0.7684\n",
            "Epoch 425/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4630 - accuracy: 0.8230 - val_loss: 0.5619 - val_accuracy: 0.7316\n",
            "Epoch 426/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4581 - accuracy: 0.8267 - val_loss: 0.5262 - val_accuracy: 0.7831\n",
            "Epoch 427/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4722 - accuracy: 0.8236 - val_loss: 0.5574 - val_accuracy: 0.7721\n",
            "Epoch 428/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4692 - accuracy: 0.8236 - val_loss: 0.5519 - val_accuracy: 0.7610\n",
            "Epoch 429/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4781 - accuracy: 0.8249 - val_loss: 0.5487 - val_accuracy: 0.7721\n",
            "Epoch 430/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4838 - accuracy: 0.8280 - val_loss: 0.5644 - val_accuracy: 0.7353\n",
            "Epoch 431/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4543 - accuracy: 0.8243 - val_loss: 0.5315 - val_accuracy: 0.7721\n",
            "Epoch 432/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4715 - accuracy: 0.8199 - val_loss: 0.5440 - val_accuracy: 0.7390\n",
            "Epoch 433/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4815 - accuracy: 0.8051 - val_loss: 0.5331 - val_accuracy: 0.7757\n",
            "Epoch 434/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4612 - accuracy: 0.8249 - val_loss: 0.5399 - val_accuracy: 0.7721\n",
            "Epoch 435/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4779 - accuracy: 0.8162 - val_loss: 0.5664 - val_accuracy: 0.7684\n",
            "Epoch 436/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4733 - accuracy: 0.8274 - val_loss: 0.5665 - val_accuracy: 0.7610\n",
            "Epoch 437/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4536 - accuracy: 0.8286 - val_loss: 0.5599 - val_accuracy: 0.7353\n",
            "Epoch 438/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4687 - accuracy: 0.8274 - val_loss: 0.5512 - val_accuracy: 0.7721\n",
            "Epoch 439/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4659 - accuracy: 0.8230 - val_loss: 0.5451 - val_accuracy: 0.7684\n",
            "Epoch 440/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4665 - accuracy: 0.8125 - val_loss: 0.5450 - val_accuracy: 0.7721\n",
            "Epoch 441/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4720 - accuracy: 0.8255 - val_loss: 0.5307 - val_accuracy: 0.7757\n",
            "Epoch 442/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4727 - accuracy: 0.8255 - val_loss: 0.5616 - val_accuracy: 0.7721\n",
            "Epoch 443/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4701 - accuracy: 0.8311 - val_loss: 0.5437 - val_accuracy: 0.7353\n",
            "Epoch 444/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4727 - accuracy: 0.8236 - val_loss: 0.5186 - val_accuracy: 0.7684\n",
            "Epoch 445/500\n",
            "202/202 [==============================] - 6s 32ms/step - loss: 0.4740 - accuracy: 0.8230 - val_loss: 0.5516 - val_accuracy: 0.7647\n",
            "Epoch 446/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4594 - accuracy: 0.8323 - val_loss: 0.5497 - val_accuracy: 0.7721\n",
            "Epoch 447/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4566 - accuracy: 0.8397 - val_loss: 0.5533 - val_accuracy: 0.7574\n",
            "Epoch 448/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4627 - accuracy: 0.8286 - val_loss: 0.5530 - val_accuracy: 0.7390\n",
            "Epoch 449/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4703 - accuracy: 0.8292 - val_loss: 0.5349 - val_accuracy: 0.7684\n",
            "Epoch 450/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4637 - accuracy: 0.8267 - val_loss: 0.5382 - val_accuracy: 0.7684\n",
            "Epoch 451/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4510 - accuracy: 0.8243 - val_loss: 0.5716 - val_accuracy: 0.7243\n",
            "Epoch 452/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4499 - accuracy: 0.8422 - val_loss: 0.5711 - val_accuracy: 0.7279\n",
            "Epoch 453/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4606 - accuracy: 0.8335 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
            "Epoch 454/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4649 - accuracy: 0.8298 - val_loss: 0.5498 - val_accuracy: 0.7684\n",
            "Epoch 455/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4811 - accuracy: 0.8137 - val_loss: 0.5777 - val_accuracy: 0.7279\n",
            "Epoch 456/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4834 - accuracy: 0.8187 - val_loss: 0.5462 - val_accuracy: 0.7684\n",
            "Epoch 457/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4515 - accuracy: 0.8323 - val_loss: 0.5419 - val_accuracy: 0.7610\n",
            "Epoch 458/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4799 - accuracy: 0.8119 - val_loss: 0.5491 - val_accuracy: 0.7390\n",
            "Epoch 459/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4535 - accuracy: 0.8317 - val_loss: 0.5583 - val_accuracy: 0.7610\n",
            "Epoch 460/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4538 - accuracy: 0.8236 - val_loss: 0.5575 - val_accuracy: 0.7610\n",
            "Epoch 461/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4476 - accuracy: 0.8379 - val_loss: 0.5448 - val_accuracy: 0.7647\n",
            "Epoch 462/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4562 - accuracy: 0.8379 - val_loss: 0.5418 - val_accuracy: 0.7500\n",
            "Epoch 463/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4708 - accuracy: 0.8274 - val_loss: 0.5711 - val_accuracy: 0.7316\n",
            "Epoch 464/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4682 - accuracy: 0.8236 - val_loss: 0.5715 - val_accuracy: 0.7316\n",
            "Epoch 465/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4635 - accuracy: 0.8150 - val_loss: 0.5682 - val_accuracy: 0.7243\n",
            "Epoch 466/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4730 - accuracy: 0.8113 - val_loss: 0.5615 - val_accuracy: 0.7574\n",
            "Epoch 467/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4670 - accuracy: 0.8193 - val_loss: 0.5818 - val_accuracy: 0.7206\n",
            "Epoch 468/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4695 - accuracy: 0.8255 - val_loss: 0.5328 - val_accuracy: 0.7647\n",
            "Epoch 469/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4449 - accuracy: 0.8447 - val_loss: 0.5554 - val_accuracy: 0.7463\n",
            "Epoch 470/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4627 - accuracy: 0.8243 - val_loss: 0.5618 - val_accuracy: 0.7353\n",
            "Epoch 471/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4639 - accuracy: 0.8311 - val_loss: 0.5646 - val_accuracy: 0.7316\n",
            "Epoch 472/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4441 - accuracy: 0.8335 - val_loss: 0.6009 - val_accuracy: 0.7463\n",
            "Epoch 473/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4560 - accuracy: 0.8311 - val_loss: 0.5551 - val_accuracy: 0.7463\n",
            "Epoch 474/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4765 - accuracy: 0.8162 - val_loss: 0.5508 - val_accuracy: 0.7390\n",
            "Epoch 475/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4557 - accuracy: 0.8280 - val_loss: 0.5581 - val_accuracy: 0.7647\n",
            "Epoch 476/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4865 - accuracy: 0.8212 - val_loss: 0.5778 - val_accuracy: 0.7243\n",
            "Epoch 477/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4590 - accuracy: 0.8298 - val_loss: 0.5592 - val_accuracy: 0.7316\n",
            "Epoch 478/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4779 - accuracy: 0.8218 - val_loss: 0.5581 - val_accuracy: 0.7390\n",
            "Epoch 479/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4589 - accuracy: 0.8317 - val_loss: 0.5733 - val_accuracy: 0.7279\n",
            "Epoch 480/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4699 - accuracy: 0.8267 - val_loss: 0.5419 - val_accuracy: 0.7721\n",
            "Epoch 481/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4611 - accuracy: 0.8292 - val_loss: 0.5462 - val_accuracy: 0.7390\n",
            "Epoch 482/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4476 - accuracy: 0.8292 - val_loss: 0.5783 - val_accuracy: 0.7390\n",
            "Epoch 483/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4621 - accuracy: 0.8218 - val_loss: 0.5430 - val_accuracy: 0.7316\n",
            "Epoch 484/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4584 - accuracy: 0.8280 - val_loss: 0.5558 - val_accuracy: 0.7279\n",
            "Epoch 485/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4696 - accuracy: 0.8175 - val_loss: 0.5827 - val_accuracy: 0.7353\n",
            "Epoch 486/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4478 - accuracy: 0.8379 - val_loss: 0.5552 - val_accuracy: 0.7390\n",
            "Epoch 487/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4610 - accuracy: 0.8267 - val_loss: 0.5679 - val_accuracy: 0.7353\n",
            "Epoch 488/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4677 - accuracy: 0.8168 - val_loss: 0.5569 - val_accuracy: 0.7610\n",
            "Epoch 489/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4552 - accuracy: 0.8342 - val_loss: 0.5174 - val_accuracy: 0.7794\n",
            "Epoch 490/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4631 - accuracy: 0.8230 - val_loss: 0.5312 - val_accuracy: 0.7721\n",
            "Epoch 491/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4498 - accuracy: 0.8379 - val_loss: 0.5451 - val_accuracy: 0.7426\n",
            "Epoch 492/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4475 - accuracy: 0.8379 - val_loss: 0.5394 - val_accuracy: 0.7721\n",
            "Epoch 493/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4717 - accuracy: 0.8261 - val_loss: 0.5337 - val_accuracy: 0.7721\n",
            "Epoch 494/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4568 - accuracy: 0.8261 - val_loss: 0.5599 - val_accuracy: 0.7390\n",
            "Epoch 495/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4487 - accuracy: 0.8342 - val_loss: 0.5405 - val_accuracy: 0.7647\n",
            "Epoch 496/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4499 - accuracy: 0.8342 - val_loss: 0.5511 - val_accuracy: 0.7353\n",
            "Epoch 497/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4439 - accuracy: 0.8292 - val_loss: 0.5395 - val_accuracy: 0.7390\n",
            "Epoch 498/500\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4514 - accuracy: 0.8280 - val_loss: 0.5346 - val_accuracy: 0.7684\n",
            "Epoch 499/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4506 - accuracy: 0.8292 - val_loss: 0.5706 - val_accuracy: 0.7279\n",
            "Epoch 500/500\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4513 - accuracy: 0.8298 - val_loss: 0.5457 - val_accuracy: 0.7684\n"
          ]
        }
      ],
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                                        patience = 20,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer= keras.optimizers.Adam(0.001, decay=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "# Start training the model.\n",
        "cnn_3d_model_training_history = model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=500,\n",
        "                                          batch_size=8,\n",
        "                                          shuffle = True,\n",
        "                                          validation_data = (features_valid, labels_valid))\n",
        "                                          # callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vimsgjjbXvL",
        "outputId": "9e409f79-beed-4fbe-eff2-ed27e01f4e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 43ms/step - loss: 1.0064 - accuracy: 0.5294\n",
            "\n",
            "\n",
            "Train accuracy: 78.775 % || Test accuracy: 52.941 % || Val accuracy: 76.838 %\n",
            "Train loss: 0.506 || Test loss: 1.006 || Val loss: 0.546\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ivmaK9BlbnRQ"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'3D_CNN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p cnn_3d_{current_date_time_string}\n",
        "# Save your Model.\n",
        "model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwU8TwPrbsKB"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cvKY05ncbwof",
        "outputId": "34d5e3ca-9704-47dc-c14d-eef2680d6118"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "o1iaaDHBb5i0",
        "outputId": "784f09e4-3b7d-477f-e7aa-1130e3d5da2c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3D_CNN.ipynb",
      "provenance": [],
      "background_execution": "on",
      "authorship_tag": "ABX9TyOF9596p9MwSF66LID3jkaW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}