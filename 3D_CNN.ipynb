{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/3D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7I8NauauE3"
      },
      "source": [
        "####**3D Convolutional Neural Network**\n",
        "######*I am using 3D Convolutional Neural Network to extract the temporal and spatial information which are merged slowly throughout the whole network.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ibtd5HKtZk",
        "outputId": "ac920a4a-fd9f-4d3a-e94a-ed3bcf0d04c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "dfdcda70-9931-43ad-fd06-13a060919bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUTeIqzpZc9J"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QRDbHG0TZkYJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(128, 128)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            # frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "fd72d23c-8484-4b97-ee2d-f7f992cba374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-9ykP4ig7IW"
      },
      "outputs": [],
      "source": [
        "def create_3D_CNN_model():\n",
        "    sample_shape = (16, 128, 128, 3)\n",
        "    model = Sequential()\n",
        "\n",
        "    ### 1\n",
        "    model.add(Conv3D(16, (3,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4),\n",
        "                     input_shape=sample_shape))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 2\n",
        "    model.add(Conv3D(32, (3,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # ### 3\n",
        "    # model.add(Conv3D(24, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "    #                  kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(MaxPooling3D(2))\n",
        "    # model.add(Dropout(0.4))\n",
        "\n",
        "    # ### 4\n",
        "    # model.add(Conv3D(32, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "    #                  kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(MaxPooling3D(2))\n",
        "    # model.add(Dropout(0.4))\n",
        "\n",
        "    # ### 5\n",
        "    # model.add(Conv3D(32, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "    #                  kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(MaxPooling3D(2))\n",
        "    # model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(GlobalAveragePooling3D())\n",
        "    model.add(Dropout(0.45))\n",
        "\n",
        "    # model.add(Dense(32, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "\n",
        "    model.summary(line_length = 125)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_GxXZBcHlB",
        "outputId": "49528e6f-d2c0-4966-a8aa-fa513d38d3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_____________________________________________________________________________________________________________________________\n",
            " Layer (type)                                           Output Shape                                      Param #            \n",
            "=============================================================================================================================\n",
            " conv3d (Conv3D)                                        (None, 14, 126, 126, 16)                          1312               \n",
            "                                                                                                                             \n",
            " max_pooling3d (MaxPooling3D)                           (None, 7, 63, 63, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout (Dropout)                                      (None, 7, 63, 63, 16)                             0                  \n",
            "                                                                                                                             \n",
            " conv3d_1 (Conv3D)                                      (None, 5, 61, 61, 32)                             13856              \n",
            "                                                                                                                             \n",
            " max_pooling3d_1 (MaxPooling3D)                         (None, 2, 30, 30, 32)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_1 (Dropout)                                    (None, 2, 30, 30, 32)                             0                  \n",
            "                                                                                                                             \n",
            " global_average_pooling3d (GlobalAveragePooling3D)      (None, 32)                                        0                  \n",
            "                                                                                                                             \n",
            " dropout_2 (Dropout)                                    (None, 32)                                        0                  \n",
            "                                                                                                                             \n",
            " dense (Dense)                                          (None, 16)                                        528                \n",
            "                                                                                                                             \n",
            " dropout_3 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense_1 (Dense)                                        (None, 8)                                         136                \n",
            "                                                                                                                             \n",
            " dense_2 (Dense)                                        (None, 4)                                         36                 \n",
            "                                                                                                                             \n",
            "=============================================================================================================================\n",
            "Total params: 15,868\n",
            "Trainable params: 15,868\n",
            "Non-trainable params: 0\n",
            "_____________________________________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "model = create_3D_CNN_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYEkaYLoyb_",
        "outputId": "e5f6a3db-0379-4291-fb38-46c660fc9a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "51/51 [==============================] - 8s 109ms/step - loss: 1.7519 - accuracy: 0.1906 - val_loss: 1.3478 - val_accuracy: 0.4816\n",
            "Epoch 2/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 1.3610 - accuracy: 0.3595 - val_loss: 1.3344 - val_accuracy: 0.4816\n",
            "Epoch 3/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 1.3033 - accuracy: 0.4059 - val_loss: 1.2762 - val_accuracy: 0.4816\n",
            "Epoch 4/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 1.2705 - accuracy: 0.4245 - val_loss: 1.2407 - val_accuracy: 0.4816\n",
            "Epoch 5/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 1.2212 - accuracy: 0.4548 - val_loss: 1.1907 - val_accuracy: 0.4816\n",
            "Epoch 6/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 1.1814 - accuracy: 0.4542 - val_loss: 1.1383 - val_accuracy: 0.4816\n",
            "Epoch 7/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 1.1493 - accuracy: 0.4709 - val_loss: 1.1210 - val_accuracy: 0.5074\n",
            "Epoch 8/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 1.1324 - accuracy: 0.4975 - val_loss: 1.0952 - val_accuracy: 0.5221\n",
            "Epoch 9/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 1.0732 - accuracy: 0.5068 - val_loss: 1.0399 - val_accuracy: 0.6287\n",
            "Epoch 10/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 1.0434 - accuracy: 0.5161 - val_loss: 1.0047 - val_accuracy: 0.6176\n",
            "Epoch 11/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 1.0283 - accuracy: 0.5179 - val_loss: 1.0211 - val_accuracy: 0.6176\n",
            "Epoch 12/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 1.0015 - accuracy: 0.5248 - val_loss: 0.9656 - val_accuracy: 0.5846\n",
            "Epoch 13/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.9518 - accuracy: 0.5489 - val_loss: 0.9096 - val_accuracy: 0.6213\n",
            "Epoch 14/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.9541 - accuracy: 0.5390 - val_loss: 0.9401 - val_accuracy: 0.6103\n",
            "Epoch 15/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.9296 - accuracy: 0.5668 - val_loss: 0.9083 - val_accuracy: 0.5993\n",
            "Epoch 16/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.9047 - accuracy: 0.5804 - val_loss: 0.8985 - val_accuracy: 0.5882\n",
            "Epoch 17/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.9163 - accuracy: 0.5662 - val_loss: 0.9031 - val_accuracy: 0.5993\n",
            "Epoch 18/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.9032 - accuracy: 0.5885 - val_loss: 0.8807 - val_accuracy: 0.6287\n",
            "Epoch 19/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.9215 - accuracy: 0.5563 - val_loss: 0.8833 - val_accuracy: 0.5882\n",
            "Epoch 20/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.8838 - accuracy: 0.5761 - val_loss: 0.8565 - val_accuracy: 0.6397\n",
            "Epoch 21/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.8820 - accuracy: 0.5854 - val_loss: 0.8611 - val_accuracy: 0.6176\n",
            "Epoch 22/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.8621 - accuracy: 0.5903 - val_loss: 0.8397 - val_accuracy: 0.6066\n",
            "Epoch 23/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.8584 - accuracy: 0.6033 - val_loss: 0.8326 - val_accuracy: 0.6176\n",
            "Epoch 24/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.8479 - accuracy: 0.5972 - val_loss: 0.8226 - val_accuracy: 0.6029\n",
            "Epoch 25/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.8580 - accuracy: 0.5891 - val_loss: 0.8303 - val_accuracy: 0.5956\n",
            "Epoch 26/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.8575 - accuracy: 0.5866 - val_loss: 0.8183 - val_accuracy: 0.6066\n",
            "Epoch 27/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.8244 - accuracy: 0.6145 - val_loss: 0.8092 - val_accuracy: 0.6140\n",
            "Epoch 28/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.8505 - accuracy: 0.6052 - val_loss: 0.8117 - val_accuracy: 0.6103\n",
            "Epoch 29/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.8259 - accuracy: 0.6207 - val_loss: 0.8098 - val_accuracy: 0.6176\n",
            "Epoch 30/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.8178 - accuracy: 0.6132 - val_loss: 0.7933 - val_accuracy: 0.6324\n",
            "Epoch 31/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.8110 - accuracy: 0.6163 - val_loss: 0.7921 - val_accuracy: 0.6581\n",
            "Epoch 32/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.8162 - accuracy: 0.6058 - val_loss: 0.7981 - val_accuracy: 0.6287\n",
            "Epoch 33/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7939 - accuracy: 0.6238 - val_loss: 0.7965 - val_accuracy: 0.6213\n",
            "Epoch 34/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.8119 - accuracy: 0.6318 - val_loss: 0.7914 - val_accuracy: 0.6654\n",
            "Epoch 35/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.7940 - accuracy: 0.6324 - val_loss: 0.7750 - val_accuracy: 0.6360\n",
            "Epoch 36/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.8048 - accuracy: 0.6250 - val_loss: 0.7899 - val_accuracy: 0.6103\n",
            "Epoch 37/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7978 - accuracy: 0.6200 - val_loss: 0.7686 - val_accuracy: 0.6691\n",
            "Epoch 38/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.8054 - accuracy: 0.6238 - val_loss: 0.7908 - val_accuracy: 0.5846\n",
            "Epoch 39/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7677 - accuracy: 0.6411 - val_loss: 0.7797 - val_accuracy: 0.6544\n",
            "Epoch 40/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.7725 - accuracy: 0.6386 - val_loss: 0.7707 - val_accuracy: 0.6360\n",
            "Epoch 41/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.7657 - accuracy: 0.6411 - val_loss: 0.7572 - val_accuracy: 0.6581\n",
            "Epoch 42/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7703 - accuracy: 0.6374 - val_loss: 0.7576 - val_accuracy: 0.6691\n",
            "Epoch 43/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7745 - accuracy: 0.6380 - val_loss: 0.7544 - val_accuracy: 0.6581\n",
            "Epoch 44/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.7425 - accuracy: 0.6405 - val_loss: 0.7664 - val_accuracy: 0.5735\n",
            "Epoch 45/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7372 - accuracy: 0.6696 - val_loss: 0.7374 - val_accuracy: 0.6691\n",
            "Epoch 46/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.7559 - accuracy: 0.6454 - val_loss: 0.7438 - val_accuracy: 0.6397\n",
            "Epoch 47/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7513 - accuracy: 0.6491 - val_loss: 0.7301 - val_accuracy: 0.6691\n",
            "Epoch 48/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7293 - accuracy: 0.6535 - val_loss: 0.7385 - val_accuracy: 0.6544\n",
            "Epoch 49/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.7372 - accuracy: 0.6547 - val_loss: 0.7277 - val_accuracy: 0.6728\n",
            "Epoch 50/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.7146 - accuracy: 0.6634 - val_loss: 0.7375 - val_accuracy: 0.6213\n",
            "Epoch 51/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7285 - accuracy: 0.6516 - val_loss: 0.7447 - val_accuracy: 0.6140\n",
            "Epoch 52/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.7127 - accuracy: 0.6795 - val_loss: 0.7224 - val_accuracy: 0.6434\n",
            "Epoch 53/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.7083 - accuracy: 0.6634 - val_loss: 0.7267 - val_accuracy: 0.6544\n",
            "Epoch 54/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.7202 - accuracy: 0.6708 - val_loss: 0.7440 - val_accuracy: 0.6287\n",
            "Epoch 55/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.7159 - accuracy: 0.6757 - val_loss: 0.7260 - val_accuracy: 0.6434\n",
            "Epoch 56/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6990 - accuracy: 0.6832 - val_loss: 0.7171 - val_accuracy: 0.6360\n",
            "Epoch 57/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6829 - accuracy: 0.7011 - val_loss: 0.7445 - val_accuracy: 0.5404\n",
            "Epoch 58/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6888 - accuracy: 0.6807 - val_loss: 0.7097 - val_accuracy: 0.6176\n",
            "Epoch 59/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6894 - accuracy: 0.6900 - val_loss: 0.7184 - val_accuracy: 0.6471\n",
            "Epoch 60/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6784 - accuracy: 0.6912 - val_loss: 0.6933 - val_accuracy: 0.6838\n",
            "Epoch 61/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6797 - accuracy: 0.6986 - val_loss: 0.7197 - val_accuracy: 0.6397\n",
            "Epoch 62/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6852 - accuracy: 0.7073 - val_loss: 0.7178 - val_accuracy: 0.5882\n",
            "Epoch 63/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6644 - accuracy: 0.6931 - val_loss: 0.7343 - val_accuracy: 0.5588\n",
            "Epoch 64/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6925 - accuracy: 0.6912 - val_loss: 0.7026 - val_accuracy: 0.6250\n",
            "Epoch 65/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6473 - accuracy: 0.7036 - val_loss: 0.7010 - val_accuracy: 0.6691\n",
            "Epoch 66/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6642 - accuracy: 0.7042 - val_loss: 0.7433 - val_accuracy: 0.5882\n",
            "Epoch 67/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.6652 - accuracy: 0.7030 - val_loss: 0.7257 - val_accuracy: 0.5993\n",
            "Epoch 68/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6686 - accuracy: 0.7123 - val_loss: 0.7075 - val_accuracy: 0.6471\n",
            "Epoch 69/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6690 - accuracy: 0.7054 - val_loss: 0.7467 - val_accuracy: 0.5846\n",
            "Epoch 70/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6627 - accuracy: 0.7061 - val_loss: 0.6973 - val_accuracy: 0.6140\n",
            "Epoch 71/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6642 - accuracy: 0.6986 - val_loss: 0.7027 - val_accuracy: 0.6434\n",
            "Epoch 72/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6649 - accuracy: 0.7030 - val_loss: 0.7157 - val_accuracy: 0.6140\n",
            "Epoch 73/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6624 - accuracy: 0.7048 - val_loss: 0.6931 - val_accuracy: 0.6213\n",
            "Epoch 74/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6297 - accuracy: 0.7141 - val_loss: 0.6891 - val_accuracy: 0.6728\n",
            "Epoch 75/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6368 - accuracy: 0.7228 - val_loss: 0.7298 - val_accuracy: 0.6029\n",
            "Epoch 76/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6531 - accuracy: 0.7153 - val_loss: 0.6945 - val_accuracy: 0.6581\n",
            "Epoch 77/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6410 - accuracy: 0.7339 - val_loss: 0.6769 - val_accuracy: 0.6838\n",
            "Epoch 78/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6253 - accuracy: 0.7172 - val_loss: 0.7078 - val_accuracy: 0.6140\n",
            "Epoch 79/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6327 - accuracy: 0.7184 - val_loss: 0.6988 - val_accuracy: 0.6360\n",
            "Epoch 80/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6346 - accuracy: 0.7228 - val_loss: 0.6950 - val_accuracy: 0.6287\n",
            "Epoch 81/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6361 - accuracy: 0.7215 - val_loss: 0.6533 - val_accuracy: 0.7022\n",
            "Epoch 82/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6298 - accuracy: 0.7283 - val_loss: 0.6953 - val_accuracy: 0.6434\n",
            "Epoch 83/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6536 - accuracy: 0.7067 - val_loss: 0.6747 - val_accuracy: 0.7169\n",
            "Epoch 84/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6315 - accuracy: 0.7302 - val_loss: 0.6725 - val_accuracy: 0.6471\n",
            "Epoch 85/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6512 - accuracy: 0.7116 - val_loss: 0.6858 - val_accuracy: 0.6765\n",
            "Epoch 86/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.6298 - accuracy: 0.7191 - val_loss: 0.6839 - val_accuracy: 0.6471\n",
            "Epoch 87/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6293 - accuracy: 0.7209 - val_loss: 0.6957 - val_accuracy: 0.6434\n",
            "Epoch 88/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6148 - accuracy: 0.7265 - val_loss: 0.6865 - val_accuracy: 0.6471\n",
            "Epoch 89/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6148 - accuracy: 0.7222 - val_loss: 0.7030 - val_accuracy: 0.6544\n",
            "Epoch 90/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6121 - accuracy: 0.7252 - val_loss: 0.6633 - val_accuracy: 0.6728\n",
            "Epoch 91/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6337 - accuracy: 0.7123 - val_loss: 0.6970 - val_accuracy: 0.6618\n",
            "Epoch 92/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6086 - accuracy: 0.7191 - val_loss: 0.6837 - val_accuracy: 0.6801\n",
            "Epoch 93/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6084 - accuracy: 0.7265 - val_loss: 0.7522 - val_accuracy: 0.6103\n",
            "Epoch 94/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6129 - accuracy: 0.7265 - val_loss: 0.6582 - val_accuracy: 0.7059\n",
            "Epoch 95/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6206 - accuracy: 0.7240 - val_loss: 0.7380 - val_accuracy: 0.6213\n",
            "Epoch 96/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6077 - accuracy: 0.7314 - val_loss: 0.7625 - val_accuracy: 0.6176\n",
            "Epoch 97/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6284 - accuracy: 0.7246 - val_loss: 0.6907 - val_accuracy: 0.6618\n",
            "Epoch 98/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6112 - accuracy: 0.7283 - val_loss: 0.7087 - val_accuracy: 0.6360\n",
            "Epoch 99/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5874 - accuracy: 0.7382 - val_loss: 0.6581 - val_accuracy: 0.6875\n",
            "Epoch 100/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5966 - accuracy: 0.7426 - val_loss: 0.6695 - val_accuracy: 0.6838\n",
            "Epoch 101/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6086 - accuracy: 0.7246 - val_loss: 0.7123 - val_accuracy: 0.6250\n",
            "Epoch 102/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6082 - accuracy: 0.7364 - val_loss: 0.7252 - val_accuracy: 0.6213\n",
            "Epoch 103/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5869 - accuracy: 0.7407 - val_loss: 0.7225 - val_accuracy: 0.6471\n",
            "Epoch 104/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6104 - accuracy: 0.7271 - val_loss: 0.6647 - val_accuracy: 0.6985\n",
            "Epoch 105/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.6063 - accuracy: 0.7277 - val_loss: 0.6947 - val_accuracy: 0.6471\n",
            "Epoch 106/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5865 - accuracy: 0.7519 - val_loss: 0.7791 - val_accuracy: 0.6029\n",
            "Epoch 107/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5936 - accuracy: 0.7420 - val_loss: 0.6962 - val_accuracy: 0.6471\n",
            "Epoch 108/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.6016 - accuracy: 0.7444 - val_loss: 0.7089 - val_accuracy: 0.6250\n",
            "Epoch 109/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.6056 - accuracy: 0.7438 - val_loss: 0.6582 - val_accuracy: 0.6912\n",
            "Epoch 110/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5891 - accuracy: 0.7420 - val_loss: 0.6745 - val_accuracy: 0.6875\n",
            "Epoch 111/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5883 - accuracy: 0.7444 - val_loss: 0.6503 - val_accuracy: 0.6875\n",
            "Epoch 112/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5780 - accuracy: 0.7488 - val_loss: 0.6867 - val_accuracy: 0.6654\n",
            "Epoch 113/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5850 - accuracy: 0.7543 - val_loss: 0.6725 - val_accuracy: 0.6765\n",
            "Epoch 114/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5953 - accuracy: 0.7450 - val_loss: 0.7042 - val_accuracy: 0.6507\n",
            "Epoch 115/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5931 - accuracy: 0.7500 - val_loss: 0.7036 - val_accuracy: 0.6544\n",
            "Epoch 116/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5714 - accuracy: 0.7463 - val_loss: 0.6528 - val_accuracy: 0.6912\n",
            "Epoch 117/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5912 - accuracy: 0.7351 - val_loss: 0.7823 - val_accuracy: 0.6103\n",
            "Epoch 118/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5820 - accuracy: 0.7494 - val_loss: 0.7551 - val_accuracy: 0.6066\n",
            "Epoch 119/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5738 - accuracy: 0.7636 - val_loss: 0.6615 - val_accuracy: 0.6838\n",
            "Epoch 120/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5876 - accuracy: 0.7469 - val_loss: 0.6912 - val_accuracy: 0.6581\n",
            "Epoch 121/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5868 - accuracy: 0.7413 - val_loss: 0.7505 - val_accuracy: 0.6176\n",
            "Epoch 122/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5624 - accuracy: 0.7679 - val_loss: 0.6877 - val_accuracy: 0.6765\n",
            "Epoch 123/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5779 - accuracy: 0.7512 - val_loss: 0.6939 - val_accuracy: 0.6728\n",
            "Epoch 124/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5789 - accuracy: 0.7308 - val_loss: 0.6757 - val_accuracy: 0.6949\n",
            "Epoch 125/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5978 - accuracy: 0.7420 - val_loss: 0.6946 - val_accuracy: 0.6728\n",
            "Epoch 126/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 0.5688 - accuracy: 0.7525 - val_loss: 0.6768 - val_accuracy: 0.6654\n",
            "Epoch 127/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5819 - accuracy: 0.7432 - val_loss: 0.6781 - val_accuracy: 0.6801\n",
            "Epoch 128/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5714 - accuracy: 0.7463 - val_loss: 0.7067 - val_accuracy: 0.6471\n",
            "Epoch 129/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5716 - accuracy: 0.7481 - val_loss: 0.6792 - val_accuracy: 0.6654\n",
            "Epoch 130/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5758 - accuracy: 0.7580 - val_loss: 0.7231 - val_accuracy: 0.6434\n",
            "Epoch 131/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5588 - accuracy: 0.7543 - val_loss: 0.6746 - val_accuracy: 0.6728\n",
            "Epoch 132/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5579 - accuracy: 0.7580 - val_loss: 0.7271 - val_accuracy: 0.6507\n",
            "Epoch 133/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5677 - accuracy: 0.7636 - val_loss: 0.7116 - val_accuracy: 0.6801\n",
            "Epoch 134/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5713 - accuracy: 0.7469 - val_loss: 0.6660 - val_accuracy: 0.6985\n",
            "Epoch 135/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5734 - accuracy: 0.7580 - val_loss: 0.7365 - val_accuracy: 0.6397\n",
            "Epoch 136/1000\n",
            "51/51 [==============================] - 5s 92ms/step - loss: 0.5653 - accuracy: 0.7562 - val_loss: 0.7244 - val_accuracy: 0.6581\n",
            "Epoch 137/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5563 - accuracy: 0.7636 - val_loss: 0.7193 - val_accuracy: 0.6544\n",
            "Epoch 138/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5663 - accuracy: 0.7735 - val_loss: 0.6652 - val_accuracy: 0.7059\n",
            "Epoch 139/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5573 - accuracy: 0.7723 - val_loss: 0.6706 - val_accuracy: 0.6949\n",
            "Epoch 140/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5658 - accuracy: 0.7618 - val_loss: 0.6768 - val_accuracy: 0.6875\n",
            "Epoch 141/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5660 - accuracy: 0.7605 - val_loss: 0.7222 - val_accuracy: 0.6360\n",
            "Epoch 142/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5741 - accuracy: 0.7537 - val_loss: 0.6686 - val_accuracy: 0.6875\n",
            "Epoch 143/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5649 - accuracy: 0.7506 - val_loss: 0.7365 - val_accuracy: 0.6360\n",
            "Epoch 144/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5704 - accuracy: 0.7537 - val_loss: 0.6610 - val_accuracy: 0.7059\n",
            "Epoch 145/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5752 - accuracy: 0.7593 - val_loss: 0.6642 - val_accuracy: 0.7316\n",
            "Epoch 146/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5541 - accuracy: 0.7587 - val_loss: 0.7058 - val_accuracy: 0.6434\n",
            "Epoch 147/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5550 - accuracy: 0.7574 - val_loss: 0.6674 - val_accuracy: 0.7022\n",
            "Epoch 148/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5655 - accuracy: 0.7475 - val_loss: 0.6957 - val_accuracy: 0.6618\n",
            "Epoch 149/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5493 - accuracy: 0.7766 - val_loss: 0.7160 - val_accuracy: 0.6471\n",
            "Epoch 150/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5546 - accuracy: 0.7729 - val_loss: 0.6803 - val_accuracy: 0.6912\n",
            "Epoch 151/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5671 - accuracy: 0.7500 - val_loss: 0.7176 - val_accuracy: 0.6434\n",
            "Epoch 152/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5417 - accuracy: 0.7686 - val_loss: 0.7454 - val_accuracy: 0.6360\n",
            "Epoch 153/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5557 - accuracy: 0.7605 - val_loss: 0.6880 - val_accuracy: 0.6875\n",
            "Epoch 154/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5646 - accuracy: 0.7587 - val_loss: 0.6855 - val_accuracy: 0.6949\n",
            "Epoch 155/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5507 - accuracy: 0.7599 - val_loss: 0.6509 - val_accuracy: 0.7059\n",
            "Epoch 156/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5388 - accuracy: 0.7877 - val_loss: 0.6818 - val_accuracy: 0.6912\n",
            "Epoch 157/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5409 - accuracy: 0.7649 - val_loss: 0.6613 - val_accuracy: 0.7316\n",
            "Epoch 158/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5458 - accuracy: 0.7760 - val_loss: 0.6686 - val_accuracy: 0.6949\n",
            "Epoch 159/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5309 - accuracy: 0.7803 - val_loss: 0.7352 - val_accuracy: 0.6507\n",
            "Epoch 160/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5538 - accuracy: 0.7624 - val_loss: 0.6492 - val_accuracy: 0.7096\n",
            "Epoch 161/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5424 - accuracy: 0.7717 - val_loss: 0.6437 - val_accuracy: 0.7316\n",
            "Epoch 162/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5478 - accuracy: 0.7729 - val_loss: 0.7061 - val_accuracy: 0.6544\n",
            "Epoch 163/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5153 - accuracy: 0.7939 - val_loss: 0.7019 - val_accuracy: 0.6728\n",
            "Epoch 164/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5303 - accuracy: 0.7809 - val_loss: 0.6608 - val_accuracy: 0.6949\n",
            "Epoch 165/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5345 - accuracy: 0.7704 - val_loss: 0.7033 - val_accuracy: 0.6654\n",
            "Epoch 166/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5600 - accuracy: 0.7673 - val_loss: 0.7338 - val_accuracy: 0.6434\n",
            "Epoch 167/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5329 - accuracy: 0.7630 - val_loss: 0.7108 - val_accuracy: 0.6581\n",
            "Epoch 168/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5278 - accuracy: 0.7741 - val_loss: 0.6451 - val_accuracy: 0.7206\n",
            "Epoch 169/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5302 - accuracy: 0.7778 - val_loss: 0.6948 - val_accuracy: 0.6801\n",
            "Epoch 170/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5323 - accuracy: 0.7729 - val_loss: 0.7631 - val_accuracy: 0.6397\n",
            "Epoch 171/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5400 - accuracy: 0.7710 - val_loss: 0.6717 - val_accuracy: 0.6875\n",
            "Epoch 172/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5363 - accuracy: 0.7735 - val_loss: 0.6886 - val_accuracy: 0.6691\n",
            "Epoch 173/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5399 - accuracy: 0.7729 - val_loss: 0.7879 - val_accuracy: 0.6287\n",
            "Epoch 174/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5148 - accuracy: 0.7766 - val_loss: 0.6582 - val_accuracy: 0.6949\n",
            "Epoch 175/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5411 - accuracy: 0.7649 - val_loss: 0.7007 - val_accuracy: 0.6728\n",
            "Epoch 176/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5474 - accuracy: 0.7704 - val_loss: 0.7168 - val_accuracy: 0.6544\n",
            "Epoch 177/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5274 - accuracy: 0.7766 - val_loss: 0.7205 - val_accuracy: 0.6765\n",
            "Epoch 178/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5279 - accuracy: 0.7785 - val_loss: 0.7329 - val_accuracy: 0.6471\n",
            "Epoch 179/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5141 - accuracy: 0.7908 - val_loss: 0.7921 - val_accuracy: 0.6287\n",
            "Epoch 180/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5395 - accuracy: 0.7840 - val_loss: 0.6945 - val_accuracy: 0.6618\n",
            "Epoch 181/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5337 - accuracy: 0.7673 - val_loss: 0.6850 - val_accuracy: 0.6875\n",
            "Epoch 182/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5381 - accuracy: 0.7766 - val_loss: 0.7135 - val_accuracy: 0.6728\n",
            "Epoch 183/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5417 - accuracy: 0.7710 - val_loss: 0.7004 - val_accuracy: 0.6728\n",
            "Epoch 184/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5306 - accuracy: 0.7809 - val_loss: 0.7026 - val_accuracy: 0.6654\n",
            "Epoch 185/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5121 - accuracy: 0.7890 - val_loss: 0.7011 - val_accuracy: 0.6838\n",
            "Epoch 186/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5505 - accuracy: 0.7679 - val_loss: 0.6910 - val_accuracy: 0.7022\n",
            "Epoch 187/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5361 - accuracy: 0.7853 - val_loss: 0.7870 - val_accuracy: 0.6360\n",
            "Epoch 188/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5256 - accuracy: 0.7760 - val_loss: 0.6623 - val_accuracy: 0.6985\n",
            "Epoch 189/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5125 - accuracy: 0.8026 - val_loss: 0.6831 - val_accuracy: 0.6838\n",
            "Epoch 190/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5017 - accuracy: 0.7946 - val_loss: 0.6611 - val_accuracy: 0.7022\n",
            "Epoch 191/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5278 - accuracy: 0.7877 - val_loss: 0.6771 - val_accuracy: 0.7059\n",
            "Epoch 192/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5178 - accuracy: 0.7840 - val_loss: 0.7581 - val_accuracy: 0.6507\n",
            "Epoch 193/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5266 - accuracy: 0.7729 - val_loss: 0.7002 - val_accuracy: 0.6912\n",
            "Epoch 194/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5272 - accuracy: 0.7785 - val_loss: 0.7304 - val_accuracy: 0.6618\n",
            "Epoch 195/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.5222 - accuracy: 0.7778 - val_loss: 0.7044 - val_accuracy: 0.6728\n",
            "Epoch 196/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5389 - accuracy: 0.7778 - val_loss: 0.6627 - val_accuracy: 0.6949\n",
            "Epoch 197/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5082 - accuracy: 0.7952 - val_loss: 0.7679 - val_accuracy: 0.6397\n",
            "Epoch 198/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5338 - accuracy: 0.7859 - val_loss: 0.6631 - val_accuracy: 0.6985\n",
            "Epoch 199/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5218 - accuracy: 0.7859 - val_loss: 0.6429 - val_accuracy: 0.7169\n",
            "Epoch 200/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5093 - accuracy: 0.7884 - val_loss: 0.6541 - val_accuracy: 0.7169\n",
            "Epoch 201/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5132 - accuracy: 0.7921 - val_loss: 0.7135 - val_accuracy: 0.6581\n",
            "Epoch 202/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4956 - accuracy: 0.7859 - val_loss: 0.6901 - val_accuracy: 0.6801\n",
            "Epoch 203/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5147 - accuracy: 0.7791 - val_loss: 0.6514 - val_accuracy: 0.7132\n",
            "Epoch 204/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5149 - accuracy: 0.7871 - val_loss: 0.6966 - val_accuracy: 0.6765\n",
            "Epoch 205/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5267 - accuracy: 0.7748 - val_loss: 0.7070 - val_accuracy: 0.6691\n",
            "Epoch 206/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5088 - accuracy: 0.7884 - val_loss: 0.6590 - val_accuracy: 0.7169\n",
            "Epoch 207/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5003 - accuracy: 0.7822 - val_loss: 0.7147 - val_accuracy: 0.6581\n",
            "Epoch 208/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4992 - accuracy: 0.7921 - val_loss: 0.6434 - val_accuracy: 0.7390\n",
            "Epoch 209/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5226 - accuracy: 0.7865 - val_loss: 0.7074 - val_accuracy: 0.6728\n",
            "Epoch 210/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4976 - accuracy: 0.7797 - val_loss: 0.6787 - val_accuracy: 0.6949\n",
            "Epoch 211/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5203 - accuracy: 0.8001 - val_loss: 0.6478 - val_accuracy: 0.7132\n",
            "Epoch 212/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5190 - accuracy: 0.7853 - val_loss: 0.6585 - val_accuracy: 0.7022\n",
            "Epoch 213/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5288 - accuracy: 0.7698 - val_loss: 0.6899 - val_accuracy: 0.6949\n",
            "Epoch 214/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5107 - accuracy: 0.7840 - val_loss: 0.6950 - val_accuracy: 0.6801\n",
            "Epoch 215/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5030 - accuracy: 0.7822 - val_loss: 0.6275 - val_accuracy: 0.7390\n",
            "Epoch 216/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5157 - accuracy: 0.7840 - val_loss: 0.6470 - val_accuracy: 0.7132\n",
            "Epoch 217/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5346 - accuracy: 0.7822 - val_loss: 0.6584 - val_accuracy: 0.7059\n",
            "Epoch 218/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5290 - accuracy: 0.7834 - val_loss: 0.6836 - val_accuracy: 0.6801\n",
            "Epoch 219/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5186 - accuracy: 0.7859 - val_loss: 0.7040 - val_accuracy: 0.6728\n",
            "Epoch 220/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5040 - accuracy: 0.7976 - val_loss: 0.7122 - val_accuracy: 0.6397\n",
            "Epoch 221/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5082 - accuracy: 0.7964 - val_loss: 0.6601 - val_accuracy: 0.7059\n",
            "Epoch 222/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5112 - accuracy: 0.7816 - val_loss: 0.6692 - val_accuracy: 0.6949\n",
            "Epoch 223/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5089 - accuracy: 0.7865 - val_loss: 0.6944 - val_accuracy: 0.6801\n",
            "Epoch 224/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5100 - accuracy: 0.7847 - val_loss: 0.6672 - val_accuracy: 0.7096\n",
            "Epoch 225/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5027 - accuracy: 0.7946 - val_loss: 0.7227 - val_accuracy: 0.6544\n",
            "Epoch 226/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5026 - accuracy: 0.7877 - val_loss: 0.6922 - val_accuracy: 0.6728\n",
            "Epoch 227/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5100 - accuracy: 0.7877 - val_loss: 0.6881 - val_accuracy: 0.6765\n",
            "Epoch 228/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4914 - accuracy: 0.7915 - val_loss: 0.6622 - val_accuracy: 0.7096\n",
            "Epoch 229/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5178 - accuracy: 0.7896 - val_loss: 0.6602 - val_accuracy: 0.7169\n",
            "Epoch 230/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.5246 - accuracy: 0.7871 - val_loss: 0.7145 - val_accuracy: 0.6544\n",
            "Epoch 231/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5011 - accuracy: 0.7890 - val_loss: 0.6544 - val_accuracy: 0.7169\n",
            "Epoch 232/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5025 - accuracy: 0.7915 - val_loss: 0.7024 - val_accuracy: 0.6581\n",
            "Epoch 233/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5100 - accuracy: 0.7754 - val_loss: 0.7102 - val_accuracy: 0.6471\n",
            "Epoch 234/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4854 - accuracy: 0.7983 - val_loss: 0.6533 - val_accuracy: 0.7243\n",
            "Epoch 235/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4899 - accuracy: 0.7976 - val_loss: 0.6936 - val_accuracy: 0.6765\n",
            "Epoch 236/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5296 - accuracy: 0.7828 - val_loss: 0.6487 - val_accuracy: 0.7279\n",
            "Epoch 237/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4944 - accuracy: 0.7939 - val_loss: 0.6600 - val_accuracy: 0.7096\n",
            "Epoch 238/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4897 - accuracy: 0.7933 - val_loss: 0.6632 - val_accuracy: 0.6985\n",
            "Epoch 239/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4842 - accuracy: 0.8082 - val_loss: 0.6849 - val_accuracy: 0.6728\n",
            "Epoch 240/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4984 - accuracy: 0.7983 - val_loss: 0.7111 - val_accuracy: 0.6507\n",
            "Epoch 241/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5014 - accuracy: 0.7921 - val_loss: 0.6457 - val_accuracy: 0.7353\n",
            "Epoch 242/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5130 - accuracy: 0.7939 - val_loss: 0.7021 - val_accuracy: 0.6728\n",
            "Epoch 243/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5001 - accuracy: 0.7865 - val_loss: 0.7753 - val_accuracy: 0.6140\n",
            "Epoch 244/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5088 - accuracy: 0.7877 - val_loss: 0.6811 - val_accuracy: 0.6949\n",
            "Epoch 245/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5029 - accuracy: 0.8020 - val_loss: 0.7586 - val_accuracy: 0.6250\n",
            "Epoch 246/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.5006 - accuracy: 0.7921 - val_loss: 0.6615 - val_accuracy: 0.7206\n",
            "Epoch 247/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4994 - accuracy: 0.8001 - val_loss: 0.6512 - val_accuracy: 0.7132\n",
            "Epoch 248/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5089 - accuracy: 0.7840 - val_loss: 0.6553 - val_accuracy: 0.7059\n",
            "Epoch 249/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4930 - accuracy: 0.7995 - val_loss: 0.6935 - val_accuracy: 0.6728\n",
            "Epoch 250/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4927 - accuracy: 0.7976 - val_loss: 0.6759 - val_accuracy: 0.6801\n",
            "Epoch 251/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4890 - accuracy: 0.7995 - val_loss: 0.6584 - val_accuracy: 0.7096\n",
            "Epoch 252/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4876 - accuracy: 0.8001 - val_loss: 0.6647 - val_accuracy: 0.7059\n",
            "Epoch 253/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 0.5099 - accuracy: 0.7921 - val_loss: 0.6362 - val_accuracy: 0.7316\n",
            "Epoch 254/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4979 - accuracy: 0.7803 - val_loss: 0.6550 - val_accuracy: 0.7096\n",
            "Epoch 255/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4984 - accuracy: 0.7976 - val_loss: 0.6689 - val_accuracy: 0.7022\n",
            "Epoch 256/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5023 - accuracy: 0.7828 - val_loss: 0.6757 - val_accuracy: 0.6765\n",
            "Epoch 257/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4945 - accuracy: 0.7933 - val_loss: 0.6402 - val_accuracy: 0.7169\n",
            "Epoch 258/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5089 - accuracy: 0.7766 - val_loss: 0.6264 - val_accuracy: 0.7353\n",
            "Epoch 259/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4913 - accuracy: 0.7952 - val_loss: 0.6587 - val_accuracy: 0.7059\n",
            "Epoch 260/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4947 - accuracy: 0.7989 - val_loss: 0.6777 - val_accuracy: 0.6949\n",
            "Epoch 261/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5200 - accuracy: 0.7840 - val_loss: 0.6829 - val_accuracy: 0.6765\n",
            "Epoch 262/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4896 - accuracy: 0.7896 - val_loss: 0.6276 - val_accuracy: 0.7279\n",
            "Epoch 263/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5051 - accuracy: 0.7803 - val_loss: 0.6682 - val_accuracy: 0.6949\n",
            "Epoch 264/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4865 - accuracy: 0.7946 - val_loss: 0.6451 - val_accuracy: 0.7169\n",
            "Epoch 265/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4980 - accuracy: 0.7933 - val_loss: 0.6772 - val_accuracy: 0.6838\n",
            "Epoch 266/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4920 - accuracy: 0.7952 - val_loss: 0.7000 - val_accuracy: 0.6581\n",
            "Epoch 267/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5037 - accuracy: 0.7865 - val_loss: 0.6982 - val_accuracy: 0.6434\n",
            "Epoch 268/1000\n",
            "51/51 [==============================] - 5s 91ms/step - loss: 0.4723 - accuracy: 0.8106 - val_loss: 0.6577 - val_accuracy: 0.7132\n",
            "Epoch 269/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5012 - accuracy: 0.7964 - val_loss: 0.6860 - val_accuracy: 0.6838\n",
            "Epoch 270/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5139 - accuracy: 0.7865 - val_loss: 0.6590 - val_accuracy: 0.7059\n",
            "Epoch 271/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4892 - accuracy: 0.7958 - val_loss: 0.6515 - val_accuracy: 0.7132\n",
            "Epoch 272/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4976 - accuracy: 0.7958 - val_loss: 0.6159 - val_accuracy: 0.7684\n",
            "Epoch 273/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4878 - accuracy: 0.8032 - val_loss: 0.6988 - val_accuracy: 0.6581\n",
            "Epoch 274/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4988 - accuracy: 0.7989 - val_loss: 0.6406 - val_accuracy: 0.7169\n",
            "Epoch 275/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.5018 - accuracy: 0.7915 - val_loss: 0.6639 - val_accuracy: 0.7059\n",
            "Epoch 276/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4786 - accuracy: 0.8007 - val_loss: 0.6524 - val_accuracy: 0.7169\n",
            "Epoch 277/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4658 - accuracy: 0.8069 - val_loss: 0.6364 - val_accuracy: 0.7243\n",
            "Epoch 278/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5050 - accuracy: 0.7884 - val_loss: 0.6621 - val_accuracy: 0.6949\n",
            "Epoch 279/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4932 - accuracy: 0.7958 - val_loss: 0.7258 - val_accuracy: 0.6471\n",
            "Epoch 280/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4908 - accuracy: 0.7964 - val_loss: 0.6436 - val_accuracy: 0.7279\n",
            "Epoch 281/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4763 - accuracy: 0.8063 - val_loss: 0.6631 - val_accuracy: 0.7169\n",
            "Epoch 282/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4969 - accuracy: 0.7921 - val_loss: 0.6707 - val_accuracy: 0.6838\n",
            "Epoch 283/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4899 - accuracy: 0.8063 - val_loss: 0.6728 - val_accuracy: 0.7059\n",
            "Epoch 284/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4931 - accuracy: 0.7970 - val_loss: 0.6485 - val_accuracy: 0.7096\n",
            "Epoch 285/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4803 - accuracy: 0.8075 - val_loss: 0.6570 - val_accuracy: 0.6949\n",
            "Epoch 286/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4766 - accuracy: 0.8032 - val_loss: 0.6230 - val_accuracy: 0.7390\n",
            "Epoch 287/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4844 - accuracy: 0.8057 - val_loss: 0.6183 - val_accuracy: 0.7500\n",
            "Epoch 288/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4975 - accuracy: 0.8001 - val_loss: 0.7023 - val_accuracy: 0.6691\n",
            "Epoch 289/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4807 - accuracy: 0.7970 - val_loss: 0.6620 - val_accuracy: 0.7096\n",
            "Epoch 290/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4773 - accuracy: 0.8045 - val_loss: 0.6417 - val_accuracy: 0.7279\n",
            "Epoch 291/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4803 - accuracy: 0.8063 - val_loss: 0.6508 - val_accuracy: 0.7169\n",
            "Epoch 292/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4803 - accuracy: 0.7989 - val_loss: 0.6907 - val_accuracy: 0.6765\n",
            "Epoch 293/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4989 - accuracy: 0.7964 - val_loss: 0.6485 - val_accuracy: 0.7316\n",
            "Epoch 294/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4923 - accuracy: 0.7970 - val_loss: 0.7133 - val_accuracy: 0.6507\n",
            "Epoch 295/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4829 - accuracy: 0.7976 - val_loss: 0.6529 - val_accuracy: 0.7243\n",
            "Epoch 296/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4779 - accuracy: 0.8020 - val_loss: 0.6901 - val_accuracy: 0.6691\n",
            "Epoch 297/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4919 - accuracy: 0.8007 - val_loss: 0.6988 - val_accuracy: 0.6838\n",
            "Epoch 298/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4964 - accuracy: 0.7933 - val_loss: 0.7313 - val_accuracy: 0.6507\n",
            "Epoch 299/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5003 - accuracy: 0.7890 - val_loss: 0.6430 - val_accuracy: 0.7206\n",
            "Epoch 300/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4714 - accuracy: 0.8119 - val_loss: 0.6322 - val_accuracy: 0.7390\n",
            "Epoch 301/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4970 - accuracy: 0.7976 - val_loss: 0.6414 - val_accuracy: 0.7279\n",
            "Epoch 302/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4905 - accuracy: 0.7983 - val_loss: 0.6486 - val_accuracy: 0.7316\n",
            "Epoch 303/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4897 - accuracy: 0.7915 - val_loss: 0.6632 - val_accuracy: 0.7169\n",
            "Epoch 304/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4734 - accuracy: 0.8007 - val_loss: 0.6346 - val_accuracy: 0.7390\n",
            "Epoch 305/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4711 - accuracy: 0.7964 - val_loss: 0.6710 - val_accuracy: 0.6912\n",
            "Epoch 306/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4823 - accuracy: 0.8063 - val_loss: 0.6627 - val_accuracy: 0.7022\n",
            "Epoch 307/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4872 - accuracy: 0.8032 - val_loss: 0.6622 - val_accuracy: 0.7096\n",
            "Epoch 308/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4868 - accuracy: 0.8014 - val_loss: 0.6641 - val_accuracy: 0.7169\n",
            "Epoch 309/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.5024 - accuracy: 0.7983 - val_loss: 0.6901 - val_accuracy: 0.6728\n",
            "Epoch 310/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4926 - accuracy: 0.7964 - val_loss: 0.6577 - val_accuracy: 0.7169\n",
            "Epoch 311/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4809 - accuracy: 0.7983 - val_loss: 0.6653 - val_accuracy: 0.7022\n",
            "Epoch 312/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4916 - accuracy: 0.7952 - val_loss: 0.6329 - val_accuracy: 0.7463\n",
            "Epoch 313/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4928 - accuracy: 0.7976 - val_loss: 0.6350 - val_accuracy: 0.7279\n",
            "Epoch 314/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4648 - accuracy: 0.8150 - val_loss: 0.6451 - val_accuracy: 0.7206\n",
            "Epoch 315/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4869 - accuracy: 0.8063 - val_loss: 0.6192 - val_accuracy: 0.7574\n",
            "Epoch 316/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4756 - accuracy: 0.8150 - val_loss: 0.6457 - val_accuracy: 0.7243\n",
            "Epoch 317/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4698 - accuracy: 0.8026 - val_loss: 0.6627 - val_accuracy: 0.7132\n",
            "Epoch 318/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4839 - accuracy: 0.7952 - val_loss: 0.6546 - val_accuracy: 0.7132\n",
            "Epoch 319/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4624 - accuracy: 0.8094 - val_loss: 0.6302 - val_accuracy: 0.7353\n",
            "Epoch 320/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4766 - accuracy: 0.8045 - val_loss: 0.6250 - val_accuracy: 0.7463\n",
            "Epoch 321/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4956 - accuracy: 0.8082 - val_loss: 0.6639 - val_accuracy: 0.7132\n",
            "Epoch 322/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4611 - accuracy: 0.8181 - val_loss: 0.6778 - val_accuracy: 0.7169\n",
            "Epoch 323/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4838 - accuracy: 0.8069 - val_loss: 0.6878 - val_accuracy: 0.6949\n",
            "Epoch 324/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4694 - accuracy: 0.8156 - val_loss: 0.6384 - val_accuracy: 0.7279\n",
            "Epoch 325/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4647 - accuracy: 0.8088 - val_loss: 0.6462 - val_accuracy: 0.7279\n",
            "Epoch 326/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4866 - accuracy: 0.8001 - val_loss: 0.6634 - val_accuracy: 0.7132\n",
            "Epoch 327/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4823 - accuracy: 0.8088 - val_loss: 0.6426 - val_accuracy: 0.7353\n",
            "Epoch 328/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4745 - accuracy: 0.8088 - val_loss: 0.6442 - val_accuracy: 0.7243\n",
            "Epoch 329/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4823 - accuracy: 0.7921 - val_loss: 0.6438 - val_accuracy: 0.7279\n",
            "Epoch 330/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4539 - accuracy: 0.8168 - val_loss: 0.6479 - val_accuracy: 0.7169\n",
            "Epoch 331/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4938 - accuracy: 0.7989 - val_loss: 0.6308 - val_accuracy: 0.7206\n",
            "Epoch 332/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4839 - accuracy: 0.8020 - val_loss: 0.6500 - val_accuracy: 0.7022\n",
            "Epoch 333/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4793 - accuracy: 0.8045 - val_loss: 0.7016 - val_accuracy: 0.6728\n",
            "Epoch 334/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4878 - accuracy: 0.8082 - val_loss: 0.6672 - val_accuracy: 0.6728\n",
            "Epoch 335/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4794 - accuracy: 0.8125 - val_loss: 0.7017 - val_accuracy: 0.6471\n",
            "Epoch 336/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4923 - accuracy: 0.7976 - val_loss: 0.6431 - val_accuracy: 0.7169\n",
            "Epoch 337/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4854 - accuracy: 0.7908 - val_loss: 0.6545 - val_accuracy: 0.7132\n",
            "Epoch 338/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4857 - accuracy: 0.8001 - val_loss: 0.6747 - val_accuracy: 0.7022\n",
            "Epoch 339/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4838 - accuracy: 0.8014 - val_loss: 0.6394 - val_accuracy: 0.7279\n",
            "Epoch 340/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4805 - accuracy: 0.8007 - val_loss: 0.6593 - val_accuracy: 0.7243\n",
            "Epoch 341/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4701 - accuracy: 0.8137 - val_loss: 0.6441 - val_accuracy: 0.7243\n",
            "Epoch 342/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4802 - accuracy: 0.8026 - val_loss: 0.6653 - val_accuracy: 0.6985\n",
            "Epoch 343/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4737 - accuracy: 0.8063 - val_loss: 0.6280 - val_accuracy: 0.7463\n",
            "Epoch 344/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4783 - accuracy: 0.8137 - val_loss: 0.6387 - val_accuracy: 0.7463\n",
            "Epoch 345/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4936 - accuracy: 0.7989 - val_loss: 0.6346 - val_accuracy: 0.7390\n",
            "Epoch 346/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4903 - accuracy: 0.7933 - val_loss: 0.6300 - val_accuracy: 0.7500\n",
            "Epoch 347/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4749 - accuracy: 0.8088 - val_loss: 0.6270 - val_accuracy: 0.7353\n",
            "Epoch 348/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4763 - accuracy: 0.8057 - val_loss: 0.6437 - val_accuracy: 0.7132\n",
            "Epoch 349/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4601 - accuracy: 0.8082 - val_loss: 0.6326 - val_accuracy: 0.7426\n",
            "Epoch 350/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4792 - accuracy: 0.8082 - val_loss: 0.6440 - val_accuracy: 0.7169\n",
            "Epoch 351/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.5001 - accuracy: 0.8075 - val_loss: 0.6577 - val_accuracy: 0.7206\n",
            "Epoch 352/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4673 - accuracy: 0.8057 - val_loss: 0.6257 - val_accuracy: 0.7463\n",
            "Epoch 353/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4900 - accuracy: 0.8001 - val_loss: 0.6301 - val_accuracy: 0.7390\n",
            "Epoch 354/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4601 - accuracy: 0.8045 - val_loss: 0.6890 - val_accuracy: 0.6654\n",
            "Epoch 355/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4660 - accuracy: 0.8100 - val_loss: 0.6595 - val_accuracy: 0.7096\n",
            "Epoch 356/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4915 - accuracy: 0.7964 - val_loss: 0.6817 - val_accuracy: 0.6765\n",
            "Epoch 357/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4695 - accuracy: 0.8063 - val_loss: 0.6202 - val_accuracy: 0.7463\n",
            "Epoch 358/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4803 - accuracy: 0.7952 - val_loss: 0.6354 - val_accuracy: 0.7353\n",
            "Epoch 359/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4696 - accuracy: 0.8125 - val_loss: 0.6897 - val_accuracy: 0.6691\n",
            "Epoch 360/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4744 - accuracy: 0.8014 - val_loss: 0.6543 - val_accuracy: 0.7096\n",
            "Epoch 361/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4687 - accuracy: 0.8131 - val_loss: 0.6472 - val_accuracy: 0.7206\n",
            "Epoch 362/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4533 - accuracy: 0.8168 - val_loss: 0.6614 - val_accuracy: 0.7096\n",
            "Epoch 363/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4665 - accuracy: 0.8187 - val_loss: 0.7209 - val_accuracy: 0.6544\n",
            "Epoch 364/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4731 - accuracy: 0.8014 - val_loss: 0.6534 - val_accuracy: 0.7059\n",
            "Epoch 365/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4683 - accuracy: 0.8001 - val_loss: 0.6904 - val_accuracy: 0.6801\n",
            "Epoch 366/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4675 - accuracy: 0.8137 - val_loss: 0.6653 - val_accuracy: 0.7022\n",
            "Epoch 367/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4624 - accuracy: 0.8038 - val_loss: 0.6598 - val_accuracy: 0.7096\n",
            "Epoch 368/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4584 - accuracy: 0.8175 - val_loss: 0.6342 - val_accuracy: 0.7353\n",
            "Epoch 369/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4639 - accuracy: 0.8168 - val_loss: 0.6461 - val_accuracy: 0.7279\n",
            "Epoch 370/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4550 - accuracy: 0.8137 - val_loss: 0.6572 - val_accuracy: 0.7059\n",
            "Epoch 371/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4672 - accuracy: 0.8045 - val_loss: 0.6540 - val_accuracy: 0.7132\n",
            "Epoch 372/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4943 - accuracy: 0.7902 - val_loss: 0.7211 - val_accuracy: 0.6471\n",
            "Epoch 373/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4576 - accuracy: 0.8113 - val_loss: 0.6540 - val_accuracy: 0.7059\n",
            "Epoch 374/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4905 - accuracy: 0.7976 - val_loss: 0.6411 - val_accuracy: 0.7390\n",
            "Epoch 375/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4716 - accuracy: 0.8106 - val_loss: 0.6736 - val_accuracy: 0.6949\n",
            "Epoch 376/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4640 - accuracy: 0.8212 - val_loss: 0.6745 - val_accuracy: 0.7022\n",
            "Epoch 377/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4726 - accuracy: 0.8014 - val_loss: 0.6543 - val_accuracy: 0.7390\n",
            "Epoch 378/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4717 - accuracy: 0.8094 - val_loss: 0.6472 - val_accuracy: 0.7243\n",
            "Epoch 379/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4661 - accuracy: 0.8063 - val_loss: 0.6770 - val_accuracy: 0.6765\n",
            "Epoch 380/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4714 - accuracy: 0.8094 - val_loss: 0.6498 - val_accuracy: 0.7353\n",
            "Epoch 381/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4715 - accuracy: 0.8069 - val_loss: 0.6315 - val_accuracy: 0.7316\n",
            "Epoch 382/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4721 - accuracy: 0.8057 - val_loss: 0.6796 - val_accuracy: 0.6728\n",
            "Epoch 383/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4634 - accuracy: 0.8057 - val_loss: 0.6776 - val_accuracy: 0.6912\n",
            "Epoch 384/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4427 - accuracy: 0.8212 - val_loss: 0.6280 - val_accuracy: 0.7390\n",
            "Epoch 385/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4793 - accuracy: 0.8131 - val_loss: 0.6250 - val_accuracy: 0.7537\n",
            "Epoch 386/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4681 - accuracy: 0.7939 - val_loss: 0.6459 - val_accuracy: 0.7132\n",
            "Epoch 387/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4675 - accuracy: 0.8119 - val_loss: 0.6392 - val_accuracy: 0.7390\n",
            "Epoch 388/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4478 - accuracy: 0.8106 - val_loss: 0.6740 - val_accuracy: 0.6838\n",
            "Epoch 389/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4583 - accuracy: 0.8045 - val_loss: 0.6792 - val_accuracy: 0.6912\n",
            "Epoch 390/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4615 - accuracy: 0.8162 - val_loss: 0.6376 - val_accuracy: 0.7279\n",
            "Epoch 391/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4658 - accuracy: 0.8224 - val_loss: 0.6554 - val_accuracy: 0.7059\n",
            "Epoch 392/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4754 - accuracy: 0.7995 - val_loss: 0.6827 - val_accuracy: 0.6875\n",
            "Epoch 393/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4772 - accuracy: 0.8094 - val_loss: 0.6769 - val_accuracy: 0.7022\n",
            "Epoch 394/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4808 - accuracy: 0.8007 - val_loss: 0.6819 - val_accuracy: 0.6728\n",
            "Epoch 395/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4715 - accuracy: 0.8051 - val_loss: 0.6375 - val_accuracy: 0.7316\n",
            "Epoch 396/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4608 - accuracy: 0.8106 - val_loss: 0.6389 - val_accuracy: 0.7390\n",
            "Epoch 397/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4526 - accuracy: 0.8100 - val_loss: 0.6244 - val_accuracy: 0.7426\n",
            "Epoch 398/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4719 - accuracy: 0.8113 - val_loss: 0.6361 - val_accuracy: 0.7316\n",
            "Epoch 399/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4679 - accuracy: 0.8088 - val_loss: 0.7139 - val_accuracy: 0.6691\n",
            "Epoch 400/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4753 - accuracy: 0.8057 - val_loss: 0.6369 - val_accuracy: 0.7353\n",
            "Epoch 401/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4673 - accuracy: 0.8020 - val_loss: 0.6523 - val_accuracy: 0.7096\n",
            "Epoch 402/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4837 - accuracy: 0.8094 - val_loss: 0.6583 - val_accuracy: 0.7096\n",
            "Epoch 403/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4671 - accuracy: 0.8051 - val_loss: 0.6379 - val_accuracy: 0.7390\n",
            "Epoch 404/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4744 - accuracy: 0.8075 - val_loss: 0.6680 - val_accuracy: 0.7132\n",
            "Epoch 405/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4770 - accuracy: 0.8175 - val_loss: 0.6260 - val_accuracy: 0.7390\n",
            "Epoch 406/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4541 - accuracy: 0.8261 - val_loss: 0.6817 - val_accuracy: 0.6838\n",
            "Epoch 407/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4579 - accuracy: 0.8199 - val_loss: 0.6576 - val_accuracy: 0.7169\n",
            "Epoch 408/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4823 - accuracy: 0.7976 - val_loss: 0.6527 - val_accuracy: 0.7169\n",
            "Epoch 409/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4743 - accuracy: 0.8032 - val_loss: 0.6721 - val_accuracy: 0.6838\n",
            "Epoch 410/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4612 - accuracy: 0.8131 - val_loss: 0.6466 - val_accuracy: 0.7206\n",
            "Epoch 411/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4654 - accuracy: 0.8113 - val_loss: 0.6947 - val_accuracy: 0.6618\n",
            "Epoch 412/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4616 - accuracy: 0.8020 - val_loss: 0.6520 - val_accuracy: 0.7169\n",
            "Epoch 413/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4663 - accuracy: 0.8038 - val_loss: 0.6808 - val_accuracy: 0.6765\n",
            "Epoch 414/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4561 - accuracy: 0.8137 - val_loss: 0.6487 - val_accuracy: 0.7206\n",
            "Epoch 415/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4708 - accuracy: 0.8075 - val_loss: 0.6451 - val_accuracy: 0.7206\n",
            "Epoch 416/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4761 - accuracy: 0.8113 - val_loss: 0.6753 - val_accuracy: 0.6985\n",
            "Epoch 417/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4646 - accuracy: 0.8082 - val_loss: 0.6681 - val_accuracy: 0.7096\n",
            "Epoch 418/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4614 - accuracy: 0.8119 - val_loss: 0.6383 - val_accuracy: 0.7353\n",
            "Epoch 419/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4661 - accuracy: 0.8205 - val_loss: 0.6345 - val_accuracy: 0.7316\n",
            "Epoch 420/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4562 - accuracy: 0.8150 - val_loss: 0.6673 - val_accuracy: 0.6985\n",
            "Epoch 421/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4487 - accuracy: 0.8125 - val_loss: 0.6433 - val_accuracy: 0.7316\n",
            "Epoch 422/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4508 - accuracy: 0.8119 - val_loss: 0.6393 - val_accuracy: 0.7390\n",
            "Epoch 423/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4715 - accuracy: 0.8125 - val_loss: 0.6619 - val_accuracy: 0.6985\n",
            "Epoch 424/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4732 - accuracy: 0.8150 - val_loss: 0.6173 - val_accuracy: 0.7463\n",
            "Epoch 425/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4615 - accuracy: 0.8088 - val_loss: 0.6589 - val_accuracy: 0.7096\n",
            "Epoch 426/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4440 - accuracy: 0.8298 - val_loss: 0.6598 - val_accuracy: 0.6985\n",
            "Epoch 427/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4449 - accuracy: 0.8243 - val_loss: 0.6992 - val_accuracy: 0.6544\n",
            "Epoch 428/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4531 - accuracy: 0.8193 - val_loss: 0.6556 - val_accuracy: 0.7132\n",
            "Epoch 429/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4551 - accuracy: 0.8100 - val_loss: 0.6400 - val_accuracy: 0.7169\n",
            "Epoch 430/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4449 - accuracy: 0.8199 - val_loss: 0.6421 - val_accuracy: 0.7390\n",
            "Epoch 431/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4609 - accuracy: 0.8162 - val_loss: 0.6988 - val_accuracy: 0.6765\n",
            "Epoch 432/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4429 - accuracy: 0.8156 - val_loss: 0.7032 - val_accuracy: 0.6654\n",
            "Epoch 433/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4510 - accuracy: 0.8131 - val_loss: 0.6489 - val_accuracy: 0.7206\n",
            "Epoch 434/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4537 - accuracy: 0.8187 - val_loss: 0.6293 - val_accuracy: 0.7463\n",
            "Epoch 435/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4517 - accuracy: 0.8106 - val_loss: 0.6223 - val_accuracy: 0.7574\n",
            "Epoch 436/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4532 - accuracy: 0.8168 - val_loss: 0.6534 - val_accuracy: 0.7206\n",
            "Epoch 437/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4517 - accuracy: 0.8236 - val_loss: 0.6588 - val_accuracy: 0.7096\n",
            "Epoch 438/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4579 - accuracy: 0.8131 - val_loss: 0.6539 - val_accuracy: 0.7059\n",
            "Epoch 439/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4557 - accuracy: 0.8205 - val_loss: 0.6311 - val_accuracy: 0.7206\n",
            "Epoch 440/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4472 - accuracy: 0.8181 - val_loss: 0.6398 - val_accuracy: 0.7132\n",
            "Epoch 441/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4771 - accuracy: 0.8100 - val_loss: 0.6292 - val_accuracy: 0.7316\n",
            "Epoch 442/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4709 - accuracy: 0.8094 - val_loss: 0.6410 - val_accuracy: 0.7316\n",
            "Epoch 443/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4698 - accuracy: 0.8175 - val_loss: 0.6668 - val_accuracy: 0.7022\n",
            "Epoch 444/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4591 - accuracy: 0.8069 - val_loss: 0.6675 - val_accuracy: 0.6912\n",
            "Epoch 445/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4870 - accuracy: 0.8088 - val_loss: 0.6191 - val_accuracy: 0.7574\n",
            "Epoch 446/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4429 - accuracy: 0.8243 - val_loss: 0.6657 - val_accuracy: 0.6875\n",
            "Epoch 447/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4679 - accuracy: 0.8082 - val_loss: 0.6441 - val_accuracy: 0.7132\n",
            "Epoch 448/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4445 - accuracy: 0.8125 - val_loss: 0.7195 - val_accuracy: 0.6507\n",
            "Epoch 449/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4540 - accuracy: 0.8088 - val_loss: 0.6763 - val_accuracy: 0.6838\n",
            "Epoch 450/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4663 - accuracy: 0.8069 - val_loss: 0.6383 - val_accuracy: 0.7390\n",
            "Epoch 451/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4731 - accuracy: 0.8131 - val_loss: 0.6396 - val_accuracy: 0.7206\n",
            "Epoch 452/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4459 - accuracy: 0.8150 - val_loss: 0.6423 - val_accuracy: 0.7169\n",
            "Epoch 453/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4381 - accuracy: 0.8193 - val_loss: 0.6520 - val_accuracy: 0.7096\n",
            "Epoch 454/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4622 - accuracy: 0.8125 - val_loss: 0.6332 - val_accuracy: 0.7243\n",
            "Epoch 455/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4438 - accuracy: 0.8187 - val_loss: 0.6370 - val_accuracy: 0.7206\n",
            "Epoch 456/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4554 - accuracy: 0.8119 - val_loss: 0.6426 - val_accuracy: 0.7132\n",
            "Epoch 457/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4610 - accuracy: 0.8119 - val_loss: 0.6374 - val_accuracy: 0.7279\n",
            "Epoch 458/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4551 - accuracy: 0.8187 - val_loss: 0.6388 - val_accuracy: 0.7243\n",
            "Epoch 459/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4702 - accuracy: 0.7970 - val_loss: 0.6635 - val_accuracy: 0.6985\n",
            "Epoch 460/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4647 - accuracy: 0.8131 - val_loss: 0.6567 - val_accuracy: 0.7132\n",
            "Epoch 461/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4634 - accuracy: 0.8131 - val_loss: 0.6601 - val_accuracy: 0.6985\n",
            "Epoch 462/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4437 - accuracy: 0.8224 - val_loss: 0.6836 - val_accuracy: 0.6581\n",
            "Epoch 463/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4583 - accuracy: 0.8150 - val_loss: 0.6471 - val_accuracy: 0.7169\n",
            "Epoch 464/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4458 - accuracy: 0.8218 - val_loss: 0.6971 - val_accuracy: 0.6618\n",
            "Epoch 465/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4579 - accuracy: 0.8094 - val_loss: 0.6533 - val_accuracy: 0.7059\n",
            "Epoch 466/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4653 - accuracy: 0.8156 - val_loss: 0.6525 - val_accuracy: 0.6949\n",
            "Epoch 467/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4486 - accuracy: 0.8218 - val_loss: 0.6473 - val_accuracy: 0.6875\n",
            "Epoch 468/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4453 - accuracy: 0.8181 - val_loss: 0.6482 - val_accuracy: 0.6912\n",
            "Epoch 469/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4707 - accuracy: 0.8014 - val_loss: 0.6702 - val_accuracy: 0.6765\n",
            "Epoch 470/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4686 - accuracy: 0.8069 - val_loss: 0.6783 - val_accuracy: 0.6544\n",
            "Epoch 471/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4469 - accuracy: 0.8187 - val_loss: 0.6582 - val_accuracy: 0.6801\n",
            "Epoch 472/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4356 - accuracy: 0.8280 - val_loss: 0.6394 - val_accuracy: 0.7096\n",
            "Epoch 473/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4347 - accuracy: 0.8286 - val_loss: 0.6582 - val_accuracy: 0.6949\n",
            "Epoch 474/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4417 - accuracy: 0.8193 - val_loss: 0.6337 - val_accuracy: 0.7132\n",
            "Epoch 475/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4512 - accuracy: 0.8125 - val_loss: 0.6999 - val_accuracy: 0.6618\n",
            "Epoch 476/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4711 - accuracy: 0.8162 - val_loss: 0.6413 - val_accuracy: 0.7132\n",
            "Epoch 477/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4595 - accuracy: 0.8162 - val_loss: 0.6591 - val_accuracy: 0.6949\n",
            "Epoch 478/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4241 - accuracy: 0.8274 - val_loss: 0.6300 - val_accuracy: 0.7279\n",
            "Epoch 479/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4362 - accuracy: 0.8280 - val_loss: 0.7004 - val_accuracy: 0.6654\n",
            "Epoch 480/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4452 - accuracy: 0.8162 - val_loss: 0.6323 - val_accuracy: 0.7206\n",
            "Epoch 481/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4472 - accuracy: 0.8137 - val_loss: 0.6716 - val_accuracy: 0.6949\n",
            "Epoch 482/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4679 - accuracy: 0.8032 - val_loss: 0.6543 - val_accuracy: 0.6985\n",
            "Epoch 483/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4567 - accuracy: 0.8125 - val_loss: 0.6455 - val_accuracy: 0.7059\n",
            "Epoch 484/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4385 - accuracy: 0.8181 - val_loss: 0.6449 - val_accuracy: 0.7279\n",
            "Epoch 485/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4652 - accuracy: 0.8137 - val_loss: 0.6286 - val_accuracy: 0.7426\n",
            "Epoch 486/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4380 - accuracy: 0.8199 - val_loss: 0.6528 - val_accuracy: 0.7169\n",
            "Epoch 487/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4481 - accuracy: 0.8249 - val_loss: 0.6473 - val_accuracy: 0.7169\n",
            "Epoch 488/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4478 - accuracy: 0.8063 - val_loss: 0.6534 - val_accuracy: 0.7169\n",
            "Epoch 489/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4541 - accuracy: 0.8113 - val_loss: 0.6929 - val_accuracy: 0.6875\n",
            "Epoch 490/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4593 - accuracy: 0.8032 - val_loss: 0.6622 - val_accuracy: 0.7022\n",
            "Epoch 491/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4524 - accuracy: 0.8175 - val_loss: 0.6586 - val_accuracy: 0.6985\n",
            "Epoch 492/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4466 - accuracy: 0.8304 - val_loss: 0.6794 - val_accuracy: 0.6801\n",
            "Epoch 493/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4519 - accuracy: 0.8125 - val_loss: 0.6321 - val_accuracy: 0.7279\n",
            "Epoch 494/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4641 - accuracy: 0.8069 - val_loss: 0.6458 - val_accuracy: 0.7022\n",
            "Epoch 495/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4358 - accuracy: 0.8274 - val_loss: 0.6259 - val_accuracy: 0.7463\n",
            "Epoch 496/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4503 - accuracy: 0.8224 - val_loss: 0.6389 - val_accuracy: 0.7279\n",
            "Epoch 497/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4639 - accuracy: 0.8292 - val_loss: 0.6479 - val_accuracy: 0.7022\n",
            "Epoch 498/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4530 - accuracy: 0.8218 - val_loss: 0.6379 - val_accuracy: 0.7353\n",
            "Epoch 499/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4650 - accuracy: 0.8088 - val_loss: 0.6190 - val_accuracy: 0.7463\n",
            "Epoch 500/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4624 - accuracy: 0.8162 - val_loss: 0.6178 - val_accuracy: 0.7390\n",
            "Epoch 501/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4464 - accuracy: 0.8150 - val_loss: 0.6236 - val_accuracy: 0.7316\n",
            "Epoch 502/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4634 - accuracy: 0.8051 - val_loss: 0.6553 - val_accuracy: 0.6875\n",
            "Epoch 503/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4500 - accuracy: 0.8175 - val_loss: 0.6462 - val_accuracy: 0.6985\n",
            "Epoch 504/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4460 - accuracy: 0.8181 - val_loss: 0.6285 - val_accuracy: 0.7353\n",
            "Epoch 505/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4608 - accuracy: 0.8106 - val_loss: 0.6641 - val_accuracy: 0.6949\n",
            "Epoch 506/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4627 - accuracy: 0.8199 - val_loss: 0.6804 - val_accuracy: 0.6801\n",
            "Epoch 507/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4501 - accuracy: 0.8168 - val_loss: 0.6488 - val_accuracy: 0.7206\n",
            "Epoch 508/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4452 - accuracy: 0.8329 - val_loss: 0.6988 - val_accuracy: 0.6581\n",
            "Epoch 509/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4621 - accuracy: 0.8137 - val_loss: 0.6366 - val_accuracy: 0.7243\n",
            "Epoch 510/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4396 - accuracy: 0.8125 - val_loss: 0.6902 - val_accuracy: 0.6618\n",
            "Epoch 511/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4508 - accuracy: 0.8205 - val_loss: 0.6478 - val_accuracy: 0.7022\n",
            "Epoch 512/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4526 - accuracy: 0.8125 - val_loss: 0.6345 - val_accuracy: 0.7316\n",
            "Epoch 513/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4338 - accuracy: 0.8218 - val_loss: 0.6362 - val_accuracy: 0.7096\n",
            "Epoch 514/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4355 - accuracy: 0.8224 - val_loss: 0.6340 - val_accuracy: 0.7426\n",
            "Epoch 515/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4533 - accuracy: 0.8094 - val_loss: 0.6371 - val_accuracy: 0.7353\n",
            "Epoch 516/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4577 - accuracy: 0.8175 - val_loss: 0.6383 - val_accuracy: 0.7132\n",
            "Epoch 517/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4634 - accuracy: 0.8069 - val_loss: 0.6763 - val_accuracy: 0.6765\n",
            "Epoch 518/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4424 - accuracy: 0.8205 - val_loss: 0.6675 - val_accuracy: 0.6875\n",
            "Epoch 519/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4689 - accuracy: 0.8082 - val_loss: 0.6663 - val_accuracy: 0.6875\n",
            "Epoch 520/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4548 - accuracy: 0.8100 - val_loss: 0.6734 - val_accuracy: 0.6801\n",
            "Epoch 521/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4499 - accuracy: 0.8156 - val_loss: 0.6841 - val_accuracy: 0.6654\n",
            "Epoch 522/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4477 - accuracy: 0.8212 - val_loss: 0.6654 - val_accuracy: 0.6838\n",
            "Epoch 523/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4580 - accuracy: 0.8100 - val_loss: 0.6466 - val_accuracy: 0.7206\n",
            "Epoch 524/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4650 - accuracy: 0.8131 - val_loss: 0.7053 - val_accuracy: 0.6434\n",
            "Epoch 525/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4382 - accuracy: 0.8274 - val_loss: 0.6615 - val_accuracy: 0.6912\n",
            "Epoch 526/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4418 - accuracy: 0.8255 - val_loss: 0.6901 - val_accuracy: 0.6618\n",
            "Epoch 527/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4475 - accuracy: 0.8137 - val_loss: 0.6560 - val_accuracy: 0.6985\n",
            "Epoch 528/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4330 - accuracy: 0.8286 - val_loss: 0.6418 - val_accuracy: 0.7243\n",
            "Epoch 529/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4498 - accuracy: 0.8230 - val_loss: 0.6680 - val_accuracy: 0.6728\n",
            "Epoch 530/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4572 - accuracy: 0.8168 - val_loss: 0.6523 - val_accuracy: 0.6912\n",
            "Epoch 531/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4426 - accuracy: 0.8150 - val_loss: 0.6316 - val_accuracy: 0.7316\n",
            "Epoch 532/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4470 - accuracy: 0.8199 - val_loss: 0.7027 - val_accuracy: 0.6618\n",
            "Epoch 533/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4505 - accuracy: 0.8181 - val_loss: 0.6398 - val_accuracy: 0.7243\n",
            "Epoch 534/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4467 - accuracy: 0.8218 - val_loss: 0.6402 - val_accuracy: 0.7279\n",
            "Epoch 535/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4393 - accuracy: 0.8156 - val_loss: 0.6471 - val_accuracy: 0.7096\n",
            "Epoch 536/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4638 - accuracy: 0.8106 - val_loss: 0.6484 - val_accuracy: 0.6985\n",
            "Epoch 537/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4634 - accuracy: 0.8106 - val_loss: 0.6566 - val_accuracy: 0.6912\n",
            "Epoch 538/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4377 - accuracy: 0.8199 - val_loss: 0.6356 - val_accuracy: 0.7059\n",
            "Epoch 539/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4492 - accuracy: 0.8131 - val_loss: 0.6459 - val_accuracy: 0.7132\n",
            "Epoch 540/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4467 - accuracy: 0.8144 - val_loss: 0.6289 - val_accuracy: 0.7243\n",
            "Epoch 541/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4516 - accuracy: 0.8199 - val_loss: 0.6179 - val_accuracy: 0.7426\n",
            "Epoch 542/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4408 - accuracy: 0.8150 - val_loss: 0.6211 - val_accuracy: 0.7206\n",
            "Epoch 543/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4475 - accuracy: 0.8243 - val_loss: 0.6458 - val_accuracy: 0.6985\n",
            "Epoch 544/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4523 - accuracy: 0.8218 - val_loss: 0.6316 - val_accuracy: 0.7243\n",
            "Epoch 545/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4432 - accuracy: 0.8243 - val_loss: 0.6454 - val_accuracy: 0.7169\n",
            "Epoch 546/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 0.4442 - accuracy: 0.8187 - val_loss: 0.6329 - val_accuracy: 0.7353\n",
            "Epoch 547/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4617 - accuracy: 0.8175 - val_loss: 0.6472 - val_accuracy: 0.7059\n",
            "Epoch 548/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4347 - accuracy: 0.8150 - val_loss: 0.6451 - val_accuracy: 0.7132\n",
            "Epoch 549/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4791 - accuracy: 0.8001 - val_loss: 0.6756 - val_accuracy: 0.6838\n",
            "Epoch 550/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4317 - accuracy: 0.8230 - val_loss: 0.6584 - val_accuracy: 0.6912\n",
            "Epoch 551/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4356 - accuracy: 0.8205 - val_loss: 0.6455 - val_accuracy: 0.7169\n",
            "Epoch 552/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4528 - accuracy: 0.8144 - val_loss: 0.6702 - val_accuracy: 0.6949\n",
            "Epoch 553/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4549 - accuracy: 0.8144 - val_loss: 0.6636 - val_accuracy: 0.6838\n",
            "Epoch 554/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4648 - accuracy: 0.8125 - val_loss: 0.6528 - val_accuracy: 0.6912\n",
            "Epoch 555/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4465 - accuracy: 0.8113 - val_loss: 0.6708 - val_accuracy: 0.7022\n",
            "Epoch 556/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4409 - accuracy: 0.8218 - val_loss: 0.6349 - val_accuracy: 0.7316\n",
            "Epoch 557/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4554 - accuracy: 0.8187 - val_loss: 0.6318 - val_accuracy: 0.7500\n",
            "Epoch 558/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4573 - accuracy: 0.8094 - val_loss: 0.6372 - val_accuracy: 0.7206\n",
            "Epoch 559/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4443 - accuracy: 0.8205 - val_loss: 0.6589 - val_accuracy: 0.7059\n",
            "Epoch 560/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4496 - accuracy: 0.8156 - val_loss: 0.6498 - val_accuracy: 0.7132\n",
            "Epoch 561/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4405 - accuracy: 0.8224 - val_loss: 0.6428 - val_accuracy: 0.7059\n",
            "Epoch 562/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4453 - accuracy: 0.8199 - val_loss: 0.6565 - val_accuracy: 0.6801\n",
            "Epoch 563/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4559 - accuracy: 0.8125 - val_loss: 0.6307 - val_accuracy: 0.7243\n",
            "Epoch 564/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4281 - accuracy: 0.8292 - val_loss: 0.6415 - val_accuracy: 0.7279\n",
            "Epoch 565/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4347 - accuracy: 0.8230 - val_loss: 0.6732 - val_accuracy: 0.6618\n",
            "Epoch 566/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4417 - accuracy: 0.8261 - val_loss: 0.6431 - val_accuracy: 0.7096\n",
            "Epoch 567/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4253 - accuracy: 0.8267 - val_loss: 0.6389 - val_accuracy: 0.7206\n",
            "Epoch 568/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4527 - accuracy: 0.8162 - val_loss: 0.6904 - val_accuracy: 0.6618\n",
            "Epoch 569/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4434 - accuracy: 0.8069 - val_loss: 0.6522 - val_accuracy: 0.6949\n",
            "Epoch 570/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4581 - accuracy: 0.8175 - val_loss: 0.6528 - val_accuracy: 0.6985\n",
            "Epoch 571/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4390 - accuracy: 0.8243 - val_loss: 0.6533 - val_accuracy: 0.6949\n",
            "Epoch 572/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4340 - accuracy: 0.8168 - val_loss: 0.6299 - val_accuracy: 0.7243\n",
            "Epoch 573/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4431 - accuracy: 0.8218 - val_loss: 0.6930 - val_accuracy: 0.6654\n",
            "Epoch 574/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4374 - accuracy: 0.8175 - val_loss: 0.6548 - val_accuracy: 0.6912\n",
            "Epoch 575/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4453 - accuracy: 0.8168 - val_loss: 0.6693 - val_accuracy: 0.6654\n",
            "Epoch 576/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4460 - accuracy: 0.8261 - val_loss: 0.6511 - val_accuracy: 0.6912\n",
            "Epoch 577/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4441 - accuracy: 0.8205 - val_loss: 0.6740 - val_accuracy: 0.6728\n",
            "Epoch 578/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4562 - accuracy: 0.8187 - val_loss: 0.6563 - val_accuracy: 0.6875\n",
            "Epoch 579/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4308 - accuracy: 0.8348 - val_loss: 0.6906 - val_accuracy: 0.6728\n",
            "Epoch 580/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4373 - accuracy: 0.8236 - val_loss: 0.6187 - val_accuracy: 0.7353\n",
            "Epoch 581/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4415 - accuracy: 0.8162 - val_loss: 0.6852 - val_accuracy: 0.6838\n",
            "Epoch 582/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4359 - accuracy: 0.8175 - val_loss: 0.6464 - val_accuracy: 0.7059\n",
            "Epoch 583/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4312 - accuracy: 0.8311 - val_loss: 0.6262 - val_accuracy: 0.7316\n",
            "Epoch 584/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4311 - accuracy: 0.8311 - val_loss: 0.6457 - val_accuracy: 0.6912\n",
            "Epoch 585/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4543 - accuracy: 0.8113 - val_loss: 0.6673 - val_accuracy: 0.6875\n",
            "Epoch 586/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4316 - accuracy: 0.8323 - val_loss: 0.6535 - val_accuracy: 0.7059\n",
            "Epoch 587/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4385 - accuracy: 0.8274 - val_loss: 0.6457 - val_accuracy: 0.7059\n",
            "Epoch 588/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4353 - accuracy: 0.8230 - val_loss: 0.6487 - val_accuracy: 0.6912\n",
            "Epoch 589/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4449 - accuracy: 0.8137 - val_loss: 0.6605 - val_accuracy: 0.6838\n",
            "Epoch 590/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4358 - accuracy: 0.8280 - val_loss: 0.6357 - val_accuracy: 0.7316\n",
            "Epoch 591/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4495 - accuracy: 0.8088 - val_loss: 0.6485 - val_accuracy: 0.7022\n",
            "Epoch 592/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4366 - accuracy: 0.8218 - val_loss: 0.6557 - val_accuracy: 0.7022\n",
            "Epoch 593/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4341 - accuracy: 0.8379 - val_loss: 0.6295 - val_accuracy: 0.7426\n",
            "Epoch 594/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4577 - accuracy: 0.8199 - val_loss: 0.6347 - val_accuracy: 0.7243\n",
            "Epoch 595/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4548 - accuracy: 0.8168 - val_loss: 0.6514 - val_accuracy: 0.6985\n",
            "Epoch 596/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4335 - accuracy: 0.8298 - val_loss: 0.6222 - val_accuracy: 0.7574\n",
            "Epoch 597/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4303 - accuracy: 0.8218 - val_loss: 0.6213 - val_accuracy: 0.7279\n",
            "Epoch 598/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4409 - accuracy: 0.8144 - val_loss: 0.6276 - val_accuracy: 0.7279\n",
            "Epoch 599/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4364 - accuracy: 0.8311 - val_loss: 0.6279 - val_accuracy: 0.7353\n",
            "Epoch 600/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4256 - accuracy: 0.8329 - val_loss: 0.6472 - val_accuracy: 0.7096\n",
            "Epoch 601/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4273 - accuracy: 0.8286 - val_loss: 0.6621 - val_accuracy: 0.6949\n",
            "Epoch 602/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4599 - accuracy: 0.8119 - val_loss: 0.6524 - val_accuracy: 0.7022\n",
            "Epoch 603/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4476 - accuracy: 0.8144 - val_loss: 0.6234 - val_accuracy: 0.7500\n",
            "Epoch 604/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4408 - accuracy: 0.8261 - val_loss: 0.6430 - val_accuracy: 0.7243\n",
            "Epoch 605/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4544 - accuracy: 0.8162 - val_loss: 0.6302 - val_accuracy: 0.7390\n",
            "Epoch 606/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4313 - accuracy: 0.8267 - val_loss: 0.6415 - val_accuracy: 0.7169\n",
            "Epoch 607/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4204 - accuracy: 0.8311 - val_loss: 0.6577 - val_accuracy: 0.7096\n",
            "Epoch 608/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4337 - accuracy: 0.8342 - val_loss: 0.6418 - val_accuracy: 0.7132\n",
            "Epoch 609/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4281 - accuracy: 0.8360 - val_loss: 0.6386 - val_accuracy: 0.7243\n",
            "Epoch 610/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4403 - accuracy: 0.8280 - val_loss: 0.6779 - val_accuracy: 0.6912\n",
            "Epoch 611/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4431 - accuracy: 0.8261 - val_loss: 0.6552 - val_accuracy: 0.6912\n",
            "Epoch 612/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4164 - accuracy: 0.8348 - val_loss: 0.6168 - val_accuracy: 0.7463\n",
            "Epoch 613/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4488 - accuracy: 0.8267 - val_loss: 0.6634 - val_accuracy: 0.6875\n",
            "Epoch 614/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4374 - accuracy: 0.8317 - val_loss: 0.6611 - val_accuracy: 0.6912\n",
            "Epoch 615/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4312 - accuracy: 0.8292 - val_loss: 0.6176 - val_accuracy: 0.7537\n",
            "Epoch 616/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4200 - accuracy: 0.8317 - val_loss: 0.6510 - val_accuracy: 0.6949\n",
            "Epoch 617/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4427 - accuracy: 0.8243 - val_loss: 0.6373 - val_accuracy: 0.7206\n",
            "Epoch 618/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4321 - accuracy: 0.8236 - val_loss: 0.6560 - val_accuracy: 0.6838\n",
            "Epoch 619/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4248 - accuracy: 0.8373 - val_loss: 0.6581 - val_accuracy: 0.6949\n",
            "Epoch 620/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4295 - accuracy: 0.8199 - val_loss: 0.6599 - val_accuracy: 0.6949\n",
            "Epoch 621/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4303 - accuracy: 0.8335 - val_loss: 0.6286 - val_accuracy: 0.7426\n",
            "Epoch 622/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4478 - accuracy: 0.8329 - val_loss: 0.6405 - val_accuracy: 0.7316\n",
            "Epoch 623/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4349 - accuracy: 0.8243 - val_loss: 0.6306 - val_accuracy: 0.7279\n",
            "Epoch 624/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4583 - accuracy: 0.8187 - val_loss: 0.6339 - val_accuracy: 0.7353\n",
            "Epoch 625/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4245 - accuracy: 0.8348 - val_loss: 0.6454 - val_accuracy: 0.7169\n",
            "Epoch 626/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4559 - accuracy: 0.8181 - val_loss: 0.6303 - val_accuracy: 0.7279\n",
            "Epoch 627/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4361 - accuracy: 0.8218 - val_loss: 0.6497 - val_accuracy: 0.6985\n",
            "Epoch 628/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4233 - accuracy: 0.8304 - val_loss: 0.6514 - val_accuracy: 0.7059\n",
            "Epoch 629/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4492 - accuracy: 0.8175 - val_loss: 0.6441 - val_accuracy: 0.7169\n",
            "Epoch 630/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4535 - accuracy: 0.8168 - val_loss: 0.6398 - val_accuracy: 0.7243\n",
            "Epoch 631/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4324 - accuracy: 0.8304 - val_loss: 0.6344 - val_accuracy: 0.7169\n",
            "Epoch 632/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4486 - accuracy: 0.8193 - val_loss: 0.6111 - val_accuracy: 0.7426\n",
            "Epoch 633/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4474 - accuracy: 0.8187 - val_loss: 0.6502 - val_accuracy: 0.6949\n",
            "Epoch 634/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4527 - accuracy: 0.8187 - val_loss: 0.6265 - val_accuracy: 0.7316\n",
            "Epoch 635/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4255 - accuracy: 0.8329 - val_loss: 0.6539 - val_accuracy: 0.6875\n",
            "Epoch 636/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4448 - accuracy: 0.8193 - val_loss: 0.6702 - val_accuracy: 0.6691\n",
            "Epoch 637/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4397 - accuracy: 0.8243 - val_loss: 0.6431 - val_accuracy: 0.7169\n",
            "Epoch 638/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4217 - accuracy: 0.8298 - val_loss: 0.6551 - val_accuracy: 0.6985\n",
            "Epoch 639/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4377 - accuracy: 0.8205 - val_loss: 0.6445 - val_accuracy: 0.7096\n",
            "Epoch 640/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4517 - accuracy: 0.8187 - val_loss: 0.6781 - val_accuracy: 0.6618\n",
            "Epoch 641/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4517 - accuracy: 0.8150 - val_loss: 0.6382 - val_accuracy: 0.7390\n",
            "Epoch 642/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4397 - accuracy: 0.8199 - val_loss: 0.6357 - val_accuracy: 0.7132\n",
            "Epoch 643/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4402 - accuracy: 0.8205 - val_loss: 0.6438 - val_accuracy: 0.7096\n",
            "Epoch 644/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4345 - accuracy: 0.8243 - val_loss: 0.6671 - val_accuracy: 0.6875\n",
            "Epoch 645/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4224 - accuracy: 0.8317 - val_loss: 0.6287 - val_accuracy: 0.7169\n",
            "Epoch 646/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4401 - accuracy: 0.8236 - val_loss: 0.6779 - val_accuracy: 0.6838\n",
            "Epoch 647/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4418 - accuracy: 0.8181 - val_loss: 0.6373 - val_accuracy: 0.7169\n",
            "Epoch 648/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4469 - accuracy: 0.8168 - val_loss: 0.6582 - val_accuracy: 0.7096\n",
            "Epoch 649/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4493 - accuracy: 0.8342 - val_loss: 0.6390 - val_accuracy: 0.7353\n",
            "Epoch 650/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4169 - accuracy: 0.8162 - val_loss: 0.6246 - val_accuracy: 0.7426\n",
            "Epoch 651/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4512 - accuracy: 0.8187 - val_loss: 0.6441 - val_accuracy: 0.7059\n",
            "Epoch 652/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4473 - accuracy: 0.8162 - val_loss: 0.6691 - val_accuracy: 0.6728\n",
            "Epoch 653/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4359 - accuracy: 0.8162 - val_loss: 0.6508 - val_accuracy: 0.6949\n",
            "Epoch 654/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4433 - accuracy: 0.8236 - val_loss: 0.6505 - val_accuracy: 0.7132\n",
            "Epoch 655/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4395 - accuracy: 0.8323 - val_loss: 0.6529 - val_accuracy: 0.7096\n",
            "Epoch 656/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4498 - accuracy: 0.8156 - val_loss: 0.6586 - val_accuracy: 0.6912\n",
            "Epoch 657/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4375 - accuracy: 0.8218 - val_loss: 0.6358 - val_accuracy: 0.7279\n",
            "Epoch 658/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4322 - accuracy: 0.8156 - val_loss: 0.6560 - val_accuracy: 0.7096\n",
            "Epoch 659/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4386 - accuracy: 0.8323 - val_loss: 0.6418 - val_accuracy: 0.7096\n",
            "Epoch 660/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4217 - accuracy: 0.8348 - val_loss: 0.6524 - val_accuracy: 0.7096\n",
            "Epoch 661/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4401 - accuracy: 0.8181 - val_loss: 0.6443 - val_accuracy: 0.7243\n",
            "Epoch 662/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4495 - accuracy: 0.8274 - val_loss: 0.6940 - val_accuracy: 0.6765\n",
            "Epoch 663/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4377 - accuracy: 0.8236 - val_loss: 0.6600 - val_accuracy: 0.6912\n",
            "Epoch 664/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4432 - accuracy: 0.8156 - val_loss: 0.6439 - val_accuracy: 0.6985\n",
            "Epoch 665/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4494 - accuracy: 0.8199 - val_loss: 0.6522 - val_accuracy: 0.7022\n",
            "Epoch 666/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4538 - accuracy: 0.8100 - val_loss: 0.6420 - val_accuracy: 0.7206\n",
            "Epoch 667/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4247 - accuracy: 0.8323 - val_loss: 0.6582 - val_accuracy: 0.6912\n",
            "Epoch 668/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4448 - accuracy: 0.8187 - val_loss: 0.6522 - val_accuracy: 0.6912\n",
            "Epoch 669/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4434 - accuracy: 0.8261 - val_loss: 0.6992 - val_accuracy: 0.6544\n",
            "Epoch 670/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4335 - accuracy: 0.8255 - val_loss: 0.6437 - val_accuracy: 0.7096\n",
            "Epoch 671/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4439 - accuracy: 0.8175 - val_loss: 0.6742 - val_accuracy: 0.6949\n",
            "Epoch 672/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4288 - accuracy: 0.8311 - val_loss: 0.6442 - val_accuracy: 0.7022\n",
            "Epoch 673/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4345 - accuracy: 0.8175 - val_loss: 0.6749 - val_accuracy: 0.6912\n",
            "Epoch 674/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4360 - accuracy: 0.8311 - val_loss: 0.6377 - val_accuracy: 0.7316\n",
            "Epoch 675/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4315 - accuracy: 0.8286 - val_loss: 0.6759 - val_accuracy: 0.6801\n",
            "Epoch 676/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4327 - accuracy: 0.8224 - val_loss: 0.6598 - val_accuracy: 0.7022\n",
            "Epoch 677/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4418 - accuracy: 0.8230 - val_loss: 0.6601 - val_accuracy: 0.6875\n",
            "Epoch 678/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4324 - accuracy: 0.8267 - val_loss: 0.6409 - val_accuracy: 0.7132\n",
            "Epoch 679/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4266 - accuracy: 0.8311 - val_loss: 0.6345 - val_accuracy: 0.7279\n",
            "Epoch 680/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4488 - accuracy: 0.8150 - val_loss: 0.6687 - val_accuracy: 0.7022\n",
            "Epoch 681/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4228 - accuracy: 0.8385 - val_loss: 0.6787 - val_accuracy: 0.6875\n",
            "Epoch 682/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4437 - accuracy: 0.8224 - val_loss: 0.6422 - val_accuracy: 0.7096\n",
            "Epoch 683/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4378 - accuracy: 0.8175 - val_loss: 0.6691 - val_accuracy: 0.6875\n",
            "Epoch 684/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4431 - accuracy: 0.8274 - val_loss: 0.6549 - val_accuracy: 0.6985\n",
            "Epoch 685/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4367 - accuracy: 0.8255 - val_loss: 0.6549 - val_accuracy: 0.6912\n",
            "Epoch 686/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4351 - accuracy: 0.8311 - val_loss: 0.6897 - val_accuracy: 0.6728\n",
            "Epoch 687/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4294 - accuracy: 0.8156 - val_loss: 0.6828 - val_accuracy: 0.6654\n",
            "Epoch 688/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4269 - accuracy: 0.8280 - val_loss: 0.6720 - val_accuracy: 0.6875\n",
            "Epoch 689/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4410 - accuracy: 0.8212 - val_loss: 0.6589 - val_accuracy: 0.6985\n",
            "Epoch 690/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4281 - accuracy: 0.8255 - val_loss: 0.6229 - val_accuracy: 0.7684\n",
            "Epoch 691/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4501 - accuracy: 0.8199 - val_loss: 0.6405 - val_accuracy: 0.7059\n",
            "Epoch 692/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4473 - accuracy: 0.8119 - val_loss: 0.6495 - val_accuracy: 0.7022\n",
            "Epoch 693/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4461 - accuracy: 0.8218 - val_loss: 0.6519 - val_accuracy: 0.7022\n",
            "Epoch 694/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4413 - accuracy: 0.8106 - val_loss: 0.6633 - val_accuracy: 0.7096\n",
            "Epoch 695/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4191 - accuracy: 0.8311 - val_loss: 0.6968 - val_accuracy: 0.6618\n",
            "Epoch 696/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4503 - accuracy: 0.8199 - val_loss: 0.6614 - val_accuracy: 0.6912\n",
            "Epoch 697/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4348 - accuracy: 0.8243 - val_loss: 0.6758 - val_accuracy: 0.6801\n",
            "Epoch 698/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4260 - accuracy: 0.8298 - val_loss: 0.6836 - val_accuracy: 0.6875\n",
            "Epoch 699/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4480 - accuracy: 0.8156 - val_loss: 0.6591 - val_accuracy: 0.6949\n",
            "Epoch 700/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4204 - accuracy: 0.8280 - val_loss: 0.6595 - val_accuracy: 0.6949\n",
            "Epoch 701/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4324 - accuracy: 0.8205 - val_loss: 0.6714 - val_accuracy: 0.6912\n",
            "Epoch 702/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4192 - accuracy: 0.8236 - val_loss: 0.6455 - val_accuracy: 0.7096\n",
            "Epoch 703/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4356 - accuracy: 0.8280 - val_loss: 0.6353 - val_accuracy: 0.7316\n",
            "Epoch 704/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4508 - accuracy: 0.8255 - val_loss: 0.6448 - val_accuracy: 0.7096\n",
            "Epoch 705/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4267 - accuracy: 0.8286 - val_loss: 0.6665 - val_accuracy: 0.6912\n",
            "Epoch 706/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4324 - accuracy: 0.8249 - val_loss: 0.6535 - val_accuracy: 0.7059\n",
            "Epoch 707/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4292 - accuracy: 0.8298 - val_loss: 0.6589 - val_accuracy: 0.6912\n",
            "Epoch 708/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4331 - accuracy: 0.8267 - val_loss: 0.6466 - val_accuracy: 0.7059\n",
            "Epoch 709/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4325 - accuracy: 0.8274 - val_loss: 0.6422 - val_accuracy: 0.7059\n",
            "Epoch 710/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4318 - accuracy: 0.8342 - val_loss: 0.6427 - val_accuracy: 0.7096\n",
            "Epoch 711/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4236 - accuracy: 0.8335 - val_loss: 0.6330 - val_accuracy: 0.7169\n",
            "Epoch 712/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4253 - accuracy: 0.8224 - val_loss: 0.6448 - val_accuracy: 0.7096\n",
            "Epoch 713/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4311 - accuracy: 0.8317 - val_loss: 0.6819 - val_accuracy: 0.6912\n",
            "Epoch 714/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4220 - accuracy: 0.8249 - val_loss: 0.6733 - val_accuracy: 0.6875\n",
            "Epoch 715/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4346 - accuracy: 0.8267 - val_loss: 0.6400 - val_accuracy: 0.7059\n",
            "Epoch 716/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4280 - accuracy: 0.8323 - val_loss: 0.6689 - val_accuracy: 0.7022\n",
            "Epoch 717/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4191 - accuracy: 0.8373 - val_loss: 0.6675 - val_accuracy: 0.6912\n",
            "Epoch 718/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4327 - accuracy: 0.8360 - val_loss: 0.6473 - val_accuracy: 0.7169\n",
            "Epoch 719/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4373 - accuracy: 0.8292 - val_loss: 0.6407 - val_accuracy: 0.7243\n",
            "Epoch 720/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4250 - accuracy: 0.8286 - val_loss: 0.6487 - val_accuracy: 0.7243\n",
            "Epoch 721/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4508 - accuracy: 0.8131 - val_loss: 0.6502 - val_accuracy: 0.7059\n",
            "Epoch 722/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4420 - accuracy: 0.8311 - val_loss: 0.6486 - val_accuracy: 0.7059\n",
            "Epoch 723/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4340 - accuracy: 0.8249 - val_loss: 0.7055 - val_accuracy: 0.6765\n",
            "Epoch 724/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4326 - accuracy: 0.8224 - val_loss: 0.6655 - val_accuracy: 0.6875\n",
            "Epoch 725/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4286 - accuracy: 0.8255 - val_loss: 0.6435 - val_accuracy: 0.7132\n",
            "Epoch 726/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4377 - accuracy: 0.8236 - val_loss: 0.6609 - val_accuracy: 0.6949\n",
            "Epoch 727/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4302 - accuracy: 0.8410 - val_loss: 0.6515 - val_accuracy: 0.7022\n",
            "Epoch 728/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4337 - accuracy: 0.8212 - val_loss: 0.6753 - val_accuracy: 0.6912\n",
            "Epoch 729/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4281 - accuracy: 0.8274 - val_loss: 0.6517 - val_accuracy: 0.6949\n",
            "Epoch 730/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4386 - accuracy: 0.8205 - val_loss: 0.6417 - val_accuracy: 0.7169\n",
            "Epoch 731/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4343 - accuracy: 0.8193 - val_loss: 0.6557 - val_accuracy: 0.7022\n",
            "Epoch 732/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4418 - accuracy: 0.8137 - val_loss: 0.6695 - val_accuracy: 0.7022\n",
            "Epoch 733/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4373 - accuracy: 0.8187 - val_loss: 0.6554 - val_accuracy: 0.7022\n",
            "Epoch 734/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4278 - accuracy: 0.8354 - val_loss: 0.6623 - val_accuracy: 0.6912\n",
            "Epoch 735/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4222 - accuracy: 0.8335 - val_loss: 0.6456 - val_accuracy: 0.7316\n",
            "Epoch 736/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4434 - accuracy: 0.8323 - val_loss: 0.6571 - val_accuracy: 0.7132\n",
            "Epoch 737/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4397 - accuracy: 0.8286 - val_loss: 0.6707 - val_accuracy: 0.6949\n",
            "Epoch 738/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4285 - accuracy: 0.8335 - val_loss: 0.6821 - val_accuracy: 0.6949\n",
            "Epoch 739/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4253 - accuracy: 0.8286 - val_loss: 0.6499 - val_accuracy: 0.7096\n",
            "Epoch 740/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4402 - accuracy: 0.8249 - val_loss: 0.6467 - val_accuracy: 0.7132\n",
            "Epoch 741/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4273 - accuracy: 0.8329 - val_loss: 0.6679 - val_accuracy: 0.6912\n",
            "Epoch 742/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4363 - accuracy: 0.8261 - val_loss: 0.6569 - val_accuracy: 0.7206\n",
            "Epoch 743/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4178 - accuracy: 0.8329 - val_loss: 0.7323 - val_accuracy: 0.6397\n",
            "Epoch 744/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4354 - accuracy: 0.8317 - val_loss: 0.6688 - val_accuracy: 0.7022\n",
            "Epoch 745/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4340 - accuracy: 0.8317 - val_loss: 0.6509 - val_accuracy: 0.7059\n",
            "Epoch 746/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4324 - accuracy: 0.8286 - val_loss: 0.6508 - val_accuracy: 0.7096\n",
            "Epoch 747/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4238 - accuracy: 0.8304 - val_loss: 0.6377 - val_accuracy: 0.7169\n",
            "Epoch 748/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4377 - accuracy: 0.8218 - val_loss: 0.6190 - val_accuracy: 0.7426\n",
            "Epoch 749/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4458 - accuracy: 0.8199 - val_loss: 0.7095 - val_accuracy: 0.6581\n",
            "Epoch 750/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4415 - accuracy: 0.8168 - val_loss: 0.6483 - val_accuracy: 0.7169\n",
            "Epoch 751/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4327 - accuracy: 0.8212 - val_loss: 0.6862 - val_accuracy: 0.6581\n",
            "Epoch 752/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4240 - accuracy: 0.8274 - val_loss: 0.6509 - val_accuracy: 0.7022\n",
            "Epoch 753/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4328 - accuracy: 0.8230 - val_loss: 0.6388 - val_accuracy: 0.7169\n",
            "Epoch 754/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4328 - accuracy: 0.8329 - val_loss: 0.7010 - val_accuracy: 0.6765\n",
            "Epoch 755/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4308 - accuracy: 0.8311 - val_loss: 0.6367 - val_accuracy: 0.7059\n",
            "Epoch 756/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4398 - accuracy: 0.8175 - val_loss: 0.6590 - val_accuracy: 0.6949\n",
            "Epoch 757/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4185 - accuracy: 0.8453 - val_loss: 0.7049 - val_accuracy: 0.6728\n",
            "Epoch 758/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4332 - accuracy: 0.8205 - val_loss: 0.6563 - val_accuracy: 0.7096\n",
            "Epoch 759/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4235 - accuracy: 0.8280 - val_loss: 0.6482 - val_accuracy: 0.7096\n",
            "Epoch 760/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4245 - accuracy: 0.8181 - val_loss: 0.6850 - val_accuracy: 0.6949\n",
            "Epoch 761/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4258 - accuracy: 0.8311 - val_loss: 0.6469 - val_accuracy: 0.7132\n",
            "Epoch 762/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4040 - accuracy: 0.8366 - val_loss: 0.6430 - val_accuracy: 0.7132\n",
            "Epoch 763/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4181 - accuracy: 0.8286 - val_loss: 0.6331 - val_accuracy: 0.7316\n",
            "Epoch 764/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4427 - accuracy: 0.8168 - val_loss: 0.6379 - val_accuracy: 0.7279\n",
            "Epoch 765/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4284 - accuracy: 0.8274 - val_loss: 0.7168 - val_accuracy: 0.6507\n",
            "Epoch 766/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4183 - accuracy: 0.8354 - val_loss: 0.6592 - val_accuracy: 0.6912\n",
            "Epoch 767/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4220 - accuracy: 0.8298 - val_loss: 0.6502 - val_accuracy: 0.7022\n",
            "Epoch 768/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4364 - accuracy: 0.8156 - val_loss: 0.6631 - val_accuracy: 0.6912\n",
            "Epoch 769/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4479 - accuracy: 0.8137 - val_loss: 0.6364 - val_accuracy: 0.7169\n",
            "Epoch 770/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4471 - accuracy: 0.8144 - val_loss: 0.6257 - val_accuracy: 0.7316\n",
            "Epoch 771/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4236 - accuracy: 0.8292 - val_loss: 0.6291 - val_accuracy: 0.7243\n",
            "Epoch 772/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4450 - accuracy: 0.8168 - val_loss: 0.6600 - val_accuracy: 0.6801\n",
            "Epoch 773/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4399 - accuracy: 0.8168 - val_loss: 0.6437 - val_accuracy: 0.7022\n",
            "Epoch 774/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4368 - accuracy: 0.8274 - val_loss: 0.6519 - val_accuracy: 0.7096\n",
            "Epoch 775/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4401 - accuracy: 0.8199 - val_loss: 0.6417 - val_accuracy: 0.7243\n",
            "Epoch 776/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4191 - accuracy: 0.8317 - val_loss: 0.6435 - val_accuracy: 0.7169\n",
            "Epoch 777/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4256 - accuracy: 0.8280 - val_loss: 0.6574 - val_accuracy: 0.6949\n",
            "Epoch 778/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4254 - accuracy: 0.8342 - val_loss: 0.6662 - val_accuracy: 0.6838\n",
            "Epoch 779/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4214 - accuracy: 0.8274 - val_loss: 0.6557 - val_accuracy: 0.6912\n",
            "Epoch 780/1000\n",
            "51/51 [==============================] - 5s 91ms/step - loss: 0.4219 - accuracy: 0.8335 - val_loss: 0.6573 - val_accuracy: 0.6949\n",
            "Epoch 781/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4312 - accuracy: 0.8292 - val_loss: 0.6381 - val_accuracy: 0.7169\n",
            "Epoch 782/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4294 - accuracy: 0.8311 - val_loss: 0.6468 - val_accuracy: 0.7022\n",
            "Epoch 783/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4212 - accuracy: 0.8243 - val_loss: 0.6536 - val_accuracy: 0.6949\n",
            "Epoch 784/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4267 - accuracy: 0.8212 - val_loss: 0.6526 - val_accuracy: 0.6949\n",
            "Epoch 785/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4217 - accuracy: 0.8360 - val_loss: 0.6678 - val_accuracy: 0.6801\n",
            "Epoch 786/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4305 - accuracy: 0.8274 - val_loss: 0.6592 - val_accuracy: 0.6838\n",
            "Epoch 787/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4258 - accuracy: 0.8261 - val_loss: 0.6903 - val_accuracy: 0.6618\n",
            "Epoch 788/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4331 - accuracy: 0.8212 - val_loss: 0.6902 - val_accuracy: 0.6581\n",
            "Epoch 789/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4363 - accuracy: 0.8280 - val_loss: 0.6658 - val_accuracy: 0.6765\n",
            "Epoch 790/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4242 - accuracy: 0.8274 - val_loss: 0.6635 - val_accuracy: 0.6912\n",
            "Epoch 791/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4317 - accuracy: 0.8224 - val_loss: 0.6735 - val_accuracy: 0.6765\n",
            "Epoch 792/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4257 - accuracy: 0.8385 - val_loss: 0.6696 - val_accuracy: 0.6765\n",
            "Epoch 793/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4374 - accuracy: 0.8274 - val_loss: 0.7109 - val_accuracy: 0.6287\n",
            "Epoch 794/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4345 - accuracy: 0.8267 - val_loss: 0.6434 - val_accuracy: 0.7059\n",
            "Epoch 795/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4083 - accuracy: 0.8342 - val_loss: 0.6403 - val_accuracy: 0.7022\n",
            "Epoch 796/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4380 - accuracy: 0.8224 - val_loss: 0.6567 - val_accuracy: 0.6985\n",
            "Epoch 797/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4078 - accuracy: 0.8342 - val_loss: 0.6544 - val_accuracy: 0.6912\n",
            "Epoch 798/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4494 - accuracy: 0.8199 - val_loss: 0.7109 - val_accuracy: 0.6728\n",
            "Epoch 799/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4296 - accuracy: 0.8280 - val_loss: 0.6763 - val_accuracy: 0.6765\n",
            "Epoch 800/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4351 - accuracy: 0.8224 - val_loss: 0.6520 - val_accuracy: 0.6912\n",
            "Epoch 801/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4363 - accuracy: 0.8212 - val_loss: 0.6528 - val_accuracy: 0.6912\n",
            "Epoch 802/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4519 - accuracy: 0.8205 - val_loss: 0.6485 - val_accuracy: 0.6875\n",
            "Epoch 803/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4083 - accuracy: 0.8323 - val_loss: 0.6580 - val_accuracy: 0.6949\n",
            "Epoch 804/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4376 - accuracy: 0.8193 - val_loss: 0.6562 - val_accuracy: 0.6912\n",
            "Epoch 805/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4239 - accuracy: 0.8280 - val_loss: 0.6756 - val_accuracy: 0.6912\n",
            "Epoch 806/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4214 - accuracy: 0.8366 - val_loss: 0.6601 - val_accuracy: 0.7022\n",
            "Epoch 807/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4092 - accuracy: 0.8292 - val_loss: 0.6477 - val_accuracy: 0.6985\n",
            "Epoch 808/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4399 - accuracy: 0.8261 - val_loss: 0.6730 - val_accuracy: 0.6875\n",
            "Epoch 809/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 0.4251 - accuracy: 0.8230 - val_loss: 0.6609 - val_accuracy: 0.6912\n",
            "Epoch 810/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4418 - accuracy: 0.8224 - val_loss: 0.6586 - val_accuracy: 0.7022\n",
            "Epoch 811/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4295 - accuracy: 0.8298 - val_loss: 0.6782 - val_accuracy: 0.6912\n",
            "Epoch 812/1000\n",
            "51/51 [==============================] - 5s 90ms/step - loss: 0.4298 - accuracy: 0.8298 - val_loss: 0.6949 - val_accuracy: 0.6801\n",
            "Epoch 813/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4285 - accuracy: 0.8335 - val_loss: 0.6535 - val_accuracy: 0.7022\n",
            "Epoch 814/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4228 - accuracy: 0.8317 - val_loss: 0.6579 - val_accuracy: 0.6912\n",
            "Epoch 815/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4315 - accuracy: 0.8175 - val_loss: 0.6302 - val_accuracy: 0.7316\n",
            "Epoch 816/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4238 - accuracy: 0.8304 - val_loss: 0.6602 - val_accuracy: 0.7059\n",
            "Epoch 817/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4335 - accuracy: 0.8193 - val_loss: 0.6475 - val_accuracy: 0.7022\n",
            "Epoch 818/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4299 - accuracy: 0.8329 - val_loss: 0.6378 - val_accuracy: 0.7206\n",
            "Epoch 819/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4250 - accuracy: 0.8261 - val_loss: 0.6860 - val_accuracy: 0.6765\n",
            "Epoch 820/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4173 - accuracy: 0.8422 - val_loss: 0.6965 - val_accuracy: 0.6875\n",
            "Epoch 821/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4258 - accuracy: 0.8342 - val_loss: 0.6908 - val_accuracy: 0.6838\n",
            "Epoch 822/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4200 - accuracy: 0.8335 - val_loss: 0.6533 - val_accuracy: 0.7022\n",
            "Epoch 823/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4191 - accuracy: 0.8317 - val_loss: 0.6369 - val_accuracy: 0.7243\n",
            "Epoch 824/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4372 - accuracy: 0.8236 - val_loss: 0.6477 - val_accuracy: 0.7059\n",
            "Epoch 825/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4111 - accuracy: 0.8373 - val_loss: 0.6493 - val_accuracy: 0.7096\n",
            "Epoch 826/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4262 - accuracy: 0.8342 - val_loss: 0.6440 - val_accuracy: 0.7022\n",
            "Epoch 827/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4398 - accuracy: 0.8249 - val_loss: 0.6637 - val_accuracy: 0.6875\n",
            "Epoch 828/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4472 - accuracy: 0.8199 - val_loss: 0.6772 - val_accuracy: 0.6838\n",
            "Epoch 829/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4208 - accuracy: 0.8280 - val_loss: 0.6539 - val_accuracy: 0.7096\n",
            "Epoch 830/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4288 - accuracy: 0.8360 - val_loss: 0.6556 - val_accuracy: 0.7022\n",
            "Epoch 831/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4180 - accuracy: 0.8360 - val_loss: 0.6684 - val_accuracy: 0.7022\n",
            "Epoch 832/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4163 - accuracy: 0.8329 - val_loss: 0.6516 - val_accuracy: 0.7022\n",
            "Epoch 833/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4173 - accuracy: 0.8391 - val_loss: 0.6759 - val_accuracy: 0.6949\n",
            "Epoch 834/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4290 - accuracy: 0.8329 - val_loss: 0.6657 - val_accuracy: 0.6875\n",
            "Epoch 835/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4232 - accuracy: 0.8298 - val_loss: 0.6880 - val_accuracy: 0.6618\n",
            "Epoch 836/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4233 - accuracy: 0.8267 - val_loss: 0.6917 - val_accuracy: 0.6765\n",
            "Epoch 837/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4452 - accuracy: 0.8261 - val_loss: 0.6689 - val_accuracy: 0.6801\n",
            "Epoch 838/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4208 - accuracy: 0.8304 - val_loss: 0.6649 - val_accuracy: 0.6912\n",
            "Epoch 839/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4330 - accuracy: 0.8267 - val_loss: 0.6638 - val_accuracy: 0.6912\n",
            "Epoch 840/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4291 - accuracy: 0.8267 - val_loss: 0.6684 - val_accuracy: 0.6912\n",
            "Epoch 841/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4192 - accuracy: 0.8230 - val_loss: 0.6833 - val_accuracy: 0.6875\n",
            "Epoch 842/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4341 - accuracy: 0.8168 - val_loss: 0.6729 - val_accuracy: 0.6949\n",
            "Epoch 843/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4176 - accuracy: 0.8472 - val_loss: 0.7163 - val_accuracy: 0.6581\n",
            "Epoch 844/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4244 - accuracy: 0.8236 - val_loss: 0.6733 - val_accuracy: 0.6838\n",
            "Epoch 845/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4256 - accuracy: 0.8317 - val_loss: 0.6376 - val_accuracy: 0.7169\n",
            "Epoch 846/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4200 - accuracy: 0.8434 - val_loss: 0.6608 - val_accuracy: 0.6949\n",
            "Epoch 847/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4248 - accuracy: 0.8385 - val_loss: 0.6572 - val_accuracy: 0.7096\n",
            "Epoch 848/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4229 - accuracy: 0.8329 - val_loss: 0.6625 - val_accuracy: 0.6912\n",
            "Epoch 849/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4191 - accuracy: 0.8360 - val_loss: 0.6566 - val_accuracy: 0.7022\n",
            "Epoch 850/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4078 - accuracy: 0.8323 - val_loss: 0.6621 - val_accuracy: 0.6838\n",
            "Epoch 851/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4101 - accuracy: 0.8379 - val_loss: 0.6516 - val_accuracy: 0.7132\n",
            "Epoch 852/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4146 - accuracy: 0.8317 - val_loss: 0.6655 - val_accuracy: 0.6985\n",
            "Epoch 853/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4302 - accuracy: 0.8243 - val_loss: 0.6288 - val_accuracy: 0.7390\n",
            "Epoch 854/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4078 - accuracy: 0.8335 - val_loss: 0.6591 - val_accuracy: 0.6985\n",
            "Epoch 855/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4205 - accuracy: 0.8323 - val_loss: 0.6834 - val_accuracy: 0.6801\n",
            "Epoch 856/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4312 - accuracy: 0.8317 - val_loss: 0.6557 - val_accuracy: 0.7022\n",
            "Epoch 857/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4195 - accuracy: 0.8348 - val_loss: 0.6761 - val_accuracy: 0.6985\n",
            "Epoch 858/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4278 - accuracy: 0.8224 - val_loss: 0.6531 - val_accuracy: 0.6985\n",
            "Epoch 859/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4357 - accuracy: 0.8230 - val_loss: 0.6604 - val_accuracy: 0.6949\n",
            "Epoch 860/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4254 - accuracy: 0.8286 - val_loss: 0.6495 - val_accuracy: 0.7022\n",
            "Epoch 861/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4280 - accuracy: 0.8335 - val_loss: 0.6327 - val_accuracy: 0.7096\n",
            "Epoch 862/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4147 - accuracy: 0.8385 - val_loss: 0.6511 - val_accuracy: 0.6949\n",
            "Epoch 863/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4320 - accuracy: 0.8286 - val_loss: 0.7072 - val_accuracy: 0.6654\n",
            "Epoch 864/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4156 - accuracy: 0.8410 - val_loss: 0.6606 - val_accuracy: 0.6912\n",
            "Epoch 865/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4424 - accuracy: 0.8205 - val_loss: 0.6231 - val_accuracy: 0.7353\n",
            "Epoch 866/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4278 - accuracy: 0.8329 - val_loss: 0.6444 - val_accuracy: 0.6985\n",
            "Epoch 867/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4310 - accuracy: 0.8335 - val_loss: 0.6602 - val_accuracy: 0.6912\n",
            "Epoch 868/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4152 - accuracy: 0.8354 - val_loss: 0.6748 - val_accuracy: 0.6875\n",
            "Epoch 869/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4270 - accuracy: 0.8298 - val_loss: 0.6482 - val_accuracy: 0.7059\n",
            "Epoch 870/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4269 - accuracy: 0.8335 - val_loss: 0.6492 - val_accuracy: 0.6985\n",
            "Epoch 871/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4322 - accuracy: 0.8218 - val_loss: 0.6753 - val_accuracy: 0.6912\n",
            "Epoch 872/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4182 - accuracy: 0.8354 - val_loss: 0.6838 - val_accuracy: 0.6912\n",
            "Epoch 873/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4174 - accuracy: 0.8342 - val_loss: 0.6840 - val_accuracy: 0.6912\n",
            "Epoch 874/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4226 - accuracy: 0.8329 - val_loss: 0.6644 - val_accuracy: 0.6949\n",
            "Epoch 875/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4264 - accuracy: 0.8323 - val_loss: 0.7059 - val_accuracy: 0.6728\n",
            "Epoch 876/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4282 - accuracy: 0.8267 - val_loss: 0.6576 - val_accuracy: 0.6912\n",
            "Epoch 877/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4308 - accuracy: 0.8236 - val_loss: 0.6691 - val_accuracy: 0.6949\n",
            "Epoch 878/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4336 - accuracy: 0.8205 - val_loss: 0.6728 - val_accuracy: 0.6912\n",
            "Epoch 879/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4157 - accuracy: 0.8379 - val_loss: 0.6966 - val_accuracy: 0.6654\n",
            "Epoch 880/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4149 - accuracy: 0.8360 - val_loss: 0.6630 - val_accuracy: 0.6949\n",
            "Epoch 881/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4381 - accuracy: 0.8230 - val_loss: 0.6816 - val_accuracy: 0.6838\n",
            "Epoch 882/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4270 - accuracy: 0.8274 - val_loss: 0.6660 - val_accuracy: 0.6912\n",
            "Epoch 883/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4206 - accuracy: 0.8230 - val_loss: 0.6378 - val_accuracy: 0.7096\n",
            "Epoch 884/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4148 - accuracy: 0.8366 - val_loss: 0.6686 - val_accuracy: 0.6985\n",
            "Epoch 885/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4317 - accuracy: 0.8317 - val_loss: 0.6415 - val_accuracy: 0.7096\n",
            "Epoch 886/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4225 - accuracy: 0.8311 - val_loss: 0.6717 - val_accuracy: 0.6838\n",
            "Epoch 887/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4191 - accuracy: 0.8360 - val_loss: 0.6636 - val_accuracy: 0.6949\n",
            "Epoch 888/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4384 - accuracy: 0.8199 - val_loss: 0.6503 - val_accuracy: 0.6949\n",
            "Epoch 889/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4334 - accuracy: 0.8292 - val_loss: 0.6709 - val_accuracy: 0.6949\n",
            "Epoch 890/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4289 - accuracy: 0.8323 - val_loss: 0.6572 - val_accuracy: 0.7022\n",
            "Epoch 891/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4347 - accuracy: 0.8317 - val_loss: 0.6456 - val_accuracy: 0.7206\n",
            "Epoch 892/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4208 - accuracy: 0.8311 - val_loss: 0.6462 - val_accuracy: 0.7059\n",
            "Epoch 893/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4224 - accuracy: 0.8274 - val_loss: 0.6451 - val_accuracy: 0.7132\n",
            "Epoch 894/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4231 - accuracy: 0.8255 - val_loss: 0.6651 - val_accuracy: 0.6985\n",
            "Epoch 895/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4373 - accuracy: 0.8292 - val_loss: 0.6826 - val_accuracy: 0.6801\n",
            "Epoch 896/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4186 - accuracy: 0.8397 - val_loss: 0.6705 - val_accuracy: 0.6912\n",
            "Epoch 897/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4218 - accuracy: 0.8311 - val_loss: 0.6538 - val_accuracy: 0.6949\n",
            "Epoch 898/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4268 - accuracy: 0.8181 - val_loss: 0.6337 - val_accuracy: 0.7169\n",
            "Epoch 899/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4336 - accuracy: 0.8261 - val_loss: 0.6983 - val_accuracy: 0.6801\n",
            "Epoch 900/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4328 - accuracy: 0.8311 - val_loss: 0.6498 - val_accuracy: 0.6912\n",
            "Epoch 901/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4223 - accuracy: 0.8274 - val_loss: 0.6391 - val_accuracy: 0.7022\n",
            "Epoch 902/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4544 - accuracy: 0.8014 - val_loss: 0.6533 - val_accuracy: 0.7096\n",
            "Epoch 903/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4101 - accuracy: 0.8323 - val_loss: 0.6655 - val_accuracy: 0.6985\n",
            "Epoch 904/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4312 - accuracy: 0.8236 - val_loss: 0.6789 - val_accuracy: 0.6912\n",
            "Epoch 905/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4384 - accuracy: 0.8298 - val_loss: 0.6697 - val_accuracy: 0.6838\n",
            "Epoch 906/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4207 - accuracy: 0.8298 - val_loss: 0.6506 - val_accuracy: 0.7022\n",
            "Epoch 907/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4264 - accuracy: 0.8168 - val_loss: 0.6422 - val_accuracy: 0.7132\n",
            "Epoch 908/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4096 - accuracy: 0.8391 - val_loss: 0.6742 - val_accuracy: 0.6912\n",
            "Epoch 909/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4221 - accuracy: 0.8298 - val_loss: 0.6724 - val_accuracy: 0.6985\n",
            "Epoch 910/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4251 - accuracy: 0.8304 - val_loss: 0.6513 - val_accuracy: 0.6912\n",
            "Epoch 911/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4315 - accuracy: 0.8311 - val_loss: 0.6491 - val_accuracy: 0.6912\n",
            "Epoch 912/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4182 - accuracy: 0.8255 - val_loss: 0.6536 - val_accuracy: 0.6801\n",
            "Epoch 913/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4176 - accuracy: 0.8292 - val_loss: 0.6460 - val_accuracy: 0.7022\n",
            "Epoch 914/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4359 - accuracy: 0.8292 - val_loss: 0.6545 - val_accuracy: 0.6985\n",
            "Epoch 915/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4277 - accuracy: 0.8162 - val_loss: 0.6400 - val_accuracy: 0.7059\n",
            "Epoch 916/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4148 - accuracy: 0.8360 - val_loss: 0.6393 - val_accuracy: 0.7059\n",
            "Epoch 917/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4153 - accuracy: 0.8298 - val_loss: 0.6679 - val_accuracy: 0.6949\n",
            "Epoch 918/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4288 - accuracy: 0.8329 - val_loss: 0.6747 - val_accuracy: 0.6875\n",
            "Epoch 919/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4147 - accuracy: 0.8373 - val_loss: 0.6568 - val_accuracy: 0.7022\n",
            "Epoch 920/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4219 - accuracy: 0.8354 - val_loss: 0.6672 - val_accuracy: 0.6949\n",
            "Epoch 921/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4210 - accuracy: 0.8311 - val_loss: 0.6429 - val_accuracy: 0.7096\n",
            "Epoch 922/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4203 - accuracy: 0.8403 - val_loss: 0.6521 - val_accuracy: 0.7022\n",
            "Epoch 923/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4251 - accuracy: 0.8342 - val_loss: 0.6421 - val_accuracy: 0.7132\n",
            "Epoch 924/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4184 - accuracy: 0.8280 - val_loss: 0.6518 - val_accuracy: 0.7022\n",
            "Epoch 925/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4207 - accuracy: 0.8224 - val_loss: 0.6382 - val_accuracy: 0.7096\n",
            "Epoch 926/1000\n",
            "51/51 [==============================] - 5s 88ms/step - loss: 0.4322 - accuracy: 0.8317 - val_loss: 0.6562 - val_accuracy: 0.6838\n",
            "Epoch 927/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.3977 - accuracy: 0.8416 - val_loss: 0.6707 - val_accuracy: 0.6912\n",
            "Epoch 928/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4477 - accuracy: 0.8199 - val_loss: 0.6500 - val_accuracy: 0.6912\n",
            "Epoch 929/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4390 - accuracy: 0.8156 - val_loss: 0.6358 - val_accuracy: 0.7096\n",
            "Epoch 930/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4303 - accuracy: 0.8212 - val_loss: 0.6994 - val_accuracy: 0.6838\n",
            "Epoch 931/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4361 - accuracy: 0.8261 - val_loss: 0.6774 - val_accuracy: 0.6765\n",
            "Epoch 932/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4230 - accuracy: 0.8261 - val_loss: 0.6440 - val_accuracy: 0.6985\n",
            "Epoch 933/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4121 - accuracy: 0.8397 - val_loss: 0.6424 - val_accuracy: 0.6985\n",
            "Epoch 934/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4190 - accuracy: 0.8298 - val_loss: 0.6884 - val_accuracy: 0.6838\n",
            "Epoch 935/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4233 - accuracy: 0.8286 - val_loss: 0.6731 - val_accuracy: 0.6912\n",
            "Epoch 936/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4389 - accuracy: 0.8175 - val_loss: 0.6822 - val_accuracy: 0.6949\n",
            "Epoch 937/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4387 - accuracy: 0.8255 - val_loss: 0.6736 - val_accuracy: 0.6875\n",
            "Epoch 938/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4203 - accuracy: 0.8373 - val_loss: 0.6545 - val_accuracy: 0.6912\n",
            "Epoch 939/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4051 - accuracy: 0.8379 - val_loss: 0.6816 - val_accuracy: 0.6875\n",
            "Epoch 940/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4154 - accuracy: 0.8317 - val_loss: 0.6768 - val_accuracy: 0.6838\n",
            "Epoch 941/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4126 - accuracy: 0.8360 - val_loss: 0.6536 - val_accuracy: 0.6985\n",
            "Epoch 942/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4147 - accuracy: 0.8379 - val_loss: 0.6423 - val_accuracy: 0.7096\n",
            "Epoch 943/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4052 - accuracy: 0.8434 - val_loss: 0.6938 - val_accuracy: 0.6618\n",
            "Epoch 944/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4278 - accuracy: 0.8280 - val_loss: 0.6352 - val_accuracy: 0.7353\n",
            "Epoch 945/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4300 - accuracy: 0.8236 - val_loss: 0.6804 - val_accuracy: 0.6838\n",
            "Epoch 946/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4209 - accuracy: 0.8311 - val_loss: 0.6556 - val_accuracy: 0.7022\n",
            "Epoch 947/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4165 - accuracy: 0.8348 - val_loss: 0.6511 - val_accuracy: 0.7059\n",
            "Epoch 948/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4222 - accuracy: 0.8317 - val_loss: 0.6743 - val_accuracy: 0.6912\n",
            "Epoch 949/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4184 - accuracy: 0.8385 - val_loss: 0.6865 - val_accuracy: 0.6875\n",
            "Epoch 950/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.3902 - accuracy: 0.8447 - val_loss: 0.6786 - val_accuracy: 0.6801\n",
            "Epoch 951/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4044 - accuracy: 0.8391 - val_loss: 0.6859 - val_accuracy: 0.6838\n",
            "Epoch 952/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4121 - accuracy: 0.8274 - val_loss: 0.6763 - val_accuracy: 0.6912\n",
            "Epoch 953/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4198 - accuracy: 0.8348 - val_loss: 0.6549 - val_accuracy: 0.7022\n",
            "Epoch 954/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4256 - accuracy: 0.8304 - val_loss: 0.6861 - val_accuracy: 0.6875\n",
            "Epoch 955/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4183 - accuracy: 0.8274 - val_loss: 0.6976 - val_accuracy: 0.6765\n",
            "Epoch 956/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4188 - accuracy: 0.8354 - val_loss: 0.6580 - val_accuracy: 0.7059\n",
            "Epoch 957/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4307 - accuracy: 0.8267 - val_loss: 0.6660 - val_accuracy: 0.6985\n",
            "Epoch 958/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4159 - accuracy: 0.8434 - val_loss: 0.6677 - val_accuracy: 0.6949\n",
            "Epoch 959/1000\n",
            "51/51 [==============================] - 4s 86ms/step - loss: 0.4305 - accuracy: 0.8187 - val_loss: 0.6670 - val_accuracy: 0.6838\n",
            "Epoch 960/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4423 - accuracy: 0.8156 - val_loss: 0.6772 - val_accuracy: 0.6912\n",
            "Epoch 961/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4244 - accuracy: 0.8274 - val_loss: 0.6721 - val_accuracy: 0.6875\n",
            "Epoch 962/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4304 - accuracy: 0.8329 - val_loss: 0.6645 - val_accuracy: 0.6875\n",
            "Epoch 963/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4208 - accuracy: 0.8397 - val_loss: 0.6880 - val_accuracy: 0.6765\n",
            "Epoch 964/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4135 - accuracy: 0.8379 - val_loss: 0.6506 - val_accuracy: 0.7022\n",
            "Epoch 965/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4261 - accuracy: 0.8329 - val_loss: 0.6597 - val_accuracy: 0.6985\n",
            "Epoch 966/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4099 - accuracy: 0.8397 - val_loss: 0.6803 - val_accuracy: 0.6949\n",
            "Epoch 967/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4295 - accuracy: 0.8329 - val_loss: 0.6777 - val_accuracy: 0.6912\n",
            "Epoch 968/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4143 - accuracy: 0.8366 - val_loss: 0.6612 - val_accuracy: 0.6912\n",
            "Epoch 969/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4279 - accuracy: 0.8218 - val_loss: 0.6655 - val_accuracy: 0.6875\n",
            "Epoch 970/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4348 - accuracy: 0.8212 - val_loss: 0.6984 - val_accuracy: 0.6765\n",
            "Epoch 971/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4279 - accuracy: 0.8162 - val_loss: 0.6596 - val_accuracy: 0.6912\n",
            "Epoch 972/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4079 - accuracy: 0.8311 - val_loss: 0.6632 - val_accuracy: 0.6949\n",
            "Epoch 973/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4201 - accuracy: 0.8366 - val_loss: 0.6749 - val_accuracy: 0.6875\n",
            "Epoch 974/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4255 - accuracy: 0.8354 - val_loss: 0.7065 - val_accuracy: 0.6691\n",
            "Epoch 975/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4397 - accuracy: 0.8218 - val_loss: 0.6738 - val_accuracy: 0.6838\n",
            "Epoch 976/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4265 - accuracy: 0.8323 - val_loss: 0.6364 - val_accuracy: 0.7132\n",
            "Epoch 977/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4124 - accuracy: 0.8422 - val_loss: 0.6602 - val_accuracy: 0.6875\n",
            "Epoch 978/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4139 - accuracy: 0.8360 - val_loss: 0.6717 - val_accuracy: 0.6838\n",
            "Epoch 979/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4159 - accuracy: 0.8329 - val_loss: 0.6482 - val_accuracy: 0.6949\n",
            "Epoch 980/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4303 - accuracy: 0.8181 - val_loss: 0.6697 - val_accuracy: 0.6949\n",
            "Epoch 981/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4164 - accuracy: 0.8329 - val_loss: 0.6444 - val_accuracy: 0.6985\n",
            "Epoch 982/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4273 - accuracy: 0.8317 - val_loss: 0.6812 - val_accuracy: 0.6801\n",
            "Epoch 983/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4249 - accuracy: 0.8317 - val_loss: 0.6627 - val_accuracy: 0.6912\n",
            "Epoch 984/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4111 - accuracy: 0.8348 - val_loss: 0.6564 - val_accuracy: 0.6985\n",
            "Epoch 985/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4083 - accuracy: 0.8348 - val_loss: 0.6300 - val_accuracy: 0.7243\n",
            "Epoch 986/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4255 - accuracy: 0.8236 - val_loss: 0.6626 - val_accuracy: 0.6875\n",
            "Epoch 987/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4106 - accuracy: 0.8354 - val_loss: 0.6565 - val_accuracy: 0.6949\n",
            "Epoch 988/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4183 - accuracy: 0.8329 - val_loss: 0.6592 - val_accuracy: 0.6985\n",
            "Epoch 989/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4247 - accuracy: 0.8323 - val_loss: 0.6790 - val_accuracy: 0.6912\n",
            "Epoch 990/1000\n",
            "51/51 [==============================] - 5s 89ms/step - loss: 0.4144 - accuracy: 0.8366 - val_loss: 0.6642 - val_accuracy: 0.6875\n",
            "Epoch 991/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4154 - accuracy: 0.8317 - val_loss: 0.6682 - val_accuracy: 0.6912\n",
            "Epoch 992/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4346 - accuracy: 0.8249 - val_loss: 0.6770 - val_accuracy: 0.6838\n",
            "Epoch 993/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4395 - accuracy: 0.8236 - val_loss: 0.6694 - val_accuracy: 0.6912\n",
            "Epoch 994/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4325 - accuracy: 0.8274 - val_loss: 0.6905 - val_accuracy: 0.6765\n",
            "Epoch 995/1000\n",
            "51/51 [==============================] - 4s 87ms/step - loss: 0.4105 - accuracy: 0.8385 - val_loss: 0.6694 - val_accuracy: 0.6912\n",
            "Epoch 996/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4020 - accuracy: 0.8422 - val_loss: 0.6770 - val_accuracy: 0.6912\n",
            "Epoch 997/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4307 - accuracy: 0.8218 - val_loss: 0.6591 - val_accuracy: 0.6949\n",
            "Epoch 998/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4200 - accuracy: 0.8205 - val_loss: 0.6682 - val_accuracy: 0.6949\n",
            "Epoch 999/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4250 - accuracy: 0.8298 - val_loss: 0.6707 - val_accuracy: 0.6912\n",
            "Epoch 1000/1000\n",
            "51/51 [==============================] - 4s 88ms/step - loss: 0.4127 - accuracy: 0.8329 - val_loss: 0.6487 - val_accuracy: 0.6912\n"
          ]
        }
      ],
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'accuracy',\n",
        "                                                        patience = 20,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer= keras.optimizers.Adam(0.0005, decay=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "# Start training the model.\n",
        "cnn_3d_model_training_history = model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=1000,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle = True,\n",
        "                                          validation_data = (features_valid, labels_valid))\n",
        "                                          # callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3vimsgjjbXvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d762076d-adfd-49e1-95cb-6f6fac2795ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 42ms/step - loss: 0.9107 - accuracy: 0.6421\n",
            "\n",
            "\n",
            "Train accuracy: 80.569 % || Test accuracy: 64.207 % || Val accuracy: 69.118 %\n",
            "Train loss: 0.407 || Test loss: 0.911 || Val loss: 0.649\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ivmaK9BlbnRQ"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'3D_CNN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p cnn_3d_{current_date_time_string}\n",
        "# Save your Model.\n",
        "model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwU8TwPrbsKB"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cvKY05ncbwof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "21be2741-5dcb-4154-f316-d3f3c1cf3e65"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o1iaaDHBb5i0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8a4f41fe-ba2f-4349-bade-a65b043755cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3D_CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/pV6edqrDh5TWxo+zrwjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}