{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/2D_CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8TLrPiv-ab"
      },
      "source": [
        "####**Convolutional Neural Network + Long Short Term Memory**\n",
        "######*I am using a Convolution Neural Network (CNN) + Long Short Term Memory (LSTM) Network to extract general representation while utilizing the Spatial-temporal aspect of the videos.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8ibtd5HKtZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae0bec1e-b24b-4693-d11f-04d8ee244fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import TimeDistributed, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "a3f6a59c-a818-4b81-a264-b42dd204313f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3mFB5qD6b3Kd"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sqeexMUjaLzJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(128, 128)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "9fcccf04-cfb7-4aeb-d091-2e19c5bd2ad4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bi-NDol3DHRV"
      },
      "outputs": [],
      "source": [
        "def create_convlstm_model():\n",
        "    # TimeDistributed is a wrapper to handle input of size five to maintain frames number for LSTM\n",
        "    # A Conv2D layer requires four dimensions: (batch_size, height, width, channels)\n",
        "    # TimeDistributed will require an additional dimension: (batch_size, frames, height, width, channels)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(8, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4)),\n",
        "                              input_shape=(16, 128, 128, 3)))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(12, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(16, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(24, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.25))\n",
        "  \n",
        "    model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(LSTM(4, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    # model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(4, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "    model.summary(line_length = 100)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FbjNYI-0DY_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54c85986-7676-4e8e-cb31-e936912889d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "____________________________________________________________________________________________________\n",
            " Layer (type)                                Output Shape                            Param #        \n",
            "====================================================================================================\n",
            " time_distributed (TimeDistributed)          (None, 16, 126, 126, 8)                 224            \n",
            "                                                                                                    \n",
            " time_distributed_1 (TimeDistributed)        (None, 16, 63, 63, 8)                   0              \n",
            "                                                                                                    \n",
            " dropout (Dropout)                           (None, 16, 63, 63, 8)                   0              \n",
            "                                                                                                    \n",
            " time_distributed_2 (TimeDistributed)        (None, 16, 61, 61, 12)                  876            \n",
            "                                                                                                    \n",
            " time_distributed_3 (TimeDistributed)        (None, 16, 30, 30, 12)                  0              \n",
            "                                                                                                    \n",
            " dropout_1 (Dropout)                         (None, 16, 30, 30, 12)                  0              \n",
            "                                                                                                    \n",
            " time_distributed_4 (TimeDistributed)        (None, 16, 28, 28, 16)                  1744           \n",
            "                                                                                                    \n",
            " time_distributed_5 (TimeDistributed)        (None, 16, 14, 14, 16)                  0              \n",
            "                                                                                                    \n",
            " dropout_2 (Dropout)                         (None, 16, 14, 14, 16)                  0              \n",
            "                                                                                                    \n",
            " time_distributed_6 (TimeDistributed)        (None, 16, 12, 12, 24)                  3480           \n",
            "                                                                                                    \n",
            " time_distributed_7 (TimeDistributed)        (None, 16, 6, 6, 24)                    0              \n",
            "                                                                                                    \n",
            " dropout_3 (Dropout)                         (None, 16, 6, 6, 24)                    0              \n",
            "                                                                                                    \n",
            " time_distributed_8 (TimeDistributed)        (None, 16, 4, 4, 32)                    6944           \n",
            "                                                                                                    \n",
            " time_distributed_9 (TimeDistributed)        (None, 16, 2, 2, 32)                    0              \n",
            "                                                                                                    \n",
            " dropout_4 (Dropout)                         (None, 16, 2, 2, 32)                    0              \n",
            "                                                                                                    \n",
            " time_distributed_10 (TimeDistributed)       (None, 16, 32)                          0              \n",
            "                                                                                                    \n",
            " dropout_5 (Dropout)                         (None, 16, 32)                          0              \n",
            "                                                                                                    \n",
            " lstm (LSTM)                                 (None, 4)                               592            \n",
            "                                                                                                    \n",
            " dropout_6 (Dropout)                         (None, 4)                               0              \n",
            "                                                                                                    \n",
            " dense (Dense)                               (None, 16)                              80             \n",
            "                                                                                                    \n",
            " dropout_7 (Dropout)                         (None, 16)                              0              \n",
            "                                                                                                    \n",
            " dense_1 (Dense)                             (None, 4)                               68             \n",
            "                                                                                                    \n",
            " dense_2 (Dense)                             (None, 4)                               20             \n",
            "                                                                                                    \n",
            "====================================================================================================\n",
            "Total params: 14,028\n",
            "Trainable params: 14,028\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "convlstm_model = create_convlstm_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SCB3R7so-wHz"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nMYwQOwyF3bd"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(convlstm_model,\n",
        "#                          to_file = 'convlstm_model_structure_plot.png',\n",
        "#                          show_shapes = True,\n",
        "#                          show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYC_6H0uGqW9",
        "outputId": "a131bc23-1f08-4ca9-fe73-e6f0fc94a497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "33/33 [==============================] - 11s 169ms/step - loss: 1.3105 - accuracy: 0.3756 - val_loss: 1.3737 - val_accuracy: 0.3566\n",
            "Epoch 2/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.3101 - accuracy: 0.3800 - val_loss: 1.3789 - val_accuracy: 0.3566\n",
            "Epoch 3/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.3173 - accuracy: 0.3769 - val_loss: 1.3728 - val_accuracy: 0.3566\n",
            "Epoch 4/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.2966 - accuracy: 0.3812 - val_loss: 1.3588 - val_accuracy: 0.3566\n",
            "Epoch 5/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.2873 - accuracy: 0.3806 - val_loss: 1.3574 - val_accuracy: 0.3566\n",
            "Epoch 6/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.2822 - accuracy: 0.3830 - val_loss: 1.3518 - val_accuracy: 0.3566\n",
            "Epoch 7/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.2585 - accuracy: 0.3929 - val_loss: 1.3407 - val_accuracy: 0.3566\n",
            "Epoch 8/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.2676 - accuracy: 0.3880 - val_loss: 1.3379 - val_accuracy: 0.3566\n",
            "Epoch 9/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.2661 - accuracy: 0.3830 - val_loss: 1.3384 - val_accuracy: 0.3566\n",
            "Epoch 10/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.2536 - accuracy: 0.3923 - val_loss: 1.3335 - val_accuracy: 0.3566\n",
            "Epoch 11/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 1.2336 - accuracy: 0.3923 - val_loss: 1.3317 - val_accuracy: 0.3566\n",
            "Epoch 12/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 1.2335 - accuracy: 0.3942 - val_loss: 1.3288 - val_accuracy: 0.3566\n",
            "Epoch 13/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 1.2227 - accuracy: 0.3936 - val_loss: 1.3173 - val_accuracy: 0.4081\n",
            "Epoch 14/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 1.2212 - accuracy: 0.3793 - val_loss: 1.3138 - val_accuracy: 0.5110\n",
            "Epoch 15/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1984 - accuracy: 0.3960 - val_loss: 1.3013 - val_accuracy: 0.5441\n",
            "Epoch 16/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 1.2009 - accuracy: 0.4059 - val_loss: 1.2984 - val_accuracy: 0.5772\n",
            "Epoch 17/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1998 - accuracy: 0.4072 - val_loss: 1.2853 - val_accuracy: 0.5882\n",
            "Epoch 18/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.1830 - accuracy: 0.4158 - val_loss: 1.2709 - val_accuracy: 0.5993\n",
            "Epoch 19/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1914 - accuracy: 0.4165 - val_loss: 1.2707 - val_accuracy: 0.6029\n",
            "Epoch 20/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.1924 - accuracy: 0.4028 - val_loss: 1.2592 - val_accuracy: 0.6066\n",
            "Epoch 21/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1742 - accuracy: 0.4090 - val_loss: 1.2519 - val_accuracy: 0.6066\n",
            "Epoch 22/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1782 - accuracy: 0.4196 - val_loss: 1.2422 - val_accuracy: 0.6066\n",
            "Epoch 23/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1750 - accuracy: 0.4152 - val_loss: 1.2530 - val_accuracy: 0.5956\n",
            "Epoch 24/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1734 - accuracy: 0.4208 - val_loss: 1.2479 - val_accuracy: 0.6029\n",
            "Epoch 25/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1765 - accuracy: 0.4295 - val_loss: 1.2486 - val_accuracy: 0.5993\n",
            "Epoch 26/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1510 - accuracy: 0.4332 - val_loss: 1.2414 - val_accuracy: 0.6103\n",
            "Epoch 27/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.1468 - accuracy: 0.4431 - val_loss: 1.2295 - val_accuracy: 0.6029\n",
            "Epoch 28/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1484 - accuracy: 0.4387 - val_loss: 1.2271 - val_accuracy: 0.5956\n",
            "Epoch 29/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 1.1308 - accuracy: 0.4474 - val_loss: 1.2173 - val_accuracy: 0.5993\n",
            "Epoch 30/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1256 - accuracy: 0.4623 - val_loss: 1.2081 - val_accuracy: 0.5956\n",
            "Epoch 31/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.1113 - accuracy: 0.4511 - val_loss: 1.2045 - val_accuracy: 0.6029\n",
            "Epoch 32/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1268 - accuracy: 0.4660 - val_loss: 1.2067 - val_accuracy: 0.6066\n",
            "Epoch 33/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.1104 - accuracy: 0.4672 - val_loss: 1.1994 - val_accuracy: 0.6066\n",
            "Epoch 34/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1073 - accuracy: 0.4697 - val_loss: 1.1976 - val_accuracy: 0.5919\n",
            "Epoch 35/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1109 - accuracy: 0.4796 - val_loss: 1.1938 - val_accuracy: 0.5919\n",
            "Epoch 36/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 1.0855 - accuracy: 0.4870 - val_loss: 1.1804 - val_accuracy: 0.6066\n",
            "Epoch 37/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.1027 - accuracy: 0.4641 - val_loss: 1.1813 - val_accuracy: 0.5993\n",
            "Epoch 38/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.0830 - accuracy: 0.4864 - val_loss: 1.1699 - val_accuracy: 0.6066\n",
            "Epoch 39/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 1.0811 - accuracy: 0.4926 - val_loss: 1.1643 - val_accuracy: 0.6140\n",
            "Epoch 40/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.0542 - accuracy: 0.5167 - val_loss: 1.1524 - val_accuracy: 0.6140\n",
            "Epoch 41/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 1.0706 - accuracy: 0.5062 - val_loss: 1.1525 - val_accuracy: 0.6176\n",
            "Epoch 42/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 1.0730 - accuracy: 0.4975 - val_loss: 1.1522 - val_accuracy: 0.6213\n",
            "Epoch 43/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.0431 - accuracy: 0.5334 - val_loss: 1.1300 - val_accuracy: 0.6176\n",
            "Epoch 44/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 1.0623 - accuracy: 0.5093 - val_loss: 1.1266 - val_accuracy: 0.6213\n",
            "Epoch 45/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.0524 - accuracy: 0.5204 - val_loss: 1.1227 - val_accuracy: 0.6213\n",
            "Epoch 46/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.0532 - accuracy: 0.5316 - val_loss: 1.0995 - val_accuracy: 0.6213\n",
            "Epoch 47/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 1.0292 - accuracy: 0.5173 - val_loss: 1.0928 - val_accuracy: 0.6507\n",
            "Epoch 48/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 1.0270 - accuracy: 0.5452 - val_loss: 1.0838 - val_accuracy: 0.6581\n",
            "Epoch 49/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.0332 - accuracy: 0.5377 - val_loss: 1.0812 - val_accuracy: 0.6434\n",
            "Epoch 50/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.0236 - accuracy: 0.5303 - val_loss: 1.0895 - val_accuracy: 0.6397\n",
            "Epoch 51/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.0132 - accuracy: 0.5520 - val_loss: 1.0596 - val_accuracy: 0.6654\n",
            "Epoch 52/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 1.0223 - accuracy: 0.5408 - val_loss: 1.0544 - val_accuracy: 0.6691\n",
            "Epoch 53/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 1.0256 - accuracy: 0.5433 - val_loss: 1.0721 - val_accuracy: 0.6618\n",
            "Epoch 54/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.9956 - accuracy: 0.5594 - val_loss: 1.0591 - val_accuracy: 0.6765\n",
            "Epoch 55/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 1.0038 - accuracy: 0.5650 - val_loss: 1.0694 - val_accuracy: 0.6581\n",
            "Epoch 56/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9989 - accuracy: 0.5675 - val_loss: 1.0418 - val_accuracy: 0.6912\n",
            "Epoch 57/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.9992 - accuracy: 0.5675 - val_loss: 1.0254 - val_accuracy: 0.6949\n",
            "Epoch 58/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9972 - accuracy: 0.5495 - val_loss: 1.0055 - val_accuracy: 0.7169\n",
            "Epoch 59/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.9919 - accuracy: 0.5619 - val_loss: 1.0475 - val_accuracy: 0.7096\n",
            "Epoch 60/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.9814 - accuracy: 0.5767 - val_loss: 1.0445 - val_accuracy: 0.7059\n",
            "Epoch 61/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.9930 - accuracy: 0.5631 - val_loss: 1.0245 - val_accuracy: 0.7022\n",
            "Epoch 62/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9830 - accuracy: 0.5972 - val_loss: 1.0421 - val_accuracy: 0.6949\n",
            "Epoch 63/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9882 - accuracy: 0.5687 - val_loss: 1.0533 - val_accuracy: 0.6912\n",
            "Epoch 64/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.9815 - accuracy: 0.5811 - val_loss: 1.0260 - val_accuracy: 0.7132\n",
            "Epoch 65/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.9782 - accuracy: 0.5718 - val_loss: 1.0414 - val_accuracy: 0.6949\n",
            "Epoch 66/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.9696 - accuracy: 0.5767 - val_loss: 1.0162 - val_accuracy: 0.7169\n",
            "Epoch 67/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.9727 - accuracy: 0.5866 - val_loss: 1.0171 - val_accuracy: 0.7169\n",
            "Epoch 68/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9677 - accuracy: 0.5792 - val_loss: 1.0045 - val_accuracy: 0.7206\n",
            "Epoch 69/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9456 - accuracy: 0.5774 - val_loss: 1.0324 - val_accuracy: 0.6912\n",
            "Epoch 70/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.9574 - accuracy: 0.5922 - val_loss: 1.0044 - val_accuracy: 0.7169\n",
            "Epoch 71/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.9645 - accuracy: 0.5842 - val_loss: 1.0055 - val_accuracy: 0.7132\n",
            "Epoch 72/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9556 - accuracy: 0.6046 - val_loss: 1.0344 - val_accuracy: 0.6875\n",
            "Epoch 73/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9490 - accuracy: 0.5978 - val_loss: 1.0170 - val_accuracy: 0.6949\n",
            "Epoch 74/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.9578 - accuracy: 0.5984 - val_loss: 1.0253 - val_accuracy: 0.6949\n",
            "Epoch 75/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.9437 - accuracy: 0.5941 - val_loss: 0.9574 - val_accuracy: 0.7316\n",
            "Epoch 76/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.9349 - accuracy: 0.5860 - val_loss: 0.9636 - val_accuracy: 0.7279\n",
            "Epoch 77/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9294 - accuracy: 0.6095 - val_loss: 0.9646 - val_accuracy: 0.7243\n",
            "Epoch 78/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.9211 - accuracy: 0.5996 - val_loss: 0.9617 - val_accuracy: 0.7279\n",
            "Epoch 79/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.9338 - accuracy: 0.6083 - val_loss: 0.9545 - val_accuracy: 0.7316\n",
            "Epoch 80/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.9403 - accuracy: 0.5947 - val_loss: 1.0223 - val_accuracy: 0.6875\n",
            "Epoch 81/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9329 - accuracy: 0.6182 - val_loss: 0.9730 - val_accuracy: 0.7206\n",
            "Epoch 82/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9188 - accuracy: 0.6046 - val_loss: 0.9677 - val_accuracy: 0.7206\n",
            "Epoch 83/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9327 - accuracy: 0.6182 - val_loss: 0.9739 - val_accuracy: 0.7022\n",
            "Epoch 84/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9295 - accuracy: 0.5959 - val_loss: 0.9567 - val_accuracy: 0.7243\n",
            "Epoch 85/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8925 - accuracy: 0.6083 - val_loss: 0.9223 - val_accuracy: 0.7353\n",
            "Epoch 86/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9146 - accuracy: 0.6089 - val_loss: 0.9092 - val_accuracy: 0.7537\n",
            "Epoch 87/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.9077 - accuracy: 0.6139 - val_loss: 0.9158 - val_accuracy: 0.7316\n",
            "Epoch 88/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9099 - accuracy: 0.6108 - val_loss: 0.9288 - val_accuracy: 0.7316\n",
            "Epoch 89/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8993 - accuracy: 0.6120 - val_loss: 0.9276 - val_accuracy: 0.7316\n",
            "Epoch 90/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.9165 - accuracy: 0.6238 - val_loss: 0.9252 - val_accuracy: 0.7316\n",
            "Epoch 91/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8896 - accuracy: 0.6318 - val_loss: 0.8904 - val_accuracy: 0.7574\n",
            "Epoch 92/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.9067 - accuracy: 0.6095 - val_loss: 0.8738 - val_accuracy: 0.7647\n",
            "Epoch 93/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8985 - accuracy: 0.6250 - val_loss: 0.9155 - val_accuracy: 0.7316\n",
            "Epoch 94/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.8941 - accuracy: 0.6374 - val_loss: 0.9135 - val_accuracy: 0.7316\n",
            "Epoch 95/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8869 - accuracy: 0.6436 - val_loss: 0.8769 - val_accuracy: 0.7610\n",
            "Epoch 96/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8965 - accuracy: 0.6318 - val_loss: 0.8644 - val_accuracy: 0.7647\n",
            "Epoch 97/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8871 - accuracy: 0.6337 - val_loss: 0.9038 - val_accuracy: 0.7316\n",
            "Epoch 98/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.8986 - accuracy: 0.6318 - val_loss: 0.8616 - val_accuracy: 0.7684\n",
            "Epoch 99/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8914 - accuracy: 0.6343 - val_loss: 0.8615 - val_accuracy: 0.7647\n",
            "Epoch 100/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8750 - accuracy: 0.6256 - val_loss: 0.8668 - val_accuracy: 0.7610\n",
            "Epoch 101/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8644 - accuracy: 0.6349 - val_loss: 0.8769 - val_accuracy: 0.7537\n",
            "Epoch 102/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8663 - accuracy: 0.6485 - val_loss: 0.8482 - val_accuracy: 0.7721\n",
            "Epoch 103/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8791 - accuracy: 0.6380 - val_loss: 0.8673 - val_accuracy: 0.7610\n",
            "Epoch 104/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8741 - accuracy: 0.6368 - val_loss: 0.8737 - val_accuracy: 0.7426\n",
            "Epoch 105/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8687 - accuracy: 0.6337 - val_loss: 0.8743 - val_accuracy: 0.7426\n",
            "Epoch 106/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8690 - accuracy: 0.6132 - val_loss: 0.8522 - val_accuracy: 0.7684\n",
            "Epoch 107/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8845 - accuracy: 0.6522 - val_loss: 0.8116 - val_accuracy: 0.7794\n",
            "Epoch 108/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8584 - accuracy: 0.6380 - val_loss: 0.8414 - val_accuracy: 0.7684\n",
            "Epoch 109/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.8614 - accuracy: 0.6343 - val_loss: 0.8500 - val_accuracy: 0.7684\n",
            "Epoch 110/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8600 - accuracy: 0.6287 - val_loss: 0.8682 - val_accuracy: 0.7426\n",
            "Epoch 111/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8693 - accuracy: 0.6380 - val_loss: 0.8281 - val_accuracy: 0.7757\n",
            "Epoch 112/1000\n",
            "33/33 [==============================] - 4s 135ms/step - loss: 0.8607 - accuracy: 0.6436 - val_loss: 0.8500 - val_accuracy: 0.7684\n",
            "Epoch 113/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8759 - accuracy: 0.6541 - val_loss: 0.8556 - val_accuracy: 0.7537\n",
            "Epoch 114/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8629 - accuracy: 0.6361 - val_loss: 0.8542 - val_accuracy: 0.7610\n",
            "Epoch 115/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8452 - accuracy: 0.6454 - val_loss: 0.8545 - val_accuracy: 0.7647\n",
            "Epoch 116/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.8533 - accuracy: 0.6405 - val_loss: 0.8799 - val_accuracy: 0.7390\n",
            "Epoch 117/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8552 - accuracy: 0.6522 - val_loss: 0.8741 - val_accuracy: 0.7390\n",
            "Epoch 118/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8362 - accuracy: 0.6528 - val_loss: 0.8572 - val_accuracy: 0.7426\n",
            "Epoch 119/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8342 - accuracy: 0.6541 - val_loss: 0.8450 - val_accuracy: 0.7610\n",
            "Epoch 120/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8673 - accuracy: 0.6460 - val_loss: 0.8978 - val_accuracy: 0.7316\n",
            "Epoch 121/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.8550 - accuracy: 0.6460 - val_loss: 0.8437 - val_accuracy: 0.7610\n",
            "Epoch 122/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8369 - accuracy: 0.6454 - val_loss: 0.8444 - val_accuracy: 0.7610\n",
            "Epoch 123/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8461 - accuracy: 0.6429 - val_loss: 0.8743 - val_accuracy: 0.7390\n",
            "Epoch 124/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.8389 - accuracy: 0.6504 - val_loss: 0.8117 - val_accuracy: 0.7757\n",
            "Epoch 125/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8498 - accuracy: 0.6504 - val_loss: 0.7958 - val_accuracy: 0.7794\n",
            "Epoch 126/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.8404 - accuracy: 0.6510 - val_loss: 0.8435 - val_accuracy: 0.7463\n",
            "Epoch 127/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8230 - accuracy: 0.6584 - val_loss: 0.8384 - val_accuracy: 0.7610\n",
            "Epoch 128/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8272 - accuracy: 0.6510 - val_loss: 0.8233 - val_accuracy: 0.7721\n",
            "Epoch 129/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.8376 - accuracy: 0.6454 - val_loss: 0.8247 - val_accuracy: 0.7684\n",
            "Epoch 130/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8237 - accuracy: 0.6658 - val_loss: 0.8209 - val_accuracy: 0.7684\n",
            "Epoch 131/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.8363 - accuracy: 0.6634 - val_loss: 0.8038 - val_accuracy: 0.7757\n",
            "Epoch 132/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8281 - accuracy: 0.6590 - val_loss: 0.8255 - val_accuracy: 0.7684\n",
            "Epoch 133/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.8248 - accuracy: 0.6541 - val_loss: 0.8175 - val_accuracy: 0.7684\n",
            "Epoch 134/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8311 - accuracy: 0.6683 - val_loss: 0.8207 - val_accuracy: 0.7647\n",
            "Epoch 135/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8342 - accuracy: 0.6516 - val_loss: 0.8376 - val_accuracy: 0.7463\n",
            "Epoch 136/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8320 - accuracy: 0.6597 - val_loss: 0.8261 - val_accuracy: 0.7684\n",
            "Epoch 137/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8090 - accuracy: 0.6615 - val_loss: 0.8252 - val_accuracy: 0.7610\n",
            "Epoch 138/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8120 - accuracy: 0.6627 - val_loss: 0.8136 - val_accuracy: 0.7684\n",
            "Epoch 139/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8236 - accuracy: 0.6652 - val_loss: 0.7980 - val_accuracy: 0.7757\n",
            "Epoch 140/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.8167 - accuracy: 0.6559 - val_loss: 0.8032 - val_accuracy: 0.7757\n",
            "Epoch 141/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.8008 - accuracy: 0.6658 - val_loss: 0.8020 - val_accuracy: 0.7757\n",
            "Epoch 142/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8061 - accuracy: 0.6597 - val_loss: 0.7953 - val_accuracy: 0.7794\n",
            "Epoch 143/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8082 - accuracy: 0.6689 - val_loss: 0.8120 - val_accuracy: 0.7684\n",
            "Epoch 144/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8031 - accuracy: 0.6640 - val_loss: 0.8134 - val_accuracy: 0.7684\n",
            "Epoch 145/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.8170 - accuracy: 0.6615 - val_loss: 0.8077 - val_accuracy: 0.7684\n",
            "Epoch 146/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8180 - accuracy: 0.6634 - val_loss: 0.8121 - val_accuracy: 0.7684\n",
            "Epoch 147/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7930 - accuracy: 0.6683 - val_loss: 0.7994 - val_accuracy: 0.7721\n",
            "Epoch 148/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8112 - accuracy: 0.6634 - val_loss: 0.7908 - val_accuracy: 0.7757\n",
            "Epoch 149/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8125 - accuracy: 0.6597 - val_loss: 0.7961 - val_accuracy: 0.7757\n",
            "Epoch 150/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.8061 - accuracy: 0.6714 - val_loss: 0.8010 - val_accuracy: 0.7721\n",
            "Epoch 151/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8068 - accuracy: 0.6745 - val_loss: 0.8054 - val_accuracy: 0.7684\n",
            "Epoch 152/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8203 - accuracy: 0.6553 - val_loss: 0.8115 - val_accuracy: 0.7647\n",
            "Epoch 153/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8032 - accuracy: 0.6696 - val_loss: 0.8502 - val_accuracy: 0.7390\n",
            "Epoch 154/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8107 - accuracy: 0.6535 - val_loss: 0.8019 - val_accuracy: 0.7721\n",
            "Epoch 155/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.8037 - accuracy: 0.6559 - val_loss: 0.8063 - val_accuracy: 0.7684\n",
            "Epoch 156/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7884 - accuracy: 0.6702 - val_loss: 0.7891 - val_accuracy: 0.7757\n",
            "Epoch 157/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8250 - accuracy: 0.6553 - val_loss: 0.7872 - val_accuracy: 0.7757\n",
            "Epoch 158/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.8034 - accuracy: 0.6714 - val_loss: 0.7975 - val_accuracy: 0.7721\n",
            "Epoch 159/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7771 - accuracy: 0.6757 - val_loss: 0.7952 - val_accuracy: 0.7757\n",
            "Epoch 160/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7812 - accuracy: 0.6726 - val_loss: 0.7774 - val_accuracy: 0.7794\n",
            "Epoch 161/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7991 - accuracy: 0.6658 - val_loss: 0.7904 - val_accuracy: 0.7757\n",
            "Epoch 162/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7891 - accuracy: 0.6708 - val_loss: 0.8044 - val_accuracy: 0.7610\n",
            "Epoch 163/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7895 - accuracy: 0.6689 - val_loss: 0.7872 - val_accuracy: 0.7757\n",
            "Epoch 164/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7918 - accuracy: 0.6708 - val_loss: 0.7913 - val_accuracy: 0.7721\n",
            "Epoch 165/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7921 - accuracy: 0.6615 - val_loss: 0.8070 - val_accuracy: 0.7463\n",
            "Epoch 166/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7880 - accuracy: 0.6795 - val_loss: 0.7984 - val_accuracy: 0.7684\n",
            "Epoch 167/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7838 - accuracy: 0.6757 - val_loss: 0.7669 - val_accuracy: 0.7794\n",
            "Epoch 168/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7860 - accuracy: 0.6597 - val_loss: 0.7665 - val_accuracy: 0.7794\n",
            "Epoch 169/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7712 - accuracy: 0.6726 - val_loss: 0.7715 - val_accuracy: 0.7794\n",
            "Epoch 170/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7729 - accuracy: 0.6776 - val_loss: 0.7667 - val_accuracy: 0.7794\n",
            "Epoch 171/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7978 - accuracy: 0.6751 - val_loss: 0.8518 - val_accuracy: 0.7353\n",
            "Epoch 172/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.8019 - accuracy: 0.6578 - val_loss: 0.7918 - val_accuracy: 0.7684\n",
            "Epoch 173/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7943 - accuracy: 0.6547 - val_loss: 0.7975 - val_accuracy: 0.7574\n",
            "Epoch 174/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7822 - accuracy: 0.6677 - val_loss: 0.7721 - val_accuracy: 0.7757\n",
            "Epoch 175/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7712 - accuracy: 0.6714 - val_loss: 0.7569 - val_accuracy: 0.7794\n",
            "Epoch 176/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7731 - accuracy: 0.6739 - val_loss: 0.7508 - val_accuracy: 0.7794\n",
            "Epoch 177/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7776 - accuracy: 0.6739 - val_loss: 0.7492 - val_accuracy: 0.7794\n",
            "Epoch 178/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7646 - accuracy: 0.6795 - val_loss: 0.7707 - val_accuracy: 0.7757\n",
            "Epoch 179/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7913 - accuracy: 0.6646 - val_loss: 0.7873 - val_accuracy: 0.7684\n",
            "Epoch 180/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7712 - accuracy: 0.6726 - val_loss: 0.7582 - val_accuracy: 0.7794\n",
            "Epoch 181/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7787 - accuracy: 0.6757 - val_loss: 0.8190 - val_accuracy: 0.7390\n",
            "Epoch 182/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7672 - accuracy: 0.6776 - val_loss: 0.7706 - val_accuracy: 0.7757\n",
            "Epoch 183/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7786 - accuracy: 0.6745 - val_loss: 0.7578 - val_accuracy: 0.7794\n",
            "Epoch 184/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7808 - accuracy: 0.6733 - val_loss: 0.7510 - val_accuracy: 0.7794\n",
            "Epoch 185/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7829 - accuracy: 0.6652 - val_loss: 0.7644 - val_accuracy: 0.7757\n",
            "Epoch 186/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7589 - accuracy: 0.6702 - val_loss: 0.7481 - val_accuracy: 0.7794\n",
            "Epoch 187/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7679 - accuracy: 0.6757 - val_loss: 0.7418 - val_accuracy: 0.7794\n",
            "Epoch 188/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7434 - accuracy: 0.6825 - val_loss: 0.7462 - val_accuracy: 0.7794\n",
            "Epoch 189/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7745 - accuracy: 0.6733 - val_loss: 0.7660 - val_accuracy: 0.7757\n",
            "Epoch 190/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7532 - accuracy: 0.6850 - val_loss: 0.7466 - val_accuracy: 0.7794\n",
            "Epoch 191/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7633 - accuracy: 0.6795 - val_loss: 0.7599 - val_accuracy: 0.7757\n",
            "Epoch 192/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7628 - accuracy: 0.6782 - val_loss: 0.7442 - val_accuracy: 0.7794\n",
            "Epoch 193/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7785 - accuracy: 0.6733 - val_loss: 0.7295 - val_accuracy: 0.7831\n",
            "Epoch 194/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7673 - accuracy: 0.6795 - val_loss: 0.7532 - val_accuracy: 0.7794\n",
            "Epoch 195/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7558 - accuracy: 0.6844 - val_loss: 0.7519 - val_accuracy: 0.7794\n",
            "Epoch 196/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7573 - accuracy: 0.6776 - val_loss: 0.7285 - val_accuracy: 0.7831\n",
            "Epoch 197/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7767 - accuracy: 0.6807 - val_loss: 0.7437 - val_accuracy: 0.7794\n",
            "Epoch 198/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7617 - accuracy: 0.6838 - val_loss: 0.7437 - val_accuracy: 0.7794\n",
            "Epoch 199/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7577 - accuracy: 0.6683 - val_loss: 0.7435 - val_accuracy: 0.7794\n",
            "Epoch 200/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7594 - accuracy: 0.6757 - val_loss: 0.7427 - val_accuracy: 0.7794\n",
            "Epoch 201/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.7500 - accuracy: 0.6739 - val_loss: 0.7203 - val_accuracy: 0.7831\n",
            "Epoch 202/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7593 - accuracy: 0.6813 - val_loss: 0.7409 - val_accuracy: 0.7794\n",
            "Epoch 203/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7747 - accuracy: 0.6745 - val_loss: 0.7371 - val_accuracy: 0.7794\n",
            "Epoch 204/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7577 - accuracy: 0.6671 - val_loss: 0.7503 - val_accuracy: 0.7794\n",
            "Epoch 205/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7633 - accuracy: 0.6757 - val_loss: 0.7435 - val_accuracy: 0.7794\n",
            "Epoch 206/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7555 - accuracy: 0.6776 - val_loss: 0.7269 - val_accuracy: 0.7831\n",
            "Epoch 207/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7466 - accuracy: 0.6850 - val_loss: 0.7410 - val_accuracy: 0.7794\n",
            "Epoch 208/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7536 - accuracy: 0.6764 - val_loss: 0.7428 - val_accuracy: 0.7794\n",
            "Epoch 209/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7547 - accuracy: 0.6770 - val_loss: 0.7262 - val_accuracy: 0.7794\n",
            "Epoch 210/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7508 - accuracy: 0.6819 - val_loss: 0.7508 - val_accuracy: 0.7794\n",
            "Epoch 211/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7481 - accuracy: 0.6850 - val_loss: 0.7266 - val_accuracy: 0.7794\n",
            "Epoch 212/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7499 - accuracy: 0.6788 - val_loss: 0.7412 - val_accuracy: 0.7794\n",
            "Epoch 213/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7595 - accuracy: 0.6702 - val_loss: 0.7402 - val_accuracy: 0.7794\n",
            "Epoch 214/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7400 - accuracy: 0.6825 - val_loss: 0.7414 - val_accuracy: 0.7794\n",
            "Epoch 215/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7552 - accuracy: 0.6819 - val_loss: 0.7142 - val_accuracy: 0.7831\n",
            "Epoch 216/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7474 - accuracy: 0.6801 - val_loss: 0.7324 - val_accuracy: 0.7794\n",
            "Epoch 217/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7491 - accuracy: 0.6782 - val_loss: 0.7129 - val_accuracy: 0.7831\n",
            "Epoch 218/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7578 - accuracy: 0.6665 - val_loss: 0.7581 - val_accuracy: 0.7757\n",
            "Epoch 219/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7504 - accuracy: 0.6801 - val_loss: 0.7095 - val_accuracy: 0.7831\n",
            "Epoch 220/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7436 - accuracy: 0.6801 - val_loss: 0.7026 - val_accuracy: 0.7831\n",
            "Epoch 221/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7414 - accuracy: 0.6844 - val_loss: 0.7114 - val_accuracy: 0.7831\n",
            "Epoch 222/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7319 - accuracy: 0.6912 - val_loss: 0.7028 - val_accuracy: 0.7831\n",
            "Epoch 223/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7491 - accuracy: 0.6733 - val_loss: 0.7384 - val_accuracy: 0.7757\n",
            "Epoch 224/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7552 - accuracy: 0.6739 - val_loss: 0.7462 - val_accuracy: 0.7757\n",
            "Epoch 225/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7487 - accuracy: 0.6825 - val_loss: 0.7042 - val_accuracy: 0.7831\n",
            "Epoch 226/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7271 - accuracy: 0.6955 - val_loss: 0.6915 - val_accuracy: 0.7831\n",
            "Epoch 227/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7471 - accuracy: 0.6856 - val_loss: 0.7060 - val_accuracy: 0.7794\n",
            "Epoch 228/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7366 - accuracy: 0.6856 - val_loss: 0.6924 - val_accuracy: 0.7831\n",
            "Epoch 229/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.7417 - accuracy: 0.6745 - val_loss: 0.6808 - val_accuracy: 0.7831\n",
            "Epoch 230/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7429 - accuracy: 0.6720 - val_loss: 0.7041 - val_accuracy: 0.7794\n",
            "Epoch 231/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7329 - accuracy: 0.6844 - val_loss: 0.6943 - val_accuracy: 0.7831\n",
            "Epoch 232/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7276 - accuracy: 0.6999 - val_loss: 0.6834 - val_accuracy: 0.7831\n",
            "Epoch 233/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7239 - accuracy: 0.6887 - val_loss: 0.6844 - val_accuracy: 0.7831\n",
            "Epoch 234/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7320 - accuracy: 0.6825 - val_loss: 0.6901 - val_accuracy: 0.7831\n",
            "Epoch 235/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7347 - accuracy: 0.6869 - val_loss: 0.7126 - val_accuracy: 0.7794\n",
            "Epoch 236/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7347 - accuracy: 0.6912 - val_loss: 0.7202 - val_accuracy: 0.7794\n",
            "Epoch 237/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7305 - accuracy: 0.6900 - val_loss: 0.7002 - val_accuracy: 0.7831\n",
            "Epoch 238/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7310 - accuracy: 0.6844 - val_loss: 0.7055 - val_accuracy: 0.7794\n",
            "Epoch 239/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7320 - accuracy: 0.6819 - val_loss: 0.7080 - val_accuracy: 0.7794\n",
            "Epoch 240/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7361 - accuracy: 0.6838 - val_loss: 0.7030 - val_accuracy: 0.7794\n",
            "Epoch 241/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7265 - accuracy: 0.6807 - val_loss: 0.7336 - val_accuracy: 0.7757\n",
            "Epoch 242/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7319 - accuracy: 0.6894 - val_loss: 0.6960 - val_accuracy: 0.7831\n",
            "Epoch 243/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7258 - accuracy: 0.6844 - val_loss: 0.6798 - val_accuracy: 0.7831\n",
            "Epoch 244/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7507 - accuracy: 0.6702 - val_loss: 0.6940 - val_accuracy: 0.7831\n",
            "Epoch 245/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7416 - accuracy: 0.6825 - val_loss: 0.7211 - val_accuracy: 0.7794\n",
            "Epoch 246/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7227 - accuracy: 0.6856 - val_loss: 0.7189 - val_accuracy: 0.7794\n",
            "Epoch 247/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7449 - accuracy: 0.6795 - val_loss: 0.7239 - val_accuracy: 0.7794\n",
            "Epoch 248/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7260 - accuracy: 0.6825 - val_loss: 0.6909 - val_accuracy: 0.7831\n",
            "Epoch 249/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7257 - accuracy: 0.6856 - val_loss: 0.6905 - val_accuracy: 0.7831\n",
            "Epoch 250/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7285 - accuracy: 0.6788 - val_loss: 0.6962 - val_accuracy: 0.7831\n",
            "Epoch 251/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7240 - accuracy: 0.6856 - val_loss: 0.6968 - val_accuracy: 0.7831\n",
            "Epoch 252/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7224 - accuracy: 0.6844 - val_loss: 0.7279 - val_accuracy: 0.7757\n",
            "Epoch 253/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7379 - accuracy: 0.6850 - val_loss: 0.7161 - val_accuracy: 0.7794\n",
            "Epoch 254/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7258 - accuracy: 0.6881 - val_loss: 0.6988 - val_accuracy: 0.7794\n",
            "Epoch 255/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7343 - accuracy: 0.6770 - val_loss: 0.6831 - val_accuracy: 0.7831\n",
            "Epoch 256/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.7180 - accuracy: 0.6881 - val_loss: 0.6908 - val_accuracy: 0.7831\n",
            "Epoch 257/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7259 - accuracy: 0.6795 - val_loss: 0.6779 - val_accuracy: 0.7831\n",
            "Epoch 258/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.7155 - accuracy: 0.6875 - val_loss: 0.6757 - val_accuracy: 0.7831\n",
            "Epoch 259/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7337 - accuracy: 0.6807 - val_loss: 0.6996 - val_accuracy: 0.7794\n",
            "Epoch 260/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7287 - accuracy: 0.6801 - val_loss: 0.6837 - val_accuracy: 0.7831\n",
            "Epoch 261/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7104 - accuracy: 0.6943 - val_loss: 0.6738 - val_accuracy: 0.7831\n",
            "Epoch 262/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7159 - accuracy: 0.6986 - val_loss: 0.6763 - val_accuracy: 0.7831\n",
            "Epoch 263/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7149 - accuracy: 0.6900 - val_loss: 0.6693 - val_accuracy: 0.7831\n",
            "Epoch 264/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7217 - accuracy: 0.6943 - val_loss: 0.6705 - val_accuracy: 0.7831\n",
            "Epoch 265/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7489 - accuracy: 0.6788 - val_loss: 0.6651 - val_accuracy: 0.7831\n",
            "Epoch 266/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7231 - accuracy: 0.6875 - val_loss: 0.6551 - val_accuracy: 0.7831\n",
            "Epoch 267/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7279 - accuracy: 0.6825 - val_loss: 0.6759 - val_accuracy: 0.7831\n",
            "Epoch 268/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7374 - accuracy: 0.6757 - val_loss: 0.6791 - val_accuracy: 0.7831\n",
            "Epoch 269/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7259 - accuracy: 0.6819 - val_loss: 0.6834 - val_accuracy: 0.7831\n",
            "Epoch 270/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7037 - accuracy: 0.6962 - val_loss: 0.6657 - val_accuracy: 0.7831\n",
            "Epoch 271/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7070 - accuracy: 0.6887 - val_loss: 0.6577 - val_accuracy: 0.7831\n",
            "Epoch 272/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7131 - accuracy: 0.6881 - val_loss: 0.6561 - val_accuracy: 0.7831\n",
            "Epoch 273/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7122 - accuracy: 0.6931 - val_loss: 0.6549 - val_accuracy: 0.7831\n",
            "Epoch 274/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7312 - accuracy: 0.6856 - val_loss: 0.6648 - val_accuracy: 0.7831\n",
            "Epoch 275/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7086 - accuracy: 0.6894 - val_loss: 0.6731 - val_accuracy: 0.7831\n",
            "Epoch 276/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7139 - accuracy: 0.6900 - val_loss: 0.6399 - val_accuracy: 0.7868\n",
            "Epoch 277/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.7004 - accuracy: 0.6900 - val_loss: 0.6675 - val_accuracy: 0.7831\n",
            "Epoch 278/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7140 - accuracy: 0.6949 - val_loss: 0.6752 - val_accuracy: 0.7831\n",
            "Epoch 279/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6998 - accuracy: 0.6949 - val_loss: 0.6326 - val_accuracy: 0.7978\n",
            "Epoch 280/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7072 - accuracy: 0.6986 - val_loss: 0.6548 - val_accuracy: 0.7831\n",
            "Epoch 281/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7112 - accuracy: 0.6863 - val_loss: 0.6529 - val_accuracy: 0.7831\n",
            "Epoch 282/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7032 - accuracy: 0.6974 - val_loss: 0.6566 - val_accuracy: 0.7831\n",
            "Epoch 283/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7194 - accuracy: 0.6813 - val_loss: 0.6705 - val_accuracy: 0.7831\n",
            "Epoch 284/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7011 - accuracy: 0.6980 - val_loss: 0.6544 - val_accuracy: 0.7831\n",
            "Epoch 285/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7076 - accuracy: 0.6925 - val_loss: 0.6567 - val_accuracy: 0.7831\n",
            "Epoch 286/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7049 - accuracy: 0.6906 - val_loss: 0.6424 - val_accuracy: 0.7868\n",
            "Epoch 287/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7138 - accuracy: 0.6875 - val_loss: 0.6493 - val_accuracy: 0.7831\n",
            "Epoch 288/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.7075 - accuracy: 0.6856 - val_loss: 0.6535 - val_accuracy: 0.7831\n",
            "Epoch 289/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7230 - accuracy: 0.6875 - val_loss: 0.6688 - val_accuracy: 0.7831\n",
            "Epoch 290/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6969 - accuracy: 0.6900 - val_loss: 0.6656 - val_accuracy: 0.7831\n",
            "Epoch 291/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7185 - accuracy: 0.6869 - val_loss: 0.6478 - val_accuracy: 0.7831\n",
            "Epoch 292/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7306 - accuracy: 0.6795 - val_loss: 0.6719 - val_accuracy: 0.7831\n",
            "Epoch 293/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7192 - accuracy: 0.6825 - val_loss: 0.6990 - val_accuracy: 0.7794\n",
            "Epoch 294/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7204 - accuracy: 0.6844 - val_loss: 0.7010 - val_accuracy: 0.7794\n",
            "Epoch 295/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7039 - accuracy: 0.6869 - val_loss: 0.6665 - val_accuracy: 0.7831\n",
            "Epoch 296/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7063 - accuracy: 0.6819 - val_loss: 0.6589 - val_accuracy: 0.7831\n",
            "Epoch 297/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7245 - accuracy: 0.6757 - val_loss: 0.6730 - val_accuracy: 0.7831\n",
            "Epoch 298/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7069 - accuracy: 0.6906 - val_loss: 0.6592 - val_accuracy: 0.7831\n",
            "Epoch 299/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7058 - accuracy: 0.6881 - val_loss: 0.6694 - val_accuracy: 0.7831\n",
            "Epoch 300/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7254 - accuracy: 0.6875 - val_loss: 0.7005 - val_accuracy: 0.7794\n",
            "Epoch 301/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7297 - accuracy: 0.6708 - val_loss: 0.6508 - val_accuracy: 0.7831\n",
            "Epoch 302/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6970 - accuracy: 0.6980 - val_loss: 0.6361 - val_accuracy: 0.7868\n",
            "Epoch 303/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7048 - accuracy: 0.6955 - val_loss: 0.7070 - val_accuracy: 0.7757\n",
            "Epoch 304/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7312 - accuracy: 0.6801 - val_loss: 0.6545 - val_accuracy: 0.7831\n",
            "Epoch 305/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7055 - accuracy: 0.6838 - val_loss: 0.6459 - val_accuracy: 0.7831\n",
            "Epoch 306/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7112 - accuracy: 0.6931 - val_loss: 0.6528 - val_accuracy: 0.7831\n",
            "Epoch 307/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.7047 - accuracy: 0.6887 - val_loss: 0.6651 - val_accuracy: 0.7831\n",
            "Epoch 308/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7042 - accuracy: 0.6925 - val_loss: 0.6531 - val_accuracy: 0.7831\n",
            "Epoch 309/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7042 - accuracy: 0.6912 - val_loss: 0.6461 - val_accuracy: 0.7831\n",
            "Epoch 310/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7020 - accuracy: 0.6974 - val_loss: 0.6809 - val_accuracy: 0.7794\n",
            "Epoch 311/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6915 - accuracy: 0.7005 - val_loss: 0.6163 - val_accuracy: 0.7978\n",
            "Epoch 312/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7169 - accuracy: 0.6856 - val_loss: 0.6473 - val_accuracy: 0.7831\n",
            "Epoch 313/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7013 - accuracy: 0.6949 - val_loss: 0.6569 - val_accuracy: 0.7831\n",
            "Epoch 314/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6956 - accuracy: 0.6900 - val_loss: 0.6390 - val_accuracy: 0.7831\n",
            "Epoch 315/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6955 - accuracy: 0.6881 - val_loss: 0.6435 - val_accuracy: 0.7831\n",
            "Epoch 316/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6818 - accuracy: 0.6986 - val_loss: 0.6187 - val_accuracy: 0.7868\n",
            "Epoch 317/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6860 - accuracy: 0.6875 - val_loss: 0.6417 - val_accuracy: 0.7831\n",
            "Epoch 318/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6862 - accuracy: 0.6931 - val_loss: 0.6258 - val_accuracy: 0.7868\n",
            "Epoch 319/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6956 - accuracy: 0.6931 - val_loss: 0.6502 - val_accuracy: 0.7831\n",
            "Epoch 320/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6989 - accuracy: 0.6906 - val_loss: 0.6302 - val_accuracy: 0.7868\n",
            "Epoch 321/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6969 - accuracy: 0.6974 - val_loss: 0.6451 - val_accuracy: 0.7831\n",
            "Epoch 322/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6920 - accuracy: 0.6937 - val_loss: 0.6368 - val_accuracy: 0.7831\n",
            "Epoch 323/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6860 - accuracy: 0.6937 - val_loss: 0.6186 - val_accuracy: 0.7868\n",
            "Epoch 324/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7096 - accuracy: 0.6850 - val_loss: 0.6225 - val_accuracy: 0.7868\n",
            "Epoch 325/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7150 - accuracy: 0.6819 - val_loss: 0.6227 - val_accuracy: 0.7868\n",
            "Epoch 326/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7006 - accuracy: 0.6906 - val_loss: 0.6592 - val_accuracy: 0.7831\n",
            "Epoch 327/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7042 - accuracy: 0.6850 - val_loss: 0.6614 - val_accuracy: 0.7831\n",
            "Epoch 328/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6989 - accuracy: 0.6894 - val_loss: 0.6386 - val_accuracy: 0.7831\n",
            "Epoch 329/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6974 - accuracy: 0.6962 - val_loss: 0.6364 - val_accuracy: 0.7831\n",
            "Epoch 330/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6951 - accuracy: 0.6869 - val_loss: 0.6429 - val_accuracy: 0.7831\n",
            "Epoch 331/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.7012 - accuracy: 0.6937 - val_loss: 0.6202 - val_accuracy: 0.7868\n",
            "Epoch 332/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6922 - accuracy: 0.6900 - val_loss: 0.6346 - val_accuracy: 0.7831\n",
            "Epoch 333/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6848 - accuracy: 0.6949 - val_loss: 0.6118 - val_accuracy: 0.7868\n",
            "Epoch 334/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6904 - accuracy: 0.6931 - val_loss: 0.6022 - val_accuracy: 0.8051\n",
            "Epoch 335/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6926 - accuracy: 0.6962 - val_loss: 0.6026 - val_accuracy: 0.8051\n",
            "Epoch 336/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7007 - accuracy: 0.6912 - val_loss: 0.6400 - val_accuracy: 0.7831\n",
            "Epoch 337/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6875 - accuracy: 0.6900 - val_loss: 0.6236 - val_accuracy: 0.7868\n",
            "Epoch 338/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6911 - accuracy: 0.6943 - val_loss: 0.6360 - val_accuracy: 0.7831\n",
            "Epoch 339/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6836 - accuracy: 0.6993 - val_loss: 0.6120 - val_accuracy: 0.7868\n",
            "Epoch 340/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.6856 - accuracy: 0.6962 - val_loss: 0.6367 - val_accuracy: 0.7831\n",
            "Epoch 341/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7019 - accuracy: 0.6925 - val_loss: 0.6307 - val_accuracy: 0.7831\n",
            "Epoch 342/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6934 - accuracy: 0.6918 - val_loss: 0.6193 - val_accuracy: 0.7868\n",
            "Epoch 343/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6910 - accuracy: 0.6918 - val_loss: 0.6135 - val_accuracy: 0.7868\n",
            "Epoch 344/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6740 - accuracy: 0.6974 - val_loss: 0.6128 - val_accuracy: 0.7868\n",
            "Epoch 345/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6875 - accuracy: 0.6887 - val_loss: 0.6198 - val_accuracy: 0.7868\n",
            "Epoch 346/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6792 - accuracy: 0.7067 - val_loss: 0.6210 - val_accuracy: 0.7868\n",
            "Epoch 347/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.6864 - accuracy: 0.6931 - val_loss: 0.6266 - val_accuracy: 0.7868\n",
            "Epoch 348/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6811 - accuracy: 0.6949 - val_loss: 0.6414 - val_accuracy: 0.7831\n",
            "Epoch 349/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6868 - accuracy: 0.7011 - val_loss: 0.6088 - val_accuracy: 0.7868\n",
            "Epoch 350/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7025 - accuracy: 0.6887 - val_loss: 0.6449 - val_accuracy: 0.7831\n",
            "Epoch 351/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7023 - accuracy: 0.6931 - val_loss: 0.6890 - val_accuracy: 0.7757\n",
            "Epoch 352/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.7064 - accuracy: 0.6801 - val_loss: 0.5979 - val_accuracy: 0.8015\n",
            "Epoch 353/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6843 - accuracy: 0.6962 - val_loss: 0.6025 - val_accuracy: 0.7868\n",
            "Epoch 354/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6861 - accuracy: 0.6943 - val_loss: 0.6215 - val_accuracy: 0.7868\n",
            "Epoch 355/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6748 - accuracy: 0.7024 - val_loss: 0.6106 - val_accuracy: 0.7868\n",
            "Epoch 356/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6728 - accuracy: 0.7042 - val_loss: 0.6066 - val_accuracy: 0.7868\n",
            "Epoch 357/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.7059 - accuracy: 0.6881 - val_loss: 0.6065 - val_accuracy: 0.7868\n",
            "Epoch 358/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6950 - accuracy: 0.6918 - val_loss: 0.6217 - val_accuracy: 0.7868\n",
            "Epoch 359/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6767 - accuracy: 0.6980 - val_loss: 0.5904 - val_accuracy: 0.8088\n",
            "Epoch 360/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6857 - accuracy: 0.6949 - val_loss: 0.5802 - val_accuracy: 0.8162\n",
            "Epoch 361/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6863 - accuracy: 0.6955 - val_loss: 0.6061 - val_accuracy: 0.7868\n",
            "Epoch 362/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6744 - accuracy: 0.6980 - val_loss: 0.6139 - val_accuracy: 0.7868\n",
            "Epoch 363/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6833 - accuracy: 0.6999 - val_loss: 0.6009 - val_accuracy: 0.7868\n",
            "Epoch 364/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6798 - accuracy: 0.6955 - val_loss: 0.6202 - val_accuracy: 0.7868\n",
            "Epoch 365/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6920 - accuracy: 0.6869 - val_loss: 0.5943 - val_accuracy: 0.8015\n",
            "Epoch 366/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6806 - accuracy: 0.6906 - val_loss: 0.5952 - val_accuracy: 0.7978\n",
            "Epoch 367/1000\n",
            "33/33 [==============================] - 4s 132ms/step - loss: 0.6784 - accuracy: 0.6918 - val_loss: 0.5942 - val_accuracy: 0.7978\n",
            "Epoch 368/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.6809 - accuracy: 0.7005 - val_loss: 0.5927 - val_accuracy: 0.8015\n",
            "Epoch 369/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6775 - accuracy: 0.6980 - val_loss: 0.5871 - val_accuracy: 0.8088\n",
            "Epoch 370/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6747 - accuracy: 0.6887 - val_loss: 0.5993 - val_accuracy: 0.7868\n",
            "Epoch 371/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6772 - accuracy: 0.6993 - val_loss: 0.5815 - val_accuracy: 0.8088\n",
            "Epoch 372/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6812 - accuracy: 0.6918 - val_loss: 0.5945 - val_accuracy: 0.7978\n",
            "Epoch 373/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6774 - accuracy: 0.6955 - val_loss: 0.5893 - val_accuracy: 0.8051\n",
            "Epoch 374/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6766 - accuracy: 0.6925 - val_loss: 0.5975 - val_accuracy: 0.7868\n",
            "Epoch 375/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6896 - accuracy: 0.6912 - val_loss: 0.5948 - val_accuracy: 0.7904\n",
            "Epoch 376/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6816 - accuracy: 0.6955 - val_loss: 0.5988 - val_accuracy: 0.7868\n",
            "Epoch 377/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6926 - accuracy: 0.6962 - val_loss: 0.6284 - val_accuracy: 0.7831\n",
            "Epoch 378/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6718 - accuracy: 0.6925 - val_loss: 0.6037 - val_accuracy: 0.7868\n",
            "Epoch 379/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6843 - accuracy: 0.6900 - val_loss: 0.5961 - val_accuracy: 0.7868\n",
            "Epoch 380/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6829 - accuracy: 0.6869 - val_loss: 0.5998 - val_accuracy: 0.7868\n",
            "Epoch 381/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6762 - accuracy: 0.7005 - val_loss: 0.5802 - val_accuracy: 0.8088\n",
            "Epoch 382/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6631 - accuracy: 0.7005 - val_loss: 0.5840 - val_accuracy: 0.8088\n",
            "Epoch 383/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6690 - accuracy: 0.6980 - val_loss: 0.5905 - val_accuracy: 0.7978\n",
            "Epoch 384/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6791 - accuracy: 0.6968 - val_loss: 0.5887 - val_accuracy: 0.8015\n",
            "Epoch 385/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6793 - accuracy: 0.6918 - val_loss: 0.5811 - val_accuracy: 0.8088\n",
            "Epoch 386/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6723 - accuracy: 0.6918 - val_loss: 0.5913 - val_accuracy: 0.7904\n",
            "Epoch 387/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6944 - accuracy: 0.6937 - val_loss: 0.6106 - val_accuracy: 0.7868\n",
            "Epoch 388/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6791 - accuracy: 0.6887 - val_loss: 0.5813 - val_accuracy: 0.8088\n",
            "Epoch 389/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6815 - accuracy: 0.7011 - val_loss: 0.5895 - val_accuracy: 0.7978\n",
            "Epoch 390/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6711 - accuracy: 0.6943 - val_loss: 0.5871 - val_accuracy: 0.8015\n",
            "Epoch 391/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6691 - accuracy: 0.6955 - val_loss: 0.5899 - val_accuracy: 0.7904\n",
            "Epoch 392/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6750 - accuracy: 0.6949 - val_loss: 0.6073 - val_accuracy: 0.7868\n",
            "Epoch 393/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6855 - accuracy: 0.6881 - val_loss: 0.5957 - val_accuracy: 0.7868\n",
            "Epoch 394/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6875 - accuracy: 0.6912 - val_loss: 0.6099 - val_accuracy: 0.7868\n",
            "Epoch 395/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6738 - accuracy: 0.6955 - val_loss: 0.5969 - val_accuracy: 0.7868\n",
            "Epoch 396/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6707 - accuracy: 0.6999 - val_loss: 0.5833 - val_accuracy: 0.8015\n",
            "Epoch 397/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6732 - accuracy: 0.6949 - val_loss: 0.5928 - val_accuracy: 0.7868\n",
            "Epoch 398/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6779 - accuracy: 0.6980 - val_loss: 0.5829 - val_accuracy: 0.8015\n",
            "Epoch 399/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6777 - accuracy: 0.6980 - val_loss: 0.5621 - val_accuracy: 0.8162\n",
            "Epoch 400/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6801 - accuracy: 0.6912 - val_loss: 0.5813 - val_accuracy: 0.8015\n",
            "Epoch 401/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6582 - accuracy: 0.7030 - val_loss: 0.5682 - val_accuracy: 0.8125\n",
            "Epoch 402/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6728 - accuracy: 0.6980 - val_loss: 0.5755 - val_accuracy: 0.8088\n",
            "Epoch 403/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6687 - accuracy: 0.7005 - val_loss: 0.5839 - val_accuracy: 0.7978\n",
            "Epoch 404/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6793 - accuracy: 0.6918 - val_loss: 0.6298 - val_accuracy: 0.7831\n",
            "Epoch 405/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6749 - accuracy: 0.6993 - val_loss: 0.6103 - val_accuracy: 0.7868\n",
            "Epoch 406/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7153 - accuracy: 0.6745 - val_loss: 0.6177 - val_accuracy: 0.7831\n",
            "Epoch 407/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6880 - accuracy: 0.6937 - val_loss: 0.6113 - val_accuracy: 0.7868\n",
            "Epoch 408/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6660 - accuracy: 0.7005 - val_loss: 0.5684 - val_accuracy: 0.8162\n",
            "Epoch 409/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6607 - accuracy: 0.7005 - val_loss: 0.5581 - val_accuracy: 0.8162\n",
            "Epoch 410/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6636 - accuracy: 0.6949 - val_loss: 0.5883 - val_accuracy: 0.7868\n",
            "Epoch 411/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6682 - accuracy: 0.6980 - val_loss: 0.5778 - val_accuracy: 0.8088\n",
            "Epoch 412/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.7146 - accuracy: 0.6844 - val_loss: 0.6626 - val_accuracy: 0.7757\n",
            "Epoch 413/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6743 - accuracy: 0.6863 - val_loss: 0.5967 - val_accuracy: 0.7868\n",
            "Epoch 414/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6791 - accuracy: 0.6937 - val_loss: 0.5912 - val_accuracy: 0.7868\n",
            "Epoch 415/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6666 - accuracy: 0.6974 - val_loss: 0.5884 - val_accuracy: 0.7904\n",
            "Epoch 416/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6719 - accuracy: 0.6918 - val_loss: 0.5903 - val_accuracy: 0.7868\n",
            "Epoch 417/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6718 - accuracy: 0.6943 - val_loss: 0.5838 - val_accuracy: 0.7978\n",
            "Epoch 418/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.6698 - accuracy: 0.6943 - val_loss: 0.5780 - val_accuracy: 0.8088\n",
            "Epoch 419/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6584 - accuracy: 0.7005 - val_loss: 0.5645 - val_accuracy: 0.8162\n",
            "Epoch 420/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6555 - accuracy: 0.7036 - val_loss: 0.5555 - val_accuracy: 0.8088\n",
            "Epoch 421/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6564 - accuracy: 0.7030 - val_loss: 0.5891 - val_accuracy: 0.7868\n",
            "Epoch 422/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6630 - accuracy: 0.7011 - val_loss: 0.5753 - val_accuracy: 0.8088\n",
            "Epoch 423/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6733 - accuracy: 0.6918 - val_loss: 0.5714 - val_accuracy: 0.8088\n",
            "Epoch 424/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6611 - accuracy: 0.7024 - val_loss: 0.5731 - val_accuracy: 0.8088\n",
            "Epoch 425/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6447 - accuracy: 0.7092 - val_loss: 0.5633 - val_accuracy: 0.8162\n",
            "Epoch 426/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6694 - accuracy: 0.6980 - val_loss: 0.5624 - val_accuracy: 0.8162\n",
            "Epoch 427/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6644 - accuracy: 0.7030 - val_loss: 0.5716 - val_accuracy: 0.8088\n",
            "Epoch 428/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6576 - accuracy: 0.6999 - val_loss: 0.5681 - val_accuracy: 0.8125\n",
            "Epoch 429/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6504 - accuracy: 0.7048 - val_loss: 0.5724 - val_accuracy: 0.8088\n",
            "Epoch 430/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6652 - accuracy: 0.7017 - val_loss: 0.5630 - val_accuracy: 0.8162\n",
            "Epoch 431/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6581 - accuracy: 0.7011 - val_loss: 0.5545 - val_accuracy: 0.8162\n",
            "Epoch 432/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6829 - accuracy: 0.6894 - val_loss: 0.5655 - val_accuracy: 0.8125\n",
            "Epoch 433/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6598 - accuracy: 0.7042 - val_loss: 0.5760 - val_accuracy: 0.8015\n",
            "Epoch 434/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6643 - accuracy: 0.7024 - val_loss: 0.5591 - val_accuracy: 0.8162\n",
            "Epoch 435/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6604 - accuracy: 0.7005 - val_loss: 0.5692 - val_accuracy: 0.8088\n",
            "Epoch 436/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6524 - accuracy: 0.7030 - val_loss: 0.5655 - val_accuracy: 0.8125\n",
            "Epoch 437/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6597 - accuracy: 0.6949 - val_loss: 0.5518 - val_accuracy: 0.8162\n",
            "Epoch 438/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6674 - accuracy: 0.6980 - val_loss: 0.5815 - val_accuracy: 0.7904\n",
            "Epoch 439/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.6607 - accuracy: 0.7024 - val_loss: 0.5751 - val_accuracy: 0.8015\n",
            "Epoch 440/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6656 - accuracy: 0.6986 - val_loss: 0.5657 - val_accuracy: 0.8125\n",
            "Epoch 441/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6588 - accuracy: 0.7011 - val_loss: 0.5548 - val_accuracy: 0.8162\n",
            "Epoch 442/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6651 - accuracy: 0.6955 - val_loss: 0.5485 - val_accuracy: 0.8088\n",
            "Epoch 443/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6710 - accuracy: 0.6986 - val_loss: 0.5486 - val_accuracy: 0.8088\n",
            "Epoch 444/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6580 - accuracy: 0.7011 - val_loss: 0.5484 - val_accuracy: 0.8088\n",
            "Epoch 445/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6616 - accuracy: 0.7024 - val_loss: 0.5761 - val_accuracy: 0.7941\n",
            "Epoch 446/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6768 - accuracy: 0.6918 - val_loss: 0.5665 - val_accuracy: 0.8088\n",
            "Epoch 447/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6474 - accuracy: 0.7079 - val_loss: 0.5485 - val_accuracy: 0.8162\n",
            "Epoch 448/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6620 - accuracy: 0.7042 - val_loss: 0.5552 - val_accuracy: 0.8162\n",
            "Epoch 449/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6675 - accuracy: 0.6906 - val_loss: 0.5523 - val_accuracy: 0.8162\n",
            "Epoch 450/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6654 - accuracy: 0.6949 - val_loss: 0.5875 - val_accuracy: 0.7868\n",
            "Epoch 451/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6616 - accuracy: 0.6999 - val_loss: 0.5519 - val_accuracy: 0.8162\n",
            "Epoch 452/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6512 - accuracy: 0.7024 - val_loss: 0.5476 - val_accuracy: 0.8088\n",
            "Epoch 453/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6644 - accuracy: 0.6968 - val_loss: 0.5644 - val_accuracy: 0.8088\n",
            "Epoch 454/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6629 - accuracy: 0.7030 - val_loss: 0.5638 - val_accuracy: 0.8088\n",
            "Epoch 455/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6524 - accuracy: 0.6980 - val_loss: 0.5589 - val_accuracy: 0.8162\n",
            "Epoch 456/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6711 - accuracy: 0.6962 - val_loss: 0.5556 - val_accuracy: 0.8162\n",
            "Epoch 457/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6551 - accuracy: 0.7036 - val_loss: 0.5477 - val_accuracy: 0.8162\n",
            "Epoch 458/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6594 - accuracy: 0.7005 - val_loss: 0.5505 - val_accuracy: 0.8162\n",
            "Epoch 459/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6653 - accuracy: 0.6986 - val_loss: 0.5487 - val_accuracy: 0.8162\n",
            "Epoch 460/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6562 - accuracy: 0.6993 - val_loss: 0.5543 - val_accuracy: 0.8162\n",
            "Epoch 461/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6595 - accuracy: 0.6993 - val_loss: 0.5941 - val_accuracy: 0.7868\n",
            "Epoch 462/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6567 - accuracy: 0.7030 - val_loss: 0.5678 - val_accuracy: 0.8088\n",
            "Epoch 463/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6663 - accuracy: 0.7024 - val_loss: 0.5606 - val_accuracy: 0.8125\n",
            "Epoch 464/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6530 - accuracy: 0.7011 - val_loss: 0.5469 - val_accuracy: 0.8162\n",
            "Epoch 465/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6448 - accuracy: 0.7054 - val_loss: 0.5505 - val_accuracy: 0.8162\n",
            "Epoch 466/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6481 - accuracy: 0.6974 - val_loss: 0.5518 - val_accuracy: 0.8162\n",
            "Epoch 467/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6546 - accuracy: 0.6962 - val_loss: 0.5470 - val_accuracy: 0.8125\n",
            "Epoch 468/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6591 - accuracy: 0.7048 - val_loss: 0.5582 - val_accuracy: 0.8162\n",
            "Epoch 469/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6562 - accuracy: 0.7042 - val_loss: 0.5990 - val_accuracy: 0.7831\n",
            "Epoch 470/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6560 - accuracy: 0.7042 - val_loss: 0.5471 - val_accuracy: 0.8088\n",
            "Epoch 471/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6588 - accuracy: 0.6993 - val_loss: 0.5641 - val_accuracy: 0.8088\n",
            "Epoch 472/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6558 - accuracy: 0.7036 - val_loss: 0.5466 - val_accuracy: 0.8199\n",
            "Epoch 473/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6637 - accuracy: 0.7054 - val_loss: 0.5520 - val_accuracy: 0.8162\n",
            "Epoch 474/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6604 - accuracy: 0.6980 - val_loss: 0.5590 - val_accuracy: 0.8162\n",
            "Epoch 475/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6574 - accuracy: 0.6999 - val_loss: 0.5526 - val_accuracy: 0.8162\n",
            "Epoch 476/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6541 - accuracy: 0.7067 - val_loss: 0.5470 - val_accuracy: 0.8051\n",
            "Epoch 477/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6497 - accuracy: 0.7048 - val_loss: 0.5465 - val_accuracy: 0.8199\n",
            "Epoch 478/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6498 - accuracy: 0.7005 - val_loss: 0.5477 - val_accuracy: 0.8162\n",
            "Epoch 479/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6532 - accuracy: 0.7067 - val_loss: 0.5492 - val_accuracy: 0.7978\n",
            "Epoch 480/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6642 - accuracy: 0.6962 - val_loss: 0.5580 - val_accuracy: 0.8162\n",
            "Epoch 481/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6534 - accuracy: 0.7073 - val_loss: 0.5479 - val_accuracy: 0.8162\n",
            "Epoch 482/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6493 - accuracy: 0.7054 - val_loss: 0.5450 - val_accuracy: 0.8051\n",
            "Epoch 483/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6406 - accuracy: 0.7030 - val_loss: 0.5440 - val_accuracy: 0.8199\n",
            "Epoch 484/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6486 - accuracy: 0.7011 - val_loss: 0.5497 - val_accuracy: 0.8162\n",
            "Epoch 485/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6481 - accuracy: 0.6993 - val_loss: 0.5445 - val_accuracy: 0.8162\n",
            "Epoch 486/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6553 - accuracy: 0.7030 - val_loss: 0.5431 - val_accuracy: 0.8199\n",
            "Epoch 487/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6381 - accuracy: 0.7079 - val_loss: 0.5664 - val_accuracy: 0.8088\n",
            "Epoch 488/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6400 - accuracy: 0.7042 - val_loss: 0.5452 - val_accuracy: 0.7978\n",
            "Epoch 489/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6482 - accuracy: 0.7048 - val_loss: 0.5460 - val_accuracy: 0.7978\n",
            "Epoch 490/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6534 - accuracy: 0.6974 - val_loss: 0.5417 - val_accuracy: 0.8199\n",
            "Epoch 491/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6408 - accuracy: 0.7017 - val_loss: 0.5417 - val_accuracy: 0.8199\n",
            "Epoch 492/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6537 - accuracy: 0.6986 - val_loss: 0.5447 - val_accuracy: 0.8162\n",
            "Epoch 493/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6453 - accuracy: 0.7061 - val_loss: 0.5448 - val_accuracy: 0.8051\n",
            "Epoch 494/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6488 - accuracy: 0.7005 - val_loss: 0.5543 - val_accuracy: 0.8162\n",
            "Epoch 495/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6485 - accuracy: 0.7017 - val_loss: 0.5491 - val_accuracy: 0.8162\n",
            "Epoch 496/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6607 - accuracy: 0.6955 - val_loss: 0.5446 - val_accuracy: 0.8088\n",
            "Epoch 497/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6538 - accuracy: 0.6968 - val_loss: 0.5434 - val_accuracy: 0.8199\n",
            "Epoch 498/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6454 - accuracy: 0.7048 - val_loss: 0.5428 - val_accuracy: 0.8199\n",
            "Epoch 499/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6497 - accuracy: 0.7030 - val_loss: 0.5434 - val_accuracy: 0.8162\n",
            "Epoch 500/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6372 - accuracy: 0.7092 - val_loss: 0.5424 - val_accuracy: 0.8125\n",
            "Epoch 501/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6548 - accuracy: 0.6993 - val_loss: 0.5474 - val_accuracy: 0.8162\n",
            "Epoch 502/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6593 - accuracy: 0.7030 - val_loss: 0.5811 - val_accuracy: 0.7868\n",
            "Epoch 503/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6490 - accuracy: 0.7024 - val_loss: 0.5419 - val_accuracy: 0.8051\n",
            "Epoch 504/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6539 - accuracy: 0.7073 - val_loss: 0.5418 - val_accuracy: 0.8162\n",
            "Epoch 505/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6674 - accuracy: 0.6986 - val_loss: 0.6004 - val_accuracy: 0.7831\n",
            "Epoch 506/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6595 - accuracy: 0.6949 - val_loss: 0.5440 - val_accuracy: 0.8015\n",
            "Epoch 507/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6553 - accuracy: 0.6974 - val_loss: 0.5469 - val_accuracy: 0.8162\n",
            "Epoch 508/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6421 - accuracy: 0.7005 - val_loss: 0.5402 - val_accuracy: 0.8162\n",
            "Epoch 509/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6422 - accuracy: 0.7098 - val_loss: 0.5399 - val_accuracy: 0.8162\n",
            "Epoch 510/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6526 - accuracy: 0.6999 - val_loss: 0.5394 - val_accuracy: 0.8199\n",
            "Epoch 511/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6337 - accuracy: 0.7110 - val_loss: 0.5671 - val_accuracy: 0.7904\n",
            "Epoch 512/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6377 - accuracy: 0.7067 - val_loss: 0.5457 - val_accuracy: 0.7978\n",
            "Epoch 513/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6554 - accuracy: 0.7054 - val_loss: 0.5452 - val_accuracy: 0.8162\n",
            "Epoch 514/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6596 - accuracy: 0.7011 - val_loss: 0.5410 - val_accuracy: 0.8199\n",
            "Epoch 515/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6465 - accuracy: 0.7030 - val_loss: 0.5563 - val_accuracy: 0.8088\n",
            "Epoch 516/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6439 - accuracy: 0.6999 - val_loss: 0.5397 - val_accuracy: 0.8199\n",
            "Epoch 517/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6334 - accuracy: 0.7085 - val_loss: 0.5815 - val_accuracy: 0.7684\n",
            "Epoch 518/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6515 - accuracy: 0.7030 - val_loss: 0.5397 - val_accuracy: 0.8199\n",
            "Epoch 519/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6464 - accuracy: 0.7054 - val_loss: 0.5408 - val_accuracy: 0.8162\n",
            "Epoch 520/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6392 - accuracy: 0.7042 - val_loss: 0.5392 - val_accuracy: 0.8199\n",
            "Epoch 521/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6509 - accuracy: 0.7030 - val_loss: 0.5394 - val_accuracy: 0.8199\n",
            "Epoch 522/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6435 - accuracy: 0.7073 - val_loss: 0.5415 - val_accuracy: 0.8051\n",
            "Epoch 523/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6397 - accuracy: 0.7067 - val_loss: 0.5410 - val_accuracy: 0.8125\n",
            "Epoch 524/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6446 - accuracy: 0.7030 - val_loss: 0.5548 - val_accuracy: 0.8015\n",
            "Epoch 525/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6450 - accuracy: 0.7036 - val_loss: 0.5409 - val_accuracy: 0.8088\n",
            "Epoch 526/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6386 - accuracy: 0.7042 - val_loss: 0.5540 - val_accuracy: 0.8015\n",
            "Epoch 527/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6477 - accuracy: 0.7017 - val_loss: 0.5387 - val_accuracy: 0.8199\n",
            "Epoch 528/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6577 - accuracy: 0.6968 - val_loss: 0.5401 - val_accuracy: 0.8162\n",
            "Epoch 529/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6413 - accuracy: 0.7067 - val_loss: 0.5383 - val_accuracy: 0.8199\n",
            "Epoch 530/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6531 - accuracy: 0.7085 - val_loss: 0.5390 - val_accuracy: 0.8162\n",
            "Epoch 531/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6584 - accuracy: 0.7005 - val_loss: 0.5517 - val_accuracy: 0.8015\n",
            "Epoch 532/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6406 - accuracy: 0.7042 - val_loss: 0.5396 - val_accuracy: 0.8088\n",
            "Epoch 533/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6336 - accuracy: 0.7123 - val_loss: 0.5370 - val_accuracy: 0.8199\n",
            "Epoch 534/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6280 - accuracy: 0.7116 - val_loss: 0.5527 - val_accuracy: 0.8015\n",
            "Epoch 535/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6283 - accuracy: 0.7135 - val_loss: 0.5408 - val_accuracy: 0.8051\n",
            "Epoch 536/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6432 - accuracy: 0.7036 - val_loss: 0.5493 - val_accuracy: 0.8015\n",
            "Epoch 537/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6312 - accuracy: 0.7085 - val_loss: 0.5459 - val_accuracy: 0.7978\n",
            "Epoch 538/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6315 - accuracy: 0.7067 - val_loss: 0.5421 - val_accuracy: 0.8088\n",
            "Epoch 539/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6324 - accuracy: 0.7048 - val_loss: 0.5492 - val_accuracy: 0.7978\n",
            "Epoch 540/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6288 - accuracy: 0.7054 - val_loss: 0.5416 - val_accuracy: 0.8125\n",
            "Epoch 541/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6705 - accuracy: 0.6980 - val_loss: 0.5550 - val_accuracy: 0.8088\n",
            "Epoch 542/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6457 - accuracy: 0.7079 - val_loss: 0.5479 - val_accuracy: 0.7978\n",
            "Epoch 543/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6403 - accuracy: 0.6999 - val_loss: 0.5392 - val_accuracy: 0.8162\n",
            "Epoch 544/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6390 - accuracy: 0.7048 - val_loss: 0.5528 - val_accuracy: 0.8015\n",
            "Epoch 545/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6463 - accuracy: 0.7011 - val_loss: 0.5371 - val_accuracy: 0.8199\n",
            "Epoch 546/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6344 - accuracy: 0.7141 - val_loss: 0.5372 - val_accuracy: 0.8199\n",
            "Epoch 547/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6489 - accuracy: 0.7017 - val_loss: 0.5616 - val_accuracy: 0.7794\n",
            "Epoch 548/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6339 - accuracy: 0.6993 - val_loss: 0.5535 - val_accuracy: 0.8015\n",
            "Epoch 549/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6603 - accuracy: 0.7036 - val_loss: 0.5468 - val_accuracy: 0.8162\n",
            "Epoch 550/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6454 - accuracy: 0.7036 - val_loss: 0.5390 - val_accuracy: 0.8162\n",
            "Epoch 551/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6290 - accuracy: 0.7110 - val_loss: 0.5419 - val_accuracy: 0.8051\n",
            "Epoch 552/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6439 - accuracy: 0.7085 - val_loss: 0.5383 - val_accuracy: 0.8162\n",
            "Epoch 553/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6369 - accuracy: 0.7042 - val_loss: 0.5532 - val_accuracy: 0.8088\n",
            "Epoch 554/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6403 - accuracy: 0.7042 - val_loss: 0.5447 - val_accuracy: 0.8051\n",
            "Epoch 555/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6317 - accuracy: 0.7073 - val_loss: 0.5522 - val_accuracy: 0.8015\n",
            "Epoch 556/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6317 - accuracy: 0.7079 - val_loss: 0.5753 - val_accuracy: 0.7610\n",
            "Epoch 557/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.6467 - accuracy: 0.7011 - val_loss: 0.5451 - val_accuracy: 0.8015\n",
            "Epoch 558/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6206 - accuracy: 0.7079 - val_loss: 0.5402 - val_accuracy: 0.8088\n",
            "Epoch 559/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6303 - accuracy: 0.7104 - val_loss: 0.5420 - val_accuracy: 0.8051\n",
            "Epoch 560/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6327 - accuracy: 0.7054 - val_loss: 0.5433 - val_accuracy: 0.8015\n",
            "Epoch 561/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6312 - accuracy: 0.7036 - val_loss: 0.5638 - val_accuracy: 0.7757\n",
            "Epoch 562/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6328 - accuracy: 0.7011 - val_loss: 0.5516 - val_accuracy: 0.8015\n",
            "Epoch 563/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6475 - accuracy: 0.6999 - val_loss: 0.5348 - val_accuracy: 0.8199\n",
            "Epoch 564/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6303 - accuracy: 0.7085 - val_loss: 0.5694 - val_accuracy: 0.7684\n",
            "Epoch 565/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6334 - accuracy: 0.7110 - val_loss: 0.5652 - val_accuracy: 0.7721\n",
            "Epoch 566/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6180 - accuracy: 0.7092 - val_loss: 0.5481 - val_accuracy: 0.8015\n",
            "Epoch 567/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6470 - accuracy: 0.6980 - val_loss: 0.5495 - val_accuracy: 0.8015\n",
            "Epoch 568/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6360 - accuracy: 0.7079 - val_loss: 0.5638 - val_accuracy: 0.7757\n",
            "Epoch 569/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6332 - accuracy: 0.7054 - val_loss: 0.5324 - val_accuracy: 0.8199\n",
            "Epoch 570/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6307 - accuracy: 0.7036 - val_loss: 0.6472 - val_accuracy: 0.6801\n",
            "Epoch 571/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6378 - accuracy: 0.7061 - val_loss: 0.5567 - val_accuracy: 0.7831\n",
            "Epoch 572/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6388 - accuracy: 0.7030 - val_loss: 0.5897 - val_accuracy: 0.7279\n",
            "Epoch 573/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6458 - accuracy: 0.6993 - val_loss: 0.5337 - val_accuracy: 0.8199\n",
            "Epoch 574/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6260 - accuracy: 0.7073 - val_loss: 0.5631 - val_accuracy: 0.7721\n",
            "Epoch 575/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.6236 - accuracy: 0.7085 - val_loss: 0.5429 - val_accuracy: 0.8162\n",
            "Epoch 576/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6330 - accuracy: 0.7116 - val_loss: 0.5513 - val_accuracy: 0.7978\n",
            "Epoch 577/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6276 - accuracy: 0.7104 - val_loss: 0.6180 - val_accuracy: 0.6985\n",
            "Epoch 578/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6157 - accuracy: 0.7123 - val_loss: 0.5450 - val_accuracy: 0.8015\n",
            "Epoch 579/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6415 - accuracy: 0.6999 - val_loss: 0.5334 - val_accuracy: 0.8125\n",
            "Epoch 580/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6343 - accuracy: 0.7116 - val_loss: 0.5365 - val_accuracy: 0.8051\n",
            "Epoch 581/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6302 - accuracy: 0.7061 - val_loss: 0.5311 - val_accuracy: 0.8199\n",
            "Epoch 582/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6415 - accuracy: 0.6993 - val_loss: 0.5381 - val_accuracy: 0.8051\n",
            "Epoch 583/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6473 - accuracy: 0.6986 - val_loss: 0.5516 - val_accuracy: 0.7978\n",
            "Epoch 584/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6344 - accuracy: 0.7092 - val_loss: 0.5391 - val_accuracy: 0.8051\n",
            "Epoch 585/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6402 - accuracy: 0.7048 - val_loss: 0.5390 - val_accuracy: 0.8162\n",
            "Epoch 586/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6360 - accuracy: 0.7061 - val_loss: 0.6020 - val_accuracy: 0.7022\n",
            "Epoch 587/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6201 - accuracy: 0.7147 - val_loss: 0.5333 - val_accuracy: 0.8199\n",
            "Epoch 588/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6364 - accuracy: 0.7005 - val_loss: 0.5540 - val_accuracy: 0.7831\n",
            "Epoch 589/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6267 - accuracy: 0.7036 - val_loss: 0.5997 - val_accuracy: 0.7022\n",
            "Epoch 590/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6277 - accuracy: 0.7030 - val_loss: 0.6412 - val_accuracy: 0.6765\n",
            "Epoch 591/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6321 - accuracy: 0.7092 - val_loss: 0.5836 - val_accuracy: 0.7243\n",
            "Epoch 592/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6178 - accuracy: 0.7092 - val_loss: 0.5883 - val_accuracy: 0.7169\n",
            "Epoch 593/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6329 - accuracy: 0.7085 - val_loss: 0.5351 - val_accuracy: 0.8199\n",
            "Epoch 594/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6147 - accuracy: 0.7085 - val_loss: 0.5962 - val_accuracy: 0.6985\n",
            "Epoch 595/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6293 - accuracy: 0.7024 - val_loss: 0.5581 - val_accuracy: 0.7794\n",
            "Epoch 596/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6157 - accuracy: 0.7054 - val_loss: 0.5616 - val_accuracy: 0.7757\n",
            "Epoch 597/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6150 - accuracy: 0.7172 - val_loss: 0.5631 - val_accuracy: 0.7721\n",
            "Epoch 598/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6322 - accuracy: 0.7073 - val_loss: 0.5556 - val_accuracy: 0.7794\n",
            "Epoch 599/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6171 - accuracy: 0.7135 - val_loss: 0.7154 - val_accuracy: 0.6654\n",
            "Epoch 600/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6176 - accuracy: 0.7135 - val_loss: 0.6415 - val_accuracy: 0.6728\n",
            "Epoch 601/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6275 - accuracy: 0.7079 - val_loss: 0.5337 - val_accuracy: 0.8199\n",
            "Epoch 602/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6176 - accuracy: 0.7123 - val_loss: 0.5892 - val_accuracy: 0.7022\n",
            "Epoch 603/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6300 - accuracy: 0.7098 - val_loss: 0.5421 - val_accuracy: 0.8199\n",
            "Epoch 604/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6158 - accuracy: 0.7135 - val_loss: 0.5524 - val_accuracy: 0.7868\n",
            "Epoch 605/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6194 - accuracy: 0.7104 - val_loss: 0.5336 - val_accuracy: 0.8199\n",
            "Epoch 606/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6262 - accuracy: 0.7073 - val_loss: 0.5574 - val_accuracy: 0.7794\n",
            "Epoch 607/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6331 - accuracy: 0.7085 - val_loss: 0.5636 - val_accuracy: 0.7684\n",
            "Epoch 608/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6193 - accuracy: 0.7141 - val_loss: 0.5769 - val_accuracy: 0.7243\n",
            "Epoch 609/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6274 - accuracy: 0.7079 - val_loss: 0.5338 - val_accuracy: 0.8162\n",
            "Epoch 610/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6314 - accuracy: 0.7073 - val_loss: 0.5481 - val_accuracy: 0.7978\n",
            "Epoch 611/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6393 - accuracy: 0.7005 - val_loss: 0.5754 - val_accuracy: 0.7243\n",
            "Epoch 612/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6107 - accuracy: 0.7178 - val_loss: 0.5516 - val_accuracy: 0.7831\n",
            "Epoch 613/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6371 - accuracy: 0.7110 - val_loss: 0.5547 - val_accuracy: 0.7794\n",
            "Epoch 614/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6215 - accuracy: 0.7104 - val_loss: 0.7280 - val_accuracy: 0.6654\n",
            "Epoch 615/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6369 - accuracy: 0.7116 - val_loss: 0.5731 - val_accuracy: 0.7353\n",
            "Epoch 616/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6345 - accuracy: 0.7092 - val_loss: 0.5670 - val_accuracy: 0.7463\n",
            "Epoch 617/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6283 - accuracy: 0.7030 - val_loss: 0.5303 - val_accuracy: 0.8199\n",
            "Epoch 618/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6259 - accuracy: 0.7104 - val_loss: 0.6134 - val_accuracy: 0.6838\n",
            "Epoch 619/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6196 - accuracy: 0.7098 - val_loss: 0.7710 - val_accuracy: 0.6654\n",
            "Epoch 620/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6238 - accuracy: 0.7098 - val_loss: 0.5973 - val_accuracy: 0.6949\n",
            "Epoch 621/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6214 - accuracy: 0.7116 - val_loss: 0.7538 - val_accuracy: 0.6654\n",
            "Epoch 622/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6407 - accuracy: 0.7017 - val_loss: 0.5309 - val_accuracy: 0.8199\n",
            "Epoch 623/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6298 - accuracy: 0.7104 - val_loss: 0.6047 - val_accuracy: 0.6801\n",
            "Epoch 624/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6317 - accuracy: 0.7061 - val_loss: 0.5916 - val_accuracy: 0.6949\n",
            "Epoch 625/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6323 - accuracy: 0.7098 - val_loss: 0.5445 - val_accuracy: 0.8088\n",
            "Epoch 626/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6150 - accuracy: 0.7141 - val_loss: 0.6333 - val_accuracy: 0.6765\n",
            "Epoch 627/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6172 - accuracy: 0.7085 - val_loss: 0.5644 - val_accuracy: 0.7574\n",
            "Epoch 628/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6275 - accuracy: 0.7061 - val_loss: 0.5866 - val_accuracy: 0.6985\n",
            "Epoch 629/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6275 - accuracy: 0.7085 - val_loss: 0.5304 - val_accuracy: 0.8199\n",
            "Epoch 630/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6191 - accuracy: 0.7110 - val_loss: 0.5392 - val_accuracy: 0.8235\n",
            "Epoch 631/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6323 - accuracy: 0.7054 - val_loss: 0.5982 - val_accuracy: 0.6875\n",
            "Epoch 632/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6215 - accuracy: 0.7092 - val_loss: 0.5473 - val_accuracy: 0.7904\n",
            "Epoch 633/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6317 - accuracy: 0.7079 - val_loss: 0.5306 - val_accuracy: 0.8199\n",
            "Epoch 634/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6182 - accuracy: 0.7153 - val_loss: 0.5534 - val_accuracy: 0.7794\n",
            "Epoch 635/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6236 - accuracy: 0.7123 - val_loss: 0.5551 - val_accuracy: 0.7757\n",
            "Epoch 636/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6380 - accuracy: 0.7030 - val_loss: 0.5390 - val_accuracy: 0.8162\n",
            "Epoch 637/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6236 - accuracy: 0.7104 - val_loss: 0.5521 - val_accuracy: 0.7831\n",
            "Epoch 638/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6156 - accuracy: 0.7104 - val_loss: 0.6209 - val_accuracy: 0.6728\n",
            "Epoch 639/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6477 - accuracy: 0.7067 - val_loss: 0.6248 - val_accuracy: 0.6728\n",
            "Epoch 640/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6242 - accuracy: 0.7079 - val_loss: 0.5346 - val_accuracy: 0.8199\n",
            "Epoch 641/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6174 - accuracy: 0.7147 - val_loss: 0.5430 - val_accuracy: 0.8199\n",
            "Epoch 642/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6217 - accuracy: 0.7036 - val_loss: 0.5598 - val_accuracy: 0.7574\n",
            "Epoch 643/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6075 - accuracy: 0.7184 - val_loss: 0.7036 - val_accuracy: 0.6654\n",
            "Epoch 644/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6133 - accuracy: 0.7166 - val_loss: 0.5729 - val_accuracy: 0.7243\n",
            "Epoch 645/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6209 - accuracy: 0.7054 - val_loss: 0.6460 - val_accuracy: 0.6691\n",
            "Epoch 646/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6118 - accuracy: 0.7141 - val_loss: 0.5800 - val_accuracy: 0.7096\n",
            "Epoch 647/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6219 - accuracy: 0.7110 - val_loss: 0.5890 - val_accuracy: 0.6985\n",
            "Epoch 648/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6203 - accuracy: 0.7129 - val_loss: 0.6268 - val_accuracy: 0.6765\n",
            "Epoch 649/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6263 - accuracy: 0.7160 - val_loss: 0.5416 - val_accuracy: 0.8235\n",
            "Epoch 650/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6238 - accuracy: 0.7123 - val_loss: 0.5318 - val_accuracy: 0.8199\n",
            "Epoch 651/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6268 - accuracy: 0.7116 - val_loss: 0.5725 - val_accuracy: 0.7206\n",
            "Epoch 652/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6383 - accuracy: 0.7017 - val_loss: 0.5437 - val_accuracy: 0.8051\n",
            "Epoch 653/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6212 - accuracy: 0.7110 - val_loss: 0.5279 - val_accuracy: 0.8199\n",
            "Epoch 654/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6244 - accuracy: 0.7135 - val_loss: 0.6132 - val_accuracy: 0.6728\n",
            "Epoch 655/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6106 - accuracy: 0.7123 - val_loss: 0.5379 - val_accuracy: 0.8199\n",
            "Epoch 656/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6083 - accuracy: 0.7172 - val_loss: 0.5687 - val_accuracy: 0.7243\n",
            "Epoch 657/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6240 - accuracy: 0.7129 - val_loss: 0.5276 - val_accuracy: 0.8199\n",
            "Epoch 658/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6111 - accuracy: 0.7141 - val_loss: 0.6605 - val_accuracy: 0.6728\n",
            "Epoch 659/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6325 - accuracy: 0.7116 - val_loss: 0.6021 - val_accuracy: 0.6838\n",
            "Epoch 660/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6175 - accuracy: 0.7092 - val_loss: 0.5750 - val_accuracy: 0.7096\n",
            "Epoch 661/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.6102 - accuracy: 0.7166 - val_loss: 0.5879 - val_accuracy: 0.6985\n",
            "Epoch 662/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6292 - accuracy: 0.7085 - val_loss: 0.5280 - val_accuracy: 0.8199\n",
            "Epoch 663/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6184 - accuracy: 0.7153 - val_loss: 0.5969 - val_accuracy: 0.6912\n",
            "Epoch 664/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6364 - accuracy: 0.7079 - val_loss: 0.5482 - val_accuracy: 0.7831\n",
            "Epoch 665/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6258 - accuracy: 0.7079 - val_loss: 0.5583 - val_accuracy: 0.7574\n",
            "Epoch 666/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6161 - accuracy: 0.7110 - val_loss: 0.7711 - val_accuracy: 0.6654\n",
            "Epoch 667/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6222 - accuracy: 0.7110 - val_loss: 0.6104 - val_accuracy: 0.6728\n",
            "Epoch 668/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6182 - accuracy: 0.7079 - val_loss: 0.6484 - val_accuracy: 0.6691\n",
            "Epoch 669/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6062 - accuracy: 0.7141 - val_loss: 0.6201 - val_accuracy: 0.6728\n",
            "Epoch 670/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6119 - accuracy: 0.7203 - val_loss: 0.5330 - val_accuracy: 0.8235\n",
            "Epoch 671/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6293 - accuracy: 0.7054 - val_loss: 0.5376 - val_accuracy: 0.8162\n",
            "Epoch 672/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6353 - accuracy: 0.7079 - val_loss: 0.5445 - val_accuracy: 0.7941\n",
            "Epoch 673/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6174 - accuracy: 0.7123 - val_loss: 0.5362 - val_accuracy: 0.8235\n",
            "Epoch 674/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6087 - accuracy: 0.7123 - val_loss: 0.5576 - val_accuracy: 0.7684\n",
            "Epoch 675/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6188 - accuracy: 0.7079 - val_loss: 0.6521 - val_accuracy: 0.6691\n",
            "Epoch 676/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6067 - accuracy: 0.7172 - val_loss: 0.5331 - val_accuracy: 0.8235\n",
            "Epoch 677/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6187 - accuracy: 0.7135 - val_loss: 0.5800 - val_accuracy: 0.6985\n",
            "Epoch 678/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6437 - accuracy: 0.7011 - val_loss: 0.5308 - val_accuracy: 0.8162\n",
            "Epoch 679/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6264 - accuracy: 0.7079 - val_loss: 0.5402 - val_accuracy: 0.8162\n",
            "Epoch 680/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.6086 - accuracy: 0.7135 - val_loss: 0.5912 - val_accuracy: 0.6838\n",
            "Epoch 681/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6098 - accuracy: 0.7147 - val_loss: 0.7490 - val_accuracy: 0.6654\n",
            "Epoch 682/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6102 - accuracy: 0.7123 - val_loss: 0.5625 - val_accuracy: 0.7390\n",
            "Epoch 683/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6159 - accuracy: 0.7079 - val_loss: 0.6335 - val_accuracy: 0.6728\n",
            "Epoch 684/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6352 - accuracy: 0.7061 - val_loss: 0.5265 - val_accuracy: 0.8199\n",
            "Epoch 685/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6178 - accuracy: 0.7054 - val_loss: 0.5709 - val_accuracy: 0.7132\n",
            "Epoch 686/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6335 - accuracy: 0.7054 - val_loss: 0.5336 - val_accuracy: 0.8199\n",
            "Epoch 687/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6205 - accuracy: 0.7110 - val_loss: 0.5277 - val_accuracy: 0.8199\n",
            "Epoch 688/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6216 - accuracy: 0.7067 - val_loss: 0.7354 - val_accuracy: 0.6654\n",
            "Epoch 689/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6083 - accuracy: 0.7172 - val_loss: 0.5637 - val_accuracy: 0.7353\n",
            "Epoch 690/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6250 - accuracy: 0.7048 - val_loss: 0.6308 - val_accuracy: 0.6691\n",
            "Epoch 691/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6029 - accuracy: 0.7209 - val_loss: 0.6912 - val_accuracy: 0.6654\n",
            "Epoch 692/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6223 - accuracy: 0.7110 - val_loss: 0.5351 - val_accuracy: 0.8235\n",
            "Epoch 693/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6088 - accuracy: 0.7197 - val_loss: 0.5793 - val_accuracy: 0.7022\n",
            "Epoch 694/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6205 - accuracy: 0.7067 - val_loss: 0.5922 - val_accuracy: 0.6838\n",
            "Epoch 695/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6123 - accuracy: 0.7123 - val_loss: 0.5364 - val_accuracy: 0.8235\n",
            "Epoch 696/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6123 - accuracy: 0.7141 - val_loss: 0.5809 - val_accuracy: 0.7022\n",
            "Epoch 697/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6109 - accuracy: 0.7123 - val_loss: 0.5939 - val_accuracy: 0.6765\n",
            "Epoch 698/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6154 - accuracy: 0.7116 - val_loss: 0.7103 - val_accuracy: 0.6654\n",
            "Epoch 699/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6294 - accuracy: 0.7110 - val_loss: 0.5526 - val_accuracy: 0.7757\n",
            "Epoch 700/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6276 - accuracy: 0.7092 - val_loss: 0.5263 - val_accuracy: 0.8199\n",
            "Epoch 701/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6104 - accuracy: 0.7129 - val_loss: 0.6066 - val_accuracy: 0.6691\n",
            "Epoch 702/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6128 - accuracy: 0.7042 - val_loss: 0.5451 - val_accuracy: 0.7941\n",
            "Epoch 703/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6153 - accuracy: 0.7153 - val_loss: 0.6117 - val_accuracy: 0.6691\n",
            "Epoch 704/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6073 - accuracy: 0.7153 - val_loss: 0.5774 - val_accuracy: 0.7059\n",
            "Epoch 705/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6193 - accuracy: 0.7079 - val_loss: 0.5526 - val_accuracy: 0.7721\n",
            "Epoch 706/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6006 - accuracy: 0.7141 - val_loss: 0.5532 - val_accuracy: 0.7757\n",
            "Epoch 707/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6195 - accuracy: 0.7098 - val_loss: 0.6453 - val_accuracy: 0.6618\n",
            "Epoch 708/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6011 - accuracy: 0.7166 - val_loss: 0.6191 - val_accuracy: 0.6691\n",
            "Epoch 709/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6073 - accuracy: 0.7166 - val_loss: 0.5873 - val_accuracy: 0.6875\n",
            "Epoch 710/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6040 - accuracy: 0.7116 - val_loss: 0.6573 - val_accuracy: 0.6618\n",
            "Epoch 711/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6111 - accuracy: 0.7135 - val_loss: 0.8082 - val_accuracy: 0.6691\n",
            "Epoch 712/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6090 - accuracy: 0.7067 - val_loss: 0.5455 - val_accuracy: 0.7941\n",
            "Epoch 713/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6164 - accuracy: 0.7098 - val_loss: 0.5302 - val_accuracy: 0.8199\n",
            "Epoch 714/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6025 - accuracy: 0.7135 - val_loss: 0.7043 - val_accuracy: 0.6654\n",
            "Epoch 715/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6005 - accuracy: 0.7123 - val_loss: 0.6836 - val_accuracy: 0.6654\n",
            "Epoch 716/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6041 - accuracy: 0.7141 - val_loss: 0.6876 - val_accuracy: 0.6654\n",
            "Epoch 717/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5999 - accuracy: 0.7184 - val_loss: 0.6819 - val_accuracy: 0.6654\n",
            "Epoch 718/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6011 - accuracy: 0.7166 - val_loss: 0.7508 - val_accuracy: 0.6691\n",
            "Epoch 719/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6236 - accuracy: 0.7042 - val_loss: 0.5612 - val_accuracy: 0.7353\n",
            "Epoch 720/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6141 - accuracy: 0.7110 - val_loss: 0.6646 - val_accuracy: 0.6691\n",
            "Epoch 721/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6091 - accuracy: 0.7184 - val_loss: 0.5541 - val_accuracy: 0.7721\n",
            "Epoch 722/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6236 - accuracy: 0.7061 - val_loss: 0.5994 - val_accuracy: 0.6765\n",
            "Epoch 723/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6142 - accuracy: 0.7104 - val_loss: 0.6529 - val_accuracy: 0.6691\n",
            "Epoch 724/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6292 - accuracy: 0.7042 - val_loss: 0.6824 - val_accuracy: 0.6654\n",
            "Epoch 725/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6079 - accuracy: 0.7098 - val_loss: 0.5839 - val_accuracy: 0.6912\n",
            "Epoch 726/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6147 - accuracy: 0.7116 - val_loss: 0.5957 - val_accuracy: 0.6765\n",
            "Epoch 727/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6114 - accuracy: 0.7166 - val_loss: 0.6426 - val_accuracy: 0.6691\n",
            "Epoch 728/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6197 - accuracy: 0.7079 - val_loss: 0.6281 - val_accuracy: 0.6654\n",
            "Epoch 729/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6107 - accuracy: 0.7116 - val_loss: 0.6477 - val_accuracy: 0.6691\n",
            "Epoch 730/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6144 - accuracy: 0.7116 - val_loss: 0.6732 - val_accuracy: 0.6654\n",
            "Epoch 731/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6085 - accuracy: 0.7085 - val_loss: 0.5455 - val_accuracy: 0.8015\n",
            "Epoch 732/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6236 - accuracy: 0.7092 - val_loss: 0.6440 - val_accuracy: 0.6654\n",
            "Epoch 733/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6056 - accuracy: 0.7191 - val_loss: 0.7343 - val_accuracy: 0.6691\n",
            "Epoch 734/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6287 - accuracy: 0.7042 - val_loss: 0.6129 - val_accuracy: 0.6728\n",
            "Epoch 735/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5932 - accuracy: 0.7160 - val_loss: 0.6093 - val_accuracy: 0.6728\n",
            "Epoch 736/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6046 - accuracy: 0.7147 - val_loss: 0.6907 - val_accuracy: 0.6691\n",
            "Epoch 737/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6005 - accuracy: 0.7184 - val_loss: 0.6276 - val_accuracy: 0.6654\n",
            "Epoch 738/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6026 - accuracy: 0.7160 - val_loss: 0.8921 - val_accuracy: 0.6691\n",
            "Epoch 739/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6177 - accuracy: 0.7135 - val_loss: 0.5258 - val_accuracy: 0.8162\n",
            "Epoch 740/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6144 - accuracy: 0.7079 - val_loss: 0.7294 - val_accuracy: 0.6691\n",
            "Epoch 741/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6113 - accuracy: 0.7098 - val_loss: 0.6723 - val_accuracy: 0.6618\n",
            "Epoch 742/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6117 - accuracy: 0.7147 - val_loss: 0.5525 - val_accuracy: 0.7721\n",
            "Epoch 743/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5896 - accuracy: 0.7135 - val_loss: 0.7850 - val_accuracy: 0.6691\n",
            "Epoch 744/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6081 - accuracy: 0.7085 - val_loss: 0.7480 - val_accuracy: 0.6691\n",
            "Epoch 745/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5919 - accuracy: 0.7178 - val_loss: 0.7817 - val_accuracy: 0.6691\n",
            "Epoch 746/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6058 - accuracy: 0.7135 - val_loss: 0.5693 - val_accuracy: 0.7096\n",
            "Epoch 747/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6030 - accuracy: 0.7172 - val_loss: 0.6580 - val_accuracy: 0.6654\n",
            "Epoch 748/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5934 - accuracy: 0.7178 - val_loss: 0.6555 - val_accuracy: 0.6654\n",
            "Epoch 749/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6209 - accuracy: 0.7073 - val_loss: 0.5772 - val_accuracy: 0.6912\n",
            "Epoch 750/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6076 - accuracy: 0.7067 - val_loss: 0.6214 - val_accuracy: 0.6691\n",
            "Epoch 751/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6061 - accuracy: 0.7061 - val_loss: 0.6068 - val_accuracy: 0.6728\n",
            "Epoch 752/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6060 - accuracy: 0.7110 - val_loss: 0.5490 - val_accuracy: 0.7757\n",
            "Epoch 753/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5994 - accuracy: 0.7203 - val_loss: 0.5648 - val_accuracy: 0.7169\n",
            "Epoch 754/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6080 - accuracy: 0.7110 - val_loss: 0.6356 - val_accuracy: 0.6691\n",
            "Epoch 755/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6004 - accuracy: 0.7172 - val_loss: 0.5762 - val_accuracy: 0.6949\n",
            "Epoch 756/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5955 - accuracy: 0.7141 - val_loss: 0.6255 - val_accuracy: 0.6691\n",
            "Epoch 757/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6025 - accuracy: 0.7160 - val_loss: 0.7275 - val_accuracy: 0.6691\n",
            "Epoch 758/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6048 - accuracy: 0.7141 - val_loss: 0.6148 - val_accuracy: 0.6691\n",
            "Epoch 759/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5985 - accuracy: 0.7160 - val_loss: 0.6632 - val_accuracy: 0.6691\n",
            "Epoch 760/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5941 - accuracy: 0.7129 - val_loss: 0.7081 - val_accuracy: 0.6691\n",
            "Epoch 761/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5977 - accuracy: 0.7141 - val_loss: 0.8338 - val_accuracy: 0.6691\n",
            "Epoch 762/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5986 - accuracy: 0.7172 - val_loss: 0.7032 - val_accuracy: 0.6691\n",
            "Epoch 763/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6147 - accuracy: 0.7141 - val_loss: 0.7074 - val_accuracy: 0.6691\n",
            "Epoch 764/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6114 - accuracy: 0.7098 - val_loss: 0.5624 - val_accuracy: 0.7206\n",
            "Epoch 765/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6069 - accuracy: 0.7191 - val_loss: 0.5983 - val_accuracy: 0.6728\n",
            "Epoch 766/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6010 - accuracy: 0.7153 - val_loss: 0.8277 - val_accuracy: 0.6691\n",
            "Epoch 767/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6203 - accuracy: 0.7061 - val_loss: 0.7005 - val_accuracy: 0.6691\n",
            "Epoch 768/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6060 - accuracy: 0.7123 - val_loss: 0.6968 - val_accuracy: 0.6691\n",
            "Epoch 769/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6049 - accuracy: 0.7123 - val_loss: 0.6333 - val_accuracy: 0.6728\n",
            "Epoch 770/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6100 - accuracy: 0.7141 - val_loss: 0.8842 - val_accuracy: 0.6691\n",
            "Epoch 771/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6053 - accuracy: 0.7110 - val_loss: 0.6522 - val_accuracy: 0.6728\n",
            "Epoch 772/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6071 - accuracy: 0.7116 - val_loss: 0.6661 - val_accuracy: 0.6691\n",
            "Epoch 773/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6205 - accuracy: 0.7110 - val_loss: 0.5827 - val_accuracy: 0.6875\n",
            "Epoch 774/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6174 - accuracy: 0.7116 - val_loss: 0.5525 - val_accuracy: 0.7537\n",
            "Epoch 775/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5891 - accuracy: 0.7203 - val_loss: 0.6384 - val_accuracy: 0.6691\n",
            "Epoch 776/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6036 - accuracy: 0.7141 - val_loss: 0.7148 - val_accuracy: 0.6691\n",
            "Epoch 777/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5963 - accuracy: 0.7197 - val_loss: 0.5201 - val_accuracy: 0.8199\n",
            "Epoch 778/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6006 - accuracy: 0.7110 - val_loss: 0.7063 - val_accuracy: 0.6691\n",
            "Epoch 779/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6005 - accuracy: 0.7129 - val_loss: 0.8117 - val_accuracy: 0.6691\n",
            "Epoch 780/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6196 - accuracy: 0.7110 - val_loss: 0.5535 - val_accuracy: 0.7353\n",
            "Epoch 781/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5943 - accuracy: 0.7172 - val_loss: 0.7272 - val_accuracy: 0.6691\n",
            "Epoch 782/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6106 - accuracy: 0.7073 - val_loss: 0.6262 - val_accuracy: 0.6728\n",
            "Epoch 783/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6019 - accuracy: 0.7129 - val_loss: 0.5326 - val_accuracy: 0.8162\n",
            "Epoch 784/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6030 - accuracy: 0.7085 - val_loss: 0.9198 - val_accuracy: 0.6654\n",
            "Epoch 785/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6092 - accuracy: 0.7067 - val_loss: 0.5738 - val_accuracy: 0.6949\n",
            "Epoch 786/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6177 - accuracy: 0.7092 - val_loss: 0.5297 - val_accuracy: 0.8235\n",
            "Epoch 787/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5987 - accuracy: 0.7141 - val_loss: 0.5796 - val_accuracy: 0.6838\n",
            "Epoch 788/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6093 - accuracy: 0.7116 - val_loss: 0.5444 - val_accuracy: 0.7794\n",
            "Epoch 789/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5988 - accuracy: 0.7135 - val_loss: 0.7403 - val_accuracy: 0.6691\n",
            "Epoch 790/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5903 - accuracy: 0.7153 - val_loss: 0.5750 - val_accuracy: 0.6875\n",
            "Epoch 791/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5930 - accuracy: 0.7147 - val_loss: 0.6658 - val_accuracy: 0.6691\n",
            "Epoch 792/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5933 - accuracy: 0.7166 - val_loss: 0.5675 - val_accuracy: 0.7096\n",
            "Epoch 793/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6147 - accuracy: 0.7172 - val_loss: 0.5779 - val_accuracy: 0.6875\n",
            "Epoch 794/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6037 - accuracy: 0.7061 - val_loss: 0.6635 - val_accuracy: 0.6691\n",
            "Epoch 795/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5967 - accuracy: 0.7209 - val_loss: 0.5569 - val_accuracy: 0.7426\n",
            "Epoch 796/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5943 - accuracy: 0.7153 - val_loss: 0.6168 - val_accuracy: 0.6691\n",
            "Epoch 797/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5972 - accuracy: 0.7178 - val_loss: 0.7161 - val_accuracy: 0.6691\n",
            "Epoch 798/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6054 - accuracy: 0.7178 - val_loss: 0.5572 - val_accuracy: 0.7463\n",
            "Epoch 799/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6087 - accuracy: 0.7110 - val_loss: 0.7041 - val_accuracy: 0.6691\n",
            "Epoch 800/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6013 - accuracy: 0.7147 - val_loss: 0.8002 - val_accuracy: 0.6691\n",
            "Epoch 801/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6086 - accuracy: 0.7085 - val_loss: 0.8698 - val_accuracy: 0.6691\n",
            "Epoch 802/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.6151 - accuracy: 0.7135 - val_loss: 0.6807 - val_accuracy: 0.6691\n",
            "Epoch 803/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5958 - accuracy: 0.7178 - val_loss: 0.8778 - val_accuracy: 0.6691\n",
            "Epoch 804/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5844 - accuracy: 0.7172 - val_loss: 0.7100 - val_accuracy: 0.6691\n",
            "Epoch 805/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5920 - accuracy: 0.7191 - val_loss: 0.7081 - val_accuracy: 0.6691\n",
            "Epoch 806/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6215 - accuracy: 0.7098 - val_loss: 0.7763 - val_accuracy: 0.6691\n",
            "Epoch 807/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5937 - accuracy: 0.7135 - val_loss: 0.6825 - val_accuracy: 0.6691\n",
            "Epoch 808/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6048 - accuracy: 0.7098 - val_loss: 0.8925 - val_accuracy: 0.6691\n",
            "Epoch 809/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5851 - accuracy: 0.7203 - val_loss: 0.5759 - val_accuracy: 0.6912\n",
            "Epoch 810/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5830 - accuracy: 0.7209 - val_loss: 1.0520 - val_accuracy: 0.6618\n",
            "Epoch 811/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6026 - accuracy: 0.7098 - val_loss: 0.5747 - val_accuracy: 0.6949\n",
            "Epoch 812/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6002 - accuracy: 0.7166 - val_loss: 0.6491 - val_accuracy: 0.6691\n",
            "Epoch 813/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6010 - accuracy: 0.7166 - val_loss: 0.6041 - val_accuracy: 0.6728\n",
            "Epoch 814/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6210 - accuracy: 0.7061 - val_loss: 0.6295 - val_accuracy: 0.6728\n",
            "Epoch 815/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5902 - accuracy: 0.7197 - val_loss: 0.8673 - val_accuracy: 0.6691\n",
            "Epoch 816/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6034 - accuracy: 0.7184 - val_loss: 0.7631 - val_accuracy: 0.6691\n",
            "Epoch 817/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5924 - accuracy: 0.7184 - val_loss: 0.6893 - val_accuracy: 0.6691\n",
            "Epoch 818/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5873 - accuracy: 0.7246 - val_loss: 0.8564 - val_accuracy: 0.6691\n",
            "Epoch 819/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6032 - accuracy: 0.7110 - val_loss: 0.7245 - val_accuracy: 0.6691\n",
            "Epoch 820/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5950 - accuracy: 0.7160 - val_loss: 0.7102 - val_accuracy: 0.6691\n",
            "Epoch 821/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6033 - accuracy: 0.7079 - val_loss: 0.8588 - val_accuracy: 0.6691\n",
            "Epoch 822/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5996 - accuracy: 0.7166 - val_loss: 0.5801 - val_accuracy: 0.6875\n",
            "Epoch 823/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6090 - accuracy: 0.7073 - val_loss: 0.5742 - val_accuracy: 0.6912\n",
            "Epoch 824/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5979 - accuracy: 0.7123 - val_loss: 0.9747 - val_accuracy: 0.6654\n",
            "Epoch 825/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.6003 - accuracy: 0.7191 - val_loss: 0.5739 - val_accuracy: 0.6912\n",
            "Epoch 826/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5943 - accuracy: 0.7153 - val_loss: 0.8906 - val_accuracy: 0.6691\n",
            "Epoch 827/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6097 - accuracy: 0.7104 - val_loss: 0.6516 - val_accuracy: 0.6691\n",
            "Epoch 828/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6101 - accuracy: 0.7147 - val_loss: 0.9253 - val_accuracy: 0.6691\n",
            "Epoch 829/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6043 - accuracy: 0.7172 - val_loss: 0.9494 - val_accuracy: 0.6654\n",
            "Epoch 830/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6113 - accuracy: 0.7166 - val_loss: 0.5921 - val_accuracy: 0.6801\n",
            "Epoch 831/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6023 - accuracy: 0.7110 - val_loss: 0.6378 - val_accuracy: 0.6728\n",
            "Epoch 832/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5908 - accuracy: 0.7215 - val_loss: 0.9097 - val_accuracy: 0.6691\n",
            "Epoch 833/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.5879 - accuracy: 0.7172 - val_loss: 0.5981 - val_accuracy: 0.6728\n",
            "Epoch 834/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6005 - accuracy: 0.7178 - val_loss: 1.0050 - val_accuracy: 0.6654\n",
            "Epoch 835/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6165 - accuracy: 0.7042 - val_loss: 0.5224 - val_accuracy: 0.8235\n",
            "Epoch 836/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6082 - accuracy: 0.7110 - val_loss: 0.5475 - val_accuracy: 0.7610\n",
            "Epoch 837/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6065 - accuracy: 0.7098 - val_loss: 0.9503 - val_accuracy: 0.6654\n",
            "Epoch 838/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5916 - accuracy: 0.7209 - val_loss: 0.5823 - val_accuracy: 0.6801\n",
            "Epoch 839/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5897 - accuracy: 0.7197 - val_loss: 0.6139 - val_accuracy: 0.6765\n",
            "Epoch 840/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6155 - accuracy: 0.7079 - val_loss: 0.7603 - val_accuracy: 0.6691\n",
            "Epoch 841/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5904 - accuracy: 0.7191 - val_loss: 0.9935 - val_accuracy: 0.6654\n",
            "Epoch 842/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5867 - accuracy: 0.7240 - val_loss: 0.8774 - val_accuracy: 0.6691\n",
            "Epoch 843/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6079 - accuracy: 0.7116 - val_loss: 0.6215 - val_accuracy: 0.6765\n",
            "Epoch 844/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6091 - accuracy: 0.7098 - val_loss: 0.7266 - val_accuracy: 0.6691\n",
            "Epoch 845/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6049 - accuracy: 0.7092 - val_loss: 0.6889 - val_accuracy: 0.6691\n",
            "Epoch 846/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6060 - accuracy: 0.7110 - val_loss: 0.5388 - val_accuracy: 0.8015\n",
            "Epoch 847/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5932 - accuracy: 0.7110 - val_loss: 0.7797 - val_accuracy: 0.6691\n",
            "Epoch 848/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5893 - accuracy: 0.7197 - val_loss: 0.6393 - val_accuracy: 0.6691\n",
            "Epoch 849/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5915 - accuracy: 0.7135 - val_loss: 0.6105 - val_accuracy: 0.6691\n",
            "Epoch 850/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5937 - accuracy: 0.7172 - val_loss: 0.5647 - val_accuracy: 0.6949\n",
            "Epoch 851/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5966 - accuracy: 0.7073 - val_loss: 0.7818 - val_accuracy: 0.6691\n",
            "Epoch 852/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5937 - accuracy: 0.7147 - val_loss: 0.7532 - val_accuracy: 0.6691\n",
            "Epoch 853/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6015 - accuracy: 0.7116 - val_loss: 0.6847 - val_accuracy: 0.6691\n",
            "Epoch 854/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5893 - accuracy: 0.7178 - val_loss: 0.8425 - val_accuracy: 0.6691\n",
            "Epoch 855/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5839 - accuracy: 0.7191 - val_loss: 0.8476 - val_accuracy: 0.6691\n",
            "Epoch 856/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6001 - accuracy: 0.7166 - val_loss: 0.7617 - val_accuracy: 0.6691\n",
            "Epoch 857/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5832 - accuracy: 0.7197 - val_loss: 0.9832 - val_accuracy: 0.6654\n",
            "Epoch 858/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.5839 - accuracy: 0.7203 - val_loss: 0.8485 - val_accuracy: 0.6691\n",
            "Epoch 859/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5964 - accuracy: 0.7234 - val_loss: 1.1329 - val_accuracy: 0.6618\n",
            "Epoch 860/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6071 - accuracy: 0.7110 - val_loss: 0.6205 - val_accuracy: 0.6691\n",
            "Epoch 861/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5843 - accuracy: 0.7172 - val_loss: 0.8631 - val_accuracy: 0.6691\n",
            "Epoch 862/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5880 - accuracy: 0.7141 - val_loss: 0.9969 - val_accuracy: 0.6654\n",
            "Epoch 863/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5814 - accuracy: 0.7166 - val_loss: 1.1493 - val_accuracy: 0.6618\n",
            "Epoch 864/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5990 - accuracy: 0.7141 - val_loss: 0.6829 - val_accuracy: 0.6691\n",
            "Epoch 865/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5956 - accuracy: 0.7209 - val_loss: 0.9125 - val_accuracy: 0.6654\n",
            "Epoch 866/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5811 - accuracy: 0.7228 - val_loss: 0.7877 - val_accuracy: 0.6691\n",
            "Epoch 867/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5980 - accuracy: 0.7147 - val_loss: 0.8573 - val_accuracy: 0.6691\n",
            "Epoch 868/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5813 - accuracy: 0.7228 - val_loss: 0.8448 - val_accuracy: 0.6691\n",
            "Epoch 869/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5943 - accuracy: 0.7129 - val_loss: 0.7390 - val_accuracy: 0.6691\n",
            "Epoch 870/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5831 - accuracy: 0.7172 - val_loss: 0.9790 - val_accuracy: 0.6654\n",
            "Epoch 871/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6131 - accuracy: 0.7184 - val_loss: 0.5538 - val_accuracy: 0.7353\n",
            "Epoch 872/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5971 - accuracy: 0.7141 - val_loss: 0.7864 - val_accuracy: 0.6691\n",
            "Epoch 873/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5821 - accuracy: 0.7166 - val_loss: 0.6695 - val_accuracy: 0.6691\n",
            "Epoch 874/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6072 - accuracy: 0.7061 - val_loss: 0.5931 - val_accuracy: 0.6765\n",
            "Epoch 875/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6018 - accuracy: 0.7135 - val_loss: 0.9586 - val_accuracy: 0.6654\n",
            "Epoch 876/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5861 - accuracy: 0.7215 - val_loss: 0.9015 - val_accuracy: 0.6691\n",
            "Epoch 877/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5947 - accuracy: 0.7178 - val_loss: 0.8310 - val_accuracy: 0.6691\n",
            "Epoch 878/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5918 - accuracy: 0.7178 - val_loss: 0.6691 - val_accuracy: 0.6691\n",
            "Epoch 879/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5923 - accuracy: 0.7160 - val_loss: 0.9373 - val_accuracy: 0.6654\n",
            "Epoch 880/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5958 - accuracy: 0.7104 - val_loss: 0.7611 - val_accuracy: 0.6691\n",
            "Epoch 881/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5979 - accuracy: 0.7110 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
            "Epoch 882/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5958 - accuracy: 0.7085 - val_loss: 0.7946 - val_accuracy: 0.6691\n",
            "Epoch 883/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5873 - accuracy: 0.7197 - val_loss: 1.0042 - val_accuracy: 0.6654\n",
            "Epoch 884/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5966 - accuracy: 0.7178 - val_loss: 0.5803 - val_accuracy: 0.6838\n",
            "Epoch 885/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6096 - accuracy: 0.7110 - val_loss: 0.5407 - val_accuracy: 0.7610\n",
            "Epoch 886/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6018 - accuracy: 0.7092 - val_loss: 0.6669 - val_accuracy: 0.6691\n",
            "Epoch 887/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6017 - accuracy: 0.7110 - val_loss: 0.5944 - val_accuracy: 0.6765\n",
            "Epoch 888/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5926 - accuracy: 0.7172 - val_loss: 0.5911 - val_accuracy: 0.6801\n",
            "Epoch 889/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6016 - accuracy: 0.7129 - val_loss: 0.5630 - val_accuracy: 0.6985\n",
            "Epoch 890/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5904 - accuracy: 0.7141 - val_loss: 0.8228 - val_accuracy: 0.6691\n",
            "Epoch 891/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5894 - accuracy: 0.7153 - val_loss: 0.8093 - val_accuracy: 0.6691\n",
            "Epoch 892/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6010 - accuracy: 0.7067 - val_loss: 0.7186 - val_accuracy: 0.6691\n",
            "Epoch 893/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5849 - accuracy: 0.7166 - val_loss: 0.6345 - val_accuracy: 0.6691\n",
            "Epoch 894/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5908 - accuracy: 0.7129 - val_loss: 0.9463 - val_accuracy: 0.6654\n",
            "Epoch 895/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5841 - accuracy: 0.7166 - val_loss: 0.8367 - val_accuracy: 0.6691\n",
            "Epoch 896/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5985 - accuracy: 0.7135 - val_loss: 0.8003 - val_accuracy: 0.6691\n",
            "Epoch 897/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5924 - accuracy: 0.7098 - val_loss: 0.8893 - val_accuracy: 0.6691\n",
            "Epoch 898/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5836 - accuracy: 0.7333 - val_loss: 0.7493 - val_accuracy: 0.6838\n",
            "Epoch 899/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5990 - accuracy: 0.7407 - val_loss: 0.7956 - val_accuracy: 0.6838\n",
            "Epoch 900/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5942 - accuracy: 0.7475 - val_loss: 0.6315 - val_accuracy: 0.6801\n",
            "Epoch 901/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5692 - accuracy: 0.7450 - val_loss: 0.9430 - val_accuracy: 0.6801\n",
            "Epoch 902/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6114 - accuracy: 0.7234 - val_loss: 0.6832 - val_accuracy: 0.6838\n",
            "Epoch 903/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5867 - accuracy: 0.7376 - val_loss: 0.9165 - val_accuracy: 0.6838\n",
            "Epoch 904/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5876 - accuracy: 0.7364 - val_loss: 0.8086 - val_accuracy: 0.6838\n",
            "Epoch 905/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5792 - accuracy: 0.7500 - val_loss: 0.8345 - val_accuracy: 0.6838\n",
            "Epoch 906/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5974 - accuracy: 0.7358 - val_loss: 0.5792 - val_accuracy: 0.6949\n",
            "Epoch 907/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5960 - accuracy: 0.7351 - val_loss: 0.8303 - val_accuracy: 0.6838\n",
            "Epoch 908/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5753 - accuracy: 0.7593 - val_loss: 1.0180 - val_accuracy: 0.6765\n",
            "Epoch 909/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6018 - accuracy: 0.7339 - val_loss: 0.7043 - val_accuracy: 0.6875\n",
            "Epoch 910/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5875 - accuracy: 0.7413 - val_loss: 0.8942 - val_accuracy: 0.6875\n",
            "Epoch 911/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5840 - accuracy: 0.7463 - val_loss: 0.6609 - val_accuracy: 0.6801\n",
            "Epoch 912/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5947 - accuracy: 0.7413 - val_loss: 0.7948 - val_accuracy: 0.6875\n",
            "Epoch 913/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6083 - accuracy: 0.7420 - val_loss: 0.5783 - val_accuracy: 0.6949\n",
            "Epoch 914/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5912 - accuracy: 0.7358 - val_loss: 0.6670 - val_accuracy: 0.6801\n",
            "Epoch 915/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5995 - accuracy: 0.7327 - val_loss: 0.6901 - val_accuracy: 0.6838\n",
            "Epoch 916/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5891 - accuracy: 0.7370 - val_loss: 0.8449 - val_accuracy: 0.6838\n",
            "Epoch 917/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6091 - accuracy: 0.7438 - val_loss: 0.6065 - val_accuracy: 0.6912\n",
            "Epoch 918/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5985 - accuracy: 0.7389 - val_loss: 0.6492 - val_accuracy: 0.6801\n",
            "Epoch 919/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5937 - accuracy: 0.7370 - val_loss: 0.8719 - val_accuracy: 0.6875\n",
            "Epoch 920/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.6023 - accuracy: 0.7308 - val_loss: 0.7009 - val_accuracy: 0.6838\n",
            "Epoch 921/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5940 - accuracy: 0.7364 - val_loss: 0.8865 - val_accuracy: 0.6875\n",
            "Epoch 922/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5955 - accuracy: 0.7469 - val_loss: 0.7226 - val_accuracy: 0.6838\n",
            "Epoch 923/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5939 - accuracy: 0.7426 - val_loss: 0.7833 - val_accuracy: 0.6838\n",
            "Epoch 924/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5932 - accuracy: 0.7444 - val_loss: 0.8600 - val_accuracy: 0.6875\n",
            "Epoch 925/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5930 - accuracy: 0.7469 - val_loss: 0.8053 - val_accuracy: 0.6875\n",
            "Epoch 926/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5894 - accuracy: 0.7469 - val_loss: 0.9566 - val_accuracy: 0.6838\n",
            "Epoch 927/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5896 - accuracy: 0.7481 - val_loss: 0.8284 - val_accuracy: 0.6875\n",
            "Epoch 928/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5758 - accuracy: 0.7519 - val_loss: 0.6297 - val_accuracy: 0.6875\n",
            "Epoch 929/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5880 - accuracy: 0.7426 - val_loss: 0.9120 - val_accuracy: 0.6838\n",
            "Epoch 930/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5967 - accuracy: 0.7413 - val_loss: 1.0714 - val_accuracy: 0.6801\n",
            "Epoch 931/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6030 - accuracy: 0.7407 - val_loss: 0.7342 - val_accuracy: 0.6875\n",
            "Epoch 932/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5867 - accuracy: 0.7463 - val_loss: 0.8584 - val_accuracy: 0.6875\n",
            "Epoch 933/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5979 - accuracy: 0.7506 - val_loss: 0.7991 - val_accuracy: 0.6875\n",
            "Epoch 934/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5936 - accuracy: 0.7370 - val_loss: 0.6770 - val_accuracy: 0.6875\n",
            "Epoch 935/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5775 - accuracy: 0.7494 - val_loss: 0.9932 - val_accuracy: 0.6838\n",
            "Epoch 936/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5919 - accuracy: 0.7525 - val_loss: 0.6000 - val_accuracy: 0.6912\n",
            "Epoch 937/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5948 - accuracy: 0.7444 - val_loss: 0.7826 - val_accuracy: 0.6875\n",
            "Epoch 938/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5815 - accuracy: 0.7481 - val_loss: 0.9059 - val_accuracy: 0.6875\n",
            "Epoch 939/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5781 - accuracy: 0.7481 - val_loss: 0.8935 - val_accuracy: 0.6838\n",
            "Epoch 940/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.6093 - accuracy: 0.7475 - val_loss: 0.5150 - val_accuracy: 0.8346\n",
            "Epoch 941/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5796 - accuracy: 0.7580 - val_loss: 1.1515 - val_accuracy: 0.6838\n",
            "Epoch 942/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5779 - accuracy: 0.7506 - val_loss: 0.8078 - val_accuracy: 0.6838\n",
            "Epoch 943/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5932 - accuracy: 0.7450 - val_loss: 0.8193 - val_accuracy: 0.6875\n",
            "Epoch 944/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5854 - accuracy: 0.7457 - val_loss: 0.5372 - val_accuracy: 0.7794\n",
            "Epoch 945/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5922 - accuracy: 0.7488 - val_loss: 0.8273 - val_accuracy: 0.6875\n",
            "Epoch 946/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5808 - accuracy: 0.7481 - val_loss: 0.8267 - val_accuracy: 0.6875\n",
            "Epoch 947/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.6049 - accuracy: 0.7469 - val_loss: 0.7704 - val_accuracy: 0.6875\n",
            "Epoch 948/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5772 - accuracy: 0.7531 - val_loss: 0.8676 - val_accuracy: 0.6838\n",
            "Epoch 949/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5789 - accuracy: 0.7481 - val_loss: 0.7712 - val_accuracy: 0.6875\n",
            "Epoch 950/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5870 - accuracy: 0.7506 - val_loss: 0.8727 - val_accuracy: 0.6838\n",
            "Epoch 951/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5915 - accuracy: 0.7512 - val_loss: 0.8959 - val_accuracy: 0.6875\n",
            "Epoch 952/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5992 - accuracy: 0.7444 - val_loss: 0.8152 - val_accuracy: 0.6875\n",
            "Epoch 953/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5850 - accuracy: 0.7481 - val_loss: 0.7855 - val_accuracy: 0.6838\n",
            "Epoch 954/1000\n",
            "33/33 [==============================] - 4s 131ms/step - loss: 0.5901 - accuracy: 0.7358 - val_loss: 0.7429 - val_accuracy: 0.6875\n",
            "Epoch 955/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5865 - accuracy: 0.7475 - val_loss: 1.1059 - val_accuracy: 0.6838\n",
            "Epoch 956/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5854 - accuracy: 0.7618 - val_loss: 0.8841 - val_accuracy: 0.6801\n",
            "Epoch 957/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5751 - accuracy: 0.7587 - val_loss: 0.8631 - val_accuracy: 0.6875\n",
            "Epoch 958/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5856 - accuracy: 0.7543 - val_loss: 0.6367 - val_accuracy: 0.6801\n",
            "Epoch 959/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5883 - accuracy: 0.7450 - val_loss: 0.9038 - val_accuracy: 0.6838\n",
            "Epoch 960/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5731 - accuracy: 0.7568 - val_loss: 0.8997 - val_accuracy: 0.6875\n",
            "Epoch 961/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5795 - accuracy: 0.7475 - val_loss: 1.0206 - val_accuracy: 0.6875\n",
            "Epoch 962/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.5863 - accuracy: 0.7481 - val_loss: 0.6689 - val_accuracy: 0.6801\n",
            "Epoch 963/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5815 - accuracy: 0.7587 - val_loss: 0.5814 - val_accuracy: 0.6912\n",
            "Epoch 964/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5806 - accuracy: 0.7506 - val_loss: 1.0241 - val_accuracy: 0.6875\n",
            "Epoch 965/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5877 - accuracy: 0.7438 - val_loss: 0.7983 - val_accuracy: 0.6838\n",
            "Epoch 966/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5783 - accuracy: 0.7618 - val_loss: 0.9306 - val_accuracy: 0.6801\n",
            "Epoch 967/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5846 - accuracy: 0.7562 - val_loss: 0.9320 - val_accuracy: 0.6801\n",
            "Epoch 968/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5755 - accuracy: 0.7506 - val_loss: 0.7939 - val_accuracy: 0.6838\n",
            "Epoch 969/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5909 - accuracy: 0.7599 - val_loss: 0.5622 - val_accuracy: 0.7059\n",
            "Epoch 970/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5820 - accuracy: 0.7587 - val_loss: 0.8529 - val_accuracy: 0.6838\n",
            "Epoch 971/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5826 - accuracy: 0.7506 - val_loss: 0.8813 - val_accuracy: 0.6838\n",
            "Epoch 972/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5735 - accuracy: 0.7525 - val_loss: 0.6168 - val_accuracy: 0.6838\n",
            "Epoch 973/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5799 - accuracy: 0.7463 - val_loss: 0.6771 - val_accuracy: 0.6801\n",
            "Epoch 974/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5944 - accuracy: 0.7450 - val_loss: 0.7659 - val_accuracy: 0.6838\n",
            "Epoch 975/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5827 - accuracy: 0.7543 - val_loss: 0.9543 - val_accuracy: 0.6838\n",
            "Epoch 976/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5923 - accuracy: 0.7432 - val_loss: 0.7323 - val_accuracy: 0.6838\n",
            "Epoch 977/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5795 - accuracy: 0.7543 - val_loss: 0.8734 - val_accuracy: 0.6838\n",
            "Epoch 978/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5845 - accuracy: 0.7488 - val_loss: 0.9267 - val_accuracy: 0.6801\n",
            "Epoch 979/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5889 - accuracy: 0.7500 - val_loss: 0.6203 - val_accuracy: 0.6838\n",
            "Epoch 980/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5830 - accuracy: 0.7556 - val_loss: 0.8677 - val_accuracy: 0.6838\n",
            "Epoch 981/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5885 - accuracy: 0.7556 - val_loss: 0.8593 - val_accuracy: 0.6838\n",
            "Epoch 982/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5981 - accuracy: 0.7512 - val_loss: 1.0391 - val_accuracy: 0.6838\n",
            "Epoch 983/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6017 - accuracy: 0.7512 - val_loss: 0.7201 - val_accuracy: 0.6838\n",
            "Epoch 984/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5636 - accuracy: 0.7593 - val_loss: 0.8102 - val_accuracy: 0.6838\n",
            "Epoch 985/1000\n",
            "33/33 [==============================] - 4s 130ms/step - loss: 0.5857 - accuracy: 0.7568 - val_loss: 0.9506 - val_accuracy: 0.6838\n",
            "Epoch 986/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5872 - accuracy: 0.7494 - val_loss: 0.8901 - val_accuracy: 0.6838\n",
            "Epoch 987/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5900 - accuracy: 0.7512 - val_loss: 0.8321 - val_accuracy: 0.6875\n",
            "Epoch 988/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5893 - accuracy: 0.7525 - val_loss: 0.8960 - val_accuracy: 0.6875\n",
            "Epoch 989/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5833 - accuracy: 0.7556 - val_loss: 0.6561 - val_accuracy: 0.6801\n",
            "Epoch 990/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5915 - accuracy: 0.7574 - val_loss: 0.8864 - val_accuracy: 0.6801\n",
            "Epoch 991/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.5833 - accuracy: 0.7481 - val_loss: 0.8126 - val_accuracy: 0.6838\n",
            "Epoch 992/1000\n",
            "33/33 [==============================] - 4s 127ms/step - loss: 0.5709 - accuracy: 0.7531 - val_loss: 0.7195 - val_accuracy: 0.6838\n",
            "Epoch 993/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.5783 - accuracy: 0.7556 - val_loss: 1.0604 - val_accuracy: 0.6801\n",
            "Epoch 994/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5738 - accuracy: 0.7506 - val_loss: 0.8758 - val_accuracy: 0.6765\n",
            "Epoch 995/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5795 - accuracy: 0.7556 - val_loss: 1.0061 - val_accuracy: 0.6801\n",
            "Epoch 996/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5871 - accuracy: 0.7587 - val_loss: 0.5110 - val_accuracy: 0.8272\n",
            "Epoch 997/1000\n",
            "33/33 [==============================] - 4s 129ms/step - loss: 0.5976 - accuracy: 0.7587 - val_loss: 0.6549 - val_accuracy: 0.6838\n",
            "Epoch 998/1000\n",
            "33/33 [==============================] - 4s 128ms/step - loss: 0.6081 - accuracy: 0.7543 - val_loss: 0.5181 - val_accuracy: 0.8382\n",
            "Epoch 999/1000\n",
            "33/33 [==============================] - 4s 126ms/step - loss: 0.5783 - accuracy: 0.7450 - val_loss: 1.0220 - val_accuracy: 0.6875\n",
            "Epoch 1000/1000\n",
            "33/33 [==============================] - 4s 125ms/step - loss: 0.5844 - accuracy: 0.7450 - val_loss: 0.7408 - val_accuracy: 0.6875\n"
          ]
        }
      ],
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "\n",
        "# https://stackoverflow.com/questions/53479007/how-to-setup-adaptive-learning-rate-in-keras\n",
        "# def adapt_learning_rate(epoch):\n",
        "#     print(0.0001 * epoch)\n",
        "#     return 0.0001 * epoch\n",
        "# my_lr_scheduler = keras.callbacks.LearningRateScheduler(adapt_learning_rate)\n",
        "\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                                        patience = 10,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "convlstm_model.compile(loss = 'categorical_crossentropy',\n",
        "                       optimizer= keras.optimizers.Adam(0.0001, decay=1e-4),\n",
        "                       metrics = [\"accuracy\"])\n",
        "# Start training the model.\n",
        "convlstm_model_training_history = convlstm_model.fit(x = features_train,\n",
        "                                                     y = labels_train,\n",
        "                                                     epochs = 1000,\n",
        "                                                     batch_size = 50,\n",
        "                                                     shuffle = True,\n",
        "                                                     validation_data = (features_valid, labels_valid)),\n",
        "                                                    #  callbacks = [early_stopping_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcpKhGqvIenv",
        "outputId": "7fcf7c06-4a79-4566-ace0-96923ed40961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 41ms/step - loss: 0.6660 - accuracy: 0.7380\n",
            "\n",
            "\n",
            "Train accuracy: 77.166 % || Test accuracy: 73.801 % || Val accuracy: 68.750 %\n",
            "\n",
            "\n",
            "Train loss: 0.570 || Test loss: 0.666 || Val loss: 0.741\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = convlstm_model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = convlstm_model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = convlstm_model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print('\\n')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qsFw5KIzIum9"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        " \n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p convlstm_{current_date_time_string}\n",
        "# Save your Model.\n",
        "convlstm_model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "convlstm_model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z0eAobhSIz_P"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history[0].history[metric_name_1]\n",
        "    metric_value_2 = model_training_history[0].history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "18RtBjI9I5lE",
        "outputId": "52236ebb-a138-4b85-9cc5-fe7cb2a4b09a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "02amk7TXI_OS",
        "outputId": "fa21d65b-18ce-44ef-ee67-acf484c28296"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "2D_CNN+LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOrZNCtz+4ONZ1Pd62v5Hym",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}