{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/3D_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7I8NauauE3"
      },
      "source": [
        "####**3D Convolutional Neural Network**\n",
        "######*I am using 3D Convolutional Neural Network to extract the temporal and spatial information which are merged slowly throughout the whole network.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ibtd5HKtZk",
        "outputId": "c635f280-2cc2-44b1-9f66-847e1a9bb06c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
        "from keras import regularizers\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)\n",
        "# https://bleedai.com/human-activity-recognition-using-tensorflow-cnn-lstm/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "1ad57407-7d43-4921-8fd0-11576f9e3806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUTeIqzpZc9J"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QRDbHG0TZkYJ"
      },
      "outputs": [],
      "source": [
        "# https://medium.com/analytics-vidhya/video-preprocessor-and-augmentation-for-deep-learning-tasks-12dd3fcce868\n",
        "def load_video(path, resize=(128, 128)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            # frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "265d7a56-07d2-4123-ceca-8e2366f5cc76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# one_hot_encoded_labels\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-9ykP4ig7IW"
      },
      "outputs": [],
      "source": [
        "def create_3D_CNN_model():\n",
        "    sample_shape = (16, 128, 128, 3)\n",
        "    model = Sequential()\n",
        "\n",
        "    ### 1\n",
        "    model.add(Conv3D(8, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4),\n",
        "                     input_shape=sample_shape))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 2\n",
        "    model.add(Conv3D(16, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 3\n",
        "    model.add(Conv3D(16, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    ### 4\n",
        "    model.add(Conv3D(32, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.45))\n",
        "\n",
        "    model.add(GlobalAveragePooling3D())\n",
        "    model.add(Dropout(0.55))\n",
        "\n",
        "    # model.add(Dense(32, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.6))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "\n",
        "    model.summary(line_length = 125)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_GxXZBcHlB",
        "outputId": "56dc1e1a-a259-48cd-a65e-46da64aa4102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_____________________________________________________________________________________________________________________________\n",
            " Layer (type)                                           Output Shape                                      Param #            \n",
            "=============================================================================================================================\n",
            " conv3d (Conv3D)                                        (None, 16, 126, 126, 8)                           224                \n",
            "                                                                                                                             \n",
            " max_pooling3d (MaxPooling3D)                           (None, 8, 63, 63, 8)                              0                  \n",
            "                                                                                                                             \n",
            " dropout (Dropout)                                      (None, 8, 63, 63, 8)                              0                  \n",
            "                                                                                                                             \n",
            " conv3d_1 (Conv3D)                                      (None, 8, 61, 61, 16)                             1168               \n",
            "                                                                                                                             \n",
            " max_pooling3d_1 (MaxPooling3D)                         (None, 4, 30, 30, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_1 (Dropout)                                    (None, 4, 30, 30, 16)                             0                  \n",
            "                                                                                                                             \n",
            " conv3d_2 (Conv3D)                                      (None, 4, 28, 28, 16)                             2320               \n",
            "                                                                                                                             \n",
            " max_pooling3d_2 (MaxPooling3D)                         (None, 2, 14, 14, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_2 (Dropout)                                    (None, 2, 14, 14, 16)                             0                  \n",
            "                                                                                                                             \n",
            " conv3d_3 (Conv3D)                                      (None, 2, 12, 12, 32)                             4640               \n",
            "                                                                                                                             \n",
            " max_pooling3d_3 (MaxPooling3D)                         (None, 1, 6, 6, 32)                               0                  \n",
            "                                                                                                                             \n",
            " dropout_3 (Dropout)                                    (None, 1, 6, 6, 32)                               0                  \n",
            "                                                                                                                             \n",
            " global_average_pooling3d (GlobalAveragePooling3D)      (None, 32)                                        0                  \n",
            "                                                                                                                             \n",
            " dropout_4 (Dropout)                                    (None, 32)                                        0                  \n",
            "                                                                                                                             \n",
            " dense (Dense)                                          (None, 16)                                        528                \n",
            "                                                                                                                             \n",
            " dropout_5 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense_1 (Dense)                                        (None, 8)                                         136                \n",
            "                                                                                                                             \n",
            " dense_2 (Dense)                                        (None, 4)                                         36                 \n",
            "                                                                                                                             \n",
            "=============================================================================================================================\n",
            "Total params: 9,052\n",
            "Trainable params: 9,052\n",
            "Non-trainable params: 0\n",
            "_____________________________________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "model = create_3D_CNN_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYEkaYLoyb_",
        "outputId": "8c7c9020-f336-4722-9fd4-6c2f2ac63946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "202/202 [==============================] - 9s 35ms/step - loss: 1.5545 - accuracy: 0.3954 - val_loss: 1.3223 - val_accuracy: 0.3566\n",
            "Epoch 2/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.2661 - accuracy: 0.4059 - val_loss: 1.2526 - val_accuracy: 0.4816\n",
            "Epoch 3/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.2236 - accuracy: 0.4066 - val_loss: 1.2142 - val_accuracy: 0.4816\n",
            "Epoch 4/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.1904 - accuracy: 0.4245 - val_loss: 1.1714 - val_accuracy: 0.4816\n",
            "Epoch 5/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.1679 - accuracy: 0.4468 - val_loss: 1.1677 - val_accuracy: 0.4816\n",
            "Epoch 6/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.1341 - accuracy: 0.4851 - val_loss: 1.1124 - val_accuracy: 0.6471\n",
            "Epoch 7/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.1006 - accuracy: 0.5254 - val_loss: 1.0889 - val_accuracy: 0.6434\n",
            "Epoch 8/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.0513 - accuracy: 0.5637 - val_loss: 1.0569 - val_accuracy: 0.6434\n",
            "Epoch 9/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.0369 - accuracy: 0.5811 - val_loss: 1.0810 - val_accuracy: 0.6434\n",
            "Epoch 10/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 1.0082 - accuracy: 0.6009 - val_loss: 0.9477 - val_accuracy: 0.7574\n",
            "Epoch 11/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9834 - accuracy: 0.5953 - val_loss: 1.0123 - val_accuracy: 0.6434\n",
            "Epoch 12/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9644 - accuracy: 0.6231 - val_loss: 0.9514 - val_accuracy: 0.6801\n",
            "Epoch 13/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9864 - accuracy: 0.6089 - val_loss: 1.0688 - val_accuracy: 0.6287\n",
            "Epoch 14/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9539 - accuracy: 0.6231 - val_loss: 0.9583 - val_accuracy: 0.6801\n",
            "Epoch 15/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9353 - accuracy: 0.6411 - val_loss: 0.8722 - val_accuracy: 0.7684\n",
            "Epoch 16/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.9428 - accuracy: 0.6293 - val_loss: 0.9774 - val_accuracy: 0.6434\n",
            "Epoch 17/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.9375 - accuracy: 0.6399 - val_loss: 1.0864 - val_accuracy: 0.6176\n",
            "Epoch 18/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.9200 - accuracy: 0.6392 - val_loss: 0.8777 - val_accuracy: 0.7574\n",
            "Epoch 19/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8782 - accuracy: 0.6597 - val_loss: 0.9652 - val_accuracy: 0.6324\n",
            "Epoch 20/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.9273 - accuracy: 0.6392 - val_loss: 0.8078 - val_accuracy: 0.7610\n",
            "Epoch 21/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8756 - accuracy: 0.6627 - val_loss: 0.8863 - val_accuracy: 0.7426\n",
            "Epoch 22/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8842 - accuracy: 0.6504 - val_loss: 0.9640 - val_accuracy: 0.6324\n",
            "Epoch 23/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8463 - accuracy: 0.6627 - val_loss: 0.7903 - val_accuracy: 0.7647\n",
            "Epoch 24/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8471 - accuracy: 0.6683 - val_loss: 0.8513 - val_accuracy: 0.7463\n",
            "Epoch 25/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8638 - accuracy: 0.6559 - val_loss: 0.7980 - val_accuracy: 0.7500\n",
            "Epoch 26/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8304 - accuracy: 0.6609 - val_loss: 0.7998 - val_accuracy: 0.7500\n",
            "Epoch 27/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8409 - accuracy: 0.6621 - val_loss: 0.8165 - val_accuracy: 0.7426\n",
            "Epoch 28/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8203 - accuracy: 0.6726 - val_loss: 0.8209 - val_accuracy: 0.7537\n",
            "Epoch 29/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8233 - accuracy: 0.6665 - val_loss: 0.7509 - val_accuracy: 0.7647\n",
            "Epoch 30/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8083 - accuracy: 0.6652 - val_loss: 0.7926 - val_accuracy: 0.7574\n",
            "Epoch 31/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8025 - accuracy: 0.6720 - val_loss: 0.8668 - val_accuracy: 0.6471\n",
            "Epoch 32/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8014 - accuracy: 0.6640 - val_loss: 0.9647 - val_accuracy: 0.6066\n",
            "Epoch 33/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.8015 - accuracy: 0.6634 - val_loss: 0.7726 - val_accuracy: 0.7500\n",
            "Epoch 34/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.7959 - accuracy: 0.6646 - val_loss: 0.7964 - val_accuracy: 0.7316\n",
            "Epoch 35/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7918 - accuracy: 0.6640 - val_loss: 0.7855 - val_accuracy: 0.7537\n",
            "Epoch 36/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7701 - accuracy: 0.6671 - val_loss: 0.7998 - val_accuracy: 0.7426\n",
            "Epoch 37/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7714 - accuracy: 0.6739 - val_loss: 0.7655 - val_accuracy: 0.7463\n",
            "Epoch 38/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7866 - accuracy: 0.6671 - val_loss: 0.7628 - val_accuracy: 0.7574\n",
            "Epoch 39/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7769 - accuracy: 0.6627 - val_loss: 0.9018 - val_accuracy: 0.6507\n",
            "Epoch 40/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7620 - accuracy: 0.6696 - val_loss: 0.9714 - val_accuracy: 0.6066\n",
            "Epoch 41/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7776 - accuracy: 0.6634 - val_loss: 1.0375 - val_accuracy: 0.6029\n",
            "Epoch 42/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7572 - accuracy: 0.6726 - val_loss: 0.8314 - val_accuracy: 0.6544\n",
            "Epoch 43/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7452 - accuracy: 0.6832 - val_loss: 0.8143 - val_accuracy: 0.6691\n",
            "Epoch 44/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7373 - accuracy: 0.6863 - val_loss: 0.9919 - val_accuracy: 0.6140\n",
            "Epoch 45/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.7407 - accuracy: 0.6751 - val_loss: 1.0703 - val_accuracy: 0.6029\n",
            "Epoch 46/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7436 - accuracy: 0.6733 - val_loss: 0.8690 - val_accuracy: 0.6654\n",
            "Epoch 47/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.7143 - accuracy: 0.6850 - val_loss: 0.8404 - val_accuracy: 0.6581\n",
            "Epoch 48/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7266 - accuracy: 0.6708 - val_loss: 0.8076 - val_accuracy: 0.7022\n",
            "Epoch 49/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7154 - accuracy: 0.6918 - val_loss: 0.9393 - val_accuracy: 0.6581\n",
            "Epoch 50/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7192 - accuracy: 0.6776 - val_loss: 0.8242 - val_accuracy: 0.6801\n",
            "Epoch 51/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7097 - accuracy: 0.6925 - val_loss: 0.9151 - val_accuracy: 0.6618\n",
            "Epoch 52/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7227 - accuracy: 0.6906 - val_loss: 0.9619 - val_accuracy: 0.6544\n",
            "Epoch 53/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7025 - accuracy: 0.6999 - val_loss: 0.8499 - val_accuracy: 0.6728\n",
            "Epoch 54/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6895 - accuracy: 0.6968 - val_loss: 0.7091 - val_accuracy: 0.7537\n",
            "Epoch 55/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7137 - accuracy: 0.6912 - val_loss: 0.7935 - val_accuracy: 0.7390\n",
            "Epoch 56/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.7055 - accuracy: 0.6912 - val_loss: 0.7351 - val_accuracy: 0.7537\n",
            "Epoch 57/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6783 - accuracy: 0.7129 - val_loss: 0.6708 - val_accuracy: 0.7537\n",
            "Epoch 58/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6754 - accuracy: 0.7048 - val_loss: 0.8036 - val_accuracy: 0.7022\n",
            "Epoch 59/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6801 - accuracy: 0.7098 - val_loss: 0.7876 - val_accuracy: 0.7132\n",
            "Epoch 60/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6734 - accuracy: 0.7166 - val_loss: 0.7094 - val_accuracy: 0.7206\n",
            "Epoch 61/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6965 - accuracy: 0.7073 - val_loss: 0.8221 - val_accuracy: 0.6801\n",
            "Epoch 62/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6924 - accuracy: 0.7030 - val_loss: 0.8695 - val_accuracy: 0.6801\n",
            "Epoch 63/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6876 - accuracy: 0.7116 - val_loss: 0.9233 - val_accuracy: 0.6801\n",
            "Epoch 64/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6930 - accuracy: 0.7085 - val_loss: 0.7852 - val_accuracy: 0.6838\n",
            "Epoch 65/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6724 - accuracy: 0.7141 - val_loss: 0.8552 - val_accuracy: 0.6765\n",
            "Epoch 66/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6797 - accuracy: 0.7135 - val_loss: 0.9067 - val_accuracy: 0.6654\n",
            "Epoch 67/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6754 - accuracy: 0.7191 - val_loss: 0.8058 - val_accuracy: 0.7022\n",
            "Epoch 68/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6856 - accuracy: 0.7011 - val_loss: 1.0284 - val_accuracy: 0.5993\n",
            "Epoch 69/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6790 - accuracy: 0.7246 - val_loss: 0.9369 - val_accuracy: 0.6618\n",
            "Epoch 70/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6497 - accuracy: 0.7345 - val_loss: 0.7912 - val_accuracy: 0.7390\n",
            "Epoch 71/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6665 - accuracy: 0.7240 - val_loss: 0.8511 - val_accuracy: 0.6618\n",
            "Epoch 72/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6513 - accuracy: 0.7191 - val_loss: 0.7839 - val_accuracy: 0.6949\n",
            "Epoch 73/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6473 - accuracy: 0.7308 - val_loss: 1.0597 - val_accuracy: 0.5699\n",
            "Epoch 74/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6450 - accuracy: 0.7283 - val_loss: 1.0127 - val_accuracy: 0.6287\n",
            "Epoch 75/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6590 - accuracy: 0.7296 - val_loss: 0.8848 - val_accuracy: 0.6471\n",
            "Epoch 76/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6428 - accuracy: 0.7197 - val_loss: 0.7989 - val_accuracy: 0.6654\n",
            "Epoch 77/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6446 - accuracy: 0.7314 - val_loss: 1.0021 - val_accuracy: 0.6176\n",
            "Epoch 78/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6478 - accuracy: 0.7271 - val_loss: 0.9864 - val_accuracy: 0.6176\n",
            "Epoch 79/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6295 - accuracy: 0.7382 - val_loss: 0.8776 - val_accuracy: 0.6581\n",
            "Epoch 80/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6316 - accuracy: 0.7271 - val_loss: 0.8175 - val_accuracy: 0.6801\n",
            "Epoch 81/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6403 - accuracy: 0.7191 - val_loss: 0.8821 - val_accuracy: 0.6324\n",
            "Epoch 82/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6128 - accuracy: 0.7605 - val_loss: 0.9264 - val_accuracy: 0.6287\n",
            "Epoch 83/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6464 - accuracy: 0.7246 - val_loss: 0.7548 - val_accuracy: 0.7353\n",
            "Epoch 84/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6235 - accuracy: 0.7327 - val_loss: 0.8911 - val_accuracy: 0.6507\n",
            "Epoch 85/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6320 - accuracy: 0.7469 - val_loss: 0.7176 - val_accuracy: 0.7500\n",
            "Epoch 86/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6311 - accuracy: 0.7382 - val_loss: 0.9234 - val_accuracy: 0.6397\n",
            "Epoch 87/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6385 - accuracy: 0.7463 - val_loss: 0.9208 - val_accuracy: 0.5956\n",
            "Epoch 88/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6261 - accuracy: 0.7444 - val_loss: 0.9660 - val_accuracy: 0.5993\n",
            "Epoch 89/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6110 - accuracy: 0.7512 - val_loss: 0.9235 - val_accuracy: 0.6140\n",
            "Epoch 90/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6170 - accuracy: 0.7290 - val_loss: 1.0190 - val_accuracy: 0.5699\n",
            "Epoch 91/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6120 - accuracy: 0.7463 - val_loss: 1.0497 - val_accuracy: 0.5625\n",
            "Epoch 92/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6012 - accuracy: 0.7401 - val_loss: 0.8161 - val_accuracy: 0.6544\n",
            "Epoch 93/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6208 - accuracy: 0.7450 - val_loss: 0.8654 - val_accuracy: 0.6324\n",
            "Epoch 94/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5860 - accuracy: 0.7438 - val_loss: 0.9520 - val_accuracy: 0.6103\n",
            "Epoch 95/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6090 - accuracy: 0.7395 - val_loss: 0.9750 - val_accuracy: 0.5956\n",
            "Epoch 96/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6121 - accuracy: 0.7587 - val_loss: 0.8912 - val_accuracy: 0.6250\n",
            "Epoch 97/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5919 - accuracy: 0.7457 - val_loss: 0.8033 - val_accuracy: 0.6581\n",
            "Epoch 98/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5949 - accuracy: 0.7438 - val_loss: 0.9614 - val_accuracy: 0.5478\n",
            "Epoch 99/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5956 - accuracy: 0.7574 - val_loss: 0.8650 - val_accuracy: 0.5993\n",
            "Epoch 100/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5911 - accuracy: 0.7519 - val_loss: 0.9147 - val_accuracy: 0.5735\n",
            "Epoch 101/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5946 - accuracy: 0.7531 - val_loss: 0.8542 - val_accuracy: 0.6213\n",
            "Epoch 102/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6073 - accuracy: 0.7494 - val_loss: 0.8338 - val_accuracy: 0.6213\n",
            "Epoch 103/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5835 - accuracy: 0.7550 - val_loss: 0.7678 - val_accuracy: 0.6507\n",
            "Epoch 104/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.6004 - accuracy: 0.7426 - val_loss: 0.8526 - val_accuracy: 0.6029\n",
            "Epoch 105/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5794 - accuracy: 0.7587 - val_loss: 0.9909 - val_accuracy: 0.5441\n",
            "Epoch 106/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5729 - accuracy: 0.7618 - val_loss: 0.8312 - val_accuracy: 0.5993\n",
            "Epoch 107/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5826 - accuracy: 0.7630 - val_loss: 0.7621 - val_accuracy: 0.6471\n",
            "Epoch 108/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5989 - accuracy: 0.7574 - val_loss: 0.8103 - val_accuracy: 0.6176\n",
            "Epoch 109/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5778 - accuracy: 0.7618 - val_loss: 0.9363 - val_accuracy: 0.5809\n",
            "Epoch 110/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5896 - accuracy: 0.7506 - val_loss: 0.7854 - val_accuracy: 0.6360\n",
            "Epoch 111/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5834 - accuracy: 0.7593 - val_loss: 0.8955 - val_accuracy: 0.5882\n",
            "Epoch 112/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5820 - accuracy: 0.7710 - val_loss: 0.8982 - val_accuracy: 0.5919\n",
            "Epoch 113/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5808 - accuracy: 0.7661 - val_loss: 0.8879 - val_accuracy: 0.5993\n",
            "Epoch 114/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5913 - accuracy: 0.7580 - val_loss: 0.8705 - val_accuracy: 0.5956\n",
            "Epoch 115/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.6133 - accuracy: 0.7450 - val_loss: 0.8046 - val_accuracy: 0.6250\n",
            "Epoch 116/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5610 - accuracy: 0.7785 - val_loss: 0.8666 - val_accuracy: 0.5809\n",
            "Epoch 117/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5684 - accuracy: 0.7735 - val_loss: 0.7348 - val_accuracy: 0.6801\n",
            "Epoch 118/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5820 - accuracy: 0.7500 - val_loss: 0.8046 - val_accuracy: 0.6360\n",
            "Epoch 119/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5738 - accuracy: 0.7649 - val_loss: 0.9285 - val_accuracy: 0.5625\n",
            "Epoch 120/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5754 - accuracy: 0.7611 - val_loss: 0.8266 - val_accuracy: 0.6066\n",
            "Epoch 121/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5761 - accuracy: 0.7710 - val_loss: 0.9747 - val_accuracy: 0.5772\n",
            "Epoch 122/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5586 - accuracy: 0.7778 - val_loss: 0.7750 - val_accuracy: 0.6397\n",
            "Epoch 123/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5589 - accuracy: 0.7692 - val_loss: 0.8211 - val_accuracy: 0.6066\n",
            "Epoch 124/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5621 - accuracy: 0.7766 - val_loss: 0.8357 - val_accuracy: 0.6250\n",
            "Epoch 125/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5646 - accuracy: 0.7624 - val_loss: 0.8598 - val_accuracy: 0.6029\n",
            "Epoch 126/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5486 - accuracy: 0.7778 - val_loss: 0.8733 - val_accuracy: 0.5919\n",
            "Epoch 127/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5840 - accuracy: 0.7624 - val_loss: 0.8241 - val_accuracy: 0.6066\n",
            "Epoch 128/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5753 - accuracy: 0.7618 - val_loss: 0.8405 - val_accuracy: 0.6324\n",
            "Epoch 129/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5686 - accuracy: 0.7698 - val_loss: 0.8027 - val_accuracy: 0.6066\n",
            "Epoch 130/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5441 - accuracy: 0.7754 - val_loss: 0.7893 - val_accuracy: 0.6581\n",
            "Epoch 131/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5720 - accuracy: 0.7531 - val_loss: 0.9449 - val_accuracy: 0.5699\n",
            "Epoch 132/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5669 - accuracy: 0.7735 - val_loss: 0.7866 - val_accuracy: 0.6360\n",
            "Epoch 133/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5538 - accuracy: 0.7760 - val_loss: 0.9661 - val_accuracy: 0.5809\n",
            "Epoch 134/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5558 - accuracy: 0.7772 - val_loss: 0.8244 - val_accuracy: 0.6029\n",
            "Epoch 135/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5600 - accuracy: 0.7710 - val_loss: 1.0208 - val_accuracy: 0.5662\n",
            "Epoch 136/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5594 - accuracy: 0.7710 - val_loss: 0.8299 - val_accuracy: 0.6029\n",
            "Epoch 137/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5510 - accuracy: 0.7834 - val_loss: 0.9198 - val_accuracy: 0.5919\n",
            "Epoch 138/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5574 - accuracy: 0.7723 - val_loss: 0.8382 - val_accuracy: 0.5956\n",
            "Epoch 139/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5470 - accuracy: 0.7729 - val_loss: 0.8572 - val_accuracy: 0.5882\n",
            "Epoch 140/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5668 - accuracy: 0.7611 - val_loss: 0.7383 - val_accuracy: 0.6838\n",
            "Epoch 141/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5512 - accuracy: 0.7766 - val_loss: 0.9512 - val_accuracy: 0.5699\n",
            "Epoch 142/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5689 - accuracy: 0.7636 - val_loss: 0.7703 - val_accuracy: 0.6691\n",
            "Epoch 143/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5632 - accuracy: 0.7698 - val_loss: 0.9694 - val_accuracy: 0.5662\n",
            "Epoch 144/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5487 - accuracy: 0.7797 - val_loss: 0.8496 - val_accuracy: 0.5956\n",
            "Epoch 145/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5708 - accuracy: 0.7679 - val_loss: 0.8945 - val_accuracy: 0.5919\n",
            "Epoch 146/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5402 - accuracy: 0.7834 - val_loss: 0.7394 - val_accuracy: 0.6875\n",
            "Epoch 147/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5345 - accuracy: 0.7791 - val_loss: 0.8060 - val_accuracy: 0.6103\n",
            "Epoch 148/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5364 - accuracy: 0.7822 - val_loss: 0.7382 - val_accuracy: 0.6801\n",
            "Epoch 149/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5380 - accuracy: 0.7754 - val_loss: 0.7748 - val_accuracy: 0.6434\n",
            "Epoch 150/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5367 - accuracy: 0.7840 - val_loss: 0.7853 - val_accuracy: 0.6360\n",
            "Epoch 151/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5484 - accuracy: 0.7723 - val_loss: 0.7395 - val_accuracy: 0.6765\n",
            "Epoch 152/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5406 - accuracy: 0.7828 - val_loss: 0.8602 - val_accuracy: 0.5993\n",
            "Epoch 153/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5471 - accuracy: 0.7741 - val_loss: 0.8049 - val_accuracy: 0.6581\n",
            "Epoch 154/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5469 - accuracy: 0.7729 - val_loss: 0.7678 - val_accuracy: 0.6397\n",
            "Epoch 155/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5543 - accuracy: 0.7735 - val_loss: 0.7495 - val_accuracy: 0.6544\n",
            "Epoch 156/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5319 - accuracy: 0.7865 - val_loss: 0.7475 - val_accuracy: 0.6728\n",
            "Epoch 157/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5259 - accuracy: 0.7877 - val_loss: 0.7839 - val_accuracy: 0.6397\n",
            "Epoch 158/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5394 - accuracy: 0.7828 - val_loss: 0.7792 - val_accuracy: 0.6103\n",
            "Epoch 159/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5398 - accuracy: 0.7797 - val_loss: 0.8159 - val_accuracy: 0.6176\n",
            "Epoch 160/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5383 - accuracy: 0.7809 - val_loss: 0.8429 - val_accuracy: 0.6066\n",
            "Epoch 161/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5319 - accuracy: 0.7828 - val_loss: 0.7513 - val_accuracy: 0.6434\n",
            "Epoch 162/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5285 - accuracy: 0.7791 - val_loss: 0.7636 - val_accuracy: 0.6728\n",
            "Epoch 163/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5448 - accuracy: 0.7859 - val_loss: 0.8812 - val_accuracy: 0.6029\n",
            "Epoch 164/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5286 - accuracy: 0.7902 - val_loss: 0.7628 - val_accuracy: 0.6471\n",
            "Epoch 165/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5483 - accuracy: 0.7704 - val_loss: 0.7759 - val_accuracy: 0.6471\n",
            "Epoch 166/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5310 - accuracy: 0.7822 - val_loss: 0.7007 - val_accuracy: 0.6765\n",
            "Epoch 167/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5220 - accuracy: 0.7970 - val_loss: 0.6958 - val_accuracy: 0.6912\n",
            "Epoch 168/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5450 - accuracy: 0.7853 - val_loss: 0.7222 - val_accuracy: 0.6507\n",
            "Epoch 169/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5349 - accuracy: 0.7834 - val_loss: 0.7879 - val_accuracy: 0.6397\n",
            "Epoch 170/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5302 - accuracy: 0.7902 - val_loss: 0.8182 - val_accuracy: 0.6176\n",
            "Epoch 171/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5250 - accuracy: 0.7952 - val_loss: 0.8531 - val_accuracy: 0.5919\n",
            "Epoch 172/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5135 - accuracy: 0.7865 - val_loss: 0.8315 - val_accuracy: 0.6324\n",
            "Epoch 173/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5321 - accuracy: 0.7803 - val_loss: 0.7502 - val_accuracy: 0.6471\n",
            "Epoch 174/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5193 - accuracy: 0.7915 - val_loss: 0.9236 - val_accuracy: 0.5993\n",
            "Epoch 175/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5202 - accuracy: 0.7983 - val_loss: 0.7599 - val_accuracy: 0.6765\n",
            "Epoch 176/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5027 - accuracy: 0.7958 - val_loss: 0.8315 - val_accuracy: 0.6397\n",
            "Epoch 177/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5268 - accuracy: 0.7908 - val_loss: 0.7519 - val_accuracy: 0.6507\n",
            "Epoch 178/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5163 - accuracy: 0.7939 - val_loss: 0.6934 - val_accuracy: 0.6912\n",
            "Epoch 179/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5243 - accuracy: 0.8020 - val_loss: 0.6778 - val_accuracy: 0.7096\n",
            "Epoch 180/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5219 - accuracy: 0.7884 - val_loss: 0.8135 - val_accuracy: 0.6213\n",
            "Epoch 181/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5247 - accuracy: 0.7816 - val_loss: 0.6774 - val_accuracy: 0.6985\n",
            "Epoch 182/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5419 - accuracy: 0.7871 - val_loss: 0.7247 - val_accuracy: 0.6765\n",
            "Epoch 183/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5142 - accuracy: 0.7896 - val_loss: 0.8890 - val_accuracy: 0.6140\n",
            "Epoch 184/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5201 - accuracy: 0.8032 - val_loss: 0.6935 - val_accuracy: 0.7022\n",
            "Epoch 185/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5242 - accuracy: 0.7983 - val_loss: 0.7832 - val_accuracy: 0.6544\n",
            "Epoch 186/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5097 - accuracy: 0.7946 - val_loss: 0.6682 - val_accuracy: 0.7243\n",
            "Epoch 187/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5434 - accuracy: 0.7847 - val_loss: 0.7472 - val_accuracy: 0.6691\n",
            "Epoch 188/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5035 - accuracy: 0.8014 - val_loss: 0.7319 - val_accuracy: 0.6728\n",
            "Epoch 189/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5053 - accuracy: 0.7946 - val_loss: 0.6580 - val_accuracy: 0.7279\n",
            "Epoch 190/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4986 - accuracy: 0.8014 - val_loss: 0.6786 - val_accuracy: 0.6838\n",
            "Epoch 191/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4970 - accuracy: 0.8014 - val_loss: 0.7915 - val_accuracy: 0.6471\n",
            "Epoch 192/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5191 - accuracy: 0.7915 - val_loss: 0.6609 - val_accuracy: 0.7206\n",
            "Epoch 193/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5299 - accuracy: 0.7970 - val_loss: 0.7452 - val_accuracy: 0.6691\n",
            "Epoch 194/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5178 - accuracy: 0.7989 - val_loss: 0.8283 - val_accuracy: 0.6324\n",
            "Epoch 195/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5002 - accuracy: 0.8088 - val_loss: 0.7557 - val_accuracy: 0.6691\n",
            "Epoch 196/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5030 - accuracy: 0.7970 - val_loss: 0.6499 - val_accuracy: 0.7169\n",
            "Epoch 197/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5153 - accuracy: 0.7970 - val_loss: 0.7449 - val_accuracy: 0.6618\n",
            "Epoch 198/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5015 - accuracy: 0.8057 - val_loss: 0.6548 - val_accuracy: 0.7353\n",
            "Epoch 199/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5036 - accuracy: 0.8057 - val_loss: 0.6808 - val_accuracy: 0.7316\n",
            "Epoch 200/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4902 - accuracy: 0.8175 - val_loss: 0.7001 - val_accuracy: 0.6912\n",
            "Epoch 201/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5138 - accuracy: 0.8007 - val_loss: 0.6802 - val_accuracy: 0.7279\n",
            "Epoch 202/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5033 - accuracy: 0.8014 - val_loss: 0.7574 - val_accuracy: 0.6618\n",
            "Epoch 203/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5047 - accuracy: 0.8069 - val_loss: 0.6855 - val_accuracy: 0.6985\n",
            "Epoch 204/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4976 - accuracy: 0.8119 - val_loss: 0.8155 - val_accuracy: 0.6324\n",
            "Epoch 205/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4976 - accuracy: 0.8051 - val_loss: 0.8318 - val_accuracy: 0.6618\n",
            "Epoch 206/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4938 - accuracy: 0.8113 - val_loss: 0.6481 - val_accuracy: 0.7096\n",
            "Epoch 207/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4882 - accuracy: 0.8069 - val_loss: 0.7734 - val_accuracy: 0.6581\n",
            "Epoch 208/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4998 - accuracy: 0.8113 - val_loss: 0.7106 - val_accuracy: 0.6949\n",
            "Epoch 209/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5122 - accuracy: 0.8032 - val_loss: 0.6353 - val_accuracy: 0.7390\n",
            "Epoch 210/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5306 - accuracy: 0.7840 - val_loss: 0.6798 - val_accuracy: 0.7316\n",
            "Epoch 211/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4850 - accuracy: 0.8175 - val_loss: 0.6457 - val_accuracy: 0.7206\n",
            "Epoch 212/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4885 - accuracy: 0.8168 - val_loss: 0.6546 - val_accuracy: 0.7279\n",
            "Epoch 213/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5053 - accuracy: 0.8063 - val_loss: 0.6634 - val_accuracy: 0.7353\n",
            "Epoch 214/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4929 - accuracy: 0.8057 - val_loss: 0.6687 - val_accuracy: 0.7353\n",
            "Epoch 215/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5056 - accuracy: 0.8045 - val_loss: 0.8079 - val_accuracy: 0.6471\n",
            "Epoch 216/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5110 - accuracy: 0.8069 - val_loss: 0.6814 - val_accuracy: 0.7316\n",
            "Epoch 217/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.5066 - accuracy: 0.8045 - val_loss: 0.6122 - val_accuracy: 0.7206\n",
            "Epoch 218/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4821 - accuracy: 0.8088 - val_loss: 0.6561 - val_accuracy: 0.7537\n",
            "Epoch 219/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5107 - accuracy: 0.8032 - val_loss: 0.6644 - val_accuracy: 0.7096\n",
            "Epoch 220/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4875 - accuracy: 0.8119 - val_loss: 0.6715 - val_accuracy: 0.7426\n",
            "Epoch 221/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4961 - accuracy: 0.8137 - val_loss: 0.6848 - val_accuracy: 0.7132\n",
            "Epoch 222/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5031 - accuracy: 0.8113 - val_loss: 0.7320 - val_accuracy: 0.6875\n",
            "Epoch 223/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4972 - accuracy: 0.8075 - val_loss: 0.7530 - val_accuracy: 0.6728\n",
            "Epoch 224/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5135 - accuracy: 0.8038 - val_loss: 0.7741 - val_accuracy: 0.6801\n",
            "Epoch 225/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4842 - accuracy: 0.8137 - val_loss: 0.7431 - val_accuracy: 0.6912\n",
            "Epoch 226/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5096 - accuracy: 0.8063 - val_loss: 0.6664 - val_accuracy: 0.7316\n",
            "Epoch 227/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4995 - accuracy: 0.8144 - val_loss: 0.6952 - val_accuracy: 0.7022\n",
            "Epoch 228/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4905 - accuracy: 0.8063 - val_loss: 0.6676 - val_accuracy: 0.7279\n",
            "Epoch 229/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4951 - accuracy: 0.8082 - val_loss: 0.6172 - val_accuracy: 0.7390\n",
            "Epoch 230/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4933 - accuracy: 0.8082 - val_loss: 0.6875 - val_accuracy: 0.7169\n",
            "Epoch 231/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5014 - accuracy: 0.8082 - val_loss: 0.7033 - val_accuracy: 0.6985\n",
            "Epoch 232/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5062 - accuracy: 0.8137 - val_loss: 0.5868 - val_accuracy: 0.7426\n",
            "Epoch 233/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5047 - accuracy: 0.8038 - val_loss: 0.6971 - val_accuracy: 0.7022\n",
            "Epoch 234/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4848 - accuracy: 0.8156 - val_loss: 0.7878 - val_accuracy: 0.6544\n",
            "Epoch 235/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4998 - accuracy: 0.8162 - val_loss: 0.7175 - val_accuracy: 0.7022\n",
            "Epoch 236/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4909 - accuracy: 0.8020 - val_loss: 0.6630 - val_accuracy: 0.7059\n",
            "Epoch 237/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4671 - accuracy: 0.8249 - val_loss: 0.7226 - val_accuracy: 0.7096\n",
            "Epoch 238/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5016 - accuracy: 0.8075 - val_loss: 0.6618 - val_accuracy: 0.7426\n",
            "Epoch 239/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4910 - accuracy: 0.8063 - val_loss: 0.6650 - val_accuracy: 0.7206\n",
            "Epoch 240/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.5163 - accuracy: 0.8057 - val_loss: 0.6740 - val_accuracy: 0.7390\n",
            "Epoch 241/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4793 - accuracy: 0.8224 - val_loss: 0.6563 - val_accuracy: 0.7353\n",
            "Epoch 242/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4724 - accuracy: 0.8168 - val_loss: 0.7335 - val_accuracy: 0.6912\n",
            "Epoch 243/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4861 - accuracy: 0.8230 - val_loss: 0.6692 - val_accuracy: 0.7426\n",
            "Epoch 244/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4774 - accuracy: 0.8280 - val_loss: 0.6534 - val_accuracy: 0.7353\n",
            "Epoch 245/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4654 - accuracy: 0.8125 - val_loss: 0.6018 - val_accuracy: 0.7500\n",
            "Epoch 246/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4661 - accuracy: 0.8199 - val_loss: 0.6781 - val_accuracy: 0.7022\n",
            "Epoch 247/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4750 - accuracy: 0.8082 - val_loss: 0.6440 - val_accuracy: 0.7353\n",
            "Epoch 248/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4805 - accuracy: 0.8168 - val_loss: 0.6977 - val_accuracy: 0.7316\n",
            "Epoch 249/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4786 - accuracy: 0.8199 - val_loss: 0.6706 - val_accuracy: 0.7426\n",
            "Epoch 250/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4689 - accuracy: 0.8212 - val_loss: 0.8043 - val_accuracy: 0.6544\n",
            "Epoch 251/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4757 - accuracy: 0.8224 - val_loss: 0.6939 - val_accuracy: 0.7279\n",
            "Epoch 252/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4879 - accuracy: 0.8063 - val_loss: 0.6351 - val_accuracy: 0.7426\n",
            "Epoch 253/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4829 - accuracy: 0.8119 - val_loss: 0.7060 - val_accuracy: 0.7279\n",
            "Epoch 254/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4741 - accuracy: 0.8032 - val_loss: 0.6832 - val_accuracy: 0.7316\n",
            "Epoch 255/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4824 - accuracy: 0.8168 - val_loss: 0.6731 - val_accuracy: 0.7390\n",
            "Epoch 256/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4864 - accuracy: 0.8100 - val_loss: 0.7267 - val_accuracy: 0.6838\n",
            "Epoch 257/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4883 - accuracy: 0.8137 - val_loss: 0.6565 - val_accuracy: 0.7500\n",
            "Epoch 258/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4804 - accuracy: 0.8181 - val_loss: 0.6505 - val_accuracy: 0.7500\n",
            "Epoch 259/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4671 - accuracy: 0.8286 - val_loss: 0.7076 - val_accuracy: 0.6949\n",
            "Epoch 260/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4736 - accuracy: 0.8243 - val_loss: 0.7893 - val_accuracy: 0.6544\n",
            "Epoch 261/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4648 - accuracy: 0.8304 - val_loss: 0.6049 - val_accuracy: 0.7500\n",
            "Epoch 262/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4656 - accuracy: 0.8205 - val_loss: 0.7192 - val_accuracy: 0.7096\n",
            "Epoch 263/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4661 - accuracy: 0.8280 - val_loss: 0.7003 - val_accuracy: 0.6985\n",
            "Epoch 264/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4536 - accuracy: 0.8286 - val_loss: 0.7216 - val_accuracy: 0.6949\n",
            "Epoch 265/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4803 - accuracy: 0.8205 - val_loss: 0.7899 - val_accuracy: 0.6801\n",
            "Epoch 266/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4658 - accuracy: 0.8335 - val_loss: 0.6705 - val_accuracy: 0.7390\n",
            "Epoch 267/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4628 - accuracy: 0.8292 - val_loss: 0.7013 - val_accuracy: 0.7059\n",
            "Epoch 268/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4635 - accuracy: 0.8274 - val_loss: 0.6515 - val_accuracy: 0.7169\n",
            "Epoch 269/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4763 - accuracy: 0.8075 - val_loss: 0.6234 - val_accuracy: 0.7463\n",
            "Epoch 270/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4611 - accuracy: 0.8261 - val_loss: 0.7001 - val_accuracy: 0.7206\n",
            "Epoch 271/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4598 - accuracy: 0.8181 - val_loss: 0.6691 - val_accuracy: 0.7390\n",
            "Epoch 272/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4850 - accuracy: 0.8168 - val_loss: 0.7113 - val_accuracy: 0.7096\n",
            "Epoch 273/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4787 - accuracy: 0.8243 - val_loss: 0.6204 - val_accuracy: 0.7610\n",
            "Epoch 274/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4829 - accuracy: 0.8106 - val_loss: 0.6611 - val_accuracy: 0.7316\n",
            "Epoch 275/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4755 - accuracy: 0.8255 - val_loss: 0.6566 - val_accuracy: 0.7243\n",
            "Epoch 276/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4553 - accuracy: 0.8224 - val_loss: 0.6868 - val_accuracy: 0.7243\n",
            "Epoch 277/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4761 - accuracy: 0.8199 - val_loss: 0.7426 - val_accuracy: 0.6912\n",
            "Epoch 278/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4558 - accuracy: 0.8354 - val_loss: 0.6587 - val_accuracy: 0.7426\n",
            "Epoch 279/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4693 - accuracy: 0.8218 - val_loss: 0.5761 - val_accuracy: 0.7463\n",
            "Epoch 280/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4950 - accuracy: 0.8193 - val_loss: 0.6780 - val_accuracy: 0.7243\n",
            "Epoch 281/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4587 - accuracy: 0.8224 - val_loss: 0.6867 - val_accuracy: 0.7279\n",
            "Epoch 282/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4509 - accuracy: 0.8329 - val_loss: 0.5642 - val_accuracy: 0.7500\n",
            "Epoch 283/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4647 - accuracy: 0.8230 - val_loss: 0.7217 - val_accuracy: 0.6949\n",
            "Epoch 284/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4719 - accuracy: 0.8261 - val_loss: 0.6936 - val_accuracy: 0.6985\n",
            "Epoch 285/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4651 - accuracy: 0.8243 - val_loss: 0.6258 - val_accuracy: 0.7500\n",
            "Epoch 286/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4588 - accuracy: 0.8304 - val_loss: 0.7494 - val_accuracy: 0.6875\n",
            "Epoch 287/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4654 - accuracy: 0.8193 - val_loss: 0.7144 - val_accuracy: 0.6912\n",
            "Epoch 288/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4704 - accuracy: 0.8249 - val_loss: 0.7088 - val_accuracy: 0.7096\n",
            "Epoch 289/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4751 - accuracy: 0.8212 - val_loss: 0.6698 - val_accuracy: 0.7426\n",
            "Epoch 290/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4577 - accuracy: 0.8366 - val_loss: 0.6953 - val_accuracy: 0.6912\n",
            "Epoch 291/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4440 - accuracy: 0.8416 - val_loss: 0.6961 - val_accuracy: 0.7279\n",
            "Epoch 292/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4687 - accuracy: 0.8212 - val_loss: 0.6697 - val_accuracy: 0.7316\n",
            "Epoch 293/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4729 - accuracy: 0.8224 - val_loss: 0.6717 - val_accuracy: 0.7426\n",
            "Epoch 294/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4473 - accuracy: 0.8317 - val_loss: 0.6985 - val_accuracy: 0.7243\n",
            "Epoch 295/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4798 - accuracy: 0.8329 - val_loss: 0.7856 - val_accuracy: 0.6838\n",
            "Epoch 296/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4571 - accuracy: 0.8298 - val_loss: 0.6269 - val_accuracy: 0.7353\n",
            "Epoch 297/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4754 - accuracy: 0.8150 - val_loss: 0.6537 - val_accuracy: 0.7426\n",
            "Epoch 298/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4773 - accuracy: 0.8311 - val_loss: 0.7785 - val_accuracy: 0.6728\n",
            "Epoch 299/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4757 - accuracy: 0.8205 - val_loss: 0.6668 - val_accuracy: 0.7206\n",
            "Epoch 300/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4664 - accuracy: 0.8230 - val_loss: 0.6905 - val_accuracy: 0.7059\n",
            "Epoch 301/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4621 - accuracy: 0.8335 - val_loss: 0.6896 - val_accuracy: 0.7206\n",
            "Epoch 302/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4691 - accuracy: 0.8230 - val_loss: 0.6705 - val_accuracy: 0.7279\n",
            "Epoch 303/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4639 - accuracy: 0.8274 - val_loss: 0.6893 - val_accuracy: 0.7169\n",
            "Epoch 304/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4680 - accuracy: 0.8187 - val_loss: 0.7610 - val_accuracy: 0.6728\n",
            "Epoch 305/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4434 - accuracy: 0.8441 - val_loss: 0.7319 - val_accuracy: 0.6949\n",
            "Epoch 306/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4753 - accuracy: 0.8230 - val_loss: 0.7024 - val_accuracy: 0.6838\n",
            "Epoch 307/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4520 - accuracy: 0.8317 - val_loss: 0.6930 - val_accuracy: 0.6949\n",
            "Epoch 308/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4557 - accuracy: 0.8360 - val_loss: 0.7111 - val_accuracy: 0.6838\n",
            "Epoch 309/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4538 - accuracy: 0.8261 - val_loss: 0.6888 - val_accuracy: 0.7243\n",
            "Epoch 310/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4656 - accuracy: 0.8261 - val_loss: 0.6893 - val_accuracy: 0.7243\n",
            "Epoch 311/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4797 - accuracy: 0.8175 - val_loss: 0.6969 - val_accuracy: 0.7096\n",
            "Epoch 312/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4606 - accuracy: 0.8218 - val_loss: 0.8279 - val_accuracy: 0.6507\n",
            "Epoch 313/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4526 - accuracy: 0.8286 - val_loss: 0.7700 - val_accuracy: 0.6765\n",
            "Epoch 314/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4533 - accuracy: 0.8261 - val_loss: 0.6821 - val_accuracy: 0.7169\n",
            "Epoch 315/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4671 - accuracy: 0.8274 - val_loss: 0.6908 - val_accuracy: 0.7243\n",
            "Epoch 316/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4798 - accuracy: 0.8137 - val_loss: 0.7101 - val_accuracy: 0.7022\n",
            "Epoch 317/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4581 - accuracy: 0.8261 - val_loss: 0.7361 - val_accuracy: 0.6838\n",
            "Epoch 318/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4660 - accuracy: 0.8304 - val_loss: 0.7070 - val_accuracy: 0.7243\n",
            "Epoch 319/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4565 - accuracy: 0.8286 - val_loss: 0.6816 - val_accuracy: 0.7206\n",
            "Epoch 320/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4752 - accuracy: 0.8230 - val_loss: 0.7094 - val_accuracy: 0.6949\n",
            "Epoch 321/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4602 - accuracy: 0.8348 - val_loss: 0.6612 - val_accuracy: 0.7500\n",
            "Epoch 322/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4650 - accuracy: 0.8348 - val_loss: 0.5939 - val_accuracy: 0.7096\n",
            "Epoch 323/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4702 - accuracy: 0.8224 - val_loss: 0.7482 - val_accuracy: 0.6949\n",
            "Epoch 324/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4615 - accuracy: 0.8249 - val_loss: 0.6850 - val_accuracy: 0.7353\n",
            "Epoch 325/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4507 - accuracy: 0.8304 - val_loss: 0.6773 - val_accuracy: 0.7096\n",
            "Epoch 326/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4624 - accuracy: 0.8267 - val_loss: 0.6999 - val_accuracy: 0.6875\n",
            "Epoch 327/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4733 - accuracy: 0.8218 - val_loss: 0.6793 - val_accuracy: 0.7279\n",
            "Epoch 328/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4506 - accuracy: 0.8280 - val_loss: 0.7804 - val_accuracy: 0.6728\n",
            "Epoch 329/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4705 - accuracy: 0.8249 - val_loss: 0.7046 - val_accuracy: 0.7132\n",
            "Epoch 330/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4573 - accuracy: 0.8267 - val_loss: 0.6808 - val_accuracy: 0.7316\n",
            "Epoch 331/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4516 - accuracy: 0.8280 - val_loss: 0.6360 - val_accuracy: 0.7279\n",
            "Epoch 332/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4469 - accuracy: 0.8298 - val_loss: 0.6925 - val_accuracy: 0.7279\n",
            "Epoch 333/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4377 - accuracy: 0.8410 - val_loss: 0.6326 - val_accuracy: 0.7353\n",
            "Epoch 334/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4452 - accuracy: 0.8410 - val_loss: 0.7176 - val_accuracy: 0.6875\n",
            "Epoch 335/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4364 - accuracy: 0.8298 - val_loss: 0.7389 - val_accuracy: 0.6985\n",
            "Epoch 336/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4482 - accuracy: 0.8354 - val_loss: 0.6712 - val_accuracy: 0.7279\n",
            "Epoch 337/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4582 - accuracy: 0.8274 - val_loss: 0.6760 - val_accuracy: 0.7390\n",
            "Epoch 338/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4636 - accuracy: 0.8199 - val_loss: 0.6773 - val_accuracy: 0.7426\n",
            "Epoch 339/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4515 - accuracy: 0.8261 - val_loss: 0.7027 - val_accuracy: 0.7206\n",
            "Epoch 340/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4513 - accuracy: 0.8348 - val_loss: 0.6767 - val_accuracy: 0.7353\n",
            "Epoch 341/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4399 - accuracy: 0.8354 - val_loss: 0.7136 - val_accuracy: 0.7022\n",
            "Epoch 342/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4319 - accuracy: 0.8317 - val_loss: 0.6082 - val_accuracy: 0.7463\n",
            "Epoch 343/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4622 - accuracy: 0.8230 - val_loss: 0.6915 - val_accuracy: 0.7279\n",
            "Epoch 344/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4560 - accuracy: 0.8286 - val_loss: 0.6296 - val_accuracy: 0.7132\n",
            "Epoch 345/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4604 - accuracy: 0.8249 - val_loss: 0.7971 - val_accuracy: 0.6434\n",
            "Epoch 346/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4503 - accuracy: 0.8329 - val_loss: 0.7091 - val_accuracy: 0.6949\n",
            "Epoch 347/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4422 - accuracy: 0.8447 - val_loss: 0.6398 - val_accuracy: 0.7132\n",
            "Epoch 348/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4618 - accuracy: 0.8360 - val_loss: 0.6847 - val_accuracy: 0.7279\n",
            "Epoch 349/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4610 - accuracy: 0.8292 - val_loss: 0.7296 - val_accuracy: 0.6949\n",
            "Epoch 350/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4748 - accuracy: 0.8267 - val_loss: 0.8152 - val_accuracy: 0.6618\n",
            "Epoch 351/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4500 - accuracy: 0.8422 - val_loss: 0.7112 - val_accuracy: 0.6801\n",
            "Epoch 352/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4347 - accuracy: 0.8403 - val_loss: 0.7637 - val_accuracy: 0.6765\n",
            "Epoch 353/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4643 - accuracy: 0.8323 - val_loss: 0.7383 - val_accuracy: 0.6912\n",
            "Epoch 354/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4267 - accuracy: 0.8373 - val_loss: 0.6717 - val_accuracy: 0.7500\n",
            "Epoch 355/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4358 - accuracy: 0.8212 - val_loss: 0.7025 - val_accuracy: 0.7132\n",
            "Epoch 356/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4508 - accuracy: 0.8236 - val_loss: 0.6814 - val_accuracy: 0.7096\n",
            "Epoch 357/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4512 - accuracy: 0.8261 - val_loss: 0.7234 - val_accuracy: 0.7132\n",
            "Epoch 358/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4563 - accuracy: 0.8410 - val_loss: 0.7003 - val_accuracy: 0.7206\n",
            "Epoch 359/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4461 - accuracy: 0.8298 - val_loss: 0.7282 - val_accuracy: 0.6765\n",
            "Epoch 360/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4549 - accuracy: 0.8311 - val_loss: 0.6772 - val_accuracy: 0.7426\n",
            "Epoch 361/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4407 - accuracy: 0.8348 - val_loss: 0.7588 - val_accuracy: 0.6801\n",
            "Epoch 362/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4431 - accuracy: 0.8379 - val_loss: 0.7354 - val_accuracy: 0.6801\n",
            "Epoch 363/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4453 - accuracy: 0.8422 - val_loss: 0.7175 - val_accuracy: 0.6912\n",
            "Epoch 364/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4559 - accuracy: 0.8329 - val_loss: 0.5902 - val_accuracy: 0.7353\n",
            "Epoch 365/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4495 - accuracy: 0.8304 - val_loss: 0.6850 - val_accuracy: 0.7132\n",
            "Epoch 366/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4535 - accuracy: 0.8354 - val_loss: 0.7506 - val_accuracy: 0.6838\n",
            "Epoch 367/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4471 - accuracy: 0.8391 - val_loss: 0.7416 - val_accuracy: 0.6985\n",
            "Epoch 368/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4606 - accuracy: 0.8255 - val_loss: 0.7217 - val_accuracy: 0.6985\n",
            "Epoch 369/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4491 - accuracy: 0.8335 - val_loss: 0.6786 - val_accuracy: 0.7353\n",
            "Epoch 370/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4532 - accuracy: 0.8342 - val_loss: 0.8259 - val_accuracy: 0.6618\n",
            "Epoch 371/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4590 - accuracy: 0.8243 - val_loss: 0.6869 - val_accuracy: 0.7169\n",
            "Epoch 372/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4481 - accuracy: 0.8255 - val_loss: 0.6341 - val_accuracy: 0.7316\n",
            "Epoch 373/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4358 - accuracy: 0.8298 - val_loss: 0.7249 - val_accuracy: 0.7022\n",
            "Epoch 374/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4493 - accuracy: 0.8317 - val_loss: 0.7065 - val_accuracy: 0.6949\n",
            "Epoch 375/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4462 - accuracy: 0.8366 - val_loss: 0.6486 - val_accuracy: 0.7390\n",
            "Epoch 376/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4379 - accuracy: 0.8354 - val_loss: 0.6629 - val_accuracy: 0.7390\n",
            "Epoch 377/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4491 - accuracy: 0.8286 - val_loss: 0.8187 - val_accuracy: 0.6471\n",
            "Epoch 378/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4489 - accuracy: 0.8348 - val_loss: 0.7135 - val_accuracy: 0.7169\n",
            "Epoch 379/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4578 - accuracy: 0.8224 - val_loss: 0.7403 - val_accuracy: 0.7059\n",
            "Epoch 380/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4536 - accuracy: 0.8422 - val_loss: 0.6821 - val_accuracy: 0.7390\n",
            "Epoch 381/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4519 - accuracy: 0.8292 - val_loss: 0.7852 - val_accuracy: 0.6765\n",
            "Epoch 382/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4497 - accuracy: 0.8329 - val_loss: 0.6972 - val_accuracy: 0.6985\n",
            "Epoch 383/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4588 - accuracy: 0.8224 - val_loss: 0.6787 - val_accuracy: 0.7316\n",
            "Epoch 384/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4623 - accuracy: 0.8391 - val_loss: 0.7586 - val_accuracy: 0.6801\n",
            "Epoch 385/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4500 - accuracy: 0.8335 - val_loss: 0.7027 - val_accuracy: 0.7316\n",
            "Epoch 386/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4390 - accuracy: 0.8280 - val_loss: 0.6800 - val_accuracy: 0.7500\n",
            "Epoch 387/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4268 - accuracy: 0.8422 - val_loss: 0.6865 - val_accuracy: 0.7096\n",
            "Epoch 388/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4356 - accuracy: 0.8335 - val_loss: 0.6888 - val_accuracy: 0.7279\n",
            "Epoch 389/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4437 - accuracy: 0.8360 - val_loss: 0.6570 - val_accuracy: 0.7279\n",
            "Epoch 390/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4622 - accuracy: 0.8236 - val_loss: 0.7239 - val_accuracy: 0.6912\n",
            "Epoch 391/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4343 - accuracy: 0.8335 - val_loss: 0.7317 - val_accuracy: 0.6949\n",
            "Epoch 392/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4577 - accuracy: 0.8354 - val_loss: 0.6124 - val_accuracy: 0.7390\n",
            "Epoch 393/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4460 - accuracy: 0.8342 - val_loss: 0.6419 - val_accuracy: 0.7390\n",
            "Epoch 394/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4411 - accuracy: 0.8385 - val_loss: 0.6551 - val_accuracy: 0.7390\n",
            "Epoch 395/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4540 - accuracy: 0.8261 - val_loss: 0.6736 - val_accuracy: 0.7353\n",
            "Epoch 396/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4463 - accuracy: 0.8366 - val_loss: 0.7414 - val_accuracy: 0.7132\n",
            "Epoch 397/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4455 - accuracy: 0.8249 - val_loss: 0.7601 - val_accuracy: 0.6875\n",
            "Epoch 398/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4488 - accuracy: 0.8311 - val_loss: 0.7030 - val_accuracy: 0.6949\n",
            "Epoch 399/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4575 - accuracy: 0.8317 - val_loss: 0.6942 - val_accuracy: 0.7206\n",
            "Epoch 400/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4272 - accuracy: 0.8403 - val_loss: 0.7139 - val_accuracy: 0.6985\n",
            "Epoch 401/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4353 - accuracy: 0.8416 - val_loss: 0.7811 - val_accuracy: 0.6728\n",
            "Epoch 402/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4595 - accuracy: 0.8280 - val_loss: 0.6581 - val_accuracy: 0.7390\n",
            "Epoch 403/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4447 - accuracy: 0.8286 - val_loss: 0.6491 - val_accuracy: 0.7169\n",
            "Epoch 404/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4351 - accuracy: 0.8434 - val_loss: 0.6874 - val_accuracy: 0.7132\n",
            "Epoch 405/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4430 - accuracy: 0.8397 - val_loss: 0.7039 - val_accuracy: 0.7132\n",
            "Epoch 406/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4587 - accuracy: 0.8335 - val_loss: 0.7664 - val_accuracy: 0.6801\n",
            "Epoch 407/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4446 - accuracy: 0.8267 - val_loss: 0.6904 - val_accuracy: 0.7169\n",
            "Epoch 408/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4549 - accuracy: 0.8205 - val_loss: 0.6986 - val_accuracy: 0.7059\n",
            "Epoch 409/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4359 - accuracy: 0.8360 - val_loss: 0.7307 - val_accuracy: 0.6912\n",
            "Epoch 410/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4504 - accuracy: 0.8472 - val_loss: 0.6900 - val_accuracy: 0.7353\n",
            "Epoch 411/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4289 - accuracy: 0.8441 - val_loss: 0.6930 - val_accuracy: 0.7243\n",
            "Epoch 412/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4504 - accuracy: 0.8317 - val_loss: 0.6498 - val_accuracy: 0.7426\n",
            "Epoch 413/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4487 - accuracy: 0.8218 - val_loss: 0.6506 - val_accuracy: 0.7279\n",
            "Epoch 414/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4581 - accuracy: 0.8298 - val_loss: 0.6994 - val_accuracy: 0.7132\n",
            "Epoch 415/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4402 - accuracy: 0.8478 - val_loss: 0.6992 - val_accuracy: 0.7243\n",
            "Epoch 416/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4293 - accuracy: 0.8434 - val_loss: 0.6806 - val_accuracy: 0.7169\n",
            "Epoch 417/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4357 - accuracy: 0.8373 - val_loss: 0.7456 - val_accuracy: 0.6875\n",
            "Epoch 418/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4352 - accuracy: 0.8403 - val_loss: 0.7336 - val_accuracy: 0.6912\n",
            "Epoch 419/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4465 - accuracy: 0.8354 - val_loss: 0.6715 - val_accuracy: 0.7316\n",
            "Epoch 420/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4430 - accuracy: 0.8373 - val_loss: 0.7543 - val_accuracy: 0.6875\n",
            "Epoch 421/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4426 - accuracy: 0.8360 - val_loss: 0.7083 - val_accuracy: 0.7169\n",
            "Epoch 422/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4574 - accuracy: 0.8255 - val_loss: 0.7669 - val_accuracy: 0.6838\n",
            "Epoch 423/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4299 - accuracy: 0.8447 - val_loss: 0.7197 - val_accuracy: 0.6801\n",
            "Epoch 424/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4374 - accuracy: 0.8403 - val_loss: 0.7307 - val_accuracy: 0.6985\n",
            "Epoch 425/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4433 - accuracy: 0.8366 - val_loss: 0.7185 - val_accuracy: 0.6912\n",
            "Epoch 426/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4457 - accuracy: 0.8317 - val_loss: 0.7357 - val_accuracy: 0.6801\n",
            "Epoch 427/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4361 - accuracy: 0.8360 - val_loss: 0.7038 - val_accuracy: 0.7206\n",
            "Epoch 428/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4474 - accuracy: 0.8280 - val_loss: 0.6920 - val_accuracy: 0.7132\n",
            "Epoch 429/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4314 - accuracy: 0.8459 - val_loss: 0.7300 - val_accuracy: 0.7206\n",
            "Epoch 430/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4319 - accuracy: 0.8391 - val_loss: 0.7182 - val_accuracy: 0.7132\n",
            "Epoch 431/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4276 - accuracy: 0.8422 - val_loss: 0.6850 - val_accuracy: 0.7390\n",
            "Epoch 432/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4644 - accuracy: 0.8274 - val_loss: 0.7182 - val_accuracy: 0.6838\n",
            "Epoch 433/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4374 - accuracy: 0.8354 - val_loss: 0.7126 - val_accuracy: 0.6985\n",
            "Epoch 434/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4458 - accuracy: 0.8354 - val_loss: 0.6670 - val_accuracy: 0.7500\n",
            "Epoch 435/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4467 - accuracy: 0.8366 - val_loss: 0.7079 - val_accuracy: 0.7206\n",
            "Epoch 436/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4295 - accuracy: 0.8391 - val_loss: 0.7535 - val_accuracy: 0.6875\n",
            "Epoch 437/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4240 - accuracy: 0.8447 - val_loss: 0.7006 - val_accuracy: 0.7390\n",
            "Epoch 438/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4372 - accuracy: 0.8379 - val_loss: 0.6987 - val_accuracy: 0.7316\n",
            "Epoch 439/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4485 - accuracy: 0.8311 - val_loss: 0.6911 - val_accuracy: 0.7279\n",
            "Epoch 440/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4512 - accuracy: 0.8373 - val_loss: 0.7058 - val_accuracy: 0.7059\n",
            "Epoch 441/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4483 - accuracy: 0.8317 - val_loss: 0.7194 - val_accuracy: 0.6912\n",
            "Epoch 442/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4436 - accuracy: 0.8422 - val_loss: 0.7565 - val_accuracy: 0.6801\n",
            "Epoch 443/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4475 - accuracy: 0.8329 - val_loss: 0.7127 - val_accuracy: 0.7022\n",
            "Epoch 444/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4290 - accuracy: 0.8428 - val_loss: 0.7331 - val_accuracy: 0.7132\n",
            "Epoch 445/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4443 - accuracy: 0.8391 - val_loss: 0.7688 - val_accuracy: 0.6765\n",
            "Epoch 446/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4286 - accuracy: 0.8397 - val_loss: 0.6958 - val_accuracy: 0.7390\n",
            "Epoch 447/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4321 - accuracy: 0.8360 - val_loss: 0.7013 - val_accuracy: 0.7243\n",
            "Epoch 448/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4434 - accuracy: 0.8428 - val_loss: 0.7003 - val_accuracy: 0.7206\n",
            "Epoch 449/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4333 - accuracy: 0.8434 - val_loss: 0.7488 - val_accuracy: 0.6838\n",
            "Epoch 450/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4316 - accuracy: 0.8385 - val_loss: 0.7536 - val_accuracy: 0.6801\n",
            "Epoch 451/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4212 - accuracy: 0.8484 - val_loss: 0.7291 - val_accuracy: 0.6912\n",
            "Epoch 452/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4256 - accuracy: 0.8428 - val_loss: 0.8042 - val_accuracy: 0.6618\n",
            "Epoch 453/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4485 - accuracy: 0.8360 - val_loss: 0.7103 - val_accuracy: 0.6985\n",
            "Epoch 454/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4233 - accuracy: 0.8391 - val_loss: 0.7725 - val_accuracy: 0.6765\n",
            "Epoch 455/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4662 - accuracy: 0.8354 - val_loss: 0.6864 - val_accuracy: 0.7279\n",
            "Epoch 456/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4420 - accuracy: 0.8428 - val_loss: 0.7546 - val_accuracy: 0.6838\n",
            "Epoch 457/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4303 - accuracy: 0.8459 - val_loss: 0.7087 - val_accuracy: 0.7169\n",
            "Epoch 458/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4327 - accuracy: 0.8447 - val_loss: 0.6806 - val_accuracy: 0.7243\n",
            "Epoch 459/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4185 - accuracy: 0.8366 - val_loss: 0.7282 - val_accuracy: 0.7096\n",
            "Epoch 460/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4314 - accuracy: 0.8298 - val_loss: 0.7327 - val_accuracy: 0.6912\n",
            "Epoch 461/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4412 - accuracy: 0.8410 - val_loss: 0.7217 - val_accuracy: 0.7022\n",
            "Epoch 462/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4345 - accuracy: 0.8465 - val_loss: 0.7189 - val_accuracy: 0.7169\n",
            "Epoch 463/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4409 - accuracy: 0.8280 - val_loss: 0.7090 - val_accuracy: 0.7206\n",
            "Epoch 464/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4457 - accuracy: 0.8410 - val_loss: 0.7030 - val_accuracy: 0.7132\n",
            "Epoch 465/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4334 - accuracy: 0.8441 - val_loss: 0.7174 - val_accuracy: 0.6985\n",
            "Epoch 466/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4465 - accuracy: 0.8348 - val_loss: 0.7462 - val_accuracy: 0.6875\n",
            "Epoch 467/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4219 - accuracy: 0.8465 - val_loss: 0.6949 - val_accuracy: 0.7206\n",
            "Epoch 468/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4341 - accuracy: 0.8366 - val_loss: 0.6626 - val_accuracy: 0.7096\n",
            "Epoch 469/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4465 - accuracy: 0.8311 - val_loss: 0.7151 - val_accuracy: 0.7206\n",
            "Epoch 470/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4434 - accuracy: 0.8391 - val_loss: 0.7570 - val_accuracy: 0.6801\n",
            "Epoch 471/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4363 - accuracy: 0.8410 - val_loss: 0.6975 - val_accuracy: 0.7390\n",
            "Epoch 472/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4359 - accuracy: 0.8335 - val_loss: 0.7073 - val_accuracy: 0.7169\n",
            "Epoch 473/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4343 - accuracy: 0.8422 - val_loss: 0.6993 - val_accuracy: 0.7132\n",
            "Epoch 474/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4186 - accuracy: 0.8441 - val_loss: 0.7067 - val_accuracy: 0.7243\n",
            "Epoch 475/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4482 - accuracy: 0.8403 - val_loss: 0.7535 - val_accuracy: 0.6912\n",
            "Epoch 476/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4552 - accuracy: 0.8354 - val_loss: 0.6889 - val_accuracy: 0.7353\n",
            "Epoch 477/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4398 - accuracy: 0.8428 - val_loss: 0.6779 - val_accuracy: 0.7353\n",
            "Epoch 478/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4368 - accuracy: 0.8434 - val_loss: 0.7188 - val_accuracy: 0.7022\n",
            "Epoch 479/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4461 - accuracy: 0.8348 - val_loss: 0.7042 - val_accuracy: 0.7132\n",
            "Epoch 480/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4517 - accuracy: 0.8403 - val_loss: 0.6945 - val_accuracy: 0.7132\n",
            "Epoch 481/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4232 - accuracy: 0.8441 - val_loss: 0.7179 - val_accuracy: 0.7169\n",
            "Epoch 482/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4237 - accuracy: 0.8416 - val_loss: 0.6947 - val_accuracy: 0.7279\n",
            "Epoch 483/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4384 - accuracy: 0.8410 - val_loss: 0.7170 - val_accuracy: 0.6912\n",
            "Epoch 484/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4323 - accuracy: 0.8379 - val_loss: 0.7208 - val_accuracy: 0.6985\n",
            "Epoch 485/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4387 - accuracy: 0.8391 - val_loss: 0.7498 - val_accuracy: 0.6875\n",
            "Epoch 486/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4180 - accuracy: 0.8540 - val_loss: 0.7296 - val_accuracy: 0.6801\n",
            "Epoch 487/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4429 - accuracy: 0.8385 - val_loss: 0.7587 - val_accuracy: 0.6838\n",
            "Epoch 488/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4412 - accuracy: 0.8403 - val_loss: 0.7250 - val_accuracy: 0.7096\n",
            "Epoch 489/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4327 - accuracy: 0.8397 - val_loss: 0.6931 - val_accuracy: 0.7426\n",
            "Epoch 490/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4474 - accuracy: 0.8373 - val_loss: 0.7201 - val_accuracy: 0.6912\n",
            "Epoch 491/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4353 - accuracy: 0.8422 - val_loss: 0.6703 - val_accuracy: 0.7243\n",
            "Epoch 492/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4344 - accuracy: 0.8434 - val_loss: 0.7790 - val_accuracy: 0.6765\n",
            "Epoch 493/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4300 - accuracy: 0.8434 - val_loss: 0.7831 - val_accuracy: 0.6838\n",
            "Epoch 494/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4325 - accuracy: 0.8397 - val_loss: 0.7020 - val_accuracy: 0.7279\n",
            "Epoch 495/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4353 - accuracy: 0.8366 - val_loss: 0.7199 - val_accuracy: 0.7096\n",
            "Epoch 496/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4500 - accuracy: 0.8391 - val_loss: 0.7480 - val_accuracy: 0.7132\n",
            "Epoch 497/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4512 - accuracy: 0.8416 - val_loss: 0.7071 - val_accuracy: 0.7243\n",
            "Epoch 498/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4198 - accuracy: 0.8496 - val_loss: 0.7148 - val_accuracy: 0.7132\n",
            "Epoch 499/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4418 - accuracy: 0.8317 - val_loss: 0.7321 - val_accuracy: 0.7132\n",
            "Epoch 500/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4317 - accuracy: 0.8298 - val_loss: 0.7231 - val_accuracy: 0.7243\n",
            "Epoch 501/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4248 - accuracy: 0.8373 - val_loss: 0.7227 - val_accuracy: 0.6875\n",
            "Epoch 502/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4238 - accuracy: 0.8478 - val_loss: 0.7338 - val_accuracy: 0.6949\n",
            "Epoch 503/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4300 - accuracy: 0.8422 - val_loss: 0.7071 - val_accuracy: 0.7243\n",
            "Epoch 504/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4490 - accuracy: 0.8441 - val_loss: 0.7452 - val_accuracy: 0.6728\n",
            "Epoch 505/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4407 - accuracy: 0.8422 - val_loss: 0.6697 - val_accuracy: 0.7132\n",
            "Epoch 506/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4433 - accuracy: 0.8304 - val_loss: 0.7074 - val_accuracy: 0.7132\n",
            "Epoch 507/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4357 - accuracy: 0.8422 - val_loss: 0.6879 - val_accuracy: 0.7206\n",
            "Epoch 508/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4512 - accuracy: 0.8410 - val_loss: 0.7008 - val_accuracy: 0.7206\n",
            "Epoch 509/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4305 - accuracy: 0.8515 - val_loss: 0.6670 - val_accuracy: 0.7243\n",
            "Epoch 510/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4380 - accuracy: 0.8391 - val_loss: 0.7222 - val_accuracy: 0.6875\n",
            "Epoch 511/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4427 - accuracy: 0.8360 - val_loss: 0.7623 - val_accuracy: 0.6875\n",
            "Epoch 512/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4400 - accuracy: 0.8379 - val_loss: 0.7406 - val_accuracy: 0.6875\n",
            "Epoch 513/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4196 - accuracy: 0.8447 - val_loss: 0.7287 - val_accuracy: 0.6801\n",
            "Epoch 514/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4314 - accuracy: 0.8366 - val_loss: 0.7266 - val_accuracy: 0.6838\n",
            "Epoch 515/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4405 - accuracy: 0.8434 - val_loss: 0.6727 - val_accuracy: 0.7426\n",
            "Epoch 516/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4310 - accuracy: 0.8410 - val_loss: 0.6975 - val_accuracy: 0.7316\n",
            "Epoch 517/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4398 - accuracy: 0.8391 - val_loss: 0.7022 - val_accuracy: 0.7132\n",
            "Epoch 518/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4404 - accuracy: 0.8379 - val_loss: 0.6546 - val_accuracy: 0.7132\n",
            "Epoch 519/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4420 - accuracy: 0.8416 - val_loss: 0.6967 - val_accuracy: 0.7206\n",
            "Epoch 520/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4153 - accuracy: 0.8453 - val_loss: 0.7585 - val_accuracy: 0.6765\n",
            "Epoch 521/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4279 - accuracy: 0.8410 - val_loss: 0.7170 - val_accuracy: 0.7169\n",
            "Epoch 522/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4194 - accuracy: 0.8484 - val_loss: 0.7167 - val_accuracy: 0.7169\n",
            "Epoch 523/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4179 - accuracy: 0.8441 - val_loss: 0.7056 - val_accuracy: 0.7169\n",
            "Epoch 524/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4232 - accuracy: 0.8373 - val_loss: 0.6975 - val_accuracy: 0.7132\n",
            "Epoch 525/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4315 - accuracy: 0.8379 - val_loss: 0.7148 - val_accuracy: 0.7022\n",
            "Epoch 526/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4358 - accuracy: 0.8403 - val_loss: 0.7440 - val_accuracy: 0.6875\n",
            "Epoch 527/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4227 - accuracy: 0.8391 - val_loss: 0.7063 - val_accuracy: 0.7169\n",
            "Epoch 528/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4326 - accuracy: 0.8397 - val_loss: 0.7474 - val_accuracy: 0.6765\n",
            "Epoch 529/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4190 - accuracy: 0.8428 - val_loss: 0.6516 - val_accuracy: 0.7243\n",
            "Epoch 530/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4314 - accuracy: 0.8410 - val_loss: 0.7523 - val_accuracy: 0.6875\n",
            "Epoch 531/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4075 - accuracy: 0.8533 - val_loss: 0.7390 - val_accuracy: 0.7206\n",
            "Epoch 532/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4301 - accuracy: 0.8391 - val_loss: 0.6949 - val_accuracy: 0.7279\n",
            "Epoch 533/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4384 - accuracy: 0.8354 - val_loss: 0.7043 - val_accuracy: 0.7059\n",
            "Epoch 534/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4117 - accuracy: 0.8403 - val_loss: 0.7395 - val_accuracy: 0.6949\n",
            "Epoch 535/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4344 - accuracy: 0.8403 - val_loss: 0.6931 - val_accuracy: 0.7132\n",
            "Epoch 536/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4457 - accuracy: 0.8410 - val_loss: 0.7519 - val_accuracy: 0.6765\n",
            "Epoch 537/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4283 - accuracy: 0.8447 - val_loss: 0.7335 - val_accuracy: 0.7132\n",
            "Epoch 538/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4259 - accuracy: 0.8441 - val_loss: 0.7147 - val_accuracy: 0.7132\n",
            "Epoch 539/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4275 - accuracy: 0.8428 - val_loss: 0.7176 - val_accuracy: 0.7169\n",
            "Epoch 540/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4254 - accuracy: 0.8472 - val_loss: 0.6914 - val_accuracy: 0.7426\n",
            "Epoch 541/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4331 - accuracy: 0.8465 - val_loss: 0.7131 - val_accuracy: 0.7169\n",
            "Epoch 542/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4326 - accuracy: 0.8403 - val_loss: 0.7296 - val_accuracy: 0.6875\n",
            "Epoch 543/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4126 - accuracy: 0.8515 - val_loss: 0.6923 - val_accuracy: 0.7169\n",
            "Epoch 544/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4271 - accuracy: 0.8441 - val_loss: 0.7085 - val_accuracy: 0.7169\n",
            "Epoch 545/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4132 - accuracy: 0.8441 - val_loss: 0.7070 - val_accuracy: 0.7206\n",
            "Epoch 546/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4237 - accuracy: 0.8472 - val_loss: 0.7370 - val_accuracy: 0.7206\n",
            "Epoch 547/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4186 - accuracy: 0.8428 - val_loss: 0.6972 - val_accuracy: 0.7279\n",
            "Epoch 548/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4311 - accuracy: 0.8527 - val_loss: 0.7389 - val_accuracy: 0.6838\n",
            "Epoch 549/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4362 - accuracy: 0.8385 - val_loss: 0.6873 - val_accuracy: 0.7279\n",
            "Epoch 550/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4317 - accuracy: 0.8335 - val_loss: 0.7362 - val_accuracy: 0.6801\n",
            "Epoch 551/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4270 - accuracy: 0.8422 - val_loss: 0.7207 - val_accuracy: 0.7243\n",
            "Epoch 552/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4216 - accuracy: 0.8484 - val_loss: 0.7294 - val_accuracy: 0.7132\n",
            "Epoch 553/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4369 - accuracy: 0.8397 - val_loss: 0.6892 - val_accuracy: 0.7169\n",
            "Epoch 554/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4266 - accuracy: 0.8472 - val_loss: 0.7065 - val_accuracy: 0.7169\n",
            "Epoch 555/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4363 - accuracy: 0.8422 - val_loss: 0.7268 - val_accuracy: 0.6912\n",
            "Epoch 556/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4319 - accuracy: 0.8515 - val_loss: 0.7406 - val_accuracy: 0.6801\n",
            "Epoch 557/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4342 - accuracy: 0.8391 - val_loss: 0.7253 - val_accuracy: 0.6875\n",
            "Epoch 558/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4235 - accuracy: 0.8304 - val_loss: 0.6967 - val_accuracy: 0.7390\n",
            "Epoch 559/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4170 - accuracy: 0.8521 - val_loss: 0.7468 - val_accuracy: 0.6838\n",
            "Epoch 560/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4408 - accuracy: 0.8379 - val_loss: 0.7486 - val_accuracy: 0.6838\n",
            "Epoch 561/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4062 - accuracy: 0.8558 - val_loss: 0.7098 - val_accuracy: 0.7169\n",
            "Epoch 562/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4306 - accuracy: 0.8329 - val_loss: 0.7495 - val_accuracy: 0.6838\n",
            "Epoch 563/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4335 - accuracy: 0.8472 - val_loss: 0.7593 - val_accuracy: 0.6765\n",
            "Epoch 564/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4361 - accuracy: 0.8292 - val_loss: 0.6701 - val_accuracy: 0.7206\n",
            "Epoch 565/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4250 - accuracy: 0.8391 - val_loss: 0.7637 - val_accuracy: 0.6912\n",
            "Epoch 566/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4226 - accuracy: 0.8434 - val_loss: 0.7239 - val_accuracy: 0.7206\n",
            "Epoch 567/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4136 - accuracy: 0.8459 - val_loss: 0.7171 - val_accuracy: 0.7279\n",
            "Epoch 568/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4240 - accuracy: 0.8478 - val_loss: 0.7355 - val_accuracy: 0.7169\n",
            "Epoch 569/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4339 - accuracy: 0.8342 - val_loss: 0.6672 - val_accuracy: 0.7279\n",
            "Epoch 570/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4097 - accuracy: 0.8490 - val_loss: 0.7314 - val_accuracy: 0.6801\n",
            "Epoch 571/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4328 - accuracy: 0.8472 - val_loss: 0.7056 - val_accuracy: 0.7169\n",
            "Epoch 572/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4196 - accuracy: 0.8385 - val_loss: 0.7186 - val_accuracy: 0.7169\n",
            "Epoch 573/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4277 - accuracy: 0.8441 - val_loss: 0.7400 - val_accuracy: 0.7169\n",
            "Epoch 574/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4205 - accuracy: 0.8441 - val_loss: 0.7478 - val_accuracy: 0.6801\n",
            "Epoch 575/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4168 - accuracy: 0.8459 - val_loss: 0.7201 - val_accuracy: 0.6949\n",
            "Epoch 576/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4517 - accuracy: 0.8304 - val_loss: 0.6942 - val_accuracy: 0.7390\n",
            "Epoch 577/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4264 - accuracy: 0.8484 - val_loss: 0.7551 - val_accuracy: 0.6728\n",
            "Epoch 578/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4391 - accuracy: 0.8441 - val_loss: 0.6868 - val_accuracy: 0.7243\n",
            "Epoch 579/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4170 - accuracy: 0.8533 - val_loss: 0.6846 - val_accuracy: 0.7169\n",
            "Epoch 580/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4192 - accuracy: 0.8385 - val_loss: 0.7408 - val_accuracy: 0.6875\n",
            "Epoch 581/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4482 - accuracy: 0.8292 - val_loss: 0.7277 - val_accuracy: 0.7096\n",
            "Epoch 582/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4295 - accuracy: 0.8391 - val_loss: 0.7590 - val_accuracy: 0.6875\n",
            "Epoch 583/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4211 - accuracy: 0.8373 - val_loss: 0.7163 - val_accuracy: 0.7022\n",
            "Epoch 584/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4174 - accuracy: 0.8509 - val_loss: 0.6910 - val_accuracy: 0.7206\n",
            "Epoch 585/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4549 - accuracy: 0.8292 - val_loss: 0.7937 - val_accuracy: 0.6801\n",
            "Epoch 586/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4380 - accuracy: 0.8366 - val_loss: 0.7273 - val_accuracy: 0.6912\n",
            "Epoch 587/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4170 - accuracy: 0.8571 - val_loss: 0.7786 - val_accuracy: 0.6618\n",
            "Epoch 588/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4222 - accuracy: 0.8422 - val_loss: 0.8103 - val_accuracy: 0.6728\n",
            "Epoch 589/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4250 - accuracy: 0.8366 - val_loss: 0.6920 - val_accuracy: 0.7426\n",
            "Epoch 590/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4274 - accuracy: 0.8403 - val_loss: 0.7600 - val_accuracy: 0.6985\n",
            "Epoch 591/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.3935 - accuracy: 0.8509 - val_loss: 0.6945 - val_accuracy: 0.7169\n",
            "Epoch 592/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4248 - accuracy: 0.8441 - val_loss: 0.7133 - val_accuracy: 0.7169\n",
            "Epoch 593/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4248 - accuracy: 0.8484 - val_loss: 0.7406 - val_accuracy: 0.7206\n",
            "Epoch 594/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4189 - accuracy: 0.8527 - val_loss: 0.7415 - val_accuracy: 0.6838\n",
            "Epoch 595/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4213 - accuracy: 0.8453 - val_loss: 0.6865 - val_accuracy: 0.7279\n",
            "Epoch 596/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4232 - accuracy: 0.8410 - val_loss: 0.6943 - val_accuracy: 0.7316\n",
            "Epoch 597/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4301 - accuracy: 0.8385 - val_loss: 0.6881 - val_accuracy: 0.7426\n",
            "Epoch 598/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4440 - accuracy: 0.8348 - val_loss: 0.7059 - val_accuracy: 0.7316\n",
            "Epoch 599/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4144 - accuracy: 0.8447 - val_loss: 0.6890 - val_accuracy: 0.7279\n",
            "Epoch 600/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4188 - accuracy: 0.8360 - val_loss: 0.6955 - val_accuracy: 0.7316\n",
            "Epoch 601/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4245 - accuracy: 0.8515 - val_loss: 0.7672 - val_accuracy: 0.6875\n",
            "Epoch 602/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4198 - accuracy: 0.8509 - val_loss: 0.7472 - val_accuracy: 0.6875\n",
            "Epoch 603/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4279 - accuracy: 0.8447 - val_loss: 0.7094 - val_accuracy: 0.7279\n",
            "Epoch 604/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4259 - accuracy: 0.8403 - val_loss: 0.7370 - val_accuracy: 0.6875\n",
            "Epoch 605/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4341 - accuracy: 0.8447 - val_loss: 0.7276 - val_accuracy: 0.7169\n",
            "Epoch 606/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4340 - accuracy: 0.8410 - val_loss: 0.7254 - val_accuracy: 0.7169\n",
            "Epoch 607/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4414 - accuracy: 0.8373 - val_loss: 0.7141 - val_accuracy: 0.7243\n",
            "Epoch 608/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4268 - accuracy: 0.8521 - val_loss: 0.7360 - val_accuracy: 0.6912\n",
            "Epoch 609/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4232 - accuracy: 0.8360 - val_loss: 0.7374 - val_accuracy: 0.6875\n",
            "Epoch 610/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4296 - accuracy: 0.8366 - val_loss: 0.7042 - val_accuracy: 0.7132\n",
            "Epoch 611/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4240 - accuracy: 0.8533 - val_loss: 0.6906 - val_accuracy: 0.7390\n",
            "Epoch 612/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4245 - accuracy: 0.8428 - val_loss: 0.7429 - val_accuracy: 0.6838\n",
            "Epoch 613/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4120 - accuracy: 0.8434 - val_loss: 0.7291 - val_accuracy: 0.6949\n",
            "Epoch 614/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4207 - accuracy: 0.8552 - val_loss: 0.6753 - val_accuracy: 0.7132\n",
            "Epoch 615/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4179 - accuracy: 0.8459 - val_loss: 0.7157 - val_accuracy: 0.7169\n",
            "Epoch 616/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4213 - accuracy: 0.8434 - val_loss: 0.7217 - val_accuracy: 0.7132\n",
            "Epoch 617/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4303 - accuracy: 0.8447 - val_loss: 0.7154 - val_accuracy: 0.7426\n",
            "Epoch 618/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4101 - accuracy: 0.8496 - val_loss: 0.6906 - val_accuracy: 0.7390\n",
            "Epoch 619/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4559 - accuracy: 0.8391 - val_loss: 0.7085 - val_accuracy: 0.7243\n",
            "Epoch 620/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4206 - accuracy: 0.8459 - val_loss: 0.7330 - val_accuracy: 0.6985\n",
            "Epoch 621/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4317 - accuracy: 0.8459 - val_loss: 0.7522 - val_accuracy: 0.6875\n",
            "Epoch 622/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4170 - accuracy: 0.8515 - val_loss: 0.7299 - val_accuracy: 0.7022\n",
            "Epoch 623/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4466 - accuracy: 0.8447 - val_loss: 0.7310 - val_accuracy: 0.7059\n",
            "Epoch 624/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4211 - accuracy: 0.8360 - val_loss: 0.7323 - val_accuracy: 0.6765\n",
            "Epoch 625/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4457 - accuracy: 0.8385 - val_loss: 0.7248 - val_accuracy: 0.7132\n",
            "Epoch 626/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4116 - accuracy: 0.8472 - val_loss: 0.7277 - val_accuracy: 0.6949\n",
            "Epoch 627/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4193 - accuracy: 0.8403 - val_loss: 0.7122 - val_accuracy: 0.7206\n",
            "Epoch 628/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4274 - accuracy: 0.8360 - val_loss: 0.6961 - val_accuracy: 0.7390\n",
            "Epoch 629/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4344 - accuracy: 0.8422 - val_loss: 0.7391 - val_accuracy: 0.6912\n",
            "Epoch 630/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4132 - accuracy: 0.8496 - val_loss: 0.7195 - val_accuracy: 0.7279\n",
            "Epoch 631/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4215 - accuracy: 0.8478 - val_loss: 0.7330 - val_accuracy: 0.7059\n",
            "Epoch 632/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4320 - accuracy: 0.8348 - val_loss: 0.7146 - val_accuracy: 0.7132\n",
            "Epoch 633/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4233 - accuracy: 0.8441 - val_loss: 0.7012 - val_accuracy: 0.7243\n",
            "Epoch 634/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4172 - accuracy: 0.8447 - val_loss: 0.7491 - val_accuracy: 0.6838\n",
            "Epoch 635/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4046 - accuracy: 0.8478 - val_loss: 0.7480 - val_accuracy: 0.6765\n",
            "Epoch 636/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4252 - accuracy: 0.8453 - val_loss: 0.7398 - val_accuracy: 0.6801\n",
            "Epoch 637/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4316 - accuracy: 0.8453 - val_loss: 0.7365 - val_accuracy: 0.6912\n",
            "Epoch 638/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4258 - accuracy: 0.8490 - val_loss: 0.7222 - val_accuracy: 0.7022\n",
            "Epoch 639/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4308 - accuracy: 0.8434 - val_loss: 0.7565 - val_accuracy: 0.7059\n",
            "Epoch 640/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4297 - accuracy: 0.8484 - val_loss: 0.7596 - val_accuracy: 0.6912\n",
            "Epoch 641/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4310 - accuracy: 0.8385 - val_loss: 0.7021 - val_accuracy: 0.7426\n",
            "Epoch 642/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4262 - accuracy: 0.8385 - val_loss: 0.7324 - val_accuracy: 0.6949\n",
            "Epoch 643/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4369 - accuracy: 0.8385 - val_loss: 0.6920 - val_accuracy: 0.7206\n",
            "Epoch 644/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4260 - accuracy: 0.8502 - val_loss: 0.7187 - val_accuracy: 0.7169\n",
            "Epoch 645/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4169 - accuracy: 0.8472 - val_loss: 0.7536 - val_accuracy: 0.6765\n",
            "Epoch 646/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4296 - accuracy: 0.8502 - val_loss: 0.7522 - val_accuracy: 0.6728\n",
            "Epoch 647/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4391 - accuracy: 0.8441 - val_loss: 0.7095 - val_accuracy: 0.7316\n",
            "Epoch 648/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4226 - accuracy: 0.8391 - val_loss: 0.7614 - val_accuracy: 0.6949\n",
            "Epoch 649/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4321 - accuracy: 0.8434 - val_loss: 0.6856 - val_accuracy: 0.7463\n",
            "Epoch 650/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4203 - accuracy: 0.8403 - val_loss: 0.7521 - val_accuracy: 0.6838\n",
            "Epoch 651/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4192 - accuracy: 0.8496 - val_loss: 0.7294 - val_accuracy: 0.6912\n",
            "Epoch 652/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4081 - accuracy: 0.8509 - val_loss: 0.6997 - val_accuracy: 0.7463\n",
            "Epoch 653/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4096 - accuracy: 0.8558 - val_loss: 0.7778 - val_accuracy: 0.6875\n",
            "Epoch 654/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4270 - accuracy: 0.8441 - val_loss: 0.6964 - val_accuracy: 0.7206\n",
            "Epoch 655/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4216 - accuracy: 0.8441 - val_loss: 0.7143 - val_accuracy: 0.7169\n",
            "Epoch 656/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4173 - accuracy: 0.8521 - val_loss: 0.7640 - val_accuracy: 0.6801\n",
            "Epoch 657/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4061 - accuracy: 0.8496 - val_loss: 0.7400 - val_accuracy: 0.6949\n",
            "Epoch 658/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4161 - accuracy: 0.8478 - val_loss: 0.7385 - val_accuracy: 0.6875\n",
            "Epoch 659/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4176 - accuracy: 0.8453 - val_loss: 0.7383 - val_accuracy: 0.6949\n",
            "Epoch 660/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4193 - accuracy: 0.8453 - val_loss: 0.7102 - val_accuracy: 0.7353\n",
            "Epoch 661/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4344 - accuracy: 0.8385 - val_loss: 0.6868 - val_accuracy: 0.7353\n",
            "Epoch 662/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4287 - accuracy: 0.8422 - val_loss: 0.7423 - val_accuracy: 0.7096\n",
            "Epoch 663/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4364 - accuracy: 0.8342 - val_loss: 0.7238 - val_accuracy: 0.7169\n",
            "Epoch 664/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4286 - accuracy: 0.8373 - val_loss: 0.7255 - val_accuracy: 0.6985\n",
            "Epoch 665/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.3996 - accuracy: 0.8496 - val_loss: 0.7364 - val_accuracy: 0.7169\n",
            "Epoch 666/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4175 - accuracy: 0.8428 - val_loss: 0.7273 - val_accuracy: 0.7169\n",
            "Epoch 667/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4238 - accuracy: 0.8478 - val_loss: 0.7621 - val_accuracy: 0.6728\n",
            "Epoch 668/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4211 - accuracy: 0.8478 - val_loss: 0.7331 - val_accuracy: 0.6912\n",
            "Epoch 669/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4180 - accuracy: 0.8465 - val_loss: 0.7095 - val_accuracy: 0.7132\n",
            "Epoch 670/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4213 - accuracy: 0.8453 - val_loss: 0.7275 - val_accuracy: 0.7206\n",
            "Epoch 671/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4066 - accuracy: 0.8626 - val_loss: 0.7018 - val_accuracy: 0.7206\n",
            "Epoch 672/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4186 - accuracy: 0.8434 - val_loss: 0.7610 - val_accuracy: 0.6801\n",
            "Epoch 673/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4175 - accuracy: 0.8410 - val_loss: 0.7387 - val_accuracy: 0.6985\n",
            "Epoch 674/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4213 - accuracy: 0.8502 - val_loss: 0.7874 - val_accuracy: 0.6581\n",
            "Epoch 675/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4147 - accuracy: 0.8434 - val_loss: 0.6986 - val_accuracy: 0.7316\n",
            "Epoch 676/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4083 - accuracy: 0.8403 - val_loss: 0.7244 - val_accuracy: 0.7096\n",
            "Epoch 677/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4199 - accuracy: 0.8434 - val_loss: 0.7301 - val_accuracy: 0.7316\n",
            "Epoch 678/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4184 - accuracy: 0.8416 - val_loss: 0.7379 - val_accuracy: 0.7243\n",
            "Epoch 679/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4283 - accuracy: 0.8416 - val_loss: 0.7337 - val_accuracy: 0.7169\n",
            "Epoch 680/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4320 - accuracy: 0.8496 - val_loss: 0.6765 - val_accuracy: 0.7059\n",
            "Epoch 681/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4316 - accuracy: 0.8546 - val_loss: 0.7080 - val_accuracy: 0.7206\n",
            "Epoch 682/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4382 - accuracy: 0.8484 - val_loss: 0.7206 - val_accuracy: 0.7096\n",
            "Epoch 683/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4165 - accuracy: 0.8533 - val_loss: 0.7474 - val_accuracy: 0.7132\n",
            "Epoch 684/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4169 - accuracy: 0.8521 - val_loss: 0.7017 - val_accuracy: 0.7279\n",
            "Epoch 685/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4278 - accuracy: 0.8447 - val_loss: 0.6944 - val_accuracy: 0.7206\n",
            "Epoch 686/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4188 - accuracy: 0.8459 - val_loss: 0.7010 - val_accuracy: 0.7279\n",
            "Epoch 687/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4080 - accuracy: 0.8564 - val_loss: 0.7242 - val_accuracy: 0.7243\n",
            "Epoch 688/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4128 - accuracy: 0.8502 - val_loss: 0.7510 - val_accuracy: 0.6912\n",
            "Epoch 689/700\n",
            "202/202 [==============================] - 6s 30ms/step - loss: 0.4198 - accuracy: 0.8540 - val_loss: 0.7119 - val_accuracy: 0.7206\n",
            "Epoch 690/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4114 - accuracy: 0.8502 - val_loss: 0.7153 - val_accuracy: 0.7279\n",
            "Epoch 691/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4176 - accuracy: 0.8410 - val_loss: 0.7331 - val_accuracy: 0.7132\n",
            "Epoch 692/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4063 - accuracy: 0.8527 - val_loss: 0.7037 - val_accuracy: 0.7279\n",
            "Epoch 693/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4175 - accuracy: 0.8527 - val_loss: 0.7338 - val_accuracy: 0.7169\n",
            "Epoch 694/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4260 - accuracy: 0.8453 - val_loss: 0.7488 - val_accuracy: 0.6838\n",
            "Epoch 695/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4324 - accuracy: 0.8465 - val_loss: 0.7189 - val_accuracy: 0.7132\n",
            "Epoch 696/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4333 - accuracy: 0.8403 - val_loss: 0.7200 - val_accuracy: 0.7096\n",
            "Epoch 697/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4193 - accuracy: 0.8490 - val_loss: 0.7714 - val_accuracy: 0.6875\n",
            "Epoch 698/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4230 - accuracy: 0.8453 - val_loss: 0.7190 - val_accuracy: 0.7243\n",
            "Epoch 699/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4214 - accuracy: 0.8527 - val_loss: 0.7041 - val_accuracy: 0.7169\n",
            "Epoch 700/700\n",
            "202/202 [==============================] - 6s 31ms/step - loss: 0.4350 - accuracy: 0.8373 - val_loss: 0.7266 - val_accuracy: 0.7169\n"
          ]
        }
      ],
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'accuracy',\n",
        "                                                        patience = 20,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer= keras.optimizers.Adam(0.001, decay=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "# Start training the model.\n",
        "cnn_3d_model_training_history = model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=700,\n",
        "                                          batch_size=8,\n",
        "                                          shuffle = True,\n",
        "                                          validation_data = (features_valid, labels_valid))\n",
        "                                          # callbacks = [early_stopping_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vimsgjjbXvL",
        "outputId": "fce0ae40-c4ab-4bc4-90df-ca7128781de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 43ms/step - loss: 1.1498 - accuracy: 0.6029\n",
            "\n",
            "\n",
            "Train accuracy: 77.661 % || Test accuracy: 60.294 % || Val accuracy: 71.691 %\n",
            "Train loss: 0.593 || Test loss: 1.150 || Val loss: 0.727\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ivmaK9BlbnRQ"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'3D_CNN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p cnn_3d_{current_date_time_string}\n",
        "# Save your Model.\n",
        "model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwU8TwPrbsKB"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cvKY05ncbwof",
        "outputId": "9c791ae9-1536-448d-9baf-c3452db09d67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "o1iaaDHBb5i0",
        "outputId": "e7862146-46e4-4589-ea5f-c51fa81f45b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3D_CNN.ipynb",
      "provenance": [],
      "background_execution": "on",
      "authorship_tag": "ABX9TyMPxA0bQ/RE4WR09T+/Njdm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}