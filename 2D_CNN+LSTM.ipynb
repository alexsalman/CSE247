{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/2D_CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8TLrPiv-ab"
      },
      "source": [
        "####**Convolutional Neural Network + Long Short Term Memory**\n",
        "######*I am using a Convolution Neural Network (CNN) + Long Short Term Memory (LSTM) Network to extract general representation while utilizing the Spatial-temporal aspect of the videos.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8ibtd5HKtZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201b9ddd-0d54-4374-b13a-299ce9377df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import TimeDistributed, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "663c0136-8c0a-4f93-dfcb-45488445f26f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3mFB5qD6b3Kd"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sqeexMUjaLzJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(128, 128)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "6c756641-b4b8-4b21-ad5d-f9e64cbea5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bi-NDol3DHRV"
      },
      "outputs": [],
      "source": [
        "def create_convlstm_model():\n",
        "    # TimeDistributed is a wrapper to handle input of size five to maintain frames number for LSTM\n",
        "    # A Conv2D layer requires four dimensions: (batch_size, height, width, channels)\n",
        "    # TimeDistributed will require an additional dimension: (batch_size, frames, height, width, channels)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(8, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4)),\n",
        "                              input_shape=(16, 128, 128, 3)))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(12, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(16, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(24, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.2))\n",
        "  \n",
        "    model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(LSTM(4, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(4, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "    model.summary(line_length = 100)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FbjNYI-0DY_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887860b2-beac-4817-cb33-492bcb8ad1f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "____________________________________________________________________________________________________\n",
            " Layer (type)                                Output Shape                            Param #        \n",
            "====================================================================================================\n",
            " time_distributed (TimeDistributed)          (None, 16, 126, 126, 8)                 224            \n",
            "                                                                                                    \n",
            " time_distributed_1 (TimeDistributed)        (None, 16, 63, 63, 8)                   0              \n",
            "                                                                                                    \n",
            " dropout (Dropout)                           (None, 16, 63, 63, 8)                   0              \n",
            "                                                                                                    \n",
            " time_distributed_2 (TimeDistributed)        (None, 16, 61, 61, 12)                  876            \n",
            "                                                                                                    \n",
            " time_distributed_3 (TimeDistributed)        (None, 16, 30, 30, 12)                  0              \n",
            "                                                                                                    \n",
            " dropout_1 (Dropout)                         (None, 16, 30, 30, 12)                  0              \n",
            "                                                                                                    \n",
            " time_distributed_4 (TimeDistributed)        (None, 16, 28, 28, 16)                  1744           \n",
            "                                                                                                    \n",
            " time_distributed_5 (TimeDistributed)        (None, 16, 14, 14, 16)                  0              \n",
            "                                                                                                    \n",
            " dropout_2 (Dropout)                         (None, 16, 14, 14, 16)                  0              \n",
            "                                                                                                    \n",
            " time_distributed_6 (TimeDistributed)        (None, 16, 12, 12, 24)                  3480           \n",
            "                                                                                                    \n",
            " time_distributed_7 (TimeDistributed)        (None, 16, 6, 6, 24)                    0              \n",
            "                                                                                                    \n",
            " dropout_3 (Dropout)                         (None, 16, 6, 6, 24)                    0              \n",
            "                                                                                                    \n",
            " time_distributed_8 (TimeDistributed)        (None, 16, 4, 4, 32)                    6944           \n",
            "                                                                                                    \n",
            " time_distributed_9 (TimeDistributed)        (None, 16, 2, 2, 32)                    0              \n",
            "                                                                                                    \n",
            " dropout_4 (Dropout)                         (None, 16, 2, 2, 32)                    0              \n",
            "                                                                                                    \n",
            " time_distributed_10 (TimeDistributed)       (None, 16, 32)                          0              \n",
            "                                                                                                    \n",
            " dropout_5 (Dropout)                         (None, 16, 32)                          0              \n",
            "                                                                                                    \n",
            " lstm (LSTM)                                 (None, 4)                               592            \n",
            "                                                                                                    \n",
            " dropout_6 (Dropout)                         (None, 4)                               0              \n",
            "                                                                                                    \n",
            " dense (Dense)                               (None, 16)                              80             \n",
            "                                                                                                    \n",
            " dropout_7 (Dropout)                         (None, 16)                              0              \n",
            "                                                                                                    \n",
            " dense_1 (Dense)                             (None, 4)                               68             \n",
            "                                                                                                    \n",
            " dense_2 (Dense)                             (None, 4)                               20             \n",
            "                                                                                                    \n",
            "====================================================================================================\n",
            "Total params: 14,028\n",
            "Trainable params: 14,028\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "convlstm_model = create_convlstm_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SCB3R7so-wHz"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nMYwQOwyF3bd"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(convlstm_model,\n",
        "#                          to_file = 'convlstm_model_structure_plot.png',\n",
        "#                          show_shapes = True,\n",
        "#                          show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYC_6H0uGqW9",
        "outputId": "84261449-9598-4be6-debb-ba3e8656604d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "30/30 [==============================] - 21s 195ms/step - loss: 1.3080 - accuracy: 0.3787 - val_loss: 1.3604 - val_accuracy: 0.3566\n",
            "Epoch 2/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.3156 - accuracy: 0.3800 - val_loss: 1.3681 - val_accuracy: 0.3566\n",
            "Epoch 3/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 1.3026 - accuracy: 0.3793 - val_loss: 1.3564 - val_accuracy: 0.3566\n",
            "Epoch 4/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.2848 - accuracy: 0.3793 - val_loss: 1.3417 - val_accuracy: 0.3566\n",
            "Epoch 5/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.2971 - accuracy: 0.3812 - val_loss: 1.3437 - val_accuracy: 0.3566\n",
            "Epoch 6/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.2802 - accuracy: 0.3824 - val_loss: 1.3280 - val_accuracy: 0.3566\n",
            "Epoch 7/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.2746 - accuracy: 0.3806 - val_loss: 1.3214 - val_accuracy: 0.3566\n",
            "Epoch 8/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.2706 - accuracy: 0.3855 - val_loss: 1.3202 - val_accuracy: 0.3566\n",
            "Epoch 9/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 1.2700 - accuracy: 0.3849 - val_loss: 1.3110 - val_accuracy: 0.3566\n",
            "Epoch 10/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 1.2574 - accuracy: 0.3886 - val_loss: 1.3058 - val_accuracy: 0.3566\n",
            "Epoch 11/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.2499 - accuracy: 0.3843 - val_loss: 1.2879 - val_accuracy: 0.3566\n",
            "Epoch 12/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.2503 - accuracy: 0.3886 - val_loss: 1.2863 - val_accuracy: 0.3566\n",
            "Epoch 13/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 1.2304 - accuracy: 0.3843 - val_loss: 1.2517 - val_accuracy: 0.3566\n",
            "Epoch 14/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.2344 - accuracy: 0.3911 - val_loss: 1.2330 - val_accuracy: 0.3566\n",
            "Epoch 15/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.2087 - accuracy: 0.3880 - val_loss: 1.2191 - val_accuracy: 0.3640\n",
            "Epoch 16/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 1.2150 - accuracy: 0.4004 - val_loss: 1.2102 - val_accuracy: 0.3713\n",
            "Epoch 17/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.2071 - accuracy: 0.4097 - val_loss: 1.1948 - val_accuracy: 0.3824\n",
            "Epoch 18/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.1863 - accuracy: 0.4053 - val_loss: 1.1874 - val_accuracy: 0.3860\n",
            "Epoch 19/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 1.1875 - accuracy: 0.4022 - val_loss: 1.1825 - val_accuracy: 0.4154\n",
            "Epoch 20/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.1793 - accuracy: 0.4016 - val_loss: 1.1696 - val_accuracy: 0.4191\n",
            "Epoch 21/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.1745 - accuracy: 0.4276 - val_loss: 1.1650 - val_accuracy: 0.4449\n",
            "Epoch 22/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.1778 - accuracy: 0.4369 - val_loss: 1.1495 - val_accuracy: 0.4301\n",
            "Epoch 23/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.1499 - accuracy: 0.4319 - val_loss: 1.1486 - val_accuracy: 0.4706\n",
            "Epoch 24/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.1589 - accuracy: 0.4363 - val_loss: 1.1402 - val_accuracy: 0.4632\n",
            "Epoch 25/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.1473 - accuracy: 0.4307 - val_loss: 1.1370 - val_accuracy: 0.4779\n",
            "Epoch 26/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.1254 - accuracy: 0.4592 - val_loss: 1.1183 - val_accuracy: 0.4853\n",
            "Epoch 27/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.1251 - accuracy: 0.4548 - val_loss: 1.1052 - val_accuracy: 0.5074\n",
            "Epoch 28/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.1144 - accuracy: 0.4616 - val_loss: 1.0924 - val_accuracy: 0.4890\n",
            "Epoch 29/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.1189 - accuracy: 0.4864 - val_loss: 1.0986 - val_accuracy: 0.5110\n",
            "Epoch 30/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.1118 - accuracy: 0.4610 - val_loss: 1.0871 - val_accuracy: 0.5441\n",
            "Epoch 31/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.1028 - accuracy: 0.4895 - val_loss: 1.0684 - val_accuracy: 0.5257\n",
            "Epoch 32/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 1.1111 - accuracy: 0.4746 - val_loss: 1.0847 - val_accuracy: 0.6397\n",
            "Epoch 33/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.0879 - accuracy: 0.4963 - val_loss: 1.0764 - val_accuracy: 0.6397\n",
            "Epoch 34/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 1.0846 - accuracy: 0.4796 - val_loss: 1.0605 - val_accuracy: 0.6176\n",
            "Epoch 35/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0825 - accuracy: 0.4981 - val_loss: 1.0686 - val_accuracy: 0.6324\n",
            "Epoch 36/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0882 - accuracy: 0.5050 - val_loss: 1.0460 - val_accuracy: 0.6434\n",
            "Epoch 37/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0792 - accuracy: 0.4981 - val_loss: 1.0482 - val_accuracy: 0.6507\n",
            "Epoch 38/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0864 - accuracy: 0.5149 - val_loss: 1.0639 - val_accuracy: 0.6618\n",
            "Epoch 39/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 1.0558 - accuracy: 0.5074 - val_loss: 1.0491 - val_accuracy: 0.6581\n",
            "Epoch 40/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 1.0494 - accuracy: 0.5235 - val_loss: 1.0185 - val_accuracy: 0.6691\n",
            "Epoch 41/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.0354 - accuracy: 0.5179 - val_loss: 1.0031 - val_accuracy: 0.6728\n",
            "Epoch 42/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0518 - accuracy: 0.5285 - val_loss: 1.0233 - val_accuracy: 0.6949\n",
            "Epoch 43/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.0379 - accuracy: 0.5328 - val_loss: 1.0138 - val_accuracy: 0.6912\n",
            "Epoch 44/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.0424 - accuracy: 0.5433 - val_loss: 1.0109 - val_accuracy: 0.6912\n",
            "Epoch 45/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 1.0286 - accuracy: 0.5514 - val_loss: 1.0166 - val_accuracy: 0.6985\n",
            "Epoch 46/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0321 - accuracy: 0.5365 - val_loss: 1.0087 - val_accuracy: 0.6985\n",
            "Epoch 47/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 1.0150 - accuracy: 0.5439 - val_loss: 0.9900 - val_accuracy: 0.6949\n",
            "Epoch 48/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.0089 - accuracy: 0.5650 - val_loss: 0.9828 - val_accuracy: 0.6985\n",
            "Epoch 49/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 1.0079 - accuracy: 0.5495 - val_loss: 0.9652 - val_accuracy: 0.7132\n",
            "Epoch 50/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.9972 - accuracy: 0.5804 - val_loss: 0.9579 - val_accuracy: 0.7316\n",
            "Epoch 51/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 1.0032 - accuracy: 0.5786 - val_loss: 0.9581 - val_accuracy: 0.7059\n",
            "Epoch 52/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 1.0000 - accuracy: 0.5631 - val_loss: 0.9572 - val_accuracy: 0.7096\n",
            "Epoch 53/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9901 - accuracy: 0.5644 - val_loss: 0.9613 - val_accuracy: 0.7169\n",
            "Epoch 54/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.9875 - accuracy: 0.5860 - val_loss: 0.9516 - val_accuracy: 0.7132\n",
            "Epoch 55/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9888 - accuracy: 0.5718 - val_loss: 0.9411 - val_accuracy: 0.7132\n",
            "Epoch 56/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.9793 - accuracy: 0.5780 - val_loss: 0.9496 - val_accuracy: 0.7353\n",
            "Epoch 57/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.9730 - accuracy: 0.5916 - val_loss: 0.9271 - val_accuracy: 0.7169\n",
            "Epoch 58/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9801 - accuracy: 0.5885 - val_loss: 0.9340 - val_accuracy: 0.7169\n",
            "Epoch 59/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9836 - accuracy: 0.5928 - val_loss: 0.9335 - val_accuracy: 0.7500\n",
            "Epoch 60/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9761 - accuracy: 0.5761 - val_loss: 0.9309 - val_accuracy: 0.7426\n",
            "Epoch 61/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.9550 - accuracy: 0.5996 - val_loss: 0.9323 - val_accuracy: 0.7390\n",
            "Epoch 62/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.9540 - accuracy: 0.5984 - val_loss: 0.9295 - val_accuracy: 0.7721\n",
            "Epoch 63/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.9629 - accuracy: 0.5891 - val_loss: 0.9239 - val_accuracy: 0.7831\n",
            "Epoch 64/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.9551 - accuracy: 0.6120 - val_loss: 0.9167 - val_accuracy: 0.7831\n",
            "Epoch 65/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.9464 - accuracy: 0.5972 - val_loss: 0.9021 - val_accuracy: 0.7721\n",
            "Epoch 66/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9423 - accuracy: 0.5953 - val_loss: 0.9247 - val_accuracy: 0.7757\n",
            "Epoch 67/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.9425 - accuracy: 0.5996 - val_loss: 0.9228 - val_accuracy: 0.7757\n",
            "Epoch 68/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9306 - accuracy: 0.5959 - val_loss: 0.9170 - val_accuracy: 0.7757\n",
            "Epoch 69/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9457 - accuracy: 0.6157 - val_loss: 0.9394 - val_accuracy: 0.7463\n",
            "Epoch 70/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9239 - accuracy: 0.6071 - val_loss: 0.9300 - val_accuracy: 0.7463\n",
            "Epoch 71/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.9270 - accuracy: 0.6126 - val_loss: 0.9529 - val_accuracy: 0.7463\n",
            "Epoch 72/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9256 - accuracy: 0.6200 - val_loss: 0.9092 - val_accuracy: 0.7647\n",
            "Epoch 73/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9231 - accuracy: 0.6163 - val_loss: 0.8920 - val_accuracy: 0.7831\n",
            "Epoch 74/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9297 - accuracy: 0.6101 - val_loss: 0.9082 - val_accuracy: 0.7794\n",
            "Epoch 75/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8959 - accuracy: 0.6188 - val_loss: 0.8851 - val_accuracy: 0.7831\n",
            "Epoch 76/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9016 - accuracy: 0.6262 - val_loss: 0.9126 - val_accuracy: 0.7463\n",
            "Epoch 77/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.9045 - accuracy: 0.6312 - val_loss: 0.8745 - val_accuracy: 0.7868\n",
            "Epoch 78/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8948 - accuracy: 0.6256 - val_loss: 0.8714 - val_accuracy: 0.7868\n",
            "Epoch 79/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.9084 - accuracy: 0.6262 - val_loss: 0.8811 - val_accuracy: 0.7794\n",
            "Epoch 80/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.9085 - accuracy: 0.6300 - val_loss: 0.8961 - val_accuracy: 0.7463\n",
            "Epoch 81/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8939 - accuracy: 0.6423 - val_loss: 0.8667 - val_accuracy: 0.7868\n",
            "Epoch 82/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8780 - accuracy: 0.6343 - val_loss: 0.8825 - val_accuracy: 0.7757\n",
            "Epoch 83/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8826 - accuracy: 0.6473 - val_loss: 0.8691 - val_accuracy: 0.7794\n",
            "Epoch 84/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.9036 - accuracy: 0.6231 - val_loss: 0.8779 - val_accuracy: 0.7757\n",
            "Epoch 85/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8814 - accuracy: 0.6318 - val_loss: 0.8757 - val_accuracy: 0.7757\n",
            "Epoch 86/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8795 - accuracy: 0.6386 - val_loss: 0.8823 - val_accuracy: 0.7684\n",
            "Epoch 87/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8776 - accuracy: 0.6547 - val_loss: 0.8775 - val_accuracy: 0.7463\n",
            "Epoch 88/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8722 - accuracy: 0.6429 - val_loss: 0.8694 - val_accuracy: 0.7757\n",
            "Epoch 89/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8766 - accuracy: 0.6460 - val_loss: 0.8877 - val_accuracy: 0.7463\n",
            "Epoch 90/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8746 - accuracy: 0.6467 - val_loss: 0.8826 - val_accuracy: 0.7463\n",
            "Epoch 91/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8754 - accuracy: 0.6460 - val_loss: 0.8717 - val_accuracy: 0.7684\n",
            "Epoch 92/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8758 - accuracy: 0.6380 - val_loss: 0.8753 - val_accuracy: 0.7463\n",
            "Epoch 93/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.8537 - accuracy: 0.6485 - val_loss: 0.8690 - val_accuracy: 0.7463\n",
            "Epoch 94/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8544 - accuracy: 0.6547 - val_loss: 0.8657 - val_accuracy: 0.7463\n",
            "Epoch 95/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8573 - accuracy: 0.6473 - val_loss: 0.8403 - val_accuracy: 0.7831\n",
            "Epoch 96/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8677 - accuracy: 0.6467 - val_loss: 0.8421 - val_accuracy: 0.7831\n",
            "Epoch 97/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8566 - accuracy: 0.6553 - val_loss: 0.8761 - val_accuracy: 0.7463\n",
            "Epoch 98/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8715 - accuracy: 0.6504 - val_loss: 0.8656 - val_accuracy: 0.7463\n",
            "Epoch 99/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8500 - accuracy: 0.6516 - val_loss: 0.8652 - val_accuracy: 0.7463\n",
            "Epoch 100/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8523 - accuracy: 0.6584 - val_loss: 0.8457 - val_accuracy: 0.7684\n",
            "Epoch 101/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8512 - accuracy: 0.6535 - val_loss: 0.8543 - val_accuracy: 0.7463\n",
            "Epoch 102/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8483 - accuracy: 0.6541 - val_loss: 0.8553 - val_accuracy: 0.7463\n",
            "Epoch 103/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8524 - accuracy: 0.6399 - val_loss: 0.8535 - val_accuracy: 0.7463\n",
            "Epoch 104/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8458 - accuracy: 0.6467 - val_loss: 0.8637 - val_accuracy: 0.7463\n",
            "Epoch 105/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8549 - accuracy: 0.6510 - val_loss: 0.8552 - val_accuracy: 0.7463\n",
            "Epoch 106/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8348 - accuracy: 0.6553 - val_loss: 0.8313 - val_accuracy: 0.7794\n",
            "Epoch 107/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8427 - accuracy: 0.6485 - val_loss: 0.8353 - val_accuracy: 0.7757\n",
            "Epoch 108/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.8360 - accuracy: 0.6559 - val_loss: 0.8391 - val_accuracy: 0.7463\n",
            "Epoch 109/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.8358 - accuracy: 0.6535 - val_loss: 0.8298 - val_accuracy: 0.7794\n",
            "Epoch 110/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8371 - accuracy: 0.6603 - val_loss: 0.8478 - val_accuracy: 0.7463\n",
            "Epoch 111/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8339 - accuracy: 0.6504 - val_loss: 0.8256 - val_accuracy: 0.7684\n",
            "Epoch 112/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8320 - accuracy: 0.6627 - val_loss: 0.8207 - val_accuracy: 0.7794\n",
            "Epoch 113/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8266 - accuracy: 0.6485 - val_loss: 0.8320 - val_accuracy: 0.7463\n",
            "Epoch 114/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8204 - accuracy: 0.6541 - val_loss: 0.8314 - val_accuracy: 0.7463\n",
            "Epoch 115/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8370 - accuracy: 0.6528 - val_loss: 0.8247 - val_accuracy: 0.7647\n",
            "Epoch 116/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8165 - accuracy: 0.6640 - val_loss: 0.8311 - val_accuracy: 0.7463\n",
            "Epoch 117/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8254 - accuracy: 0.6590 - val_loss: 0.8320 - val_accuracy: 0.7463\n",
            "Epoch 118/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8366 - accuracy: 0.6448 - val_loss: 0.8162 - val_accuracy: 0.7757\n",
            "Epoch 119/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8205 - accuracy: 0.6559 - val_loss: 0.8216 - val_accuracy: 0.7574\n",
            "Epoch 120/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8213 - accuracy: 0.6566 - val_loss: 0.8262 - val_accuracy: 0.7463\n",
            "Epoch 121/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8126 - accuracy: 0.6584 - val_loss: 0.8288 - val_accuracy: 0.7463\n",
            "Epoch 122/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.8044 - accuracy: 0.6683 - val_loss: 0.8183 - val_accuracy: 0.7721\n",
            "Epoch 123/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.8091 - accuracy: 0.6658 - val_loss: 0.8134 - val_accuracy: 0.7757\n",
            "Epoch 124/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8261 - accuracy: 0.6658 - val_loss: 0.7993 - val_accuracy: 0.7868\n",
            "Epoch 125/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8053 - accuracy: 0.6733 - val_loss: 0.7922 - val_accuracy: 0.7868\n",
            "Epoch 126/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8319 - accuracy: 0.6516 - val_loss: 0.8154 - val_accuracy: 0.7647\n",
            "Epoch 127/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8059 - accuracy: 0.6720 - val_loss: 0.8283 - val_accuracy: 0.7463\n",
            "Epoch 128/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8165 - accuracy: 0.6597 - val_loss: 0.8125 - val_accuracy: 0.7610\n",
            "Epoch 129/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8200 - accuracy: 0.6609 - val_loss: 0.8023 - val_accuracy: 0.7757\n",
            "Epoch 130/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8083 - accuracy: 0.6714 - val_loss: 0.8000 - val_accuracy: 0.7794\n",
            "Epoch 131/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7952 - accuracy: 0.6714 - val_loss: 0.8122 - val_accuracy: 0.7463\n",
            "Epoch 132/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8151 - accuracy: 0.6597 - val_loss: 0.8079 - val_accuracy: 0.7463\n",
            "Epoch 133/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8039 - accuracy: 0.6621 - val_loss: 0.8050 - val_accuracy: 0.7647\n",
            "Epoch 134/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.8000 - accuracy: 0.6652 - val_loss: 0.8068 - val_accuracy: 0.7537\n",
            "Epoch 135/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8031 - accuracy: 0.6714 - val_loss: 0.8036 - val_accuracy: 0.7721\n",
            "Epoch 136/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.8057 - accuracy: 0.6510 - val_loss: 0.8127 - val_accuracy: 0.7463\n",
            "Epoch 137/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7951 - accuracy: 0.6714 - val_loss: 0.7925 - val_accuracy: 0.7831\n",
            "Epoch 138/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7894 - accuracy: 0.6733 - val_loss: 0.7861 - val_accuracy: 0.7831\n",
            "Epoch 139/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7896 - accuracy: 0.6782 - val_loss: 0.7832 - val_accuracy: 0.7831\n",
            "Epoch 140/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7934 - accuracy: 0.6652 - val_loss: 0.7868 - val_accuracy: 0.7831\n",
            "Epoch 141/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7996 - accuracy: 0.6696 - val_loss: 0.7921 - val_accuracy: 0.7794\n",
            "Epoch 142/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.7908 - accuracy: 0.6733 - val_loss: 0.7826 - val_accuracy: 0.7794\n",
            "Epoch 143/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7972 - accuracy: 0.6634 - val_loss: 0.7996 - val_accuracy: 0.7647\n",
            "Epoch 144/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.8039 - accuracy: 0.6696 - val_loss: 0.7998 - val_accuracy: 0.7500\n",
            "Epoch 145/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7974 - accuracy: 0.6708 - val_loss: 0.7972 - val_accuracy: 0.7684\n",
            "Epoch 146/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7942 - accuracy: 0.6621 - val_loss: 0.7998 - val_accuracy: 0.7574\n",
            "Epoch 147/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7868 - accuracy: 0.6757 - val_loss: 0.7999 - val_accuracy: 0.7610\n",
            "Epoch 148/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7767 - accuracy: 0.6813 - val_loss: 0.7932 - val_accuracy: 0.7684\n",
            "Epoch 149/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7857 - accuracy: 0.6609 - val_loss: 0.7949 - val_accuracy: 0.7463\n",
            "Epoch 150/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7803 - accuracy: 0.6733 - val_loss: 0.7934 - val_accuracy: 0.7463\n",
            "Epoch 151/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7957 - accuracy: 0.6696 - val_loss: 0.8093 - val_accuracy: 0.7463\n",
            "Epoch 152/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7859 - accuracy: 0.6708 - val_loss: 0.7930 - val_accuracy: 0.7463\n",
            "Epoch 153/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7948 - accuracy: 0.6677 - val_loss: 0.7986 - val_accuracy: 0.7463\n",
            "Epoch 154/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7905 - accuracy: 0.6640 - val_loss: 0.8068 - val_accuracy: 0.7463\n",
            "Epoch 155/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7777 - accuracy: 0.6745 - val_loss: 0.7924 - val_accuracy: 0.7463\n",
            "Epoch 156/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.7825 - accuracy: 0.6757 - val_loss: 0.7718 - val_accuracy: 0.7831\n",
            "Epoch 157/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7749 - accuracy: 0.6726 - val_loss: 0.7785 - val_accuracy: 0.7794\n",
            "Epoch 158/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7667 - accuracy: 0.6733 - val_loss: 0.7775 - val_accuracy: 0.7684\n",
            "Epoch 159/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7742 - accuracy: 0.6634 - val_loss: 0.7787 - val_accuracy: 0.7610\n",
            "Epoch 160/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7731 - accuracy: 0.6819 - val_loss: 0.7807 - val_accuracy: 0.7574\n",
            "Epoch 161/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7822 - accuracy: 0.6702 - val_loss: 0.7675 - val_accuracy: 0.7794\n",
            "Epoch 162/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7868 - accuracy: 0.6640 - val_loss: 0.7715 - val_accuracy: 0.7684\n",
            "Epoch 163/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7619 - accuracy: 0.6751 - val_loss: 0.7653 - val_accuracy: 0.7831\n",
            "Epoch 164/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7635 - accuracy: 0.6782 - val_loss: 0.7672 - val_accuracy: 0.7831\n",
            "Epoch 165/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7570 - accuracy: 0.6819 - val_loss: 0.7746 - val_accuracy: 0.7684\n",
            "Epoch 166/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7584 - accuracy: 0.6788 - val_loss: 0.7592 - val_accuracy: 0.7831\n",
            "Epoch 167/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7677 - accuracy: 0.6801 - val_loss: 0.7588 - val_accuracy: 0.7794\n",
            "Epoch 168/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7574 - accuracy: 0.6838 - val_loss: 0.7712 - val_accuracy: 0.7684\n",
            "Epoch 169/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7766 - accuracy: 0.6665 - val_loss: 0.7708 - val_accuracy: 0.7794\n",
            "Epoch 170/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7627 - accuracy: 0.6770 - val_loss: 0.7725 - val_accuracy: 0.7757\n",
            "Epoch 171/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7621 - accuracy: 0.6825 - val_loss: 0.7678 - val_accuracy: 0.7794\n",
            "Epoch 172/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7700 - accuracy: 0.6757 - val_loss: 0.7703 - val_accuracy: 0.7794\n",
            "Epoch 173/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7698 - accuracy: 0.6652 - val_loss: 0.7724 - val_accuracy: 0.7757\n",
            "Epoch 174/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7636 - accuracy: 0.6751 - val_loss: 0.7493 - val_accuracy: 0.7868\n",
            "Epoch 175/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7548 - accuracy: 0.6838 - val_loss: 0.7546 - val_accuracy: 0.7868\n",
            "Epoch 176/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7516 - accuracy: 0.6813 - val_loss: 0.7631 - val_accuracy: 0.7831\n",
            "Epoch 177/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7614 - accuracy: 0.6813 - val_loss: 0.7448 - val_accuracy: 0.7868\n",
            "Epoch 178/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7555 - accuracy: 0.6776 - val_loss: 0.7674 - val_accuracy: 0.7537\n",
            "Epoch 179/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7653 - accuracy: 0.6696 - val_loss: 0.7522 - val_accuracy: 0.7868\n",
            "Epoch 180/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7660 - accuracy: 0.6683 - val_loss: 0.7688 - val_accuracy: 0.7684\n",
            "Epoch 181/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7540 - accuracy: 0.6795 - val_loss: 0.7428 - val_accuracy: 0.7868\n",
            "Epoch 182/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7553 - accuracy: 0.6745 - val_loss: 0.7474 - val_accuracy: 0.7868\n",
            "Epoch 183/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7442 - accuracy: 0.6844 - val_loss: 0.7541 - val_accuracy: 0.7757\n",
            "Epoch 184/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7544 - accuracy: 0.6708 - val_loss: 0.7479 - val_accuracy: 0.7831\n",
            "Epoch 185/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7527 - accuracy: 0.6788 - val_loss: 0.7675 - val_accuracy: 0.7463\n",
            "Epoch 186/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7527 - accuracy: 0.6751 - val_loss: 0.7437 - val_accuracy: 0.7794\n",
            "Epoch 187/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7554 - accuracy: 0.6801 - val_loss: 0.7442 - val_accuracy: 0.7831\n",
            "Epoch 188/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7476 - accuracy: 0.6869 - val_loss: 0.7511 - val_accuracy: 0.7757\n",
            "Epoch 189/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7508 - accuracy: 0.6813 - val_loss: 0.7539 - val_accuracy: 0.7684\n",
            "Epoch 190/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7753 - accuracy: 0.6807 - val_loss: 0.7651 - val_accuracy: 0.7463\n",
            "Epoch 191/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7395 - accuracy: 0.6739 - val_loss: 0.7465 - val_accuracy: 0.7757\n",
            "Epoch 192/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7440 - accuracy: 0.6844 - val_loss: 0.7337 - val_accuracy: 0.7868\n",
            "Epoch 193/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7368 - accuracy: 0.6900 - val_loss: 0.7375 - val_accuracy: 0.7794\n",
            "Epoch 194/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7363 - accuracy: 0.6751 - val_loss: 0.7407 - val_accuracy: 0.7757\n",
            "Epoch 195/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7633 - accuracy: 0.6745 - val_loss: 0.7405 - val_accuracy: 0.7831\n",
            "Epoch 196/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7300 - accuracy: 0.6832 - val_loss: 0.7344 - val_accuracy: 0.7868\n",
            "Epoch 197/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7431 - accuracy: 0.6887 - val_loss: 0.7287 - val_accuracy: 0.7868\n",
            "Epoch 198/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7356 - accuracy: 0.6801 - val_loss: 0.7303 - val_accuracy: 0.7868\n",
            "Epoch 199/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7682 - accuracy: 0.6683 - val_loss: 0.7567 - val_accuracy: 0.7463\n",
            "Epoch 200/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7457 - accuracy: 0.6856 - val_loss: 0.7548 - val_accuracy: 0.7684\n",
            "Epoch 201/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7310 - accuracy: 0.6925 - val_loss: 0.7398 - val_accuracy: 0.7831\n",
            "Epoch 202/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7349 - accuracy: 0.6850 - val_loss: 0.7540 - val_accuracy: 0.7574\n",
            "Epoch 203/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7383 - accuracy: 0.6819 - val_loss: 0.7383 - val_accuracy: 0.7831\n",
            "Epoch 204/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7455 - accuracy: 0.6764 - val_loss: 0.7310 - val_accuracy: 0.7831\n",
            "Epoch 205/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7427 - accuracy: 0.6825 - val_loss: 0.7428 - val_accuracy: 0.7794\n",
            "Epoch 206/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7392 - accuracy: 0.6887 - val_loss: 0.7457 - val_accuracy: 0.7757\n",
            "Epoch 207/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7430 - accuracy: 0.6770 - val_loss: 0.7324 - val_accuracy: 0.7831\n",
            "Epoch 208/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7334 - accuracy: 0.6807 - val_loss: 0.7231 - val_accuracy: 0.7868\n",
            "Epoch 209/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7342 - accuracy: 0.6813 - val_loss: 0.7390 - val_accuracy: 0.7831\n",
            "Epoch 210/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7240 - accuracy: 0.6881 - val_loss: 0.7248 - val_accuracy: 0.7868\n",
            "Epoch 211/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7378 - accuracy: 0.6788 - val_loss: 0.7254 - val_accuracy: 0.7868\n",
            "Epoch 212/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7254 - accuracy: 0.6863 - val_loss: 0.7242 - val_accuracy: 0.7868\n",
            "Epoch 213/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7351 - accuracy: 0.6813 - val_loss: 0.7225 - val_accuracy: 0.7868\n",
            "Epoch 214/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7315 - accuracy: 0.6832 - val_loss: 0.7367 - val_accuracy: 0.7831\n",
            "Epoch 215/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7315 - accuracy: 0.6894 - val_loss: 0.7338 - val_accuracy: 0.7794\n",
            "Epoch 216/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7375 - accuracy: 0.6757 - val_loss: 0.7260 - val_accuracy: 0.7831\n",
            "Epoch 217/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7327 - accuracy: 0.6918 - val_loss: 0.7183 - val_accuracy: 0.7868\n",
            "Epoch 218/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7310 - accuracy: 0.6875 - val_loss: 0.7340 - val_accuracy: 0.7794\n",
            "Epoch 219/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7194 - accuracy: 0.6875 - val_loss: 0.7189 - val_accuracy: 0.7831\n",
            "Epoch 220/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.7185 - accuracy: 0.6863 - val_loss: 0.7068 - val_accuracy: 0.7904\n",
            "Epoch 221/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7429 - accuracy: 0.6788 - val_loss: 0.7035 - val_accuracy: 0.7904\n",
            "Epoch 222/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.7165 - accuracy: 0.6881 - val_loss: 0.7173 - val_accuracy: 0.7831\n",
            "Epoch 223/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7270 - accuracy: 0.6832 - val_loss: 0.7399 - val_accuracy: 0.7721\n",
            "Epoch 224/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7347 - accuracy: 0.6894 - val_loss: 0.7411 - val_accuracy: 0.7757\n",
            "Epoch 225/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7268 - accuracy: 0.6838 - val_loss: 0.7147 - val_accuracy: 0.7868\n",
            "Epoch 226/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7463 - accuracy: 0.6788 - val_loss: 0.7221 - val_accuracy: 0.7831\n",
            "Epoch 227/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7218 - accuracy: 0.6900 - val_loss: 0.7315 - val_accuracy: 0.7794\n",
            "Epoch 228/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7279 - accuracy: 0.6838 - val_loss: 0.6999 - val_accuracy: 0.7904\n",
            "Epoch 229/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7285 - accuracy: 0.6875 - val_loss: 0.7110 - val_accuracy: 0.7868\n",
            "Epoch 230/500\n",
            "30/30 [==============================] - 4s 131ms/step - loss: 0.7195 - accuracy: 0.6906 - val_loss: 0.7213 - val_accuracy: 0.7831\n",
            "Epoch 231/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7194 - accuracy: 0.6838 - val_loss: 0.7089 - val_accuracy: 0.7868\n",
            "Epoch 232/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7217 - accuracy: 0.6807 - val_loss: 0.7169 - val_accuracy: 0.7868\n",
            "Epoch 233/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7209 - accuracy: 0.6925 - val_loss: 0.7167 - val_accuracy: 0.7868\n",
            "Epoch 234/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7233 - accuracy: 0.6875 - val_loss: 0.7216 - val_accuracy: 0.7831\n",
            "Epoch 235/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7046 - accuracy: 0.6925 - val_loss: 0.7158 - val_accuracy: 0.7831\n",
            "Epoch 236/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7093 - accuracy: 0.6906 - val_loss: 0.7041 - val_accuracy: 0.7868\n",
            "Epoch 237/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7251 - accuracy: 0.6795 - val_loss: 0.7083 - val_accuracy: 0.7831\n",
            "Epoch 238/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7118 - accuracy: 0.6832 - val_loss: 0.7183 - val_accuracy: 0.7831\n",
            "Epoch 239/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7247 - accuracy: 0.6881 - val_loss: 0.7151 - val_accuracy: 0.7831\n",
            "Epoch 240/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7215 - accuracy: 0.6825 - val_loss: 0.7091 - val_accuracy: 0.7831\n",
            "Epoch 241/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7216 - accuracy: 0.6838 - val_loss: 0.7049 - val_accuracy: 0.7831\n",
            "Epoch 242/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7248 - accuracy: 0.6813 - val_loss: 0.7315 - val_accuracy: 0.7794\n",
            "Epoch 243/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7115 - accuracy: 0.6912 - val_loss: 0.7217 - val_accuracy: 0.7794\n",
            "Epoch 244/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.7152 - accuracy: 0.6887 - val_loss: 0.6902 - val_accuracy: 0.7904\n",
            "Epoch 245/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7104 - accuracy: 0.6962 - val_loss: 0.7086 - val_accuracy: 0.7831\n",
            "Epoch 246/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7000 - accuracy: 0.6974 - val_loss: 0.6976 - val_accuracy: 0.7868\n",
            "Epoch 247/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7191 - accuracy: 0.6850 - val_loss: 0.6957 - val_accuracy: 0.7868\n",
            "Epoch 248/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7128 - accuracy: 0.6869 - val_loss: 0.6940 - val_accuracy: 0.7904\n",
            "Epoch 249/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7187 - accuracy: 0.6894 - val_loss: 0.6962 - val_accuracy: 0.7904\n",
            "Epoch 250/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7230 - accuracy: 0.6856 - val_loss: 0.7090 - val_accuracy: 0.7831\n",
            "Epoch 251/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7265 - accuracy: 0.6832 - val_loss: 0.7077 - val_accuracy: 0.7831\n",
            "Epoch 252/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7006 - accuracy: 0.6918 - val_loss: 0.7131 - val_accuracy: 0.7831\n",
            "Epoch 253/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6968 - accuracy: 0.7011 - val_loss: 0.7078 - val_accuracy: 0.7831\n",
            "Epoch 254/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7147 - accuracy: 0.6875 - val_loss: 0.6901 - val_accuracy: 0.7904\n",
            "Epoch 255/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6992 - accuracy: 0.6943 - val_loss: 0.7066 - val_accuracy: 0.7831\n",
            "Epoch 256/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7120 - accuracy: 0.6912 - val_loss: 0.7411 - val_accuracy: 0.7757\n",
            "Epoch 257/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7041 - accuracy: 0.6894 - val_loss: 0.6971 - val_accuracy: 0.7831\n",
            "Epoch 258/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7179 - accuracy: 0.6739 - val_loss: 0.7057 - val_accuracy: 0.7831\n",
            "Epoch 259/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7017 - accuracy: 0.6900 - val_loss: 0.7177 - val_accuracy: 0.7831\n",
            "Epoch 260/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7120 - accuracy: 0.6825 - val_loss: 0.7016 - val_accuracy: 0.7868\n",
            "Epoch 261/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6853 - accuracy: 0.7011 - val_loss: 0.7041 - val_accuracy: 0.7868\n",
            "Epoch 262/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7112 - accuracy: 0.6869 - val_loss: 0.7236 - val_accuracy: 0.7831\n",
            "Epoch 263/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.7114 - accuracy: 0.6887 - val_loss: 0.7125 - val_accuracy: 0.7831\n",
            "Epoch 264/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.7303 - accuracy: 0.6838 - val_loss: 0.7322 - val_accuracy: 0.7794\n",
            "Epoch 265/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7261 - accuracy: 0.6819 - val_loss: 0.7120 - val_accuracy: 0.7831\n",
            "Epoch 266/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7118 - accuracy: 0.6881 - val_loss: 0.6994 - val_accuracy: 0.7831\n",
            "Epoch 267/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7136 - accuracy: 0.6832 - val_loss: 0.7053 - val_accuracy: 0.7831\n",
            "Epoch 268/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7076 - accuracy: 0.6943 - val_loss: 0.7139 - val_accuracy: 0.7831\n",
            "Epoch 269/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7023 - accuracy: 0.6955 - val_loss: 0.7098 - val_accuracy: 0.7831\n",
            "Epoch 270/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7029 - accuracy: 0.6937 - val_loss: 0.7030 - val_accuracy: 0.7831\n",
            "Epoch 271/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7068 - accuracy: 0.6875 - val_loss: 0.7027 - val_accuracy: 0.7831\n",
            "Epoch 272/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7013 - accuracy: 0.6925 - val_loss: 0.6936 - val_accuracy: 0.7868\n",
            "Epoch 273/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7029 - accuracy: 0.6887 - val_loss: 0.7020 - val_accuracy: 0.7831\n",
            "Epoch 274/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7095 - accuracy: 0.6832 - val_loss: 0.6844 - val_accuracy: 0.7904\n",
            "Epoch 275/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7041 - accuracy: 0.6875 - val_loss: 0.7033 - val_accuracy: 0.7831\n",
            "Epoch 276/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7001 - accuracy: 0.6881 - val_loss: 0.7015 - val_accuracy: 0.7831\n",
            "Epoch 277/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6881 - accuracy: 0.7030 - val_loss: 0.6927 - val_accuracy: 0.7868\n",
            "Epoch 278/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7079 - accuracy: 0.6918 - val_loss: 0.7098 - val_accuracy: 0.7831\n",
            "Epoch 279/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6925 - accuracy: 0.6931 - val_loss: 0.6768 - val_accuracy: 0.7904\n",
            "Epoch 280/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6929 - accuracy: 0.6894 - val_loss: 0.6839 - val_accuracy: 0.7868\n",
            "Epoch 281/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7021 - accuracy: 0.6887 - val_loss: 0.6977 - val_accuracy: 0.7831\n",
            "Epoch 282/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6885 - accuracy: 0.6993 - val_loss: 0.6728 - val_accuracy: 0.7904\n",
            "Epoch 283/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6981 - accuracy: 0.6918 - val_loss: 0.7035 - val_accuracy: 0.7831\n",
            "Epoch 284/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6927 - accuracy: 0.6993 - val_loss: 0.7151 - val_accuracy: 0.7831\n",
            "Epoch 285/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7007 - accuracy: 0.6838 - val_loss: 0.6827 - val_accuracy: 0.7904\n",
            "Epoch 286/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7086 - accuracy: 0.6863 - val_loss: 0.6954 - val_accuracy: 0.7831\n",
            "Epoch 287/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6915 - accuracy: 0.6856 - val_loss: 0.6985 - val_accuracy: 0.7831\n",
            "Epoch 288/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6822 - accuracy: 0.6925 - val_loss: 0.6794 - val_accuracy: 0.7868\n",
            "Epoch 289/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.7040 - accuracy: 0.6863 - val_loss: 0.6805 - val_accuracy: 0.7868\n",
            "Epoch 290/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6920 - accuracy: 0.6974 - val_loss: 0.6876 - val_accuracy: 0.7868\n",
            "Epoch 291/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.7070 - accuracy: 0.6856 - val_loss: 0.7044 - val_accuracy: 0.7794\n",
            "Epoch 292/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6994 - accuracy: 0.6906 - val_loss: 0.6897 - val_accuracy: 0.7831\n",
            "Epoch 293/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6866 - accuracy: 0.6875 - val_loss: 0.6937 - val_accuracy: 0.7831\n",
            "Epoch 294/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6982 - accuracy: 0.6875 - val_loss: 0.6849 - val_accuracy: 0.7868\n",
            "Epoch 295/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6862 - accuracy: 0.6887 - val_loss: 0.6924 - val_accuracy: 0.7831\n",
            "Epoch 296/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6988 - accuracy: 0.6955 - val_loss: 0.6930 - val_accuracy: 0.7831\n",
            "Epoch 297/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6792 - accuracy: 0.6955 - val_loss: 0.6824 - val_accuracy: 0.7868\n",
            "Epoch 298/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6842 - accuracy: 0.6937 - val_loss: 0.6885 - val_accuracy: 0.7831\n",
            "Epoch 299/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6926 - accuracy: 0.6869 - val_loss: 0.6960 - val_accuracy: 0.7831\n",
            "Epoch 300/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6967 - accuracy: 0.6887 - val_loss: 0.6868 - val_accuracy: 0.7831\n",
            "Epoch 301/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6886 - accuracy: 0.6912 - val_loss: 0.6933 - val_accuracy: 0.7831\n",
            "Epoch 302/500\n",
            "30/30 [==============================] - 4s 131ms/step - loss: 0.6934 - accuracy: 0.6776 - val_loss: 0.6808 - val_accuracy: 0.7868\n",
            "Epoch 303/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6897 - accuracy: 0.6949 - val_loss: 0.6911 - val_accuracy: 0.7831\n",
            "Epoch 304/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6991 - accuracy: 0.6918 - val_loss: 0.6808 - val_accuracy: 0.7831\n",
            "Epoch 305/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6901 - accuracy: 0.6900 - val_loss: 0.6877 - val_accuracy: 0.7831\n",
            "Epoch 306/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6906 - accuracy: 0.6912 - val_loss: 0.7012 - val_accuracy: 0.7831\n",
            "Epoch 307/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6838 - accuracy: 0.6962 - val_loss: 0.6887 - val_accuracy: 0.7831\n",
            "Epoch 308/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.7089 - accuracy: 0.6776 - val_loss: 0.6985 - val_accuracy: 0.7831\n",
            "Epoch 309/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.7020 - accuracy: 0.6863 - val_loss: 0.6769 - val_accuracy: 0.7868\n",
            "Epoch 310/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6777 - accuracy: 0.6993 - val_loss: 0.6912 - val_accuracy: 0.7831\n",
            "Epoch 311/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6978 - accuracy: 0.6925 - val_loss: 0.6636 - val_accuracy: 0.7868\n",
            "Epoch 312/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6793 - accuracy: 0.6962 - val_loss: 0.6769 - val_accuracy: 0.7831\n",
            "Epoch 313/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6901 - accuracy: 0.6925 - val_loss: 0.6875 - val_accuracy: 0.7831\n",
            "Epoch 314/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6892 - accuracy: 0.6869 - val_loss: 0.6867 - val_accuracy: 0.7831\n",
            "Epoch 315/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6852 - accuracy: 0.6931 - val_loss: 0.6743 - val_accuracy: 0.7868\n",
            "Epoch 316/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6826 - accuracy: 0.6949 - val_loss: 0.6522 - val_accuracy: 0.7904\n",
            "Epoch 317/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6803 - accuracy: 0.6918 - val_loss: 0.6758 - val_accuracy: 0.7831\n",
            "Epoch 318/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6667 - accuracy: 0.7079 - val_loss: 0.6665 - val_accuracy: 0.7868\n",
            "Epoch 319/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6860 - accuracy: 0.6912 - val_loss: 0.6918 - val_accuracy: 0.7831\n",
            "Epoch 320/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6762 - accuracy: 0.6986 - val_loss: 0.6710 - val_accuracy: 0.7868\n",
            "Epoch 321/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6928 - accuracy: 0.6918 - val_loss: 0.6664 - val_accuracy: 0.7868\n",
            "Epoch 322/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6862 - accuracy: 0.6894 - val_loss: 0.6722 - val_accuracy: 0.7868\n",
            "Epoch 323/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6664 - accuracy: 0.6943 - val_loss: 0.6669 - val_accuracy: 0.7868\n",
            "Epoch 324/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6891 - accuracy: 0.6912 - val_loss: 0.6605 - val_accuracy: 0.7868\n",
            "Epoch 325/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6833 - accuracy: 0.6869 - val_loss: 0.6558 - val_accuracy: 0.7904\n",
            "Epoch 326/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6813 - accuracy: 0.6906 - val_loss: 0.6798 - val_accuracy: 0.7831\n",
            "Epoch 327/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6798 - accuracy: 0.7005 - val_loss: 0.6625 - val_accuracy: 0.7868\n",
            "Epoch 328/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6738 - accuracy: 0.6912 - val_loss: 0.6618 - val_accuracy: 0.7868\n",
            "Epoch 329/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6762 - accuracy: 0.6931 - val_loss: 0.6684 - val_accuracy: 0.7868\n",
            "Epoch 330/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6863 - accuracy: 0.6974 - val_loss: 0.6932 - val_accuracy: 0.7831\n",
            "Epoch 331/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6839 - accuracy: 0.6974 - val_loss: 0.6685 - val_accuracy: 0.7831\n",
            "Epoch 332/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6857 - accuracy: 0.6912 - val_loss: 0.6696 - val_accuracy: 0.7831\n",
            "Epoch 333/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6718 - accuracy: 0.7005 - val_loss: 0.6734 - val_accuracy: 0.7831\n",
            "Epoch 334/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6735 - accuracy: 0.6999 - val_loss: 0.6730 - val_accuracy: 0.7831\n",
            "Epoch 335/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6677 - accuracy: 0.6955 - val_loss: 0.6501 - val_accuracy: 0.7904\n",
            "Epoch 336/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6911 - accuracy: 0.6850 - val_loss: 0.6749 - val_accuracy: 0.7831\n",
            "Epoch 337/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6760 - accuracy: 0.6968 - val_loss: 0.6726 - val_accuracy: 0.7831\n",
            "Epoch 338/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6771 - accuracy: 0.6968 - val_loss: 0.6870 - val_accuracy: 0.7831\n",
            "Epoch 339/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6751 - accuracy: 0.6949 - val_loss: 0.6711 - val_accuracy: 0.7831\n",
            "Epoch 340/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6801 - accuracy: 0.6887 - val_loss: 0.6566 - val_accuracy: 0.7868\n",
            "Epoch 341/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6804 - accuracy: 0.6937 - val_loss: 0.6806 - val_accuracy: 0.7831\n",
            "Epoch 342/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6749 - accuracy: 0.6974 - val_loss: 0.6522 - val_accuracy: 0.7868\n",
            "Epoch 343/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6721 - accuracy: 0.7042 - val_loss: 0.6601 - val_accuracy: 0.7831\n",
            "Epoch 344/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6734 - accuracy: 0.6943 - val_loss: 0.6598 - val_accuracy: 0.7868\n",
            "Epoch 345/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6716 - accuracy: 0.6968 - val_loss: 0.6869 - val_accuracy: 0.7831\n",
            "Epoch 346/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6759 - accuracy: 0.6918 - val_loss: 0.6443 - val_accuracy: 0.7868\n",
            "Epoch 347/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6604 - accuracy: 0.7061 - val_loss: 0.6655 - val_accuracy: 0.7831\n",
            "Epoch 348/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6684 - accuracy: 0.6912 - val_loss: 0.6569 - val_accuracy: 0.7868\n",
            "Epoch 349/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6832 - accuracy: 0.6881 - val_loss: 0.6574 - val_accuracy: 0.7868\n",
            "Epoch 350/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6711 - accuracy: 0.7030 - val_loss: 0.6625 - val_accuracy: 0.7868\n",
            "Epoch 351/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6685 - accuracy: 0.6974 - val_loss: 0.6630 - val_accuracy: 0.7868\n",
            "Epoch 352/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6715 - accuracy: 0.6937 - val_loss: 0.6693 - val_accuracy: 0.7831\n",
            "Epoch 353/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6725 - accuracy: 0.6955 - val_loss: 0.6506 - val_accuracy: 0.7868\n",
            "Epoch 354/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6793 - accuracy: 0.6980 - val_loss: 0.6591 - val_accuracy: 0.7831\n",
            "Epoch 355/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6709 - accuracy: 0.6943 - val_loss: 0.6623 - val_accuracy: 0.7831\n",
            "Epoch 356/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6697 - accuracy: 0.6906 - val_loss: 0.6696 - val_accuracy: 0.7831\n",
            "Epoch 357/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6681 - accuracy: 0.6955 - val_loss: 0.6537 - val_accuracy: 0.7831\n",
            "Epoch 358/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6611 - accuracy: 0.6962 - val_loss: 0.6546 - val_accuracy: 0.7868\n",
            "Epoch 359/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6621 - accuracy: 0.7061 - val_loss: 0.6546 - val_accuracy: 0.7831\n",
            "Epoch 360/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6758 - accuracy: 0.6993 - val_loss: 0.6633 - val_accuracy: 0.7831\n",
            "Epoch 361/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6522 - accuracy: 0.7054 - val_loss: 0.6515 - val_accuracy: 0.7868\n",
            "Epoch 362/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6775 - accuracy: 0.6986 - val_loss: 0.6588 - val_accuracy: 0.7831\n",
            "Epoch 363/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6647 - accuracy: 0.6986 - val_loss: 0.6569 - val_accuracy: 0.7831\n",
            "Epoch 364/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6631 - accuracy: 0.6962 - val_loss: 0.6556 - val_accuracy: 0.7831\n",
            "Epoch 365/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6573 - accuracy: 0.7036 - val_loss: 0.6549 - val_accuracy: 0.7831\n",
            "Epoch 366/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6596 - accuracy: 0.7005 - val_loss: 0.6495 - val_accuracy: 0.7831\n",
            "Epoch 367/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6555 - accuracy: 0.6949 - val_loss: 0.6520 - val_accuracy: 0.7831\n",
            "Epoch 368/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6723 - accuracy: 0.6962 - val_loss: 0.6532 - val_accuracy: 0.7831\n",
            "Epoch 369/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6629 - accuracy: 0.6931 - val_loss: 0.6595 - val_accuracy: 0.7831\n",
            "Epoch 370/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6666 - accuracy: 0.6962 - val_loss: 0.6567 - val_accuracy: 0.7831\n",
            "Epoch 371/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6601 - accuracy: 0.7024 - val_loss: 0.6417 - val_accuracy: 0.7868\n",
            "Epoch 372/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6715 - accuracy: 0.6918 - val_loss: 0.6397 - val_accuracy: 0.7868\n",
            "Epoch 373/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6620 - accuracy: 0.6980 - val_loss: 0.6433 - val_accuracy: 0.7868\n",
            "Epoch 374/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6644 - accuracy: 0.6968 - val_loss: 0.6461 - val_accuracy: 0.7831\n",
            "Epoch 375/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6479 - accuracy: 0.6980 - val_loss: 0.6376 - val_accuracy: 0.7868\n",
            "Epoch 376/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6726 - accuracy: 0.6887 - val_loss: 0.6261 - val_accuracy: 0.7868\n",
            "Epoch 377/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6729 - accuracy: 0.6881 - val_loss: 0.6540 - val_accuracy: 0.7831\n",
            "Epoch 378/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6429 - accuracy: 0.7104 - val_loss: 0.6502 - val_accuracy: 0.7831\n",
            "Epoch 379/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6472 - accuracy: 0.7042 - val_loss: 0.6274 - val_accuracy: 0.7868\n",
            "Epoch 380/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6635 - accuracy: 0.6955 - val_loss: 0.6406 - val_accuracy: 0.7831\n",
            "Epoch 381/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6739 - accuracy: 0.6955 - val_loss: 0.6411 - val_accuracy: 0.7868\n",
            "Epoch 382/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6554 - accuracy: 0.7005 - val_loss: 0.6343 - val_accuracy: 0.7868\n",
            "Epoch 383/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6562 - accuracy: 0.7024 - val_loss: 0.6369 - val_accuracy: 0.7868\n",
            "Epoch 384/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6613 - accuracy: 0.6925 - val_loss: 0.6494 - val_accuracy: 0.7831\n",
            "Epoch 385/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6551 - accuracy: 0.6999 - val_loss: 0.6390 - val_accuracy: 0.7868\n",
            "Epoch 386/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6596 - accuracy: 0.7048 - val_loss: 0.6466 - val_accuracy: 0.7831\n",
            "Epoch 387/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6646 - accuracy: 0.6986 - val_loss: 0.6518 - val_accuracy: 0.7831\n",
            "Epoch 388/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6582 - accuracy: 0.7048 - val_loss: 0.6425 - val_accuracy: 0.7868\n",
            "Epoch 389/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6615 - accuracy: 0.6931 - val_loss: 0.6268 - val_accuracy: 0.7868\n",
            "Epoch 390/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6527 - accuracy: 0.7030 - val_loss: 0.6461 - val_accuracy: 0.7831\n",
            "Epoch 391/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6538 - accuracy: 0.7073 - val_loss: 0.6447 - val_accuracy: 0.7868\n",
            "Epoch 392/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6614 - accuracy: 0.6900 - val_loss: 0.6216 - val_accuracy: 0.7868\n",
            "Epoch 393/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6737 - accuracy: 0.6925 - val_loss: 0.6370 - val_accuracy: 0.7831\n",
            "Epoch 394/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6616 - accuracy: 0.6974 - val_loss: 0.6453 - val_accuracy: 0.7831\n",
            "Epoch 395/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6641 - accuracy: 0.6962 - val_loss: 0.6464 - val_accuracy: 0.7831\n",
            "Epoch 396/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6607 - accuracy: 0.6968 - val_loss: 0.6316 - val_accuracy: 0.7831\n",
            "Epoch 397/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6546 - accuracy: 0.6993 - val_loss: 0.6492 - val_accuracy: 0.7831\n",
            "Epoch 398/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6582 - accuracy: 0.7024 - val_loss: 0.6334 - val_accuracy: 0.7868\n",
            "Epoch 399/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6494 - accuracy: 0.6999 - val_loss: 0.6530 - val_accuracy: 0.7831\n",
            "Epoch 400/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6490 - accuracy: 0.6980 - val_loss: 0.6290 - val_accuracy: 0.7868\n",
            "Epoch 401/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6578 - accuracy: 0.6949 - val_loss: 0.6362 - val_accuracy: 0.7831\n",
            "Epoch 402/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6458 - accuracy: 0.7005 - val_loss: 0.6663 - val_accuracy: 0.7831\n",
            "Epoch 403/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6602 - accuracy: 0.6943 - val_loss: 0.6339 - val_accuracy: 0.7868\n",
            "Epoch 404/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6521 - accuracy: 0.7024 - val_loss: 0.6458 - val_accuracy: 0.7831\n",
            "Epoch 405/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6525 - accuracy: 0.6999 - val_loss: 0.6324 - val_accuracy: 0.7868\n",
            "Epoch 406/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6470 - accuracy: 0.6993 - val_loss: 0.6199 - val_accuracy: 0.7868\n",
            "Epoch 407/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6656 - accuracy: 0.6931 - val_loss: 0.6425 - val_accuracy: 0.7831\n",
            "Epoch 408/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6591 - accuracy: 0.7017 - val_loss: 0.6361 - val_accuracy: 0.7831\n",
            "Epoch 409/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6656 - accuracy: 0.6968 - val_loss: 0.6489 - val_accuracy: 0.7831\n",
            "Epoch 410/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6641 - accuracy: 0.6918 - val_loss: 0.6448 - val_accuracy: 0.7831\n",
            "Epoch 411/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6549 - accuracy: 0.6986 - val_loss: 0.6469 - val_accuracy: 0.7831\n",
            "Epoch 412/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6494 - accuracy: 0.7005 - val_loss: 0.6405 - val_accuracy: 0.7831\n",
            "Epoch 413/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6637 - accuracy: 0.6943 - val_loss: 0.6482 - val_accuracy: 0.7831\n",
            "Epoch 414/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6367 - accuracy: 0.7067 - val_loss: 0.6374 - val_accuracy: 0.7831\n",
            "Epoch 415/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6301 - accuracy: 0.7079 - val_loss: 0.6478 - val_accuracy: 0.7831\n",
            "Epoch 416/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6370 - accuracy: 0.7085 - val_loss: 0.6410 - val_accuracy: 0.7831\n",
            "Epoch 417/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6465 - accuracy: 0.7036 - val_loss: 0.6256 - val_accuracy: 0.7868\n",
            "Epoch 418/500\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.6497 - accuracy: 0.6999 - val_loss: 0.6379 - val_accuracy: 0.7831\n",
            "Epoch 419/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6507 - accuracy: 0.6925 - val_loss: 0.6298 - val_accuracy: 0.7831\n",
            "Epoch 420/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6502 - accuracy: 0.7042 - val_loss: 0.6374 - val_accuracy: 0.7831\n",
            "Epoch 421/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6521 - accuracy: 0.7054 - val_loss: 0.6371 - val_accuracy: 0.7831\n",
            "Epoch 422/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6529 - accuracy: 0.7030 - val_loss: 0.6262 - val_accuracy: 0.7868\n",
            "Epoch 423/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6449 - accuracy: 0.6986 - val_loss: 0.6251 - val_accuracy: 0.7831\n",
            "Epoch 424/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6543 - accuracy: 0.7011 - val_loss: 0.6328 - val_accuracy: 0.7831\n",
            "Epoch 425/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6468 - accuracy: 0.6986 - val_loss: 0.6228 - val_accuracy: 0.7868\n",
            "Epoch 426/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6432 - accuracy: 0.7048 - val_loss: 0.6334 - val_accuracy: 0.7831\n",
            "Epoch 427/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6464 - accuracy: 0.7098 - val_loss: 0.6286 - val_accuracy: 0.7831\n",
            "Epoch 428/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6447 - accuracy: 0.7092 - val_loss: 0.6254 - val_accuracy: 0.7831\n",
            "Epoch 429/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6416 - accuracy: 0.7011 - val_loss: 0.6233 - val_accuracy: 0.7868\n",
            "Epoch 430/500\n",
            "30/30 [==============================] - 4s 140ms/step - loss: 0.6430 - accuracy: 0.7054 - val_loss: 0.6311 - val_accuracy: 0.7831\n",
            "Epoch 431/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6439 - accuracy: 0.7073 - val_loss: 0.6218 - val_accuracy: 0.7868\n",
            "Epoch 432/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6557 - accuracy: 0.6999 - val_loss: 0.6343 - val_accuracy: 0.7831\n",
            "Epoch 433/500\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.6497 - accuracy: 0.7017 - val_loss: 0.6224 - val_accuracy: 0.7868\n",
            "Epoch 434/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6488 - accuracy: 0.6949 - val_loss: 0.6232 - val_accuracy: 0.7868\n",
            "Epoch 435/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6560 - accuracy: 0.6968 - val_loss: 0.6362 - val_accuracy: 0.7831\n",
            "Epoch 436/500\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.6518 - accuracy: 0.6980 - val_loss: 0.6491 - val_accuracy: 0.7831\n",
            "Epoch 437/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6488 - accuracy: 0.7079 - val_loss: 0.6207 - val_accuracy: 0.7868\n",
            "Epoch 438/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6408 - accuracy: 0.7011 - val_loss: 0.6433 - val_accuracy: 0.7831\n",
            "Epoch 439/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6478 - accuracy: 0.7017 - val_loss: 0.6217 - val_accuracy: 0.7868\n",
            "Epoch 440/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6427 - accuracy: 0.7073 - val_loss: 0.6239 - val_accuracy: 0.7831\n",
            "Epoch 441/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6395 - accuracy: 0.7073 - val_loss: 0.6254 - val_accuracy: 0.7831\n",
            "Epoch 442/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6335 - accuracy: 0.7005 - val_loss: 0.6325 - val_accuracy: 0.7831\n",
            "Epoch 443/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6487 - accuracy: 0.6993 - val_loss: 0.6253 - val_accuracy: 0.7831\n",
            "Epoch 444/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6319 - accuracy: 0.7110 - val_loss: 0.6233 - val_accuracy: 0.7868\n",
            "Epoch 445/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6475 - accuracy: 0.7042 - val_loss: 0.6243 - val_accuracy: 0.7831\n",
            "Epoch 446/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6513 - accuracy: 0.6999 - val_loss: 0.6267 - val_accuracy: 0.7831\n",
            "Epoch 447/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6557 - accuracy: 0.6999 - val_loss: 0.6206 - val_accuracy: 0.7831\n",
            "Epoch 448/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6594 - accuracy: 0.6931 - val_loss: 0.6171 - val_accuracy: 0.7868\n",
            "Epoch 449/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6434 - accuracy: 0.7011 - val_loss: 0.6250 - val_accuracy: 0.7868\n",
            "Epoch 450/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6356 - accuracy: 0.7079 - val_loss: 0.6305 - val_accuracy: 0.7831\n",
            "Epoch 451/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6429 - accuracy: 0.6993 - val_loss: 0.6306 - val_accuracy: 0.7831\n",
            "Epoch 452/500\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.6465 - accuracy: 0.7073 - val_loss: 0.6233 - val_accuracy: 0.7831\n",
            "Epoch 453/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6462 - accuracy: 0.6999 - val_loss: 0.6431 - val_accuracy: 0.7831\n",
            "Epoch 454/500\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.6370 - accuracy: 0.7073 - val_loss: 0.6275 - val_accuracy: 0.7831\n",
            "Epoch 455/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6329 - accuracy: 0.7085 - val_loss: 0.6364 - val_accuracy: 0.7831\n",
            "Epoch 456/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6397 - accuracy: 0.7054 - val_loss: 0.6283 - val_accuracy: 0.7831\n",
            "Epoch 457/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6571 - accuracy: 0.6931 - val_loss: 0.6399 - val_accuracy: 0.7831\n",
            "Epoch 458/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6452 - accuracy: 0.6999 - val_loss: 0.6147 - val_accuracy: 0.7868\n",
            "Epoch 459/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6260 - accuracy: 0.7073 - val_loss: 0.6464 - val_accuracy: 0.7831\n",
            "Epoch 460/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6461 - accuracy: 0.6993 - val_loss: 0.6191 - val_accuracy: 0.7868\n",
            "Epoch 461/500\n",
            "30/30 [==============================] - 4s 138ms/step - loss: 0.6455 - accuracy: 0.7061 - val_loss: 0.6379 - val_accuracy: 0.7831\n",
            "Epoch 462/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6335 - accuracy: 0.7067 - val_loss: 0.6212 - val_accuracy: 0.7831\n",
            "Epoch 463/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6325 - accuracy: 0.7011 - val_loss: 0.6293 - val_accuracy: 0.7831\n",
            "Epoch 464/500\n",
            "30/30 [==============================] - 4s 139ms/step - loss: 0.6313 - accuracy: 0.7030 - val_loss: 0.6113 - val_accuracy: 0.7868\n",
            "Epoch 465/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6441 - accuracy: 0.7030 - val_loss: 0.6303 - val_accuracy: 0.7831\n",
            "Epoch 466/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6421 - accuracy: 0.7011 - val_loss: 0.6451 - val_accuracy: 0.7831\n",
            "Epoch 467/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6279 - accuracy: 0.7030 - val_loss: 0.6169 - val_accuracy: 0.7831\n",
            "Epoch 468/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6297 - accuracy: 0.7104 - val_loss: 0.6304 - val_accuracy: 0.7831\n",
            "Epoch 469/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6390 - accuracy: 0.7042 - val_loss: 0.6643 - val_accuracy: 0.7794\n",
            "Epoch 470/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6501 - accuracy: 0.7017 - val_loss: 0.6172 - val_accuracy: 0.7831\n",
            "Epoch 471/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6440 - accuracy: 0.7011 - val_loss: 0.6339 - val_accuracy: 0.7831\n",
            "Epoch 472/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6408 - accuracy: 0.7061 - val_loss: 0.6293 - val_accuracy: 0.7831\n",
            "Epoch 473/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6247 - accuracy: 0.7092 - val_loss: 0.6145 - val_accuracy: 0.7831\n",
            "Epoch 474/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6361 - accuracy: 0.7005 - val_loss: 0.6254 - val_accuracy: 0.7831\n",
            "Epoch 475/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6342 - accuracy: 0.7073 - val_loss: 0.6134 - val_accuracy: 0.7868\n",
            "Epoch 476/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6299 - accuracy: 0.7079 - val_loss: 0.6205 - val_accuracy: 0.7831\n",
            "Epoch 477/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6322 - accuracy: 0.7061 - val_loss: 0.6187 - val_accuracy: 0.7831\n",
            "Epoch 478/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6574 - accuracy: 0.6925 - val_loss: 0.6230 - val_accuracy: 0.7831\n",
            "Epoch 479/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6238 - accuracy: 0.7054 - val_loss: 0.6125 - val_accuracy: 0.7868\n",
            "Epoch 480/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6256 - accuracy: 0.7042 - val_loss: 0.6265 - val_accuracy: 0.7831\n",
            "Epoch 481/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6381 - accuracy: 0.7061 - val_loss: 0.6155 - val_accuracy: 0.7868\n",
            "Epoch 482/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6275 - accuracy: 0.7073 - val_loss: 0.6197 - val_accuracy: 0.7831\n",
            "Epoch 483/500\n",
            "30/30 [==============================] - 4s 132ms/step - loss: 0.6435 - accuracy: 0.7011 - val_loss: 0.6305 - val_accuracy: 0.7831\n",
            "Epoch 484/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6349 - accuracy: 0.7061 - val_loss: 0.6287 - val_accuracy: 0.7831\n",
            "Epoch 485/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6333 - accuracy: 0.7036 - val_loss: 0.6252 - val_accuracy: 0.7831\n",
            "Epoch 486/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6262 - accuracy: 0.7110 - val_loss: 0.6173 - val_accuracy: 0.7831\n",
            "Epoch 487/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6456 - accuracy: 0.6993 - val_loss: 0.6216 - val_accuracy: 0.7831\n",
            "Epoch 488/500\n",
            "30/30 [==============================] - 4s 133ms/step - loss: 0.6361 - accuracy: 0.7024 - val_loss: 0.6184 - val_accuracy: 0.7831\n",
            "Epoch 489/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6166 - accuracy: 0.7141 - val_loss: 0.6121 - val_accuracy: 0.7868\n",
            "Epoch 490/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6165 - accuracy: 0.7073 - val_loss: 0.6190 - val_accuracy: 0.7831\n",
            "Epoch 491/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6269 - accuracy: 0.7054 - val_loss: 0.6074 - val_accuracy: 0.7868\n",
            "Epoch 492/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6453 - accuracy: 0.7011 - val_loss: 0.6278 - val_accuracy: 0.7831\n",
            "Epoch 493/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6468 - accuracy: 0.6980 - val_loss: 0.6291 - val_accuracy: 0.7831\n",
            "Epoch 494/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6417 - accuracy: 0.6955 - val_loss: 0.6203 - val_accuracy: 0.7831\n",
            "Epoch 495/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6231 - accuracy: 0.7098 - val_loss: 0.6253 - val_accuracy: 0.7831\n",
            "Epoch 496/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6255 - accuracy: 0.7116 - val_loss: 0.6259 - val_accuracy: 0.7831\n",
            "Epoch 497/500\n",
            "30/30 [==============================] - 4s 135ms/step - loss: 0.6449 - accuracy: 0.7054 - val_loss: 0.6065 - val_accuracy: 0.7868\n",
            "Epoch 498/500\n",
            "30/30 [==============================] - 4s 134ms/step - loss: 0.6273 - accuracy: 0.7153 - val_loss: 0.6161 - val_accuracy: 0.7831\n",
            "Epoch 499/500\n",
            "30/30 [==============================] - 4s 137ms/step - loss: 0.6436 - accuracy: 0.7011 - val_loss: 0.6207 - val_accuracy: 0.7831\n",
            "Epoch 500/500\n",
            "30/30 [==============================] - 4s 136ms/step - loss: 0.6243 - accuracy: 0.7135 - val_loss: 0.6122 - val_accuracy: 0.7831\n"
          ]
        }
      ],
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "\n",
        "# https://stackoverflow.com/questions/53479007/how-to-setup-adaptive-learning-rate-in-keras\n",
        "# def adapt_learning_rate(epoch):\n",
        "#     print(0.0001 * epoch)\n",
        "#     return 0.0001 * epoch\n",
        "# my_lr_scheduler = keras.callbacks.LearningRateScheduler(adapt_learning_rate)\n",
        "\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                                        patience = 10,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "convlstm_model.compile(loss = 'categorical_crossentropy',\n",
        "                       optimizer= keras.optimizers.Adam(0.0001, decay=1e-4),\n",
        "                       metrics = [\"accuracy\"])\n",
        "# Start training the model.\n",
        "convlstm_model_training_history = convlstm_model.fit(x = features_train,\n",
        "                                                     y = labels_train,\n",
        "                                                     epochs = 500,\n",
        "                                                     batch_size = 54,\n",
        "                                                     shuffle = True,\n",
        "                                                     validation_data = (features_valid, labels_valid)),\n",
        "                                                    #  callbacks = [early_stopping_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcpKhGqvIenv",
        "outputId": "58967ef9-0495-408f-c3ea-bb4634eb1187"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 41ms/step - loss: 0.7745 - accuracy: 0.5240\n",
            "\n",
            "\n",
            "Train accuracy: 68.193 % || Test accuracy: 52.399 % || Val accuracy: 78.309 %\n",
            "\n",
            "\n",
            "Train loss: 0.717 || Test loss: 0.775 || Val loss: 0.612\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = convlstm_model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = convlstm_model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = convlstm_model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print('\\n')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qsFw5KIzIum9"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        " \n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p convlstm_{current_date_time_string}\n",
        "# Save your Model.\n",
        "convlstm_model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "convlstm_model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z0eAobhSIz_P"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history[0].history[metric_name_1]\n",
        "    metric_value_2 = model_training_history[0].history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "18RtBjI9I5lE",
        "outputId": "7eb2da98-2aaa-425e-a5ae-7c1a0ec099d9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3wU1drA8d8TEnqHQOgBaSIIeAMiSrEjCCiIiF4VRRF7v4oFEetVr+1elKu+iBXhKiqKio0iKkqA0KuhhRpa6CXJ8/5xJptNX8Imm/J8P58lM2fOzjwzuzw7e3bmHFFVjDHGFH9hoQ7AGGNMcFhCN8aYEsISujHGlBCW0I0xpoSwhG6MMSWEJXRjjCkhLKGXIiKiItI81HEURyLSU0QSCmC90d7rEu7Nfysi1wdSNx/bekRE3jmZeE3RZgm9CBCRA36PVBE57Dd/TQ7PCWqCEZGZInJTsNZXWESkm9+xOuglPP/j2TiH540WkQ+DFMNKEbkxm/K7RST2RNalqpeo6ntBiCnL+0NVn1XVoL/GIjJUROYEe73mxOXrk94El6pWTpsWkfXATar6Y+giKj5U9RegMrgzWGAdUF1VkwsxjPeA64Dxmcqv9ZYZUyjsDL0IE5FyIvKqiGzxHq96ZZWAb4H6fmei9UWks4j8LiJ7RWSriPxHRMqeZAxhIvKYiGwQkR0i8r6IVPOWlReRD0Vkl7fNeSJS11s2VETiRWS/iKzL7puGF/NhEanpV9ZRRHaKSISINBeRWSKS5JVNOsHY64vIVBHZLSJrReRmr7wX8Agw2Dt2i7zyG0RkhRdzvIjcEuCmPgDOEZEmfttuA5wOTBSRPiKyUET2icgmERmdS8y+b0oiUkZEXvL2PR7ok6lutvHm8v7I8K1ERPqJyDLvtZspIqf6LVsvIg+IyGLv+E8SkfIBHg//GLt674sk729Xv2XZvkdO9nUv1VTVHkXoAawHLvCmxwBzgTpAJPAb8JS3rCeQkOm5fwO64L55RQMrgHv8livQPIftzsR9M8hcfiOwFmiGOxOeAnzgLbsF+AqoCJTxtl8VqATsA1p59eoBp+Ww3Z+Bm/3mXwTGedMTgUdxJx7lgXPyOHbR3j6Ge/OzgTe853YAEoHzvGWjgQ8zPb8PcAogQA/gEHBGTsc703N/AB7zm38O+MLvue28/Tgd2A5clkPMvtcBGAGsBBoBNYEZmeqeULz++wy0BA4CFwIRwD+817ms3/vwT6C+t+0VwIgc9n0oMCeb8prAHtw3lXBgiDdfK7f3yIm+7vZIf9gZetF2DTBGVXeoaiLwJO4/R7ZUdb6qzlXVZFVdD/wX9x/9ZGN4WVXjVfUAMBK4StwPc8dx/zmbq2qKt/193vNSgbYiUkFVt6rqshzW/zHuPzoiIsBVXhne+psA9VX1iKoG3E4rIo2As4GHvOfGAe/gmkayparTVPUvdWYB3wPdAtzke3ivjYiE4Y7be956Z6rqElVNVdXFuIQVyOtyJfCqqm5S1d24D4lgxTsYmKaqP6jqceAloALQ1a/O66q6xdv2V7gPxRPRB1ijqh9478mJuA+ovt7ynN4j+X7dSztL6EVbfWCD3/wGryxbItJSRL4WkW0isg94FqhdADGEA3VxTQ3TgU+8JqEXRCRCVQ/iEsYIYKuITBOR1jms/zPgLBGpB3TH/Sf/xVv2D9zZ559e00CWHx7ziHu3qu7PFHuDnJ4gIpeIyFyviWYv0JvAj98UoJ6IdMGdHVcEpnnrPVNEZohIoogk4Y5LIOutD2zKFH+w4s3wuqpqqrct/+OzzW/6EN5vFScg83sHb75BHu+Rk3ndSzVL6EXbFtyZSprGXhm4r96ZvYk7A2qhqlVx7cRSADEkA9tV9biqPqmqbXBndpfinQGr6nRVvRD3VXol8HZ2K1fVPbgzy8HA1cAnqu57t6puU9WbVbU+rnnnDQn8ssstQE0RqZIp9s1pm/avLCLlcB8uLwF1VbU68A0BHj9VPQR8itv/a739OOYt/hiYCjRS1WrAuADXuxXX3OIff6Dx5tWNaobX1ft21Ij04xMMmd874Pca5PQeOcnXvVSzhF60TQQeE5FIEakNjALSftTaDtQS7wdKTxVcu+QB72zn1hPcXri4HzrTHhFeDPeKSFMRqYw765+kqskicq6ItBORMt52jwOpIlJXRPp7P84dBQ7gzrxz8jEuEV5BenMLIjJIRBp6s3twSSq39fio6ibcbw7PeftyOjCMjMcv2mseASgLlMO1syeLyCXARYFsy897uA+mgWS8uqUK7tvCERHpjPvgCsRk4C4RaSgiNYCH/ZblFW9274/M6+4jIud7r/P9uNfqtwBjy0wyvXfK4z5gWorI1SISLiKDgTbA17m9R07mdS/tLKEXbU8DscBiYAmwwCtDVVfikm28d5VCfeABXLLYjzvbOdGrA94EDvs93sVdivcB7gfGdcAR4E6vfhTurHQf7kezWV7dMOA+3Bnablx7cW4fLlOBFsA2VV3kV94J+ENEDnh17lbV+BPYnyG4Hx23AJ8DT2j65aD/8/7uEpEFXtPMXbhEtwd3HKeewLbAHaMk3I+R8/zKbwPGiMh+3Ify5ADX9zauSWsR7rWfkrYgr3hzeH/gt3wV8Hfg38BOXLt2X79vFSeqKxnfO4dxx+JS3IfFLlxTyqWqupPc3yMn+7qXWuJ9uzXGGFPM2Rm6McaUEJbQjTGmhLCEbowxJUSeCV1Exou75XtpHvU6iUiyiFwRvPCMMcYEKs8fRUWkO+6SovdVtW0Odcrgbn0+AoxX1U/z2nDt2rU1Ojr6hAM2xpjSbP78+TtVNTK7ZXn2tqiqs8X1YpebO3E3OXQKNKjo6GhiY0+oZ1FjjCn1RCTz3bc+J92GLiINgMtx1zDnVXe4iMSKSGxiYuLJbtoYY4yfYPwo+iquA6Q87+RS1bdUNUZVYyIjs/3GYIwxJp+CMcBFDK5zJnAdA/UWkWRV/SII6zbGGBOgk07oqto0bVpEJgBfWzI3xuTk+PHjJCQkcOTIkVCHUqSVL1+ehg0bEhEREfBz8kzoIjIR1x1obXFjFD6B6xAfVR2Xv1CNMaVVQkICVapUITo6Gu+bvclEVdm1axcJCQk0bdo07yd4ArnKZcgJBDE04C0bY0qlI0eOWDLPg4hQq1YtTvTiEbtT1BhT6CyZ5y0/x6h4JvR58+DXX0MdhTHGFCnBuMql8HXu7P5a17/GmHyoXLkyBw4cCHUYQVf8ztDXrEmf3rcv53rGGFPKFL+EPn9++vTChaGLwxhT7KkqDz74IG3btqVdu3ZMmuQG+dq6dSvdu3enQ4cOtG3bll9++YWUlBSGDh3qq/vKK6+EOPqsil+Ty1VXwRlnQKtWEBcHPXqEOiJjTD7dc4/7bxxMHTrAq68GVnfKlCnExcWxaNEidu7cSadOnejevTsff/wxF198MY8++igpKSkcOnSIuLg4Nm/ezNKlruPZvXv3BjfwICh+Z+gALVpAjRqwYkWoIzHGFGNz5sxhyJAhlClThrp169KjRw/mzZtHp06dePfddxk9ejRLliyhSpUqNGvWjPj4eO68806+++47qlatGurwsyh+Z+gAInDqqa7J5dgxKFs21BEZY/Ih0DPpwta9e3dmz57NtGnTGDp0KPfddx/XXXcdixYtYvr06YwbN47Jkyczfvz4UIeaQfE8Qwdo2hT+/BMefzzUkRhjiqlu3boxadIkUlJSSExMZPbs2XTu3JkNGzZQt25dbr75Zm666SYWLFjAzp07SU1NZeDAgTz99NMsWLAg1OFnUTzP0AGGDYOPPoJvvoF//jPU0RhjiqHLL7+c33//nfbt2yMivPDCC0RFRfHee+/x4osvEhERQeXKlXn//ffZvHkzN9xwA6mprmPZ5557LsTRZ5XniEUFJSYmRk96gIthw2DaNNi2LThBGWMK3IoVKzj11FNDHUaxkN2xEpH5qhqTXf3i2+QC0LIlbN8OSUmhjsQYY0KueCf01q3d38WLQxuHMcYUAcU7offsCeXKwfjx1g2AMabUK94JvVo1uPJKmDABJk4MdTTGGBNSxTKhjxkDI0d6M2+/DbVrw5QpIY3JGGNCrdgl9OPH4Ykn4PnnvYJy5aBPH5g5E1JSQhmaMcaEVJ4JXUTGi8gOEVmaw/L+IrJYROJEJFZEzgl+mOlmzUqf3rHDm+jbF3btgqlTC3LTxhhTpAVyhj4B6JXL8p+A9qraAbgReCcIceWoenWoV89N+y5u6d8fGjSAjz8uyE0bY0qhypUr57hs/fr1tG3bthCjyV2eCV1VZwO7c1l+QNPvTqoEFOjlJjEx6b3mLl/uFYaHQ/v28NdfBblpY4wp0oJy67+IXA48B9QB+uRSbzgwHKBx48b53l6dOlCpEtx9t+t6c/x4XN8uc+a4yxdtvEJjiocQ9J/78MMP06hRI26//XYARo8eTXh4ODNmzGDPnj0cP36cp59+mv79+5/QZo8cOcKtt95KbGws4eHhvPzyy5x77rksW7aMG264gWPHjpGamspnn31G/fr1ufLKK0lISCAlJYXHH3+cwYMHn9RuQ5B+FFXVz1W1NXAZ8FQu9d5S1RhVjYmMjMz39kRc0wvAu+96hc2auRGM9uzJ93qNMSXf4MGDmTx5sm9+8uTJXH/99Xz++ecsWLCAGTNmcP/993Oi3aKMHTsWEWHJkiVMnDiR66+/niNHjjBu3Djuvvtu4uLiiI2NpWHDhnz33XfUr1+fRYsWsXTpUnr1yq1VO3BB7ZxLVWeLSDMRqa2qO4O57syyjD7XtKn7+9NPMGhQQW7aGBMsIeg/t2PHjuzYsYMtW7aQmJhIjRo1iIqK4t5772X27NmEhYWxefNmtm/fTlRUVMDrnTNnDnfeeScArVu3pkmTJqxevZqzzjqLZ555hoSEBAYMGECLFi1o164d999/Pw899BCXXnop3bp1C8q+nfQZuog0F3FtHCJyBlAO2HWy682L/wn+sWNAt25QpQqMGlXQmzbGFHODBg3i008/ZdKkSQwePJiPPvqIxMRE5s+fT1xcHHXr1uXIkSNB2dbVV1/N1KlTqVChAr179+bnn3+mZcuWLFiwgHbt2vHYY48xZsyYoGwrkMsWJwK/A61EJEFEhonICBEZ4VUZCCwVkThgLDBYC6ELx2++gc6d3fS6dbibi268ERISCnrTxphibvDgwXzyySd8+umnDBo0iKSkJOrUqUNERAQzZsxgw4YNJ7zObt268dFHHwGwevVqNm7cSKtWrYiPj6dZs2bcdddd9O/fn8WLF7NlyxYqVqzI3//+dx588MGg9a2eZ5OLqg7JY/k/gULvkLxVK3jvPTdw0RdfwEMPAbVqwYED7u6jiIjCDskYU0ycdtpp7N+/nwYNGlCvXj2uueYa+vbtS7t27YiJiaF1Wsd/J+C2227j1ltvpV27doSHhzNhwgTKlSvH5MmT+eCDD4iIiCAqKopHHnmEefPm8eCDDxIWFkZERARvvvlmUParePeHDpx3nhtaNC4O6v7vP3Dnna5L3Tp1ghClMSbYrD/0wJWu/tCBZ59141u0bg3HKtd0hXalizGmFCq+Q9B5unSB0aPdY93eGrQCS+jGmKBasmQJ1157bYaycuXK8ccff4QoouwV+4QOcO21LqGv2F7TJfTdOd7YaowpAlQVKUY3ALZr1464YN8AlYf8NIcX+yYXgOhoqFoV4jbUcAV2hm5MkVW+fHl27dqVr4RVWqgqu3btonz58if0vBJxhh4WBl27wrTfazIa7AzdmCKsYcOGJCQkkJiYGOpQirTy5cvTsGHDE3pOiUjoAJddBrePqE4qQpi9UYwpsiIiImiadme3CaoS0eQCcNVVkEI4m2mAbtwY6nCMMabQlZiEXq0avPYarCea5DXrQx2OMcYUuhKT0AEaN3YJPXXd+lCHYowxha5EJvQyWxM4dig51OEYY0yhKnEJPZ5mhJNCwi/rQh2OMcYUqhKV0GvVguPN2wBwOHZZiKMxxpjCVaISugg88qFL6KlLLaEbY0qXEpXQASKbVWE9TSi3emmoQzHGmEJV4hJ6rVowj05UWDCHdfF2a7ExpvQocQk9LAx+4nwakcD/Pbwm1OEYY0yhCWQIuvEiskNEsm3DEJFrRGSxiCwRkd9EpH3wwzwxs+gBQNifc0MciTHGFJ5AztAnAL1yWb4O6KGq7YCngLeCENdJmbayOckSTsVNq0hNDXU0xhhTOPJM6Ko6G8ix+0JV/U1V0/qrnQucWPdgBaBZqwj2Rzajeeoqtm8PdTTGGFM4gt2GPgz4NqeFIjJcRGJFJLagu848Gt2a1qxk06YC3YwxxhQZQUvoInIuLqE/lFMdVX1LVWNUNSYyMjJYm85e+/a0ZiXbl+8q2O0YY0wREZSELiKnA+8A/VW1SGTQ8lf2I5wUvh4+lWPHQh2NMcYUvJNO6CLSGJgCXKuqq08+pOCodt7fWENzbjr+Bj/+YNejG2NKvkAuW5wI/A60EpEEERkmIiNEZIRXZRRQC3hDROJEJLYA4w2YhAlRz99LJ2JZ+OEyjhwJdUTGGFOw8hyCTlWH5LH8JuCmoEUURFX6dIeHYcUncVT5tC3Hjrn+XowxpiQqcXeKZtCqFakRZWnPIpKT4cCBUAdkjDEFp2Qn9IgIwtqexlVNfgfAxo42xpRkJTuhAwwZQqMNv9KJP9mxI9TBGGNMwSn5CX3YMAB6MItFi0IcizHGFKCSn9Br1iSldh1asYoRI2DevFAHZIwxBaPkJ3SAVq1oxSoA5loHjMaYEqpUJPQyp7aiG3M4leXW7GKMKbFKRULn5ptREV6OeJiFC0MdjDHGFIzSkdA7d0ZGjKCn/sy2jdaxizGmZCodCR2gb1/KJx9kyM7XOXo01MEYY0zwlZ6E3qsXW1v15GbeZsuWUAdjjDHBV3oSughH28XQhA1s3mTj0hljSp7Sk9CBsq2bUp6jfPKajUtnjCl5SlVCr9kxGoD5U9bbWKPGmBKnVCX08q2jAWjKOqKiICEhtPEYY0wwlaqETtOmaFiY767Rt98OcTzGGBNEpSuhV6iAtGzJgFPc7aJjxsBVV0FycojjMsaYIAhkCLrxIrJDRJbmsLy1iPwuIkdF5IHghxhkp59Ou5RFPPOMm500CdatC21IxhgTDIGcoU8AeuWyfDdwF/BSMAIqcO3bw/r1XHRmkq9o27YQxmOMMUGSZ0JX1dm4pJ3T8h2qOg84HszACkz79gCc8e+htG3hbhm1G42MMSVBobahi8hwEYkVkdjEUI0Hd/rpAIR9+QVz754IWEI3xpQMhZrQVfUtVY1R1ZjIyMjC3HS6hg19kxU3raJ8eUvoxpiSoXRd5QIgAl9/DSLI/Fjq14c1a2DgQPjXv+Cvv0IdoDHG5E/pS+gAffrADTfAjz/y+64W/PTlfqZMgQcegObNQx2cMcbkTyCXLU4EfgdaiUiCiAwTkREiMsJbHiUiCcB9wGNenaoFG3YQNG0KQJ2ktdzR6scQB2OMMScvPK8Kqjokj+XbgIa51SmSoqN9k8+e+wPn/+dyLrwQypQJXUjGGHMySmeTC2RI6BK3kAsugIcfhrAwUA1dWMYYk1+W0AHmzoVRo6hdG44fh/37QxaVMcbkW+lN6PXrw4gRrjMXgKeeou32n+jOLHbuDG1oxhiTH6U3oYeFwZtvQt++vqKLX7yAWfRk164QxmWMMflUehN6ml5Zu6nZmWiN6MaY4scSes2a8MsvGYpW/rSZr76yH0eNMcWLJXSABg0yzH7z8gr69YMffghRPMYYkw+W0AHq1csw24hNgHUDYIwpXiyhA5QvD+PGwcyZANTC/Sp6223w888hjMsYY06AJfQ0t9wC3buTWrYctUm/bnHChNCFZIwxJ8ISuj8RJLJ2hoS+YAHs2RPCmIwxJkCW0DORWrW48ryd7N4NXbvCsmVw442hjsoYY/JmCT2z2rWpcnQXNWrAEK9bstjY0IZkjDGBsISeWa1a8OuvIMLtvf7i6qtd/y7GGFPUWULPrHZt36S8N4HudVayfTscOBDCmIwxJgCW0DPzG3OUp5/mlldPpTp7WLMmdCEZY0wgLKFn1qpVlqJLZDoffhiCWIwx5gQEMgTdeBHZISJLc1guIvK6iKwVkcUickbwwyxE/gn9rrsAuKHxj7z8MkyZEqKYjDEmAIGcoU8AsnZJmO4SoIX3GA68efJhhZD/KNGvvQZdu3Ju43gqVICBA90NpcYYUxTlmdBVdTawO5cq/YH31ZkLVBeRernUL9rKl4cxY2DGDDcfHU14wnpat3azt94KixaFLjxjjMlJMNrQG4DXm5WT4JVlISLDRSRWRGITExODsOkC8vjj0LOnm46Oho0b6XtJsm/xd9+FJCpjjMlVof4oqqpvqWqMqsZERkYW5qbzr2lTSEnhsRs2s349tG6dpft0Y4wpEoKR0DcDjfzmG3plJUOLFgBELF1IkyZw0UUwbRpUqICNPWqMKVKCkdCnAtd5V7t0AZJUdWsQ1ls0dO0KNWr4LnF55hmX448ccc3s//iHr9ddY4wJqfC8KojIRKAnUFtEEoAngAgAVR0HfAP0BtYCh4AbCirYkIiIgIsvhtmzAahc2XXYVaMGXHstHD0Kn31mg2EYY0Ivz4SuqkPyWK7A7UGLqChq2RImT4Zjx6BsWSIi4Nxz4euv3eKNGyEpCapVC22YxpjSze4UDUSzZpCa6jK3Z/Bg97dVK0hOhhUrQhSbMcZ48jxDN7iEDhAf77vx6KqrYN8+OP106NYNEhJCGJ8xxmBn6IFJS+irV/uKwsPdmKOnnurmly+Hpdl2jmCMMYVDXBN44YuJidHY4jJyhKpL6g0bQq9esGQJfPKJb1GlSnD4sKu6d6+1pRtjCo6IzFfVmOyW2Rl6IERgwACYMwceewwmTYLdu32L/Hvc/fHHEMVojCn1LKEHauRIePVVaN/ezf/+u29RWrMLwLff+j3nyy/hxRcLJz5jTKlnTS4n6tAh16aSnAzPPgsjR7J7t7vv6H//c9eob9rkztzdP7h2GWOMCQJrcgmmihXhtNPc9COPAFCzJtx0k7uUcfNm19fL8OEhjNEYUypZQs+PSpWyLR40COrUgR494PO3/XqTTE0tpMCMMaWZJfT8GDs2fTolxTdZpQp88YWbTqROep2DBwspMGNMaWYJPT86dEhP6q1auR67Fi8G4KyzADK1me/bV6jhGWNKJ0vo+dXAG8Pjr7/cpYydO8PKlQD0aLcnQ9WJ/93HZ58VdoDGmNLGEnp+1a3r/g4Y4IasO3oUXngB4uP5/IapGaq++tQ+rrgiBDEaY0oV68slv848090t2r+/G4d0yxaYMAEWLqRGXBwAD/E8/+RhqmJNLsaYgmdn6Pkl4q5TLF/ezV99tRv1wkvmALf/291xVDN8P02bhiJIY0xpYgk9WLp2hVq1MhQ1vrAVAH177iN59z7YsCEUkRljSglL6MFSpoy74gVcm3pKCtSuDUAd2cn3SZ0hOpq9e2H+fLs03RgTfAEldBHpJSKrRGStiDyczfImIvKTiCwWkZki0jC79ZR41au7vw0aQFgYVK0KIlz0w4O0ZhUAvS9RYmJ8Q5QaY0zQ5JnQRaQMMBa4BGgDDBGRNpmqvQS8r6qnA2OA54IdaLGQ1m9uWh8uERHQqFGGKnFzXT+7ixbBHXe4gTKMMSYYAjlD7wysVdV4VT0GfAL0z1SnDfCzNz0jm+Wlw8iR6X2mp6lSJUOV6uwF3CXrY8e6nniNMSYYAknoDYBNfvMJXpm/RcAAb/pyoIqI1MpUBxEZLiKxIhKbmJiYeXHx166d62qxXr30skyN5aexDEWoPj+943TrjNEYEwzB+lH0AaCHiCwEegCbgZTMlVT1LVWNUdWYyMjIIG26iGvSJMPsfY3dLaPnr3vHV7ZzZ6FGZIwpoQJJ6JsB/4bghl6Zj6puUdUBqtoReNQr2xu0KIuz995zZ+6eS5qvAWAX6V9gNm/26v3jH4UdnTGmBAkkoc8DWohIUxEpC1wFZLi3XURqi0jaukYC44MbZjFWpw689FL6/Pz5APRgFo3YSE12ceTrH2HoUDe6kdfJlzHGnKg8E7qqJgN3ANOBFcBkVV0mImNEpJ9XrSewSkRWA3WBZwoo3uLpoovg00/ddFISAG1ZxkaaMJ2L6fL4hel1vcGnjTHmRNkQdIXlyBGoUCGgqjMe/5lzx5wL//oXlCvnrm80xhhyH4LOEnphSrs+PZMjEVUof3x/xsLUVHdzErBnt1KjRkEHZ4wpDmxM0aLi229dv+n+PvqI4w+OBODgrQ/4ind+8K1v+qX7txZKeMaY4s0SemHq1Qv++CO9CeW//4XBg6ky5h/wxRdUGvsC9916mFVhrTl0W3pyv29yFzexapV7jjHGZMMSeii8/jocOwbDh7tOvcqUcf2qixAVXZ7PU/vT+OAKX/VaBzfCoUPQuzeMGOFuXjLGmEwsoYeCiOvnJRsNGsB26vrm53C2m/jgA4iPB+DglOkFHqIxpvixhF7ENGoE24jyzS+ko5sYMcJX9tPTvxd2WMaYYsASehFz9tkw5J70hF6hSwff9KM8zVpOIWLnFlfwxx+wdm1hh2iMKaIsoRcxZcpAv5vTm1z6/OM03/SzPMpy2tBAtnDoENClC7RoEYIojTFFkSX0oigq/Qy9Xoe68P77sGQJa9bAnnL1iNKtnBW1LoQBGmOKovBQB2CyUaOGG6O0dWuIjiZthOnmwPZu9ajzYyKL9jfL8JQPP3TjayQlwZln2om7MaWRJfSiSAR+/TX7ZX5n72n+eOkXnn4wEkEpx1F2N+rAxo3pyxcsgNNOc70IGGNKLmtyKWa6DMw8tgic+WB3VnIqK2jDb3Rl+6aj8NprsGsXGzfC+X/bw9hBMws/WGNMobKEXsyU6dcH5s6FJUvg1FOzLK/IYb4ucxnccw97XnyHM8+Ez7mc+746F/btC0HExpjCYgm9uAkLc43kbdvC99/7imfSg/W40ZEuTPkOgNUfx7JtG/RkFgDrf1hT+PEaYwqNJfTirGFDGDSIXQ1P51xm0pOZABylLL+W6U7zxN8Q0sc0HXnFaubMCVGsxpgCZwm9uPvkExE9y0oAABy0SURBVGpuiOO332ATjThaqQarzrqB11Nuo9aRLdzAu76qLVnNa/eup1qlZPbvB+LifANuGGOKP0voxV1YGBImnHUW7NpThnIrF1Pl3df5lCvYShR38bqvald+43+xTZlwaBBxs5KgY0e49trc1//rr7BiRe51jDFFQkAJXUR6icgqEVkrIg9ns7yxiMwQkYUislhEegc/VJOX6tWBhg1p2qosEeXKEEcH2uPGKN1AYy7Gtblfzhd061sdgOQ/52dYR0pKppWecw60aQNDhsDPPxf0LhhjTkKeCV1EygBjgUuANsAQEWmTqdpjuLFGO+IGkX4j2IGaEzNgACwjvduAWXUG+aYPUtE3nZCafhlkQgKEhysff6Rw/LjrsjfNJ5/kfTZvjAmpQM7QOwNrVTVeVY8BnwD9M9VRoKo3XQ3YErwQTX689RZc80z65+51s2/2TUeSSEcWkERVyu7dQWoq9OgB37W9HyWMq/8eBpUrwxdfZFxptWqFFb4xJh8CSegNAP8RFRK8Mn+jgb+LSALwDXBndisSkeEiEisisYmJifkI1wSqcmWod2X39IJWrdj442o6soC7H67IU191ZH6XO6hzPIHPP01h9mzokuTXz/qxY3DNNRlXaq+ZMUVasH4UHQJMUNWGQG/gAxHJsm5VfUtVY1Q1JjIyMkibNjlq3jzDbKPzWtBvVEeuuw4uvRSiezYhnBRGDV7JalrQlmXMPeteOkbvYVbtgRmeu4bmsHOnexhjiqRAEvpmoJHffEOvzN8wYDKAqv4OlAdqByNAc5KWLoV58wDXRcyTT6bfYNr0losB+IyBtMD1q95uYAv6XFOdS3e9x/h/7aESB2jFSh7kRfekDRsAOHoUnngCttr41cYUGYEk9HlACxFpKiJlcT96Ts1UZyNwPoCInIpL6Pb9vCg47TSIicl2kUQ3IfmCXrRmla+sUrMo+vaFA1qJYfdX5xCVWE0rNnmf6Wt+cr1+/fN5ZcwYG7PamKIkz4SuqsnAHcB0YAXuapZlIjJGRPp51e4HbhaRRcBEYKiqakEFbYInfMI7MGiQy8xNmkC3bpxxRsY6GzbAGf1cQj/00Gi4/npufbo+ddiOvcrGFB0SqrwbExOjsbGxIdm2yZuI+ztuHNxyC7wxVrntjoyf/32ZSuNhFzG2x2S45hrO6R5G587w8suBbUMVnnsOBg+GU04J8g4YU0KJyHxVzfZrtyV0k63ly2HPHjfGKbgbjsqEuyx/JnP5gy4A/FZvAF23TkH/M5Z37ljImfxB/RH9qRQ7iwpzfsi1E/aNG92XgvbtXS8Expi85ZbQ7dZ/k602bdKTObixThk7lqG8y5+c6SvvunUKAIfvHcnNvMPpLKH2uKepEPsLCb9thJ07Sb3/QVIrVUF/+x1SU+Gpp2DzZnbtcus4eDDjtr/+Gm6/vYB30JgSyBK6Cdxtt1HrvqFUrQqpT4zOsKji8X3MI4ahvMsqWgIQ+9qv0L49YS+/RNihA2y+/2U3fNKoUTBsGNvXHeII5bj8yETA3Yy6cSP07QtvvAHJyYW9g8YUb5bQzQl56SXXFBM2+gleeGAHvZnGEtoCsJCOvMdQbq7t7jC97MsbYEv6TcOb91fFd1q+bx/H/1xIOY5xR+IoDh923cVccEH6trZvL7TdMqZEsIRuToiIG2MD4LYnIqk6uDdzOAeAX+jGggXw8cz62T530bIybPtpGQB7DkRwYIa7Pj6pbCQ7drg669dDL77lQ65hx8LNrk8ZY0xA7EdRc1L27oVXXlb6d01k4+FILrtc3OUrYbmfK8zhbMJIpSu/s6LCGRyYNZ/OnaFCBZhw+Equ5H+uYuPGvpuZjDG5/ygaXtjBmJKlenV4cowAdfBdvp52zWMuzuFXAA5Rgaij6/nNO0MPD4fK+P1KunFjvuI6fBjKlw8oFGNKDGtyMQXj889hypT0+bPOylIlQRryZuQT1EjdzYzP9wKwfz/UIWPj+RMtPuZ4k1PYPj8h101u3Oi+HGzfDhUrwr//ffK7YUxxYgndFIzLLoPLL4e774ZZs3wdyFzYZjP7XnPD4jV4/WHC2rcDoM7/Pct7XEdz1lA3U0J/cu01RGyM5/FzZrhO27OxfLm7pv2rYV8Qds0QKnKQ998Pwn688QZ89FEQVmRMwbM2dFM4DhyAHTugWTM3n5oKYWFMfGkzQx5s6Kv2NX24kB9YS3NOY3m2q2rfdB9vPZNIm9/eYfCyUbz0n/KsXQv9+4Pi2ljO4Re06zn8+utJxp3WZmN9HJgiwm4sMqFXuXJ6Mgffj6ZX3VeflBq1OBRWiY8ZwqVMoxzH+CZqGGFkHg/PKbduBbOuHkeV/zzHRTMeJrnTWdT6agJV2Oer05iNNE1ek3tMqamwcuWJ78svv8CmTXnXM6aQWUI3ISVhQplX/kXFLz/h9z7P+Mq7DohCCWNHc9f2njogvX/2NiynkTfmyo2M5/RDczn7nRto4Ner88dcw4d/tuSNV4/lfOXj//2fawr65Zfsl2d3Vq4K3btzuOXpJ7ajxhQCu8rFhN711wPwyN9g4WXD6VBnK52f7secqyGy7XewLp6w2FiY8hkAE7jB99Sq7PdNN8jSTT+MuXc3dRtFMXCgu8Ty6FGXx2vUgKvmr6YGoN//gHTrBrg+a7p3hz594JF7DmdZ3/GFS4kAKhzZy9atUK9eEI+DMSfJEropMurVg3p/uA7WI0jrS6YqdOjgLlD3HKICFTkMQ4fChx/6+gjILqEP5DNmDKvGM/f35rYN/+A/dZ5i0Q6XhXdTlkeB3bOXUgt38v3f/8Jvv7nHI9ftzriy+Hgi/pZ+Zj5vHvTrhzFFhiV0Uzy0agU//cShtp2JqBAO773jrqTZuBF+/hmAzvyZ5WljuQOSYHVSC1qyhiM7ypNENcpyjBrsAUDj45k/P+M4IKefjuvjwPPzuU9x3gUZWyiXL1P69bML3U3RYVe5mOJt7lxS33iTsA/eJzE8CpKTiSTncU+3UI/6uHHztGxZ5NgxNtGQKzpv4k/v8+BvbY9y7vp3SW7UlFdW9MpxXb34lslDv6Xq2/9yd0Tl5OKLXRcG3gePMScjt6tcUNU8H0AvYBWwFng4m+WvAHHeYzWwN691/u1vf1NjgmL/flURVdCU7j1UZ89WffNNVdeK4ns8VfvVLGVpj9NYoqDare1u3VSvkyrofDrmWF9BD1POTY8bp6qqn32m+vPPqqkJm/Xw/Y+qpqS4+Lz6Cxee+K59953qgQPBO1Sm+ANiNadcndMCXwUoA/wFNAPKAouANrnUvxMYn9d6LaGboGrZ0r2db7/dzR88mDEBv/CCnl9+jm/+4IC/Z0nQldivqaOeyDWJb6aePj14ccayyNP1mmvSiza2PM+VfzlPdcsW34Jy5dxnz5efHtNep67Xgwdz36Vt29xTzz23wI+eKUZyS+iBXLbYGVirqvGqegz4BOifS/0huHFFjSk8gwa5v2lj2VWs6DpziXLNMDzwANGXdQAgtdWpVPw/r1+Ahuk3Nf2N+UjcQgA+4O/ZbmYL9bno3tN883/SifqJi/n7R734F/exmHY0Wu2aVr798hifj1roq3v0qNKsGay/4n6+XRHN7C/3ZFm/T3IyBz/+ElBmzLD7mkxgAknoDQD/uygSvLIsRKQJ0BSwxkJTuJ58EiZMgGHD0suioqBrVzfckghjJ1QiacYCwmL/dL2KHTkCr77qq963xq+waBE7L7yKmfTMsomNNOIuXqduvfT/Nt8O/4LtFZrQi+ncxyu0Y6lv2YLxC5F33vLN/5s76ZQ4jSv4FID3Rq7knnvcmKrHjiqbNqRy+DB8+SW83/EVmt13GetoSitW8uSTcOxY8A6XKaFyOnVPewBXAO/4zV8L/CeHug8B/85lXcOBWCC2cePGhfL1xJRi8+apbtiQe52ZM7M0q6Q+/08dUOPnDGXH33nXN3v4sKrOmaM6bZpbx/TpuTbT+D9W0lLX0UQV9EfO03ps1vYs1LWX3q2HKK/3dJihoPo2w3zPmc6FCqqvvJI1/DVrVFNTMxVu3aq6du3JHz9TJHGSbehnAdP95kcCI3OouxDomtc61drQTVHxxx/uv0GjRqoDBrgG6z179PCqDa68TBnVpCRVTc/LWRw4EHBCn09H3UjDXOusooWupGWGsqv4WBs0cD+6qqrq999rqojWIlFHjVJdscIvnogIX6CpqarDh6vOmlWgR9EUopNN6OFAPK4pJe1H0dOyqdcaWI93KWReD0vopkhISlKNjFT9/vuM5cnJqo0bq773nq8ox4SeVt+rcAprckzWB6ioKUjAHwD+j2lcoq9yl/4yK0WTe56vCtqLb3xVvvwyY6Bz56ru2eNmb+Qd1Y8/To83NlZ19OigHkpTOE4qobvn0xt3OeJfwKNe2Rign1+d0cDzgaxPLaGbYqhsWXfCniMvkX71Vfp0To9dE6fr+gqtMpT91aZPhvkneEIPUiHLcy+IWqILonqpgg5ikm9Rhw7u4p60gooc0Bkz0v6XuzJf84w3n3z4mI4YobpkSUEfPRMsuSX0gDrnUtVvVLWlqp6iqs94ZaNUdapfndGq+nBgLffGFD87d2a4eTSr+fNh9WouvTSbZWefzZYr7vTN1hx4Lk02/Qpr1vAOw3iDW6k84+sMTznv09uRmjWzrKppUhwJ29yNTA1x/cOX5SgvxF3IsHbpd8tGsY3vv4eKfiNASZgQ2+1e3/zq+fsZNw4GDnSdT951F74brNKsXWtX2RQbOWX6gn7YGbop0TKflauq7tihetVVqj/9lKHqiy+qvv66N7N2rWvX/+MPN9+3r28dByvUVC1XTvdUb+Ire5l7FFQ7Ml8VMrTP9+MLbR+5OcMPrJkfI3qtU1CtXl31l19ccZMmbtPLlqm2aOHKnnoq9909fNj93btXdfnynOvltswEhpNtcimIhyV0U6ItW6a6cqX7LxYVlf/17N2rxy/q7dbTrZtqx6x3r35Nb72QwK+08X+0Y5Fvtm3jJAXVuuX26K4N+7Vz5/Sqbdu6cKZNc2EcO6Z6332qcXHuAwnczbnt2rnpLFfeeM8F1UmT8n84TBCaXIwxJ6hNG9eh2KxZcDJ9FlWrRvjlfd10VBQ0apSlSh++YQTjcl9P06bZFqf1K9+baSzZWI1n+81l29EabGl2doaml+3eqIDXX++6j+/fH15+Gfr2hd9/d8uWLYMlS9z0jh1Zt5W2vt9+y7Rg40bYsAFwg3snJcGuXbnvjsmeJXRjClL37tAg2/vwAnfggPsbFZXhztbVbS7zTQ/g8/T64eHw/PPwtV+b/NixULVqllVP41LGnD2dzypfD8DIZpMAaJuymJrs4l5eRkglMREWLYL69d3zvv3W/d20KX0s8Pj49PXGx7u+5fv2hZdecv3Qpy1/7TX4/nu/IJo0gehoAM47z93zVbs2vPuuu19sxYrADlOBGjHCBVTU5XTqXtAPa3IxJkDbt6tefLHq5s2qzzzj2i1uvtktO3hQk0c+lrEp5bLL0p+bVrZwoWqnTifUHDOFy1RBn+RxbVx9r2/RlXyiZ/NLlqdUrJjz6s44Q7V16/T5cuXclZOpqekxprVQpT1q1XJ/TzstuIdzxgzVqVNP8En+v4WEGNbkYkwxVqcOfPedOz1OO8v2xmSlYkXKDPfr7mDuXHj77azrqFcPWrfOeRveqFG+usDlfAHAKJ5izaEGDOVdapPIJK5iDt0Y+9BGLrrIPaUGuzl8KDXH1S9Y4IZvffBBeOMNd8YeE4Pv+QBXX50+3a5derNLajarVYV16zKWrVsHL7zgzv5fein7OHbtclf03H13xvKEBHdo583L5knZBQB89JEbQ3xnzr01F76cMn1BP+wM3Zh8eOMNd6Z4yy0Zy596SvXxx7PWTzuzTE5W/fNPd2oMqo/5ndWPGeMuT0mbf/fdLKfYqXXqZD3tnjhRH31UVUhRBf2eC7RMGfej6SmnuCq/j5ig08fM9T0lPt6dlbdurXob/9GfONe3PkhVUH35ZdVff03fTPfubleSklwXxZdfnr7s11/Td7VPxsv4debMrIfj1lvdsrAw1SNH0svTdnngwGyOuf+x8XPGGa4o7YKkwoJd5WJMCZGUpHrFFa75JRBpiThNfLzqoEFuPZmTVM+e6rtE5csvVRcs0GVdbtSVMVe7D4QyZdzy0aNdRnziCX1hzGGtwzbfurpEb3XrGjFCU2Ni3IdBhQr66ANHdPIk79KXbdv06A3Ds3xAVMFdZTN71A+a2quXdmOWPspT+mr0K7rjy9+0Xr2snykPPuiuBlVVPftsVyak6Jf01SE1vtWnn3Z3y775puqwYS7sZs1cveXL3WPfPtdPDqj2675HDyUdy3gM4+N9G/zuu/Titm1d8ezZOR/+5GTXpVB2V/3klyV0Y0qrHTtyvvg7c0I/eFB1166c1xUXl37ae8opqpdcoseatdSFEelt83edOTfjuv0b2M88U/XVnAcZUdAKHNTD7bJv6y9fLlU//th90ci8eNQo97dVK9VHrlqrCjqVSzWaeL366vR6FSqk96V2+eWqddimvZuv0jvvVIVUVdCPGKI33ugS/Y99Xtajl/T3raBPn/TDkdYF/xdfuLP9KVNc4u7cWfWhh1ydgQNdnQ8/VH3uOdWRI1V//DH/L6c7tJbQjTGZjRiRoa+aE3Lppdkm3ZSIcqr9+2e7TEG1WrVcE3pKVDan4WkfFucu9m3++edVX3vNdceQVkXEjfCkU6ZkeF7aFwtw18n7fznZQW1V0NPbpugdvO5bUK2a6ltvaZYYRNLPyKOjXfH48a7VCjJuWlW1ShU3nfn36JM5Y7eEbowJrjlz3GUoPXrkmqB1yJDcl+f06NZN9b//zVpeq5bLjt63jkOHXBP3iy/69ZT8xBMZnuP/9DPPdFW8EQt9C+KJzvCcSQzSQQOSs2y/bFnVLl3c7tev74orV85+d9NaakRUw8MzrioxMf+H3hK6MSb4UlIyDLGX5bF4sWuLyE9C9xqrp4+L19GMyrr8rrtU77hDtVcv96vk/v2uTQNUL7wwQ93enXboIzyt4RzTrl1d6M8/r1qNPbnG0DL8ryxlsypdomk/3mZ9ZCz/17/c3/PPz1o3Njb/h90SujGm4GTOVnPmqG7cmPPytPYJ/8tVxo1TrVvXTY8a5Xvq4cNpWSqPD4BTT81x2eGL+qmCDuBTnfxJimpqqqb++z95rnMpbbItv4jvshSfw2w9SAUdzjhfWb9+qjH8qfM73aI12JWh/mefnczhtoRujCkoaVkqLEy1fPmcl6c9UlPdL46qqjfdpK6/YXVX74BravHz3Xd+63jsMc0wIveJPNq2dX3cjxyZ3gCej8cRyupX1/9P33xTtTmrVUEX0t63vC2LFVQrVUpvo1fQHzhfy3JEwV2amf/DbQndGFNQFi5UnTzZXR/oje6UwYYNrrOytKSYk7Qz96+/zrpsxgzXhqGqumqV6iWXpK+vd++8E3GXLlnLLrjA/X3nHdXjx088uadd5uk9Uk5prqner7TDqn+qZTiuR4nIUGfDi5P06nKf6n335f9w55bQxS0vfDExMRp7Mp0WGWOKl1decf22DBiQ/fKZM+GCC2DVKjjllLzXt2KFGzm7bVs3PXEiREa6O2urVIF+/WDQIHj0UWjf3vUetmED9Onjnr93r7u9tH17d8unyMnt3733wqRJsGVLxvKyZbOM8K1J+5CqVfK1GRGZr6ox2S6zhG6MKTL27IEaNQp2Gw89BPv3uz4I/KUl9JkzXTcJUVFuvmZNGDPGdXB2/Lgb8SM769a5HsyeeML9TTN1KnTsmLGnzK++IvuRUPKWW0IPqC8XEeklIqtEZK2IZDsqkYhcKSLLRWSZiHycr0iNMaVbQSdzgH/+M2syB1i9GqZNgx493Fk+QOPGrgOY22+H5cvh55/hkUdcL5pr1rhvHK1aubP/6GjXr3BcHNq2bfp6GzdO76YyzfTpBbJreZ6hi0gZ3HiiFwIJwDxgiKou96vTApgMnKeqe0Skjqpm0yNyOjtDN8YUafPmubPqtDP17CQnuzP7MmUylh84AF27ug7id+1yZ/lp3wDmznX95VcJfpNLeADP7wysVdV4b2WfAP2B5X51bgbGquoegLySuTHGFHmdOuVdJzyHFFq5MsyeDX/84ZI5uO4Zq1SBM88MXoyZwwmgTgPwhjVxEoDMEbUEEJFfgTLAaFX9LigRGmNMcVS9Olx8cfq8f//ABSSQhB7oeloAPYGGwGwRaaeqe/0richwYDhA48aNg7RpY4wxENiPopsB/4EMG3pl/hKAqap6XFXX4drcW2Rekaq+paoxqhoTGRmZ35iNMcZkI5CEPg9oISJNRaQscBUwNVOdL3Bn54hIbVwTTDzGGGMKTZ4JXVWTgTuA6cAKYLKqLhORMSLSz6s2HdglIsuBGcCDqmrjdhtjTCGyG4uMMaYYOekbi4wxxhR9ltCNMaaEsIRujDElRMja0EUkEdiQz6fXBnYGMZziwPa5dLB9Lh1OZp+bqGq2132HLKGfDBGJzelHgZLK9rl0sH0uHQpqn63JxRhjSghL6MYYU0IU14T+VqgDCAHb59LB9rl0KJB9LpZt6MYYY7IqrmfoxhhjMrGEbowxJUSxS+iBjG9aHInIeBHZISJL/cpqisgPIrLG+1vDKxcRed07BotF5IzQRZ5/ItJIRGb4jUV7t1deYvdbRMqLyJ8issjb5ye98qYi8oe3b5O8nk0RkXLe/FpveXQo488vESkjIgtF5GtvvkTvL4CIrBeRJSISJyKxXlmBvreLVUL3xjcdC1wCtAGGiEib0EYVNBOAXpnKHgZ+UtUWwE/ePLj9b+E9hgNvFlKMwZYM3K+qbYAuwO3e61mS9/sobuzd9kAHoJeIdAH+Cbyiqs2BPcAwr/4wYI9X/opXrzi6G9dba5qSvr9pzlXVDn7XnBfse1tVi80DOAuY7jc/EhgZ6riCuH/RwFK/+VVAPW+6HrDKm/4vbqDuLPWK8wP4EjcYeanYb6AisAA3pONOINwr973PcV1Tn+VNh3v1JNSxn+B+NvSS13nA14CU5P312+/1QO1MZQX63i5WZ+hkP75pgxDFUhjqqupWb3obUNebLnHHwftq3RH4gxK+317zQxywA/gB+AvYq27sAci4X7599pYnAbUKN+KT9irwDyDVm69Fyd7fNAp8LyLzveE3oYDf28EaU9QUMFVVESmR15iKSGXgM+AeVd0nIr5lJXG/VTUF6CAi1YHPgdYhDqnAiMilwA5VnS8iPUMdTyE7R1U3i0gd4AcRWem/sCDe28XtDD2Q8U1Lku0iUg/A+7vDKy8xx0FEInDJ/CNVneIVl/j9BlA3iPoMXJNDdRFJO8Hy3y/fPnvLqwHFaTSws4F+IrIe+ATX7PIaJXd/fVR1s/d3B+6DuzMF/N4ubgk9kPFNS5KpwPXe9PW4Nua08uu8X8a7AEl+X+OKDXGn4v8HrFDVl/0Wldj9FpFI78wcEamA+81gBS6xX+FVy7zPacfiCuBn9RpZiwNVHamqDVU1Gvf/9WdVvYYSur9pRKSSiFRJmwYuApZS0O/tUP9wkI8fGnoDq3Htjo+GOp4g7tdEYCtwHNd+NgzXdvgTsAb4Eajp1RXc1T5/AUuAmFDHn899PgfXzrgYiPMevUvyfgOnAwu9fV4KjPLKmwF/AmuB/wHlvPLy3vxab3mzUO/DSex7T+Dr0rC/3v4t8h7L0nJVQb+37dZ/Y4wpIYpbk4sxxpgcWEI3xpgSwhK6McaUEJbQjTGmhLCEbowxJYQldGOMKSEsoRtjTAnx/+iPlA2d9dShAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "02amk7TXI_OS",
        "outputId": "e8508136-48b5-4493-a59a-3fc6c7c51f74"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "2D_CNN+LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9MbuPNvhyZ073tcj1/ATM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}