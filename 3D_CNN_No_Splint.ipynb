{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/3D_CNN_No_Splint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7I8NauauE3"
      },
      "source": [
        "####**3D Convolutional Neural Network**\n",
        "######*I am using 3D Convolutional Neural Network to extract the temporal and spatial information which are merged slowly throughout the whole network.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ibtd5HKtZk",
        "outputId": "bcf47f1e-402c-43ff-e65c-82087fcd1a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "cce1be66-f1d3-4512-aadd-1e74c3d65b92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 96, 96\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Circle_Cropped_videos_labeled'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUTeIqzpZc9J"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QRDbHG0TZkYJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(96, 96)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            # frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "c5017445-b30b-43e8-aa1d-cc3a8fc3559e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-9ykP4ig7IW"
      },
      "outputs": [],
      "source": [
        "def create_3D_CNN_model():\n",
        "    sample_shape = (16, 96, 96, 3)\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv3D(8, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4),\n",
        "                     input_shape=sample_shape))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Conv3D(16, (3,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(GlobalAveragePooling3D())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "\n",
        "    model.summary(line_length = 125)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_GxXZBcHlB",
        "outputId": "16b2cf42-0c49-4e7d-bac1-fd6b7e91c811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_____________________________________________________________________________________________________________________________\n",
            " Layer (type)                                           Output Shape                                      Param #            \n",
            "=============================================================================================================================\n",
            " conv3d (Conv3D)                                        (None, 16, 94, 94, 8)                             224                \n",
            "                                                                                                                             \n",
            " max_pooling3d (MaxPooling3D)                           (None, 8, 47, 47, 8)                              0                  \n",
            "                                                                                                                             \n",
            " dropout (Dropout)                                      (None, 8, 47, 47, 8)                              0                  \n",
            "                                                                                                                             \n",
            " conv3d_1 (Conv3D)                                      (None, 6, 45, 45, 16)                             3472               \n",
            "                                                                                                                             \n",
            " max_pooling3d_1 (MaxPooling3D)                         (None, 3, 22, 22, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_1 (Dropout)                                    (None, 3, 22, 22, 16)                             0                  \n",
            "                                                                                                                             \n",
            " global_average_pooling3d (GlobalAveragePooling3D)      (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dropout_2 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense (Dense)                                          (None, 16)                                        272                \n",
            "                                                                                                                             \n",
            " dropout_3 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense_1 (Dense)                                        (None, 8)                                         136                \n",
            "                                                                                                                             \n",
            " dense_2 (Dense)                                        (None, 4)                                         36                 \n",
            "                                                                                                                             \n",
            "=============================================================================================================================\n",
            "Total params: 4,140\n",
            "Trainable params: 4,140\n",
            "Non-trainable params: 0\n",
            "_____________________________________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "model = create_3D_CNN_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYEkaYLoyb_",
        "outputId": "15942fbe-a9bb-4545-c7c9-917116c773f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "26/26 [==============================] - 5s 108ms/step - loss: 1.6017 - accuracy: 0.2048 - val_loss: 1.3447 - val_accuracy: 0.3971\n",
            "Epoch 2/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.3440 - accuracy: 0.3758 - val_loss: 1.3106 - val_accuracy: 0.3971\n",
            "Epoch 3/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.2863 - accuracy: 0.4250 - val_loss: 1.2715 - val_accuracy: 0.3971\n",
            "Epoch 4/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.2455 - accuracy: 0.4483 - val_loss: 1.2448 - val_accuracy: 0.3971\n",
            "Epoch 5/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.2377 - accuracy: 0.4465 - val_loss: 1.2330 - val_accuracy: 0.3971\n",
            "Epoch 6/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.2036 - accuracy: 0.4453 - val_loss: 1.1982 - val_accuracy: 0.3971\n",
            "Epoch 7/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.1863 - accuracy: 0.4397 - val_loss: 1.1777 - val_accuracy: 0.3971\n",
            "Epoch 8/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.1569 - accuracy: 0.4502 - val_loss: 1.1476 - val_accuracy: 0.3971\n",
            "Epoch 9/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.1320 - accuracy: 0.4490 - val_loss: 1.1244 - val_accuracy: 0.3971\n",
            "Epoch 10/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.1152 - accuracy: 0.4736 - val_loss: 1.0879 - val_accuracy: 0.3971\n",
            "Epoch 11/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.0881 - accuracy: 0.4852 - val_loss: 1.0558 - val_accuracy: 0.5294\n",
            "Epoch 12/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.0477 - accuracy: 0.5049 - val_loss: 0.9848 - val_accuracy: 0.5184\n",
            "Epoch 13/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.0205 - accuracy: 0.4926 - val_loss: 0.9645 - val_accuracy: 0.5294\n",
            "Epoch 14/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 1.0056 - accuracy: 0.5105 - val_loss: 0.9868 - val_accuracy: 0.5441\n",
            "Epoch 15/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9843 - accuracy: 0.5252 - val_loss: 0.9321 - val_accuracy: 0.5294\n",
            "Epoch 16/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9770 - accuracy: 0.5129 - val_loss: 0.9391 - val_accuracy: 0.5368\n",
            "Epoch 17/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9634 - accuracy: 0.5320 - val_loss: 0.9219 - val_accuracy: 0.5331\n",
            "Epoch 18/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9754 - accuracy: 0.5252 - val_loss: 0.9012 - val_accuracy: 0.6029\n",
            "Epoch 19/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9561 - accuracy: 0.5455 - val_loss: 0.9091 - val_accuracy: 0.5699\n",
            "Epoch 20/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9553 - accuracy: 0.5394 - val_loss: 0.8941 - val_accuracy: 0.5441\n",
            "Epoch 21/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9281 - accuracy: 0.5652 - val_loss: 0.8917 - val_accuracy: 0.5956\n",
            "Epoch 22/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9442 - accuracy: 0.5394 - val_loss: 0.9181 - val_accuracy: 0.5331\n",
            "Epoch 23/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9411 - accuracy: 0.5517 - val_loss: 0.9212 - val_accuracy: 0.5478\n",
            "Epoch 24/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9166 - accuracy: 0.5381 - val_loss: 0.8876 - val_accuracy: 0.6029\n",
            "Epoch 25/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9148 - accuracy: 0.5738 - val_loss: 0.8506 - val_accuracy: 0.6140\n",
            "Epoch 26/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8951 - accuracy: 0.5744 - val_loss: 0.8511 - val_accuracy: 0.6250\n",
            "Epoch 27/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.9076 - accuracy: 0.5517 - val_loss: 0.8314 - val_accuracy: 0.5993\n",
            "Epoch 28/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9015 - accuracy: 0.5756 - val_loss: 0.8353 - val_accuracy: 0.6213\n",
            "Epoch 29/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9024 - accuracy: 0.5670 - val_loss: 0.8479 - val_accuracy: 0.6176\n",
            "Epoch 30/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8895 - accuracy: 0.5793 - val_loss: 0.8162 - val_accuracy: 0.6066\n",
            "Epoch 31/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9021 - accuracy: 0.5523 - val_loss: 0.8211 - val_accuracy: 0.5993\n",
            "Epoch 32/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8750 - accuracy: 0.5843 - val_loss: 0.8021 - val_accuracy: 0.5919\n",
            "Epoch 33/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8759 - accuracy: 0.5898 - val_loss: 0.8091 - val_accuracy: 0.6103\n",
            "Epoch 34/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8698 - accuracy: 0.5941 - val_loss: 0.8004 - val_accuracy: 0.6029\n",
            "Epoch 35/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8528 - accuracy: 0.6064 - val_loss: 0.7988 - val_accuracy: 0.6103\n",
            "Epoch 36/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8706 - accuracy: 0.6125 - val_loss: 0.7974 - val_accuracy: 0.6103\n",
            "Epoch 37/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8673 - accuracy: 0.5996 - val_loss: 0.7986 - val_accuracy: 0.6029\n",
            "Epoch 38/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8506 - accuracy: 0.5873 - val_loss: 0.7971 - val_accuracy: 0.6213\n",
            "Epoch 39/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.8495 - accuracy: 0.5984 - val_loss: 0.7893 - val_accuracy: 0.6250\n",
            "Epoch 40/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8631 - accuracy: 0.6101 - val_loss: 0.7997 - val_accuracy: 0.6213\n",
            "Epoch 41/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8482 - accuracy: 0.5972 - val_loss: 0.7854 - val_accuracy: 0.6176\n",
            "Epoch 42/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8558 - accuracy: 0.6046 - val_loss: 0.7927 - val_accuracy: 0.6103\n",
            "Epoch 43/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8521 - accuracy: 0.5830 - val_loss: 0.7827 - val_accuracy: 0.6103\n",
            "Epoch 44/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8359 - accuracy: 0.6107 - val_loss: 0.8033 - val_accuracy: 0.6434\n",
            "Epoch 45/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8383 - accuracy: 0.6144 - val_loss: 0.7890 - val_accuracy: 0.6397\n",
            "Epoch 46/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8289 - accuracy: 0.6181 - val_loss: 0.7770 - val_accuracy: 0.6397\n",
            "Epoch 47/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8472 - accuracy: 0.6199 - val_loss: 0.7661 - val_accuracy: 0.6176\n",
            "Epoch 48/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8162 - accuracy: 0.6156 - val_loss: 0.7533 - val_accuracy: 0.6287\n",
            "Epoch 49/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8246 - accuracy: 0.6193 - val_loss: 0.7595 - val_accuracy: 0.6360\n",
            "Epoch 50/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8305 - accuracy: 0.6199 - val_loss: 0.7607 - val_accuracy: 0.6434\n",
            "Epoch 51/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8122 - accuracy: 0.6310 - val_loss: 0.7392 - val_accuracy: 0.6324\n",
            "Epoch 52/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.7966 - accuracy: 0.6421 - val_loss: 0.7303 - val_accuracy: 0.6324\n",
            "Epoch 53/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7985 - accuracy: 0.6205 - val_loss: 0.7386 - val_accuracy: 0.6434\n",
            "Epoch 54/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8230 - accuracy: 0.6451 - val_loss: 0.7461 - val_accuracy: 0.6434\n",
            "Epoch 55/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8018 - accuracy: 0.6384 - val_loss: 0.7612 - val_accuracy: 0.6471\n",
            "Epoch 56/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8022 - accuracy: 0.6328 - val_loss: 0.7722 - val_accuracy: 0.6507\n",
            "Epoch 57/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8081 - accuracy: 0.6494 - val_loss: 0.7275 - val_accuracy: 0.6507\n",
            "Epoch 58/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7814 - accuracy: 0.6427 - val_loss: 0.7365 - val_accuracy: 0.6507\n",
            "Epoch 59/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7962 - accuracy: 0.6476 - val_loss: 0.7137 - val_accuracy: 0.6434\n",
            "Epoch 60/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7772 - accuracy: 0.6488 - val_loss: 0.7039 - val_accuracy: 0.6507\n",
            "Epoch 61/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7823 - accuracy: 0.6476 - val_loss: 0.7111 - val_accuracy: 0.6507\n",
            "Epoch 62/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7803 - accuracy: 0.6439 - val_loss: 0.6906 - val_accuracy: 0.6801\n",
            "Epoch 63/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7676 - accuracy: 0.6538 - val_loss: 0.7196 - val_accuracy: 0.6507\n",
            "Epoch 64/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7577 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.6875\n",
            "Epoch 65/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7604 - accuracy: 0.6642 - val_loss: 0.6899 - val_accuracy: 0.7279\n",
            "Epoch 66/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7532 - accuracy: 0.6685 - val_loss: 0.6831 - val_accuracy: 0.7243\n",
            "Epoch 67/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7505 - accuracy: 0.6544 - val_loss: 0.6811 - val_accuracy: 0.7279\n",
            "Epoch 68/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7613 - accuracy: 0.6587 - val_loss: 0.6754 - val_accuracy: 0.6801\n",
            "Epoch 69/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7629 - accuracy: 0.6642 - val_loss: 0.7135 - val_accuracy: 0.6507\n",
            "Epoch 70/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.7384 - accuracy: 0.6605 - val_loss: 0.6621 - val_accuracy: 0.7206\n",
            "Epoch 71/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7379 - accuracy: 0.6661 - val_loss: 0.6620 - val_accuracy: 0.7132\n",
            "Epoch 72/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7498 - accuracy: 0.6679 - val_loss: 0.6607 - val_accuracy: 0.7206\n",
            "Epoch 73/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7437 - accuracy: 0.6605 - val_loss: 0.6602 - val_accuracy: 0.7059\n",
            "Epoch 74/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7600 - accuracy: 0.6642 - val_loss: 0.6679 - val_accuracy: 0.6838\n",
            "Epoch 75/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7302 - accuracy: 0.6667 - val_loss: 0.6568 - val_accuracy: 0.6728\n",
            "Epoch 76/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7476 - accuracy: 0.6611 - val_loss: 0.6649 - val_accuracy: 0.6691\n",
            "Epoch 77/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7345 - accuracy: 0.6814 - val_loss: 0.6488 - val_accuracy: 0.7096\n",
            "Epoch 78/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7233 - accuracy: 0.6777 - val_loss: 0.6761 - val_accuracy: 0.6434\n",
            "Epoch 79/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7467 - accuracy: 0.6648 - val_loss: 0.6607 - val_accuracy: 0.7169\n",
            "Epoch 80/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7254 - accuracy: 0.6808 - val_loss: 0.6453 - val_accuracy: 0.6985\n",
            "Epoch 81/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7123 - accuracy: 0.6907 - val_loss: 0.6408 - val_accuracy: 0.6801\n",
            "Epoch 82/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7224 - accuracy: 0.6820 - val_loss: 0.6395 - val_accuracy: 0.7353\n",
            "Epoch 83/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7226 - accuracy: 0.6771 - val_loss: 0.6365 - val_accuracy: 0.7096\n",
            "Epoch 84/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7031 - accuracy: 0.6999 - val_loss: 0.6365 - val_accuracy: 0.6654\n",
            "Epoch 85/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7328 - accuracy: 0.6833 - val_loss: 0.6287 - val_accuracy: 0.7279\n",
            "Epoch 86/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7144 - accuracy: 0.6845 - val_loss: 0.6440 - val_accuracy: 0.6912\n",
            "Epoch 87/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6981 - accuracy: 0.6900 - val_loss: 0.6282 - val_accuracy: 0.7316\n",
            "Epoch 88/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7012 - accuracy: 0.7011 - val_loss: 0.6183 - val_accuracy: 0.7169\n",
            "Epoch 89/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7003 - accuracy: 0.6913 - val_loss: 0.6405 - val_accuracy: 0.7316\n",
            "Epoch 90/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7053 - accuracy: 0.6968 - val_loss: 0.6233 - val_accuracy: 0.7096\n",
            "Epoch 91/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7021 - accuracy: 0.6925 - val_loss: 0.6157 - val_accuracy: 0.7169\n",
            "Epoch 92/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7023 - accuracy: 0.6870 - val_loss: 0.6235 - val_accuracy: 0.7169\n",
            "Epoch 93/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6958 - accuracy: 0.6974 - val_loss: 0.6133 - val_accuracy: 0.7316\n",
            "Epoch 94/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6978 - accuracy: 0.6986 - val_loss: 0.5993 - val_accuracy: 0.7390\n",
            "Epoch 95/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6863 - accuracy: 0.7042 - val_loss: 0.6222 - val_accuracy: 0.6838\n",
            "Epoch 96/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6971 - accuracy: 0.7017 - val_loss: 0.6104 - val_accuracy: 0.7206\n",
            "Epoch 97/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6848 - accuracy: 0.6999 - val_loss: 0.6013 - val_accuracy: 0.7463\n",
            "Epoch 98/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6633 - accuracy: 0.7202 - val_loss: 0.5905 - val_accuracy: 0.7206\n",
            "Epoch 99/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7020 - accuracy: 0.6870 - val_loss: 0.6003 - val_accuracy: 0.7169\n",
            "Epoch 100/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6695 - accuracy: 0.7017 - val_loss: 0.5927 - val_accuracy: 0.7537\n",
            "Epoch 101/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6793 - accuracy: 0.7054 - val_loss: 0.6017 - val_accuracy: 0.7426\n",
            "Epoch 102/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6793 - accuracy: 0.7005 - val_loss: 0.5896 - val_accuracy: 0.7426\n",
            "Epoch 103/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6732 - accuracy: 0.7079 - val_loss: 0.5905 - val_accuracy: 0.7243\n",
            "Epoch 104/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6549 - accuracy: 0.7122 - val_loss: 0.5882 - val_accuracy: 0.7463\n",
            "Epoch 105/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6757 - accuracy: 0.7128 - val_loss: 0.5937 - val_accuracy: 0.7169\n",
            "Epoch 106/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6862 - accuracy: 0.6993 - val_loss: 0.5999 - val_accuracy: 0.7316\n",
            "Epoch 107/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6636 - accuracy: 0.7085 - val_loss: 0.5898 - val_accuracy: 0.7316\n",
            "Epoch 108/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6634 - accuracy: 0.7091 - val_loss: 0.5821 - val_accuracy: 0.7353\n",
            "Epoch 109/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6559 - accuracy: 0.7196 - val_loss: 0.6022 - val_accuracy: 0.7022\n",
            "Epoch 110/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6646 - accuracy: 0.7189 - val_loss: 0.5773 - val_accuracy: 0.7353\n",
            "Epoch 111/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6613 - accuracy: 0.7017 - val_loss: 0.5799 - val_accuracy: 0.7390\n",
            "Epoch 112/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6595 - accuracy: 0.7232 - val_loss: 0.5910 - val_accuracy: 0.7463\n",
            "Epoch 113/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6623 - accuracy: 0.7085 - val_loss: 0.5931 - val_accuracy: 0.7574\n",
            "Epoch 114/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6532 - accuracy: 0.7085 - val_loss: 0.5811 - val_accuracy: 0.7169\n",
            "Epoch 115/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6378 - accuracy: 0.7343 - val_loss: 0.5673 - val_accuracy: 0.7463\n",
            "Epoch 116/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6510 - accuracy: 0.7202 - val_loss: 0.5812 - val_accuracy: 0.7463\n",
            "Epoch 117/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6614 - accuracy: 0.7165 - val_loss: 0.5735 - val_accuracy: 0.7426\n",
            "Epoch 118/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6617 - accuracy: 0.7153 - val_loss: 0.5816 - val_accuracy: 0.7390\n",
            "Epoch 119/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6527 - accuracy: 0.7140 - val_loss: 0.5900 - val_accuracy: 0.7169\n",
            "Epoch 120/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6570 - accuracy: 0.6993 - val_loss: 0.5859 - val_accuracy: 0.7243\n",
            "Epoch 121/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6606 - accuracy: 0.7116 - val_loss: 0.6010 - val_accuracy: 0.6838\n",
            "Epoch 122/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6472 - accuracy: 0.7257 - val_loss: 0.5858 - val_accuracy: 0.7390\n",
            "Epoch 123/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6440 - accuracy: 0.7232 - val_loss: 0.5809 - val_accuracy: 0.7316\n",
            "Epoch 124/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6501 - accuracy: 0.7257 - val_loss: 0.5853 - val_accuracy: 0.7353\n",
            "Epoch 125/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6227 - accuracy: 0.7386 - val_loss: 0.5801 - val_accuracy: 0.7059\n",
            "Epoch 126/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6517 - accuracy: 0.7251 - val_loss: 0.5860 - val_accuracy: 0.7390\n",
            "Epoch 127/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6339 - accuracy: 0.7319 - val_loss: 0.5638 - val_accuracy: 0.7316\n",
            "Epoch 128/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6313 - accuracy: 0.7276 - val_loss: 0.5769 - val_accuracy: 0.7206\n",
            "Epoch 129/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6363 - accuracy: 0.7429 - val_loss: 0.5684 - val_accuracy: 0.7316\n",
            "Epoch 130/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6162 - accuracy: 0.7583 - val_loss: 0.5705 - val_accuracy: 0.7206\n",
            "Epoch 131/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6466 - accuracy: 0.7103 - val_loss: 0.5901 - val_accuracy: 0.6949\n",
            "Epoch 132/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6436 - accuracy: 0.7189 - val_loss: 0.5952 - val_accuracy: 0.6949\n",
            "Epoch 133/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6073 - accuracy: 0.7454 - val_loss: 0.5583 - val_accuracy: 0.7279\n",
            "Epoch 134/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6088 - accuracy: 0.7454 - val_loss: 0.5650 - val_accuracy: 0.7353\n",
            "Epoch 135/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6323 - accuracy: 0.7294 - val_loss: 0.5703 - val_accuracy: 0.7463\n",
            "Epoch 136/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6257 - accuracy: 0.7355 - val_loss: 0.5724 - val_accuracy: 0.7096\n",
            "Epoch 137/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6452 - accuracy: 0.7276 - val_loss: 0.5729 - val_accuracy: 0.7206\n",
            "Epoch 138/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6119 - accuracy: 0.7392 - val_loss: 0.5801 - val_accuracy: 0.7132\n",
            "Epoch 139/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6087 - accuracy: 0.7325 - val_loss: 0.5537 - val_accuracy: 0.7426\n",
            "Epoch 140/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6284 - accuracy: 0.7325 - val_loss: 0.6054 - val_accuracy: 0.6728\n",
            "Epoch 141/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6212 - accuracy: 0.7411 - val_loss: 0.5738 - val_accuracy: 0.7390\n",
            "Epoch 142/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6255 - accuracy: 0.7196 - val_loss: 0.5817 - val_accuracy: 0.7206\n",
            "Epoch 143/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6129 - accuracy: 0.7442 - val_loss: 0.5688 - val_accuracy: 0.7426\n",
            "Epoch 144/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6294 - accuracy: 0.7380 - val_loss: 0.5804 - val_accuracy: 0.6801\n",
            "Epoch 145/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6178 - accuracy: 0.7392 - val_loss: 0.5780 - val_accuracy: 0.7206\n",
            "Epoch 146/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6081 - accuracy: 0.7454 - val_loss: 0.5718 - val_accuracy: 0.7059\n",
            "Epoch 147/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6151 - accuracy: 0.7337 - val_loss: 0.5639 - val_accuracy: 0.7243\n",
            "Epoch 148/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6276 - accuracy: 0.7300 - val_loss: 0.5668 - val_accuracy: 0.7390\n",
            "Epoch 149/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6203 - accuracy: 0.7282 - val_loss: 0.5684 - val_accuracy: 0.7316\n",
            "Epoch 150/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6115 - accuracy: 0.7392 - val_loss: 0.5731 - val_accuracy: 0.7096\n",
            "Epoch 151/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6110 - accuracy: 0.7300 - val_loss: 0.5932 - val_accuracy: 0.6801\n",
            "Epoch 152/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6114 - accuracy: 0.7411 - val_loss: 0.5647 - val_accuracy: 0.7243\n",
            "Epoch 153/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6094 - accuracy: 0.7515 - val_loss: 0.5676 - val_accuracy: 0.7132\n",
            "Epoch 154/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5935 - accuracy: 0.7528 - val_loss: 0.5624 - val_accuracy: 0.7096\n",
            "Epoch 155/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5864 - accuracy: 0.7565 - val_loss: 0.5581 - val_accuracy: 0.7169\n",
            "Epoch 156/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5939 - accuracy: 0.7491 - val_loss: 0.5549 - val_accuracy: 0.7537\n",
            "Epoch 157/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6030 - accuracy: 0.7491 - val_loss: 0.5636 - val_accuracy: 0.7279\n",
            "Epoch 158/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5920 - accuracy: 0.7571 - val_loss: 0.5653 - val_accuracy: 0.7059\n",
            "Epoch 159/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5874 - accuracy: 0.7577 - val_loss: 0.5776 - val_accuracy: 0.6875\n",
            "Epoch 160/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5895 - accuracy: 0.7442 - val_loss: 0.5609 - val_accuracy: 0.7243\n",
            "Epoch 161/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6079 - accuracy: 0.7522 - val_loss: 0.5603 - val_accuracy: 0.7169\n",
            "Epoch 162/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6025 - accuracy: 0.7478 - val_loss: 0.5711 - val_accuracy: 0.6949\n",
            "Epoch 163/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5825 - accuracy: 0.7558 - val_loss: 0.5519 - val_accuracy: 0.7316\n",
            "Epoch 164/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5987 - accuracy: 0.7491 - val_loss: 0.5788 - val_accuracy: 0.6801\n",
            "Epoch 165/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5880 - accuracy: 0.7485 - val_loss: 0.5820 - val_accuracy: 0.6838\n",
            "Epoch 166/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5903 - accuracy: 0.7423 - val_loss: 0.5566 - val_accuracy: 0.7169\n",
            "Epoch 167/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6061 - accuracy: 0.7411 - val_loss: 0.5671 - val_accuracy: 0.7279\n",
            "Epoch 168/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6002 - accuracy: 0.7442 - val_loss: 0.5535 - val_accuracy: 0.7390\n",
            "Epoch 169/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5942 - accuracy: 0.7497 - val_loss: 0.5545 - val_accuracy: 0.7537\n",
            "Epoch 170/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5937 - accuracy: 0.7626 - val_loss: 0.5496 - val_accuracy: 0.7316\n",
            "Epoch 171/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5880 - accuracy: 0.7589 - val_loss: 0.5787 - val_accuracy: 0.6949\n",
            "Epoch 172/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5929 - accuracy: 0.7405 - val_loss: 0.5587 - val_accuracy: 0.7243\n",
            "Epoch 173/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5939 - accuracy: 0.7497 - val_loss: 0.5776 - val_accuracy: 0.6875\n",
            "Epoch 174/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5851 - accuracy: 0.7515 - val_loss: 0.5327 - val_accuracy: 0.7206\n",
            "Epoch 175/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5818 - accuracy: 0.7620 - val_loss: 0.5898 - val_accuracy: 0.6912\n",
            "Epoch 176/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5902 - accuracy: 0.7411 - val_loss: 0.5386 - val_accuracy: 0.7500\n",
            "Epoch 177/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5753 - accuracy: 0.7651 - val_loss: 0.6023 - val_accuracy: 0.6949\n",
            "Epoch 178/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5884 - accuracy: 0.7534 - val_loss: 0.5576 - val_accuracy: 0.7500\n",
            "Epoch 179/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5824 - accuracy: 0.7497 - val_loss: 0.5727 - val_accuracy: 0.6838\n",
            "Epoch 180/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5851 - accuracy: 0.7700 - val_loss: 0.5579 - val_accuracy: 0.7279\n",
            "Epoch 181/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5589 - accuracy: 0.7712 - val_loss: 0.5849 - val_accuracy: 0.6875\n",
            "Epoch 182/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5859 - accuracy: 0.7632 - val_loss: 0.5855 - val_accuracy: 0.6949\n",
            "Epoch 183/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5882 - accuracy: 0.7534 - val_loss: 0.5693 - val_accuracy: 0.7059\n",
            "Epoch 184/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5892 - accuracy: 0.7509 - val_loss: 0.5588 - val_accuracy: 0.7169\n",
            "Epoch 185/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5787 - accuracy: 0.7601 - val_loss: 0.5703 - val_accuracy: 0.6875\n",
            "Epoch 186/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5791 - accuracy: 0.7663 - val_loss: 0.5506 - val_accuracy: 0.7279\n",
            "Epoch 187/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5806 - accuracy: 0.7589 - val_loss: 0.5605 - val_accuracy: 0.7132\n",
            "Epoch 188/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5521 - accuracy: 0.7669 - val_loss: 0.5659 - val_accuracy: 0.6838\n",
            "Epoch 189/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5832 - accuracy: 0.7608 - val_loss: 0.5674 - val_accuracy: 0.6875\n",
            "Epoch 190/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5637 - accuracy: 0.7712 - val_loss: 0.5579 - val_accuracy: 0.7059\n",
            "Epoch 191/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5757 - accuracy: 0.7620 - val_loss: 0.5545 - val_accuracy: 0.7243\n",
            "Epoch 192/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5527 - accuracy: 0.7669 - val_loss: 0.5956 - val_accuracy: 0.6801\n",
            "Epoch 193/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5714 - accuracy: 0.7755 - val_loss: 0.5656 - val_accuracy: 0.6949\n",
            "Epoch 194/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5630 - accuracy: 0.7663 - val_loss: 0.5785 - val_accuracy: 0.6949\n",
            "Epoch 195/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5771 - accuracy: 0.7491 - val_loss: 0.5651 - val_accuracy: 0.6912\n",
            "Epoch 196/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5776 - accuracy: 0.7509 - val_loss: 0.5701 - val_accuracy: 0.6875\n",
            "Epoch 197/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5545 - accuracy: 0.7620 - val_loss: 0.5724 - val_accuracy: 0.6985\n",
            "Epoch 198/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5780 - accuracy: 0.7626 - val_loss: 0.5562 - val_accuracy: 0.6912\n",
            "Epoch 199/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5851 - accuracy: 0.7694 - val_loss: 0.5712 - val_accuracy: 0.7279\n",
            "Epoch 200/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5896 - accuracy: 0.7601 - val_loss: 0.5614 - val_accuracy: 0.7132\n",
            "Epoch 201/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5816 - accuracy: 0.7589 - val_loss: 0.5633 - val_accuracy: 0.7169\n",
            "Epoch 202/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5752 - accuracy: 0.7515 - val_loss: 0.5424 - val_accuracy: 0.7243\n",
            "Epoch 203/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5855 - accuracy: 0.7601 - val_loss: 0.5565 - val_accuracy: 0.6875\n",
            "Epoch 204/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5956 - accuracy: 0.7472 - val_loss: 0.5479 - val_accuracy: 0.7206\n",
            "Epoch 205/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5656 - accuracy: 0.7663 - val_loss: 0.5444 - val_accuracy: 0.7206\n",
            "Epoch 206/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5761 - accuracy: 0.7577 - val_loss: 0.5780 - val_accuracy: 0.6838\n",
            "Epoch 207/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5690 - accuracy: 0.7798 - val_loss: 0.5699 - val_accuracy: 0.6838\n",
            "Epoch 208/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5624 - accuracy: 0.7688 - val_loss: 0.5663 - val_accuracy: 0.7426\n",
            "Epoch 209/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5652 - accuracy: 0.7706 - val_loss: 0.5670 - val_accuracy: 0.6985\n",
            "Epoch 210/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5922 - accuracy: 0.7392 - val_loss: 0.5645 - val_accuracy: 0.6838\n",
            "Epoch 211/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5790 - accuracy: 0.7645 - val_loss: 0.5568 - val_accuracy: 0.7243\n",
            "Epoch 212/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5828 - accuracy: 0.7577 - val_loss: 0.5786 - val_accuracy: 0.6985\n",
            "Epoch 213/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5664 - accuracy: 0.7608 - val_loss: 0.5924 - val_accuracy: 0.6838\n",
            "Epoch 214/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5624 - accuracy: 0.7614 - val_loss: 0.5587 - val_accuracy: 0.6985\n",
            "Epoch 215/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5595 - accuracy: 0.7620 - val_loss: 0.5398 - val_accuracy: 0.7500\n",
            "Epoch 216/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5552 - accuracy: 0.7565 - val_loss: 0.5994 - val_accuracy: 0.6949\n",
            "Epoch 217/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5644 - accuracy: 0.7608 - val_loss: 0.5462 - val_accuracy: 0.7426\n",
            "Epoch 218/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5773 - accuracy: 0.7632 - val_loss: 0.5735 - val_accuracy: 0.6838\n",
            "Epoch 219/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5533 - accuracy: 0.7817 - val_loss: 0.5785 - val_accuracy: 0.6912\n",
            "Epoch 220/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5559 - accuracy: 0.7681 - val_loss: 0.5825 - val_accuracy: 0.6912\n",
            "Epoch 221/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5667 - accuracy: 0.7601 - val_loss: 0.5510 - val_accuracy: 0.7243\n",
            "Epoch 222/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5467 - accuracy: 0.7724 - val_loss: 0.5558 - val_accuracy: 0.7096\n",
            "Epoch 223/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5483 - accuracy: 0.7749 - val_loss: 0.5430 - val_accuracy: 0.7390\n",
            "Epoch 224/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5530 - accuracy: 0.7749 - val_loss: 0.5569 - val_accuracy: 0.7022\n",
            "Epoch 225/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5739 - accuracy: 0.7577 - val_loss: 0.5457 - val_accuracy: 0.7390\n",
            "Epoch 226/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5453 - accuracy: 0.7829 - val_loss: 0.5833 - val_accuracy: 0.7096\n",
            "Epoch 227/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5445 - accuracy: 0.7718 - val_loss: 0.5476 - val_accuracy: 0.7169\n",
            "Epoch 228/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5626 - accuracy: 0.7737 - val_loss: 0.5577 - val_accuracy: 0.7059\n",
            "Epoch 229/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5598 - accuracy: 0.7675 - val_loss: 0.5512 - val_accuracy: 0.6875\n",
            "Epoch 230/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5550 - accuracy: 0.7712 - val_loss: 0.5366 - val_accuracy: 0.7279\n",
            "Epoch 231/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5487 - accuracy: 0.7651 - val_loss: 0.5605 - val_accuracy: 0.7096\n",
            "Epoch 232/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5574 - accuracy: 0.7749 - val_loss: 0.5370 - val_accuracy: 0.7390\n",
            "Epoch 233/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5347 - accuracy: 0.7774 - val_loss: 0.5779 - val_accuracy: 0.6985\n",
            "Epoch 234/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5844 - accuracy: 0.7472 - val_loss: 0.5648 - val_accuracy: 0.7022\n",
            "Epoch 235/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5626 - accuracy: 0.7632 - val_loss: 0.5537 - val_accuracy: 0.7243\n",
            "Epoch 236/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5628 - accuracy: 0.7595 - val_loss: 0.5398 - val_accuracy: 0.7279\n",
            "Epoch 237/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5610 - accuracy: 0.7675 - val_loss: 0.5823 - val_accuracy: 0.6949\n",
            "Epoch 238/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5745 - accuracy: 0.7565 - val_loss: 0.5590 - val_accuracy: 0.6875\n",
            "Epoch 239/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5424 - accuracy: 0.7737 - val_loss: 0.5403 - val_accuracy: 0.7390\n",
            "Epoch 240/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5569 - accuracy: 0.7638 - val_loss: 0.5718 - val_accuracy: 0.6912\n",
            "Epoch 241/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5608 - accuracy: 0.7681 - val_loss: 0.5371 - val_accuracy: 0.7316\n",
            "Epoch 242/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5440 - accuracy: 0.7829 - val_loss: 0.5666 - val_accuracy: 0.6949\n",
            "Epoch 243/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5613 - accuracy: 0.7601 - val_loss: 0.5712 - val_accuracy: 0.6949\n",
            "Epoch 244/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5552 - accuracy: 0.7620 - val_loss: 0.5558 - val_accuracy: 0.7279\n",
            "Epoch 245/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5396 - accuracy: 0.7792 - val_loss: 0.5729 - val_accuracy: 0.6985\n",
            "Epoch 246/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5499 - accuracy: 0.7638 - val_loss: 0.5581 - val_accuracy: 0.6985\n",
            "Epoch 247/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5484 - accuracy: 0.7798 - val_loss: 0.5595 - val_accuracy: 0.7353\n",
            "Epoch 248/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5631 - accuracy: 0.7571 - val_loss: 0.5466 - val_accuracy: 0.7279\n",
            "Epoch 249/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5672 - accuracy: 0.7645 - val_loss: 0.5691 - val_accuracy: 0.6949\n",
            "Epoch 250/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5476 - accuracy: 0.7786 - val_loss: 0.5352 - val_accuracy: 0.7353\n",
            "Epoch 251/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5499 - accuracy: 0.7737 - val_loss: 0.5440 - val_accuracy: 0.7132\n",
            "Epoch 252/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5608 - accuracy: 0.7694 - val_loss: 0.5564 - val_accuracy: 0.7059\n",
            "Epoch 253/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5464 - accuracy: 0.7804 - val_loss: 0.5541 - val_accuracy: 0.7169\n",
            "Epoch 254/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5414 - accuracy: 0.7737 - val_loss: 0.5609 - val_accuracy: 0.6985\n",
            "Epoch 255/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5655 - accuracy: 0.7749 - val_loss: 0.5556 - val_accuracy: 0.7206\n",
            "Epoch 256/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5405 - accuracy: 0.7829 - val_loss: 0.5386 - val_accuracy: 0.7279\n",
            "Epoch 257/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5529 - accuracy: 0.7638 - val_loss: 0.5800 - val_accuracy: 0.6838\n",
            "Epoch 258/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5694 - accuracy: 0.7724 - val_loss: 0.5664 - val_accuracy: 0.6949\n",
            "Epoch 259/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5352 - accuracy: 0.7774 - val_loss: 0.5332 - val_accuracy: 0.7353\n",
            "Epoch 260/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5709 - accuracy: 0.7589 - val_loss: 0.5889 - val_accuracy: 0.6985\n",
            "Epoch 261/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5526 - accuracy: 0.7792 - val_loss: 0.5601 - val_accuracy: 0.6912\n",
            "Epoch 262/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5561 - accuracy: 0.7731 - val_loss: 0.5456 - val_accuracy: 0.7243\n",
            "Epoch 263/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5575 - accuracy: 0.7571 - val_loss: 0.5858 - val_accuracy: 0.6875\n",
            "Epoch 264/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5277 - accuracy: 0.7866 - val_loss: 0.5500 - val_accuracy: 0.7132\n",
            "Epoch 265/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5396 - accuracy: 0.7749 - val_loss: 0.5368 - val_accuracy: 0.7353\n",
            "Epoch 266/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5467 - accuracy: 0.7718 - val_loss: 0.5377 - val_accuracy: 0.7132\n",
            "Epoch 267/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5587 - accuracy: 0.7700 - val_loss: 0.5867 - val_accuracy: 0.6838\n",
            "Epoch 268/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5551 - accuracy: 0.7669 - val_loss: 0.5735 - val_accuracy: 0.6875\n",
            "Epoch 269/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5458 - accuracy: 0.7804 - val_loss: 0.5353 - val_accuracy: 0.7316\n",
            "Epoch 270/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5528 - accuracy: 0.7860 - val_loss: 0.5388 - val_accuracy: 0.7390\n",
            "Epoch 271/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5376 - accuracy: 0.7823 - val_loss: 0.5728 - val_accuracy: 0.6949\n",
            "Epoch 272/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5368 - accuracy: 0.7688 - val_loss: 0.5656 - val_accuracy: 0.6875\n",
            "Epoch 273/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5509 - accuracy: 0.7731 - val_loss: 0.5346 - val_accuracy: 0.7243\n",
            "Epoch 274/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5392 - accuracy: 0.7712 - val_loss: 0.5470 - val_accuracy: 0.7132\n",
            "Epoch 275/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5372 - accuracy: 0.7712 - val_loss: 0.5827 - val_accuracy: 0.6949\n",
            "Epoch 276/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5333 - accuracy: 0.7884 - val_loss: 0.5346 - val_accuracy: 0.7169\n",
            "Epoch 277/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5472 - accuracy: 0.7774 - val_loss: 0.5460 - val_accuracy: 0.7279\n",
            "Epoch 278/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5348 - accuracy: 0.7786 - val_loss: 0.5573 - val_accuracy: 0.7022\n",
            "Epoch 279/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5275 - accuracy: 0.7903 - val_loss: 0.5255 - val_accuracy: 0.7463\n",
            "Epoch 280/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5301 - accuracy: 0.7891 - val_loss: 0.5285 - val_accuracy: 0.7243\n",
            "Epoch 281/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5779 - accuracy: 0.7645 - val_loss: 0.5578 - val_accuracy: 0.7059\n",
            "Epoch 282/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5405 - accuracy: 0.7817 - val_loss: 0.5591 - val_accuracy: 0.7059\n",
            "Epoch 283/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5600 - accuracy: 0.7737 - val_loss: 0.5596 - val_accuracy: 0.7096\n",
            "Epoch 284/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5328 - accuracy: 0.7823 - val_loss: 0.5516 - val_accuracy: 0.7096\n",
            "Epoch 285/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5512 - accuracy: 0.7724 - val_loss: 0.5489 - val_accuracy: 0.7096\n",
            "Epoch 286/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5452 - accuracy: 0.7866 - val_loss: 0.5399 - val_accuracy: 0.7096\n",
            "Epoch 287/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5385 - accuracy: 0.7798 - val_loss: 0.5374 - val_accuracy: 0.7243\n",
            "Epoch 288/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5290 - accuracy: 0.7798 - val_loss: 0.5564 - val_accuracy: 0.7096\n",
            "Epoch 289/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5643 - accuracy: 0.7614 - val_loss: 0.5512 - val_accuracy: 0.6949\n",
            "Epoch 290/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5531 - accuracy: 0.7718 - val_loss: 0.5524 - val_accuracy: 0.6912\n",
            "Epoch 291/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5462 - accuracy: 0.7768 - val_loss: 0.5514 - val_accuracy: 0.7022\n",
            "Epoch 292/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5335 - accuracy: 0.7823 - val_loss: 0.5467 - val_accuracy: 0.7096\n",
            "Epoch 293/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5499 - accuracy: 0.7749 - val_loss: 0.5700 - val_accuracy: 0.7096\n",
            "Epoch 294/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5262 - accuracy: 0.7798 - val_loss: 0.5959 - val_accuracy: 0.6949\n",
            "Epoch 295/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5243 - accuracy: 0.7847 - val_loss: 0.5435 - val_accuracy: 0.7132\n",
            "Epoch 296/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5524 - accuracy: 0.7749 - val_loss: 0.5454 - val_accuracy: 0.7243\n",
            "Epoch 297/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5366 - accuracy: 0.7897 - val_loss: 0.5576 - val_accuracy: 0.6949\n",
            "Epoch 298/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5188 - accuracy: 0.7958 - val_loss: 0.5534 - val_accuracy: 0.7096\n",
            "Epoch 299/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5312 - accuracy: 0.7854 - val_loss: 0.5649 - val_accuracy: 0.6912\n",
            "Epoch 300/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5452 - accuracy: 0.7669 - val_loss: 0.5405 - val_accuracy: 0.7206\n",
            "Epoch 301/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5483 - accuracy: 0.7645 - val_loss: 0.5596 - val_accuracy: 0.6912\n",
            "Epoch 302/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5550 - accuracy: 0.7724 - val_loss: 0.5664 - val_accuracy: 0.6949\n",
            "Epoch 303/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5410 - accuracy: 0.7749 - val_loss: 0.5305 - val_accuracy: 0.7463\n",
            "Epoch 304/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5510 - accuracy: 0.7755 - val_loss: 0.5641 - val_accuracy: 0.7096\n",
            "Epoch 305/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5207 - accuracy: 0.7891 - val_loss: 0.5448 - val_accuracy: 0.7132\n",
            "Epoch 306/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5356 - accuracy: 0.7755 - val_loss: 0.5372 - val_accuracy: 0.7169\n",
            "Epoch 307/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5247 - accuracy: 0.7884 - val_loss: 0.5387 - val_accuracy: 0.7132\n",
            "Epoch 308/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5486 - accuracy: 0.7872 - val_loss: 0.5624 - val_accuracy: 0.6949\n",
            "Epoch 309/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5166 - accuracy: 0.7829 - val_loss: 0.5711 - val_accuracy: 0.6875\n",
            "Epoch 310/400\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5460 - accuracy: 0.7595 - val_loss: 0.5793 - val_accuracy: 0.6985\n",
            "Epoch 311/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5464 - accuracy: 0.7737 - val_loss: 0.5420 - val_accuracy: 0.7279\n",
            "Epoch 312/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5335 - accuracy: 0.7878 - val_loss: 0.5347 - val_accuracy: 0.7132\n",
            "Epoch 313/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5279 - accuracy: 0.7811 - val_loss: 0.5447 - val_accuracy: 0.7316\n",
            "Epoch 314/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5290 - accuracy: 0.7835 - val_loss: 0.5419 - val_accuracy: 0.7316\n",
            "Epoch 315/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5579 - accuracy: 0.7688 - val_loss: 0.5466 - val_accuracy: 0.7206\n",
            "Epoch 316/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5419 - accuracy: 0.7860 - val_loss: 0.5488 - val_accuracy: 0.7096\n",
            "Epoch 317/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5292 - accuracy: 0.7841 - val_loss: 0.5387 - val_accuracy: 0.7206\n",
            "Epoch 318/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5413 - accuracy: 0.7724 - val_loss: 0.5813 - val_accuracy: 0.6985\n",
            "Epoch 319/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5432 - accuracy: 0.7780 - val_loss: 0.5476 - val_accuracy: 0.7206\n",
            "Epoch 320/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5378 - accuracy: 0.7835 - val_loss: 0.5849 - val_accuracy: 0.6985\n",
            "Epoch 321/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5253 - accuracy: 0.7835 - val_loss: 0.5463 - val_accuracy: 0.7243\n",
            "Epoch 322/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5206 - accuracy: 0.7829 - val_loss: 0.5562 - val_accuracy: 0.7022\n",
            "Epoch 323/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5294 - accuracy: 0.7841 - val_loss: 0.5539 - val_accuracy: 0.7059\n",
            "Epoch 324/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5333 - accuracy: 0.7829 - val_loss: 0.5475 - val_accuracy: 0.7243\n",
            "Epoch 325/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5328 - accuracy: 0.7897 - val_loss: 0.5453 - val_accuracy: 0.7243\n",
            "Epoch 326/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5227 - accuracy: 0.7866 - val_loss: 0.5608 - val_accuracy: 0.6985\n",
            "Epoch 327/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5403 - accuracy: 0.7866 - val_loss: 0.5468 - val_accuracy: 0.7132\n",
            "Epoch 328/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5450 - accuracy: 0.7780 - val_loss: 0.5611 - val_accuracy: 0.7096\n",
            "Epoch 329/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5292 - accuracy: 0.7866 - val_loss: 0.5820 - val_accuracy: 0.7132\n",
            "Epoch 330/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5509 - accuracy: 0.7823 - val_loss: 0.5751 - val_accuracy: 0.6875\n",
            "Epoch 331/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5431 - accuracy: 0.7718 - val_loss: 0.5331 - val_accuracy: 0.7463\n",
            "Epoch 332/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5434 - accuracy: 0.7835 - val_loss: 0.5665 - val_accuracy: 0.6985\n",
            "Epoch 333/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5295 - accuracy: 0.7872 - val_loss: 0.5471 - val_accuracy: 0.7243\n",
            "Epoch 334/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5212 - accuracy: 0.7847 - val_loss: 0.5571 - val_accuracy: 0.7096\n",
            "Epoch 335/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5202 - accuracy: 0.7891 - val_loss: 0.5567 - val_accuracy: 0.7059\n",
            "Epoch 336/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5367 - accuracy: 0.7700 - val_loss: 0.5480 - val_accuracy: 0.7022\n",
            "Epoch 337/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5412 - accuracy: 0.7761 - val_loss: 0.5352 - val_accuracy: 0.7096\n",
            "Epoch 338/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5352 - accuracy: 0.7854 - val_loss: 0.5700 - val_accuracy: 0.6838\n",
            "Epoch 339/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5146 - accuracy: 0.7854 - val_loss: 0.5404 - val_accuracy: 0.7537\n",
            "Epoch 340/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5358 - accuracy: 0.7829 - val_loss: 0.5636 - val_accuracy: 0.6838\n",
            "Epoch 341/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5188 - accuracy: 0.7780 - val_loss: 0.6103 - val_accuracy: 0.7022\n",
            "Epoch 342/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5324 - accuracy: 0.7786 - val_loss: 0.5454 - val_accuracy: 0.7059\n",
            "Epoch 343/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5220 - accuracy: 0.7903 - val_loss: 0.5715 - val_accuracy: 0.6949\n",
            "Epoch 344/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5210 - accuracy: 0.7903 - val_loss: 0.5336 - val_accuracy: 0.7243\n",
            "Epoch 345/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5509 - accuracy: 0.7626 - val_loss: 0.5415 - val_accuracy: 0.7243\n",
            "Epoch 346/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5110 - accuracy: 0.7835 - val_loss: 0.5506 - val_accuracy: 0.7132\n",
            "Epoch 347/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5300 - accuracy: 0.7768 - val_loss: 0.5598 - val_accuracy: 0.7059\n",
            "Epoch 348/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5227 - accuracy: 0.7847 - val_loss: 0.5383 - val_accuracy: 0.7206\n",
            "Epoch 349/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5328 - accuracy: 0.7909 - val_loss: 0.5406 - val_accuracy: 0.7353\n",
            "Epoch 350/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5234 - accuracy: 0.7780 - val_loss: 0.5599 - val_accuracy: 0.6949\n",
            "Epoch 351/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5066 - accuracy: 0.7921 - val_loss: 0.5340 - val_accuracy: 0.7316\n",
            "Epoch 352/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5464 - accuracy: 0.7768 - val_loss: 0.5725 - val_accuracy: 0.6912\n",
            "Epoch 353/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5327 - accuracy: 0.7817 - val_loss: 0.5614 - val_accuracy: 0.6949\n",
            "Epoch 354/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5182 - accuracy: 0.7866 - val_loss: 0.5846 - val_accuracy: 0.7132\n",
            "Epoch 355/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5137 - accuracy: 0.8032 - val_loss: 0.5701 - val_accuracy: 0.6912\n",
            "Epoch 356/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5500 - accuracy: 0.7724 - val_loss: 0.5501 - val_accuracy: 0.7279\n",
            "Epoch 357/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5250 - accuracy: 0.7804 - val_loss: 0.5458 - val_accuracy: 0.7353\n",
            "Epoch 358/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5245 - accuracy: 0.7878 - val_loss: 0.5393 - val_accuracy: 0.7132\n",
            "Epoch 359/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5186 - accuracy: 0.7878 - val_loss: 0.6113 - val_accuracy: 0.7022\n",
            "Epoch 360/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5343 - accuracy: 0.7792 - val_loss: 0.5654 - val_accuracy: 0.7059\n",
            "Epoch 361/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5273 - accuracy: 0.7989 - val_loss: 0.5605 - val_accuracy: 0.7096\n",
            "Epoch 362/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5188 - accuracy: 0.7829 - val_loss: 0.5417 - val_accuracy: 0.7243\n",
            "Epoch 363/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5179 - accuracy: 0.7897 - val_loss: 0.5684 - val_accuracy: 0.6985\n",
            "Epoch 364/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5309 - accuracy: 0.7921 - val_loss: 0.5493 - val_accuracy: 0.7096\n",
            "Epoch 365/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5160 - accuracy: 0.7897 - val_loss: 0.5535 - val_accuracy: 0.7059\n",
            "Epoch 366/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5209 - accuracy: 0.7915 - val_loss: 0.5632 - val_accuracy: 0.6949\n",
            "Epoch 367/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5074 - accuracy: 0.7946 - val_loss: 0.5579 - val_accuracy: 0.7169\n",
            "Epoch 368/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5165 - accuracy: 0.7847 - val_loss: 0.5611 - val_accuracy: 0.6985\n",
            "Epoch 369/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5082 - accuracy: 0.8063 - val_loss: 0.5707 - val_accuracy: 0.6949\n",
            "Epoch 370/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5285 - accuracy: 0.7835 - val_loss: 0.5514 - val_accuracy: 0.7169\n",
            "Epoch 371/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5133 - accuracy: 0.7970 - val_loss: 0.5491 - val_accuracy: 0.7059\n",
            "Epoch 372/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5063 - accuracy: 0.7970 - val_loss: 0.5577 - val_accuracy: 0.7206\n",
            "Epoch 373/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5119 - accuracy: 0.7860 - val_loss: 0.5661 - val_accuracy: 0.6985\n",
            "Epoch 374/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5110 - accuracy: 0.7946 - val_loss: 0.5706 - val_accuracy: 0.6875\n",
            "Epoch 375/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5072 - accuracy: 0.7964 - val_loss: 0.5924 - val_accuracy: 0.6949\n",
            "Epoch 376/400\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5284 - accuracy: 0.7786 - val_loss: 0.5338 - val_accuracy: 0.7132\n",
            "Epoch 377/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5189 - accuracy: 0.7989 - val_loss: 0.5610 - val_accuracy: 0.7096\n",
            "Epoch 378/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5291 - accuracy: 0.7798 - val_loss: 0.5519 - val_accuracy: 0.7169\n",
            "Epoch 379/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5279 - accuracy: 0.7946 - val_loss: 0.5665 - val_accuracy: 0.7022\n",
            "Epoch 380/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5157 - accuracy: 0.7983 - val_loss: 0.5662 - val_accuracy: 0.6985\n",
            "Epoch 381/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5123 - accuracy: 0.7878 - val_loss: 0.5715 - val_accuracy: 0.6985\n",
            "Epoch 382/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5284 - accuracy: 0.7872 - val_loss: 0.5684 - val_accuracy: 0.7022\n",
            "Epoch 383/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5158 - accuracy: 0.7743 - val_loss: 0.5565 - val_accuracy: 0.7279\n",
            "Epoch 384/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5483 - accuracy: 0.7835 - val_loss: 0.5792 - val_accuracy: 0.7132\n",
            "Epoch 385/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5172 - accuracy: 0.7811 - val_loss: 0.5474 - val_accuracy: 0.7169\n",
            "Epoch 386/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5060 - accuracy: 0.8007 - val_loss: 0.5370 - val_accuracy: 0.7243\n",
            "Epoch 387/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5183 - accuracy: 0.7860 - val_loss: 0.5453 - val_accuracy: 0.7206\n",
            "Epoch 388/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5154 - accuracy: 0.7921 - val_loss: 0.5327 - val_accuracy: 0.7574\n",
            "Epoch 389/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5117 - accuracy: 0.7995 - val_loss: 0.5514 - val_accuracy: 0.7059\n",
            "Epoch 390/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5110 - accuracy: 0.7872 - val_loss: 0.5827 - val_accuracy: 0.6912\n",
            "Epoch 391/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4982 - accuracy: 0.7983 - val_loss: 0.5924 - val_accuracy: 0.7022\n",
            "Epoch 392/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5089 - accuracy: 0.7934 - val_loss: 0.5518 - val_accuracy: 0.7206\n",
            "Epoch 393/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5204 - accuracy: 0.7952 - val_loss: 0.5473 - val_accuracy: 0.6985\n",
            "Epoch 394/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.4993 - accuracy: 0.7921 - val_loss: 0.5637 - val_accuracy: 0.6838\n",
            "Epoch 395/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5068 - accuracy: 0.7946 - val_loss: 0.5546 - val_accuracy: 0.7096\n",
            "Epoch 396/400\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5237 - accuracy: 0.7804 - val_loss: 0.5926 - val_accuracy: 0.6912\n",
            "Epoch 397/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5117 - accuracy: 0.7897 - val_loss: 0.5780 - val_accuracy: 0.6949\n",
            "Epoch 398/400\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5232 - accuracy: 0.7927 - val_loss: 0.5637 - val_accuracy: 0.7022\n",
            "Epoch 399/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5038 - accuracy: 0.7995 - val_loss: 0.5366 - val_accuracy: 0.7243\n",
            "Epoch 400/400\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5094 - accuracy: 0.7921 - val_loss: 0.5429 - val_accuracy: 0.7169\n"
          ]
        }
      ],
      "source": [
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer= keras.optimizers.Adam(0.001, decay=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "# Start training the model.\n",
        "cnn_3d_model_training_history = model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=400,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle = True,\n",
        "                                          validation_data = (features_valid, labels_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3vimsgjjbXvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda567fd-91db-4c04-fd74-ceed41622d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 22ms/step - loss: 0.6982 - accuracy: 0.7206\n",
            "\n",
            "\n",
            "Train accuracy: 82.903 % || Test accuracy: 72.059 % || Val accuracy: 71.691 %\n",
            "Train loss: 0.455 || Test loss: 0.698 || Val loss: 0.543\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ivmaK9BlbnRQ"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'3D_CNN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p cnn_3d_{current_date_time_string}\n",
        "# Save your Model.\n",
        "model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwU8TwPrbsKB"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cvKY05ncbwof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "01bc8115-bdc0-413d-8f18-35d16fcb2f8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o1iaaDHBb5i0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "cf0207f0-40ed-482b-cf3f-9fbe1843ba58"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3D_CNN_No_Splint.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0+0Xa3ox6VMFQNJxIQ7Ff",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}