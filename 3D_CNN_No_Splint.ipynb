{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/3D_CNN_No_Splint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7I8NauauE3"
      },
      "source": [
        "####**3D Convolutional Neural Network**\n",
        "######*I am using 3D Convolutional Neural Network to extract the temporal and spatial information which are merged slowly throughout the whole network.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ibtd5HKtZk",
        "outputId": "8443b2a1-3022-416e-e862-ce099ae317c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "1e82c129-8ce8-478f-8cb4-0141b4da8a80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 96, 96\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Circle_Cropped_videos_labeled'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUTeIqzpZc9J"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QRDbHG0TZkYJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(96, 96)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            # frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "547fd88b-3b13-429c-d79e-470568541054"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-9ykP4ig7IW"
      },
      "outputs": [],
      "source": [
        "def create_3D_CNN_model():\n",
        "    sample_shape = (16, 96, 96, 3)\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv3D(8, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4),\n",
        "                     input_shape=sample_shape))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv3D(16, (3,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(GlobalAveragePooling3D())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "\n",
        "    model.summary(line_length = 125)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_GxXZBcHlB",
        "outputId": "12cb8516-1c30-42ee-d659-ca22e2b13b81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_____________________________________________________________________________________________________________________________\n",
            " Layer (type)                                           Output Shape                                      Param #            \n",
            "=============================================================================================================================\n",
            " conv3d (Conv3D)                                        (None, 16, 94, 94, 8)                             224                \n",
            "                                                                                                                             \n",
            " max_pooling3d (MaxPooling3D)                           (None, 8, 47, 47, 8)                              0                  \n",
            "                                                                                                                             \n",
            " dropout (Dropout)                                      (None, 8, 47, 47, 8)                              0                  \n",
            "                                                                                                                             \n",
            " conv3d_1 (Conv3D)                                      (None, 6, 45, 45, 16)                             3472               \n",
            "                                                                                                                             \n",
            " max_pooling3d_1 (MaxPooling3D)                         (None, 3, 22, 22, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_1 (Dropout)                                    (None, 3, 22, 22, 16)                             0                  \n",
            "                                                                                                                             \n",
            " global_average_pooling3d (GlobalAveragePooling3D)      (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dropout_2 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense (Dense)                                          (None, 16)                                        272                \n",
            "                                                                                                                             \n",
            " dropout_3 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense_1 (Dense)                                        (None, 8)                                         136                \n",
            "                                                                                                                             \n",
            " dense_2 (Dense)                                        (None, 4)                                         36                 \n",
            "                                                                                                                             \n",
            "=============================================================================================================================\n",
            "Total params: 4,140\n",
            "Trainable params: 4,140\n",
            "Non-trainable params: 0\n",
            "_____________________________________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "model = create_3D_CNN_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYEkaYLoyb_",
        "outputId": "c85ab5c2-9e7e-4aa8-9021-eb9b4938e306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "26/26 [==============================] - 5s 108ms/step - loss: 1.5281 - accuracy: 0.2128 - val_loss: 1.3354 - val_accuracy: 0.3971\n",
            "Epoch 2/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.3238 - accuracy: 0.4010 - val_loss: 1.2926 - val_accuracy: 0.3971\n",
            "Epoch 3/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.2705 - accuracy: 0.4379 - val_loss: 1.2525 - val_accuracy: 0.3971\n",
            "Epoch 4/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.2236 - accuracy: 0.4539 - val_loss: 1.2213 - val_accuracy: 0.3971\n",
            "Epoch 5/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.2087 - accuracy: 0.4551 - val_loss: 1.1978 - val_accuracy: 0.3971\n",
            "Epoch 6/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.1703 - accuracy: 0.4477 - val_loss: 1.1489 - val_accuracy: 0.3971\n",
            "Epoch 7/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 1.1470 - accuracy: 0.4508 - val_loss: 1.1247 - val_accuracy: 0.3971\n",
            "Epoch 8/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.1215 - accuracy: 0.4514 - val_loss: 1.0991 - val_accuracy: 0.3971\n",
            "Epoch 9/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.0850 - accuracy: 0.4686 - val_loss: 1.0573 - val_accuracy: 0.5184\n",
            "Epoch 10/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.0625 - accuracy: 0.5012 - val_loss: 1.0103 - val_accuracy: 0.5184\n",
            "Epoch 11/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.0400 - accuracy: 0.5105 - val_loss: 1.0229 - val_accuracy: 0.5221\n",
            "Epoch 12/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.0066 - accuracy: 0.5000 - val_loss: 0.9374 - val_accuracy: 0.5184\n",
            "Epoch 13/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9837 - accuracy: 0.5055 - val_loss: 0.9246 - val_accuracy: 0.5625\n",
            "Epoch 14/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9760 - accuracy: 0.5332 - val_loss: 0.9396 - val_accuracy: 0.5625\n",
            "Epoch 15/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9567 - accuracy: 0.5203 - val_loss: 0.9078 - val_accuracy: 0.5515\n",
            "Epoch 16/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9414 - accuracy: 0.5394 - val_loss: 0.9136 - val_accuracy: 0.5441\n",
            "Epoch 17/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9385 - accuracy: 0.5492 - val_loss: 0.8850 - val_accuracy: 0.5809\n",
            "Epoch 18/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9419 - accuracy: 0.5443 - val_loss: 0.8643 - val_accuracy: 0.6176\n",
            "Epoch 19/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9244 - accuracy: 0.5529 - val_loss: 0.8792 - val_accuracy: 0.6213\n",
            "Epoch 20/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9274 - accuracy: 0.5609 - val_loss: 0.8709 - val_accuracy: 0.5699\n",
            "Epoch 21/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9081 - accuracy: 0.5732 - val_loss: 0.8426 - val_accuracy: 0.6287\n",
            "Epoch 22/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.9047 - accuracy: 0.5510 - val_loss: 0.8872 - val_accuracy: 0.5772\n",
            "Epoch 23/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9210 - accuracy: 0.5652 - val_loss: 0.8859 - val_accuracy: 0.5772\n",
            "Epoch 24/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8882 - accuracy: 0.5670 - val_loss: 0.8338 - val_accuracy: 0.6176\n",
            "Epoch 25/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8846 - accuracy: 0.5886 - val_loss: 0.8207 - val_accuracy: 0.6397\n",
            "Epoch 26/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8776 - accuracy: 0.5879 - val_loss: 0.8165 - val_accuracy: 0.6213\n",
            "Epoch 27/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8705 - accuracy: 0.5959 - val_loss: 0.8052 - val_accuracy: 0.5993\n",
            "Epoch 28/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8744 - accuracy: 0.5935 - val_loss: 0.8173 - val_accuracy: 0.6324\n",
            "Epoch 29/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8756 - accuracy: 0.5756 - val_loss: 0.8062 - val_accuracy: 0.6140\n",
            "Epoch 30/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8761 - accuracy: 0.6046 - val_loss: 0.7970 - val_accuracy: 0.6324\n",
            "Epoch 31/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8757 - accuracy: 0.5707 - val_loss: 0.7958 - val_accuracy: 0.6250\n",
            "Epoch 32/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8390 - accuracy: 0.6009 - val_loss: 0.7757 - val_accuracy: 0.6103\n",
            "Epoch 33/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8391 - accuracy: 0.5966 - val_loss: 0.7724 - val_accuracy: 0.6029\n",
            "Epoch 34/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8403 - accuracy: 0.6101 - val_loss: 0.7728 - val_accuracy: 0.6103\n",
            "Epoch 35/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8403 - accuracy: 0.6064 - val_loss: 0.7802 - val_accuracy: 0.6324\n",
            "Epoch 36/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8441 - accuracy: 0.6107 - val_loss: 0.7588 - val_accuracy: 0.6140\n",
            "Epoch 37/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8365 - accuracy: 0.6150 - val_loss: 0.7644 - val_accuracy: 0.6287\n",
            "Epoch 38/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8264 - accuracy: 0.6107 - val_loss: 0.7659 - val_accuracy: 0.6507\n",
            "Epoch 39/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8215 - accuracy: 0.6162 - val_loss: 0.7558 - val_accuracy: 0.6066\n",
            "Epoch 40/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8253 - accuracy: 0.6101 - val_loss: 0.7603 - val_accuracy: 0.6140\n",
            "Epoch 41/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8306 - accuracy: 0.6119 - val_loss: 0.7622 - val_accuracy: 0.6213\n",
            "Epoch 42/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8316 - accuracy: 0.6101 - val_loss: 0.7566 - val_accuracy: 0.6287\n",
            "Epoch 43/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8330 - accuracy: 0.6076 - val_loss: 0.7630 - val_accuracy: 0.6140\n",
            "Epoch 44/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8093 - accuracy: 0.6175 - val_loss: 0.7844 - val_accuracy: 0.6434\n",
            "Epoch 45/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8099 - accuracy: 0.6384 - val_loss: 0.7486 - val_accuracy: 0.6360\n",
            "Epoch 46/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8047 - accuracy: 0.6451 - val_loss: 0.7557 - val_accuracy: 0.6434\n",
            "Epoch 47/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8279 - accuracy: 0.6279 - val_loss: 0.7582 - val_accuracy: 0.6250\n",
            "Epoch 48/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7934 - accuracy: 0.6341 - val_loss: 0.7359 - val_accuracy: 0.6360\n",
            "Epoch 49/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8000 - accuracy: 0.6347 - val_loss: 0.7424 - val_accuracy: 0.6360\n",
            "Epoch 50/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8037 - accuracy: 0.6267 - val_loss: 0.7326 - val_accuracy: 0.6471\n",
            "Epoch 51/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7827 - accuracy: 0.6427 - val_loss: 0.7183 - val_accuracy: 0.6434\n",
            "Epoch 52/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7785 - accuracy: 0.6525 - val_loss: 0.7139 - val_accuracy: 0.6213\n",
            "Epoch 53/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7721 - accuracy: 0.6531 - val_loss: 0.7285 - val_accuracy: 0.6581\n",
            "Epoch 54/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8007 - accuracy: 0.6415 - val_loss: 0.7201 - val_accuracy: 0.6397\n",
            "Epoch 55/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7779 - accuracy: 0.6587 - val_loss: 0.7326 - val_accuracy: 0.6544\n",
            "Epoch 56/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7817 - accuracy: 0.6562 - val_loss: 0.7263 - val_accuracy: 0.6985\n",
            "Epoch 57/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7806 - accuracy: 0.6556 - val_loss: 0.6999 - val_accuracy: 0.6397\n",
            "Epoch 58/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7638 - accuracy: 0.6611 - val_loss: 0.6991 - val_accuracy: 0.6397\n",
            "Epoch 59/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7766 - accuracy: 0.6445 - val_loss: 0.7037 - val_accuracy: 0.6544\n",
            "Epoch 60/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7603 - accuracy: 0.6581 - val_loss: 0.6953 - val_accuracy: 0.6434\n",
            "Epoch 61/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7580 - accuracy: 0.6691 - val_loss: 0.6950 - val_accuracy: 0.6471\n",
            "Epoch 62/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7593 - accuracy: 0.6605 - val_loss: 0.6924 - val_accuracy: 0.6728\n",
            "Epoch 63/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7448 - accuracy: 0.6808 - val_loss: 0.6830 - val_accuracy: 0.7096\n",
            "Epoch 64/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7464 - accuracy: 0.6697 - val_loss: 0.6962 - val_accuracy: 0.6765\n",
            "Epoch 65/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7504 - accuracy: 0.6802 - val_loss: 0.6760 - val_accuracy: 0.6507\n",
            "Epoch 66/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7442 - accuracy: 0.6759 - val_loss: 0.6710 - val_accuracy: 0.6691\n",
            "Epoch 67/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7440 - accuracy: 0.6642 - val_loss: 0.6673 - val_accuracy: 0.6838\n",
            "Epoch 68/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7528 - accuracy: 0.6722 - val_loss: 0.6772 - val_accuracy: 0.6618\n",
            "Epoch 69/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7433 - accuracy: 0.6845 - val_loss: 0.6706 - val_accuracy: 0.6581\n",
            "Epoch 70/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7375 - accuracy: 0.6771 - val_loss: 0.6634 - val_accuracy: 0.6434\n",
            "Epoch 71/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7274 - accuracy: 0.6759 - val_loss: 0.6611 - val_accuracy: 0.6544\n",
            "Epoch 72/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7308 - accuracy: 0.6814 - val_loss: 0.6495 - val_accuracy: 0.6728\n",
            "Epoch 73/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7326 - accuracy: 0.6716 - val_loss: 0.6553 - val_accuracy: 0.6801\n",
            "Epoch 74/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7279 - accuracy: 0.6796 - val_loss: 0.6686 - val_accuracy: 0.6728\n",
            "Epoch 75/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7220 - accuracy: 0.6925 - val_loss: 0.6569 - val_accuracy: 0.6838\n",
            "Epoch 76/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7351 - accuracy: 0.6882 - val_loss: 0.6780 - val_accuracy: 0.6875\n",
            "Epoch 77/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7084 - accuracy: 0.6986 - val_loss: 0.6308 - val_accuracy: 0.7022\n",
            "Epoch 78/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7036 - accuracy: 0.6943 - val_loss: 0.6297 - val_accuracy: 0.7279\n",
            "Epoch 79/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7263 - accuracy: 0.6882 - val_loss: 0.6524 - val_accuracy: 0.6912\n",
            "Epoch 80/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7137 - accuracy: 0.6913 - val_loss: 0.6473 - val_accuracy: 0.7022\n",
            "Epoch 81/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7085 - accuracy: 0.7048 - val_loss: 0.6454 - val_accuracy: 0.6801\n",
            "Epoch 82/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7244 - accuracy: 0.6845 - val_loss: 0.6342 - val_accuracy: 0.7169\n",
            "Epoch 83/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7069 - accuracy: 0.7023 - val_loss: 0.6262 - val_accuracy: 0.7022\n",
            "Epoch 84/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7039 - accuracy: 0.7060 - val_loss: 0.6523 - val_accuracy: 0.6949\n",
            "Epoch 85/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7141 - accuracy: 0.6870 - val_loss: 0.6290 - val_accuracy: 0.6985\n",
            "Epoch 86/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6996 - accuracy: 0.6999 - val_loss: 0.6510 - val_accuracy: 0.6912\n",
            "Epoch 87/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6916 - accuracy: 0.7005 - val_loss: 0.6175 - val_accuracy: 0.7316\n",
            "Epoch 88/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7028 - accuracy: 0.7017 - val_loss: 0.6679 - val_accuracy: 0.6912\n",
            "Epoch 89/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6909 - accuracy: 0.6968 - val_loss: 0.6202 - val_accuracy: 0.7316\n",
            "Epoch 90/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7004 - accuracy: 0.7079 - val_loss: 0.6080 - val_accuracy: 0.7279\n",
            "Epoch 91/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7001 - accuracy: 0.6913 - val_loss: 0.6216 - val_accuracy: 0.7096\n",
            "Epoch 92/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6902 - accuracy: 0.7042 - val_loss: 0.6384 - val_accuracy: 0.7059\n",
            "Epoch 93/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6885 - accuracy: 0.7183 - val_loss: 0.5938 - val_accuracy: 0.7390\n",
            "Epoch 94/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6887 - accuracy: 0.7079 - val_loss: 0.5979 - val_accuracy: 0.7353\n",
            "Epoch 95/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6744 - accuracy: 0.7189 - val_loss: 0.6277 - val_accuracy: 0.7022\n",
            "Epoch 96/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6784 - accuracy: 0.7060 - val_loss: 0.5919 - val_accuracy: 0.7316\n",
            "Epoch 97/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6764 - accuracy: 0.7214 - val_loss: 0.5910 - val_accuracy: 0.7206\n",
            "Epoch 98/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6639 - accuracy: 0.7232 - val_loss: 0.5765 - val_accuracy: 0.7574\n",
            "Epoch 99/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6984 - accuracy: 0.7017 - val_loss: 0.6026 - val_accuracy: 0.6985\n",
            "Epoch 100/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6689 - accuracy: 0.7091 - val_loss: 0.5880 - val_accuracy: 0.7353\n",
            "Epoch 101/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6701 - accuracy: 0.7140 - val_loss: 0.5817 - val_accuracy: 0.7574\n",
            "Epoch 102/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6649 - accuracy: 0.7122 - val_loss: 0.5960 - val_accuracy: 0.7059\n",
            "Epoch 103/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6630 - accuracy: 0.7116 - val_loss: 0.5802 - val_accuracy: 0.7390\n",
            "Epoch 104/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6476 - accuracy: 0.7257 - val_loss: 0.5652 - val_accuracy: 0.7537\n",
            "Epoch 105/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6760 - accuracy: 0.7091 - val_loss: 0.6019 - val_accuracy: 0.7059\n",
            "Epoch 106/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6772 - accuracy: 0.7103 - val_loss: 0.5791 - val_accuracy: 0.7574\n",
            "Epoch 107/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6645 - accuracy: 0.7288 - val_loss: 0.5834 - val_accuracy: 0.7169\n",
            "Epoch 108/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6560 - accuracy: 0.7239 - val_loss: 0.5672 - val_accuracy: 0.7463\n",
            "Epoch 109/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6495 - accuracy: 0.7282 - val_loss: 0.6454 - val_accuracy: 0.6985\n",
            "Epoch 110/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6622 - accuracy: 0.7183 - val_loss: 0.5688 - val_accuracy: 0.7426\n",
            "Epoch 111/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6594 - accuracy: 0.7189 - val_loss: 0.5754 - val_accuracy: 0.7390\n",
            "Epoch 112/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6457 - accuracy: 0.7312 - val_loss: 0.5680 - val_accuracy: 0.7500\n",
            "Epoch 113/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6633 - accuracy: 0.7159 - val_loss: 0.5728 - val_accuracy: 0.7500\n",
            "Epoch 114/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6554 - accuracy: 0.7159 - val_loss: 0.5974 - val_accuracy: 0.7059\n",
            "Epoch 115/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6333 - accuracy: 0.7386 - val_loss: 0.5615 - val_accuracy: 0.7500\n",
            "Epoch 116/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6403 - accuracy: 0.7226 - val_loss: 0.5696 - val_accuracy: 0.7390\n",
            "Epoch 117/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6730 - accuracy: 0.7232 - val_loss: 0.5686 - val_accuracy: 0.7279\n",
            "Epoch 118/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6624 - accuracy: 0.7177 - val_loss: 0.5704 - val_accuracy: 0.7463\n",
            "Epoch 119/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6423 - accuracy: 0.7429 - val_loss: 0.6105 - val_accuracy: 0.6912\n",
            "Epoch 120/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6513 - accuracy: 0.7355 - val_loss: 0.5646 - val_accuracy: 0.7353\n",
            "Epoch 121/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6503 - accuracy: 0.7159 - val_loss: 0.6298 - val_accuracy: 0.7022\n",
            "Epoch 122/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6377 - accuracy: 0.7276 - val_loss: 0.5553 - val_accuracy: 0.7500\n",
            "Epoch 123/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6336 - accuracy: 0.7337 - val_loss: 0.5635 - val_accuracy: 0.7463\n",
            "Epoch 124/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6475 - accuracy: 0.7300 - val_loss: 0.5671 - val_accuracy: 0.7610\n",
            "Epoch 125/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6359 - accuracy: 0.7362 - val_loss: 0.6013 - val_accuracy: 0.6912\n",
            "Epoch 126/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6439 - accuracy: 0.7220 - val_loss: 0.5911 - val_accuracy: 0.7096\n",
            "Epoch 127/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6378 - accuracy: 0.7325 - val_loss: 0.5498 - val_accuracy: 0.7610\n",
            "Epoch 128/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6332 - accuracy: 0.7355 - val_loss: 0.5731 - val_accuracy: 0.7426\n",
            "Epoch 129/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6281 - accuracy: 0.7460 - val_loss: 0.5695 - val_accuracy: 0.7390\n",
            "Epoch 130/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6153 - accuracy: 0.7503 - val_loss: 0.5834 - val_accuracy: 0.6949\n",
            "Epoch 131/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6328 - accuracy: 0.7263 - val_loss: 0.6094 - val_accuracy: 0.7022\n",
            "Epoch 132/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6273 - accuracy: 0.7337 - val_loss: 0.6077 - val_accuracy: 0.7059\n",
            "Epoch 133/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6074 - accuracy: 0.7472 - val_loss: 0.5838 - val_accuracy: 0.6949\n",
            "Epoch 134/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6195 - accuracy: 0.7386 - val_loss: 0.5626 - val_accuracy: 0.7390\n",
            "Epoch 135/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6388 - accuracy: 0.7374 - val_loss: 0.5826 - val_accuracy: 0.7279\n",
            "Epoch 136/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6161 - accuracy: 0.7399 - val_loss: 0.5925 - val_accuracy: 0.6838\n",
            "Epoch 137/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6401 - accuracy: 0.7294 - val_loss: 0.5720 - val_accuracy: 0.7390\n",
            "Epoch 138/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6110 - accuracy: 0.7478 - val_loss: 0.5643 - val_accuracy: 0.7206\n",
            "Epoch 139/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6099 - accuracy: 0.7429 - val_loss: 0.5932 - val_accuracy: 0.6985\n",
            "Epoch 140/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6177 - accuracy: 0.7429 - val_loss: 0.6145 - val_accuracy: 0.6838\n",
            "Epoch 141/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6165 - accuracy: 0.7429 - val_loss: 0.5669 - val_accuracy: 0.7426\n",
            "Epoch 142/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6189 - accuracy: 0.7362 - val_loss: 0.5878 - val_accuracy: 0.7243\n",
            "Epoch 143/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6175 - accuracy: 0.7405 - val_loss: 0.5551 - val_accuracy: 0.7390\n",
            "Epoch 144/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6232 - accuracy: 0.7392 - val_loss: 0.5948 - val_accuracy: 0.6838\n",
            "Epoch 145/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6223 - accuracy: 0.7343 - val_loss: 0.5917 - val_accuracy: 0.7059\n",
            "Epoch 146/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6133 - accuracy: 0.7472 - val_loss: 0.5684 - val_accuracy: 0.7243\n",
            "Epoch 147/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6241 - accuracy: 0.7288 - val_loss: 0.5813 - val_accuracy: 0.7096\n",
            "Epoch 148/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6211 - accuracy: 0.7362 - val_loss: 0.5482 - val_accuracy: 0.7463\n",
            "Epoch 149/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6190 - accuracy: 0.7454 - val_loss: 0.5885 - val_accuracy: 0.6949\n",
            "Epoch 150/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6146 - accuracy: 0.7374 - val_loss: 0.5733 - val_accuracy: 0.7169\n",
            "Epoch 151/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6202 - accuracy: 0.7294 - val_loss: 0.6323 - val_accuracy: 0.6838\n",
            "Epoch 152/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6025 - accuracy: 0.7411 - val_loss: 0.5449 - val_accuracy: 0.7390\n",
            "Epoch 153/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6015 - accuracy: 0.7497 - val_loss: 0.5545 - val_accuracy: 0.7426\n",
            "Epoch 154/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6070 - accuracy: 0.7423 - val_loss: 0.5692 - val_accuracy: 0.7132\n",
            "Epoch 155/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5926 - accuracy: 0.7565 - val_loss: 0.5618 - val_accuracy: 0.7132\n",
            "Epoch 156/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5861 - accuracy: 0.7620 - val_loss: 0.5219 - val_accuracy: 0.7610\n",
            "Epoch 157/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6045 - accuracy: 0.7491 - val_loss: 0.5677 - val_accuracy: 0.7059\n",
            "Epoch 158/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5910 - accuracy: 0.7688 - val_loss: 0.5585 - val_accuracy: 0.7390\n",
            "Epoch 159/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5926 - accuracy: 0.7589 - val_loss: 0.5954 - val_accuracy: 0.6985\n",
            "Epoch 160/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5927 - accuracy: 0.7472 - val_loss: 0.5617 - val_accuracy: 0.7132\n",
            "Epoch 161/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5997 - accuracy: 0.7651 - val_loss: 0.5445 - val_accuracy: 0.7316\n",
            "Epoch 162/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6088 - accuracy: 0.7485 - val_loss: 0.5517 - val_accuracy: 0.7426\n",
            "Epoch 163/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5889 - accuracy: 0.7651 - val_loss: 0.5959 - val_accuracy: 0.6838\n",
            "Epoch 164/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5970 - accuracy: 0.7460 - val_loss: 0.5705 - val_accuracy: 0.7279\n",
            "Epoch 165/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5995 - accuracy: 0.7411 - val_loss: 0.6037 - val_accuracy: 0.6949\n",
            "Epoch 166/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5917 - accuracy: 0.7552 - val_loss: 0.5941 - val_accuracy: 0.6912\n",
            "Epoch 167/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6109 - accuracy: 0.7319 - val_loss: 0.5725 - val_accuracy: 0.7279\n",
            "Epoch 168/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5964 - accuracy: 0.7558 - val_loss: 0.5508 - val_accuracy: 0.7132\n",
            "Epoch 169/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5924 - accuracy: 0.7558 - val_loss: 0.5317 - val_accuracy: 0.7463\n",
            "Epoch 170/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6032 - accuracy: 0.7546 - val_loss: 0.5431 - val_accuracy: 0.7390\n",
            "Epoch 171/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5987 - accuracy: 0.7614 - val_loss: 0.5790 - val_accuracy: 0.7022\n",
            "Epoch 172/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5935 - accuracy: 0.7509 - val_loss: 0.6193 - val_accuracy: 0.6912\n",
            "Epoch 173/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5954 - accuracy: 0.7491 - val_loss: 0.5694 - val_accuracy: 0.7059\n",
            "Epoch 174/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5845 - accuracy: 0.7583 - val_loss: 0.5536 - val_accuracy: 0.7096\n",
            "Epoch 175/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5863 - accuracy: 0.7626 - val_loss: 0.5988 - val_accuracy: 0.7059\n",
            "Epoch 176/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5963 - accuracy: 0.7429 - val_loss: 0.5537 - val_accuracy: 0.7316\n",
            "Epoch 177/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5792 - accuracy: 0.7657 - val_loss: 0.5936 - val_accuracy: 0.6949\n",
            "Epoch 178/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5662 - accuracy: 0.7614 - val_loss: 0.5171 - val_accuracy: 0.7684\n",
            "Epoch 179/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5810 - accuracy: 0.7632 - val_loss: 0.5831 - val_accuracy: 0.6912\n",
            "Epoch 180/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5817 - accuracy: 0.7669 - val_loss: 0.5611 - val_accuracy: 0.7169\n",
            "Epoch 181/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5727 - accuracy: 0.7669 - val_loss: 0.5676 - val_accuracy: 0.7132\n",
            "Epoch 182/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5960 - accuracy: 0.7503 - val_loss: 0.5799 - val_accuracy: 0.7059\n",
            "Epoch 183/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6031 - accuracy: 0.7435 - val_loss: 0.6122 - val_accuracy: 0.7059\n",
            "Epoch 184/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6134 - accuracy: 0.7466 - val_loss: 0.5566 - val_accuracy: 0.7316\n",
            "Epoch 185/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5895 - accuracy: 0.7565 - val_loss: 0.5676 - val_accuracy: 0.7096\n",
            "Epoch 186/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5752 - accuracy: 0.7620 - val_loss: 0.5383 - val_accuracy: 0.7243\n",
            "Epoch 187/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5865 - accuracy: 0.7522 - val_loss: 0.5958 - val_accuracy: 0.7059\n",
            "Epoch 188/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5821 - accuracy: 0.7577 - val_loss: 0.5808 - val_accuracy: 0.6912\n",
            "Epoch 189/500\n",
            "26/26 [==============================] - 2s 81ms/step - loss: 0.5663 - accuracy: 0.7712 - val_loss: 0.5795 - val_accuracy: 0.6949\n",
            "Epoch 190/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5688 - accuracy: 0.7792 - val_loss: 0.6110 - val_accuracy: 0.6838\n",
            "Epoch 191/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5841 - accuracy: 0.7571 - val_loss: 0.5289 - val_accuracy: 0.7463\n",
            "Epoch 192/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5564 - accuracy: 0.7558 - val_loss: 0.6258 - val_accuracy: 0.6912\n",
            "Epoch 193/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5688 - accuracy: 0.7755 - val_loss: 0.5890 - val_accuracy: 0.6949\n",
            "Epoch 194/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5561 - accuracy: 0.7663 - val_loss: 0.5897 - val_accuracy: 0.7059\n",
            "Epoch 195/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5636 - accuracy: 0.7595 - val_loss: 0.5955 - val_accuracy: 0.7059\n",
            "Epoch 196/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5796 - accuracy: 0.7429 - val_loss: 0.5824 - val_accuracy: 0.6949\n",
            "Epoch 197/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5557 - accuracy: 0.7626 - val_loss: 0.5837 - val_accuracy: 0.7059\n",
            "Epoch 198/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5568 - accuracy: 0.7768 - val_loss: 0.5669 - val_accuracy: 0.6912\n",
            "Epoch 199/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5776 - accuracy: 0.7645 - val_loss: 0.5715 - val_accuracy: 0.6949\n",
            "Epoch 200/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5875 - accuracy: 0.7663 - val_loss: 0.5517 - val_accuracy: 0.7243\n",
            "Epoch 201/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5682 - accuracy: 0.7614 - val_loss: 0.5961 - val_accuracy: 0.6875\n",
            "Epoch 202/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5610 - accuracy: 0.7595 - val_loss: 0.5142 - val_accuracy: 0.7390\n",
            "Epoch 203/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5868 - accuracy: 0.7540 - val_loss: 0.5903 - val_accuracy: 0.6912\n",
            "Epoch 204/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5708 - accuracy: 0.7571 - val_loss: 0.5711 - val_accuracy: 0.6949\n",
            "Epoch 205/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5593 - accuracy: 0.7681 - val_loss: 0.5510 - val_accuracy: 0.7279\n",
            "Epoch 206/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5700 - accuracy: 0.7565 - val_loss: 0.6282 - val_accuracy: 0.6875\n",
            "Epoch 207/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5558 - accuracy: 0.7731 - val_loss: 0.5683 - val_accuracy: 0.7022\n",
            "Epoch 208/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5704 - accuracy: 0.7626 - val_loss: 0.5661 - val_accuracy: 0.7169\n",
            "Epoch 209/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5728 - accuracy: 0.7712 - val_loss: 0.5703 - val_accuracy: 0.6985\n",
            "Epoch 210/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5768 - accuracy: 0.7571 - val_loss: 0.5448 - val_accuracy: 0.7022\n",
            "Epoch 211/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5557 - accuracy: 0.7835 - val_loss: 0.5677 - val_accuracy: 0.7132\n",
            "Epoch 212/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5753 - accuracy: 0.7589 - val_loss: 0.6012 - val_accuracy: 0.6949\n",
            "Epoch 213/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5701 - accuracy: 0.7669 - val_loss: 0.5991 - val_accuracy: 0.6949\n",
            "Epoch 214/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5461 - accuracy: 0.7804 - val_loss: 0.5788 - val_accuracy: 0.6912\n",
            "Epoch 215/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5543 - accuracy: 0.7749 - val_loss: 0.5225 - val_accuracy: 0.7426\n",
            "Epoch 216/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5553 - accuracy: 0.7718 - val_loss: 0.5710 - val_accuracy: 0.6949\n",
            "Epoch 217/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5657 - accuracy: 0.7626 - val_loss: 0.5490 - val_accuracy: 0.7132\n",
            "Epoch 218/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5683 - accuracy: 0.7694 - val_loss: 0.5519 - val_accuracy: 0.6949\n",
            "Epoch 219/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5612 - accuracy: 0.7694 - val_loss: 0.6049 - val_accuracy: 0.6912\n",
            "Epoch 220/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5640 - accuracy: 0.7577 - val_loss: 0.6228 - val_accuracy: 0.6912\n",
            "Epoch 221/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5579 - accuracy: 0.7731 - val_loss: 0.5645 - val_accuracy: 0.6985\n",
            "Epoch 222/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5542 - accuracy: 0.7737 - val_loss: 0.5473 - val_accuracy: 0.7390\n",
            "Epoch 223/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5561 - accuracy: 0.7847 - val_loss: 0.5493 - val_accuracy: 0.7096\n",
            "Epoch 224/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5629 - accuracy: 0.7675 - val_loss: 0.5621 - val_accuracy: 0.6949\n",
            "Epoch 225/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5729 - accuracy: 0.7688 - val_loss: 0.5143 - val_accuracy: 0.7353\n",
            "Epoch 226/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5532 - accuracy: 0.7694 - val_loss: 0.5964 - val_accuracy: 0.6912\n",
            "Epoch 227/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5398 - accuracy: 0.7731 - val_loss: 0.5918 - val_accuracy: 0.6912\n",
            "Epoch 228/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5668 - accuracy: 0.7718 - val_loss: 0.5377 - val_accuracy: 0.7169\n",
            "Epoch 229/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5672 - accuracy: 0.7712 - val_loss: 0.6130 - val_accuracy: 0.6875\n",
            "Epoch 230/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5476 - accuracy: 0.7786 - val_loss: 0.5858 - val_accuracy: 0.6912\n",
            "Epoch 231/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5476 - accuracy: 0.7712 - val_loss: 0.5250 - val_accuracy: 0.7426\n",
            "Epoch 232/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5496 - accuracy: 0.7780 - val_loss: 0.5478 - val_accuracy: 0.7022\n",
            "Epoch 233/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5397 - accuracy: 0.7712 - val_loss: 0.5416 - val_accuracy: 0.7316\n",
            "Epoch 234/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5742 - accuracy: 0.7626 - val_loss: 0.5769 - val_accuracy: 0.6912\n",
            "Epoch 235/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5687 - accuracy: 0.7645 - val_loss: 0.5628 - val_accuracy: 0.7059\n",
            "Epoch 236/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5763 - accuracy: 0.7749 - val_loss: 0.5736 - val_accuracy: 0.6912\n",
            "Epoch 237/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5696 - accuracy: 0.7768 - val_loss: 0.5554 - val_accuracy: 0.7279\n",
            "Epoch 238/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5668 - accuracy: 0.7675 - val_loss: 0.5487 - val_accuracy: 0.6875\n",
            "Epoch 239/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5541 - accuracy: 0.7774 - val_loss: 0.5242 - val_accuracy: 0.7390\n",
            "Epoch 240/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5511 - accuracy: 0.7768 - val_loss: 0.5976 - val_accuracy: 0.6912\n",
            "Epoch 241/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5496 - accuracy: 0.7737 - val_loss: 0.5302 - val_accuracy: 0.7132\n",
            "Epoch 242/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5445 - accuracy: 0.7700 - val_loss: 0.5530 - val_accuracy: 0.7132\n",
            "Epoch 243/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5604 - accuracy: 0.7626 - val_loss: 0.6200 - val_accuracy: 0.6838\n",
            "Epoch 244/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5568 - accuracy: 0.7694 - val_loss: 0.5426 - val_accuracy: 0.7096\n",
            "Epoch 245/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5568 - accuracy: 0.7866 - val_loss: 0.6077 - val_accuracy: 0.6912\n",
            "Epoch 246/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5516 - accuracy: 0.7718 - val_loss: 0.5309 - val_accuracy: 0.7169\n",
            "Epoch 247/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5416 - accuracy: 0.7675 - val_loss: 0.5348 - val_accuracy: 0.7279\n",
            "Epoch 248/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5306 - accuracy: 0.7731 - val_loss: 0.5214 - val_accuracy: 0.7426\n",
            "Epoch 249/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5631 - accuracy: 0.7743 - val_loss: 0.6182 - val_accuracy: 0.6912\n",
            "Epoch 250/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5668 - accuracy: 0.7669 - val_loss: 0.5411 - val_accuracy: 0.7206\n",
            "Epoch 251/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5402 - accuracy: 0.7841 - val_loss: 0.5507 - val_accuracy: 0.6875\n",
            "Epoch 252/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5514 - accuracy: 0.7817 - val_loss: 0.5583 - val_accuracy: 0.7206\n",
            "Epoch 253/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5390 - accuracy: 0.7897 - val_loss: 0.5561 - val_accuracy: 0.6949\n",
            "Epoch 254/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5508 - accuracy: 0.7749 - val_loss: 0.5830 - val_accuracy: 0.6838\n",
            "Epoch 255/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5533 - accuracy: 0.7829 - val_loss: 0.5456 - val_accuracy: 0.7132\n",
            "Epoch 256/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5543 - accuracy: 0.7669 - val_loss: 0.6026 - val_accuracy: 0.6801\n",
            "Epoch 257/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5551 - accuracy: 0.7860 - val_loss: 0.5271 - val_accuracy: 0.7206\n",
            "Epoch 258/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5542 - accuracy: 0.7694 - val_loss: 0.6058 - val_accuracy: 0.6912\n",
            "Epoch 259/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5406 - accuracy: 0.7712 - val_loss: 0.5157 - val_accuracy: 0.7243\n",
            "Epoch 260/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5540 - accuracy: 0.7663 - val_loss: 0.5648 - val_accuracy: 0.6985\n",
            "Epoch 261/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5358 - accuracy: 0.7970 - val_loss: 0.5595 - val_accuracy: 0.6875\n",
            "Epoch 262/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5337 - accuracy: 0.7761 - val_loss: 0.5745 - val_accuracy: 0.6801\n",
            "Epoch 263/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5559 - accuracy: 0.7608 - val_loss: 0.5524 - val_accuracy: 0.7022\n",
            "Epoch 264/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5286 - accuracy: 0.7823 - val_loss: 0.5776 - val_accuracy: 0.6949\n",
            "Epoch 265/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5496 - accuracy: 0.7706 - val_loss: 0.5781 - val_accuracy: 0.6912\n",
            "Epoch 266/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5516 - accuracy: 0.7651 - val_loss: 0.5773 - val_accuracy: 0.6838\n",
            "Epoch 267/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5568 - accuracy: 0.7657 - val_loss: 0.5987 - val_accuracy: 0.6875\n",
            "Epoch 268/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5330 - accuracy: 0.7792 - val_loss: 0.6081 - val_accuracy: 0.6912\n",
            "Epoch 269/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5606 - accuracy: 0.7632 - val_loss: 0.5243 - val_accuracy: 0.7390\n",
            "Epoch 270/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5389 - accuracy: 0.7866 - val_loss: 0.5379 - val_accuracy: 0.7132\n",
            "Epoch 271/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5411 - accuracy: 0.7761 - val_loss: 0.5813 - val_accuracy: 0.6912\n",
            "Epoch 272/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5342 - accuracy: 0.7731 - val_loss: 0.5645 - val_accuracy: 0.6949\n",
            "Epoch 273/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5589 - accuracy: 0.7669 - val_loss: 0.5515 - val_accuracy: 0.7022\n",
            "Epoch 274/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5424 - accuracy: 0.7700 - val_loss: 0.5848 - val_accuracy: 0.6912\n",
            "Epoch 275/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5237 - accuracy: 0.7737 - val_loss: 0.5527 - val_accuracy: 0.7316\n",
            "Epoch 276/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5327 - accuracy: 0.7804 - val_loss: 0.5256 - val_accuracy: 0.7206\n",
            "Epoch 277/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5349 - accuracy: 0.7700 - val_loss: 0.5464 - val_accuracy: 0.7279\n",
            "Epoch 278/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5227 - accuracy: 0.7804 - val_loss: 0.5502 - val_accuracy: 0.6949\n",
            "Epoch 279/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5358 - accuracy: 0.7768 - val_loss: 0.5589 - val_accuracy: 0.7169\n",
            "Epoch 280/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5346 - accuracy: 0.7829 - val_loss: 0.5045 - val_accuracy: 0.7537\n",
            "Epoch 281/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5609 - accuracy: 0.7608 - val_loss: 0.5308 - val_accuracy: 0.7316\n",
            "Epoch 282/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5412 - accuracy: 0.7657 - val_loss: 0.6337 - val_accuracy: 0.6838\n",
            "Epoch 283/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5441 - accuracy: 0.7731 - val_loss: 0.5663 - val_accuracy: 0.6949\n",
            "Epoch 284/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5299 - accuracy: 0.7866 - val_loss: 0.5423 - val_accuracy: 0.7206\n",
            "Epoch 285/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5436 - accuracy: 0.7749 - val_loss: 0.5180 - val_accuracy: 0.7537\n",
            "Epoch 286/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5329 - accuracy: 0.7804 - val_loss: 0.5160 - val_accuracy: 0.7279\n",
            "Epoch 287/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5290 - accuracy: 0.7804 - val_loss: 0.5084 - val_accuracy: 0.7390\n",
            "Epoch 288/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5270 - accuracy: 0.7841 - val_loss: 0.5809 - val_accuracy: 0.6912\n",
            "Epoch 289/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5530 - accuracy: 0.7712 - val_loss: 0.5797 - val_accuracy: 0.6912\n",
            "Epoch 290/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5430 - accuracy: 0.7829 - val_loss: 0.5697 - val_accuracy: 0.6912\n",
            "Epoch 291/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5365 - accuracy: 0.7755 - val_loss: 0.5577 - val_accuracy: 0.6949\n",
            "Epoch 292/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5254 - accuracy: 0.7823 - val_loss: 0.5378 - val_accuracy: 0.7169\n",
            "Epoch 293/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5495 - accuracy: 0.7688 - val_loss: 0.5900 - val_accuracy: 0.6912\n",
            "Epoch 294/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5227 - accuracy: 0.7878 - val_loss: 0.6082 - val_accuracy: 0.6912\n",
            "Epoch 295/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5236 - accuracy: 0.7841 - val_loss: 0.5213 - val_accuracy: 0.7243\n",
            "Epoch 296/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5414 - accuracy: 0.7780 - val_loss: 0.5609 - val_accuracy: 0.6949\n",
            "Epoch 297/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5521 - accuracy: 0.7669 - val_loss: 0.5560 - val_accuracy: 0.6985\n",
            "Epoch 298/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5248 - accuracy: 0.7952 - val_loss: 0.5648 - val_accuracy: 0.6949\n",
            "Epoch 299/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5259 - accuracy: 0.7737 - val_loss: 0.5907 - val_accuracy: 0.6912\n",
            "Epoch 300/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5221 - accuracy: 0.7823 - val_loss: 0.5261 - val_accuracy: 0.7426\n",
            "Epoch 301/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5386 - accuracy: 0.7847 - val_loss: 0.5758 - val_accuracy: 0.6912\n",
            "Epoch 302/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5383 - accuracy: 0.7786 - val_loss: 0.6049 - val_accuracy: 0.6912\n",
            "Epoch 303/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5248 - accuracy: 0.7841 - val_loss: 0.5165 - val_accuracy: 0.7390\n",
            "Epoch 304/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5371 - accuracy: 0.7798 - val_loss: 0.6120 - val_accuracy: 0.6912\n",
            "Epoch 305/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5234 - accuracy: 0.7921 - val_loss: 0.5607 - val_accuracy: 0.6875\n",
            "Epoch 306/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5414 - accuracy: 0.7780 - val_loss: 0.5354 - val_accuracy: 0.7279\n",
            "Epoch 307/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5145 - accuracy: 0.7811 - val_loss: 0.5743 - val_accuracy: 0.6912\n",
            "Epoch 308/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5274 - accuracy: 0.7786 - val_loss: 0.6054 - val_accuracy: 0.6912\n",
            "Epoch 309/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5278 - accuracy: 0.7780 - val_loss: 0.5509 - val_accuracy: 0.6912\n",
            "Epoch 310/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5245 - accuracy: 0.7780 - val_loss: 0.5920 - val_accuracy: 0.6912\n",
            "Epoch 311/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5302 - accuracy: 0.7915 - val_loss: 0.5857 - val_accuracy: 0.6912\n",
            "Epoch 312/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5296 - accuracy: 0.7841 - val_loss: 0.5539 - val_accuracy: 0.6949\n",
            "Epoch 313/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5231 - accuracy: 0.7940 - val_loss: 0.5219 - val_accuracy: 0.7316\n",
            "Epoch 314/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5146 - accuracy: 0.7823 - val_loss: 0.5278 - val_accuracy: 0.7353\n",
            "Epoch 315/500\n",
            "26/26 [==============================] - 2s 81ms/step - loss: 0.5357 - accuracy: 0.7884 - val_loss: 0.5667 - val_accuracy: 0.6949\n",
            "Epoch 316/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5224 - accuracy: 0.7817 - val_loss: 0.5336 - val_accuracy: 0.7243\n",
            "Epoch 317/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5318 - accuracy: 0.7811 - val_loss: 0.5151 - val_accuracy: 0.7316\n",
            "Epoch 318/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5447 - accuracy: 0.7780 - val_loss: 0.5840 - val_accuracy: 0.6912\n",
            "Epoch 319/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5371 - accuracy: 0.7786 - val_loss: 0.5172 - val_accuracy: 0.7279\n",
            "Epoch 320/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5254 - accuracy: 0.7829 - val_loss: 0.5842 - val_accuracy: 0.6949\n",
            "Epoch 321/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5233 - accuracy: 0.7878 - val_loss: 0.5592 - val_accuracy: 0.7022\n",
            "Epoch 322/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5105 - accuracy: 0.7946 - val_loss: 0.5515 - val_accuracy: 0.7022\n",
            "Epoch 323/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5114 - accuracy: 0.7921 - val_loss: 0.5208 - val_accuracy: 0.7243\n",
            "Epoch 324/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5223 - accuracy: 0.7878 - val_loss: 0.5445 - val_accuracy: 0.7206\n",
            "Epoch 325/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5195 - accuracy: 0.7847 - val_loss: 0.5456 - val_accuracy: 0.7059\n",
            "Epoch 326/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5211 - accuracy: 0.7817 - val_loss: 0.5651 - val_accuracy: 0.6949\n",
            "Epoch 327/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5288 - accuracy: 0.7897 - val_loss: 0.5455 - val_accuracy: 0.7096\n",
            "Epoch 328/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5338 - accuracy: 0.7780 - val_loss: 0.5500 - val_accuracy: 0.7169\n",
            "Epoch 329/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5240 - accuracy: 0.7897 - val_loss: 0.5944 - val_accuracy: 0.6949\n",
            "Epoch 330/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5444 - accuracy: 0.7774 - val_loss: 0.5967 - val_accuracy: 0.6912\n",
            "Epoch 331/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5252 - accuracy: 0.7897 - val_loss: 0.5823 - val_accuracy: 0.6949\n",
            "Epoch 332/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5398 - accuracy: 0.7841 - val_loss: 0.5363 - val_accuracy: 0.7206\n",
            "Epoch 333/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5291 - accuracy: 0.7780 - val_loss: 0.5430 - val_accuracy: 0.7169\n",
            "Epoch 334/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5130 - accuracy: 0.7823 - val_loss: 0.5786 - val_accuracy: 0.6985\n",
            "Epoch 335/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5239 - accuracy: 0.7940 - val_loss: 0.5721 - val_accuracy: 0.6949\n",
            "Epoch 336/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5235 - accuracy: 0.7921 - val_loss: 0.5559 - val_accuracy: 0.7022\n",
            "Epoch 337/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5239 - accuracy: 0.7891 - val_loss: 0.5360 - val_accuracy: 0.7206\n",
            "Epoch 338/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5264 - accuracy: 0.7811 - val_loss: 0.5542 - val_accuracy: 0.6949\n",
            "Epoch 339/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5165 - accuracy: 0.7897 - val_loss: 0.5498 - val_accuracy: 0.7132\n",
            "Epoch 340/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5203 - accuracy: 0.7940 - val_loss: 0.5818 - val_accuracy: 0.6985\n",
            "Epoch 341/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5234 - accuracy: 0.7774 - val_loss: 0.5315 - val_accuracy: 0.7243\n",
            "Epoch 342/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5270 - accuracy: 0.7829 - val_loss: 0.5214 - val_accuracy: 0.7279\n",
            "Epoch 343/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5090 - accuracy: 0.7878 - val_loss: 0.5580 - val_accuracy: 0.6949\n",
            "Epoch 344/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5111 - accuracy: 0.7909 - val_loss: 0.5560 - val_accuracy: 0.6985\n",
            "Epoch 345/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5255 - accuracy: 0.7860 - val_loss: 0.5202 - val_accuracy: 0.7279\n",
            "Epoch 346/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5147 - accuracy: 0.7854 - val_loss: 0.5732 - val_accuracy: 0.6985\n",
            "Epoch 347/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5231 - accuracy: 0.7841 - val_loss: 0.5740 - val_accuracy: 0.6949\n",
            "Epoch 348/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5181 - accuracy: 0.7989 - val_loss: 0.5278 - val_accuracy: 0.7206\n",
            "Epoch 349/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5072 - accuracy: 0.7891 - val_loss: 0.5519 - val_accuracy: 0.6985\n",
            "Epoch 350/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5191 - accuracy: 0.7811 - val_loss: 0.5851 - val_accuracy: 0.6949\n",
            "Epoch 351/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5042 - accuracy: 0.7897 - val_loss: 0.5306 - val_accuracy: 0.7206\n",
            "Epoch 352/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5417 - accuracy: 0.7761 - val_loss: 0.5874 - val_accuracy: 0.6949\n",
            "Epoch 353/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5345 - accuracy: 0.7743 - val_loss: 0.5719 - val_accuracy: 0.6985\n",
            "Epoch 354/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5155 - accuracy: 0.7909 - val_loss: 0.6105 - val_accuracy: 0.6949\n",
            "Epoch 355/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5162 - accuracy: 0.7903 - val_loss: 0.5443 - val_accuracy: 0.7059\n",
            "Epoch 356/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5233 - accuracy: 0.7743 - val_loss: 0.5241 - val_accuracy: 0.7243\n",
            "Epoch 357/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5129 - accuracy: 0.7909 - val_loss: 0.5379 - val_accuracy: 0.7169\n",
            "Epoch 358/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5122 - accuracy: 0.7891 - val_loss: 0.5251 - val_accuracy: 0.7243\n",
            "Epoch 359/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5060 - accuracy: 0.7897 - val_loss: 0.5664 - val_accuracy: 0.6949\n",
            "Epoch 360/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5364 - accuracy: 0.7718 - val_loss: 0.5314 - val_accuracy: 0.7169\n",
            "Epoch 361/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5198 - accuracy: 0.7970 - val_loss: 0.5484 - val_accuracy: 0.7096\n",
            "Epoch 362/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5122 - accuracy: 0.7860 - val_loss: 0.5351 - val_accuracy: 0.7132\n",
            "Epoch 363/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5073 - accuracy: 0.7964 - val_loss: 0.5420 - val_accuracy: 0.7243\n",
            "Epoch 364/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5315 - accuracy: 0.7934 - val_loss: 0.5601 - val_accuracy: 0.6985\n",
            "Epoch 365/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5101 - accuracy: 0.7921 - val_loss: 0.5501 - val_accuracy: 0.7022\n",
            "Epoch 366/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5199 - accuracy: 0.7878 - val_loss: 0.5410 - val_accuracy: 0.7059\n",
            "Epoch 367/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4998 - accuracy: 0.8057 - val_loss: 0.5516 - val_accuracy: 0.6985\n",
            "Epoch 368/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5218 - accuracy: 0.7989 - val_loss: 0.5525 - val_accuracy: 0.6875\n",
            "Epoch 369/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.4997 - accuracy: 0.8026 - val_loss: 0.5855 - val_accuracy: 0.6985\n",
            "Epoch 370/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5263 - accuracy: 0.7823 - val_loss: 0.5486 - val_accuracy: 0.7169\n",
            "Epoch 371/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5051 - accuracy: 0.8001 - val_loss: 0.5688 - val_accuracy: 0.6985\n",
            "Epoch 372/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5174 - accuracy: 0.7958 - val_loss: 0.6215 - val_accuracy: 0.6949\n",
            "Epoch 373/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5154 - accuracy: 0.7934 - val_loss: 0.5452 - val_accuracy: 0.7169\n",
            "Epoch 374/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5121 - accuracy: 0.7958 - val_loss: 0.5622 - val_accuracy: 0.6985\n",
            "Epoch 375/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5117 - accuracy: 0.7897 - val_loss: 0.5700 - val_accuracy: 0.6985\n",
            "Epoch 376/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5071 - accuracy: 0.8014 - val_loss: 0.5468 - val_accuracy: 0.7059\n",
            "Epoch 377/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5175 - accuracy: 0.7866 - val_loss: 0.6066 - val_accuracy: 0.6912\n",
            "Epoch 378/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5119 - accuracy: 0.7835 - val_loss: 0.5502 - val_accuracy: 0.7096\n",
            "Epoch 379/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5053 - accuracy: 0.8069 - val_loss: 0.5441 - val_accuracy: 0.7390\n",
            "Epoch 380/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5157 - accuracy: 0.8069 - val_loss: 0.5458 - val_accuracy: 0.7132\n",
            "Epoch 381/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5063 - accuracy: 0.7964 - val_loss: 0.5665 - val_accuracy: 0.7022\n",
            "Epoch 382/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5064 - accuracy: 0.7903 - val_loss: 0.5577 - val_accuracy: 0.6949\n",
            "Epoch 383/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5171 - accuracy: 0.7934 - val_loss: 0.5637 - val_accuracy: 0.6985\n",
            "Epoch 384/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5297 - accuracy: 0.7792 - val_loss: 0.5821 - val_accuracy: 0.6949\n",
            "Epoch 385/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5145 - accuracy: 0.7989 - val_loss: 0.5795 - val_accuracy: 0.7022\n",
            "Epoch 386/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5039 - accuracy: 0.8014 - val_loss: 0.5684 - val_accuracy: 0.6949\n",
            "Epoch 387/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4996 - accuracy: 0.7970 - val_loss: 0.5321 - val_accuracy: 0.7206\n",
            "Epoch 388/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5108 - accuracy: 0.7909 - val_loss: 0.5463 - val_accuracy: 0.7206\n",
            "Epoch 389/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4969 - accuracy: 0.8032 - val_loss: 0.5380 - val_accuracy: 0.7206\n",
            "Epoch 390/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5059 - accuracy: 0.8026 - val_loss: 0.5861 - val_accuracy: 0.6949\n",
            "Epoch 391/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4961 - accuracy: 0.8020 - val_loss: 0.6010 - val_accuracy: 0.6912\n",
            "Epoch 392/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4990 - accuracy: 0.7958 - val_loss: 0.5342 - val_accuracy: 0.7206\n",
            "Epoch 393/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5214 - accuracy: 0.7934 - val_loss: 0.5460 - val_accuracy: 0.7096\n",
            "Epoch 394/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5072 - accuracy: 0.7958 - val_loss: 0.5529 - val_accuracy: 0.7059\n",
            "Epoch 395/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5049 - accuracy: 0.7964 - val_loss: 0.5425 - val_accuracy: 0.6949\n",
            "Epoch 396/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5126 - accuracy: 0.8044 - val_loss: 0.5601 - val_accuracy: 0.7022\n",
            "Epoch 397/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5139 - accuracy: 0.7872 - val_loss: 0.5543 - val_accuracy: 0.7022\n",
            "Epoch 398/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4980 - accuracy: 0.8106 - val_loss: 0.5628 - val_accuracy: 0.7022\n",
            "Epoch 399/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5031 - accuracy: 0.8026 - val_loss: 0.5503 - val_accuracy: 0.7243\n",
            "Epoch 400/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5219 - accuracy: 0.7786 - val_loss: 0.5201 - val_accuracy: 0.7243\n",
            "Epoch 401/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5140 - accuracy: 0.7934 - val_loss: 0.5600 - val_accuracy: 0.7022\n",
            "Epoch 402/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4991 - accuracy: 0.8032 - val_loss: 0.6411 - val_accuracy: 0.6949\n",
            "Epoch 403/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5134 - accuracy: 0.7798 - val_loss: 0.5883 - val_accuracy: 0.6949\n",
            "Epoch 404/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5156 - accuracy: 0.7847 - val_loss: 0.5633 - val_accuracy: 0.6985\n",
            "Epoch 405/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4931 - accuracy: 0.7866 - val_loss: 0.6035 - val_accuracy: 0.6949\n",
            "Epoch 406/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5193 - accuracy: 0.7860 - val_loss: 0.5583 - val_accuracy: 0.7096\n",
            "Epoch 407/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5183 - accuracy: 0.7878 - val_loss: 0.5650 - val_accuracy: 0.7022\n",
            "Epoch 408/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5146 - accuracy: 0.7952 - val_loss: 0.5491 - val_accuracy: 0.7243\n",
            "Epoch 409/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5062 - accuracy: 0.7952 - val_loss: 0.5388 - val_accuracy: 0.7500\n",
            "Epoch 410/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5129 - accuracy: 0.7872 - val_loss: 0.5491 - val_accuracy: 0.7169\n",
            "Epoch 411/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5123 - accuracy: 0.7970 - val_loss: 0.5802 - val_accuracy: 0.7022\n",
            "Epoch 412/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5084 - accuracy: 0.7964 - val_loss: 0.5338 - val_accuracy: 0.7316\n",
            "Epoch 413/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4984 - accuracy: 0.7983 - val_loss: 0.5518 - val_accuracy: 0.7169\n",
            "Epoch 414/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5009 - accuracy: 0.8057 - val_loss: 0.5792 - val_accuracy: 0.6949\n",
            "Epoch 415/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5002 - accuracy: 0.8001 - val_loss: 0.5484 - val_accuracy: 0.7243\n",
            "Epoch 416/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5073 - accuracy: 0.7897 - val_loss: 0.5472 - val_accuracy: 0.7096\n",
            "Epoch 417/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5109 - accuracy: 0.7897 - val_loss: 0.5394 - val_accuracy: 0.7353\n",
            "Epoch 418/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4960 - accuracy: 0.8026 - val_loss: 0.5136 - val_accuracy: 0.7500\n",
            "Epoch 419/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4975 - accuracy: 0.7964 - val_loss: 0.5632 - val_accuracy: 0.7096\n",
            "Epoch 420/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4929 - accuracy: 0.8081 - val_loss: 0.5638 - val_accuracy: 0.6985\n",
            "Epoch 421/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5031 - accuracy: 0.7909 - val_loss: 0.5457 - val_accuracy: 0.7059\n",
            "Epoch 422/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5055 - accuracy: 0.7952 - val_loss: 0.5382 - val_accuracy: 0.7206\n",
            "Epoch 423/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4964 - accuracy: 0.7970 - val_loss: 0.5668 - val_accuracy: 0.7096\n",
            "Epoch 424/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4975 - accuracy: 0.7964 - val_loss: 0.5629 - val_accuracy: 0.7206\n",
            "Epoch 425/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5061 - accuracy: 0.8007 - val_loss: 0.5330 - val_accuracy: 0.7132\n",
            "Epoch 426/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5083 - accuracy: 0.7964 - val_loss: 0.5437 - val_accuracy: 0.7096\n",
            "Epoch 427/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5131 - accuracy: 0.8007 - val_loss: 0.5476 - val_accuracy: 0.7206\n",
            "Epoch 428/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5055 - accuracy: 0.8050 - val_loss: 0.5738 - val_accuracy: 0.7022\n",
            "Epoch 429/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5094 - accuracy: 0.7891 - val_loss: 0.5385 - val_accuracy: 0.7243\n",
            "Epoch 430/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4987 - accuracy: 0.8057 - val_loss: 0.5735 - val_accuracy: 0.7132\n",
            "Epoch 431/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5064 - accuracy: 0.7970 - val_loss: 0.5581 - val_accuracy: 0.7279\n",
            "Epoch 432/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5124 - accuracy: 0.7934 - val_loss: 0.5566 - val_accuracy: 0.7132\n",
            "Epoch 433/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5039 - accuracy: 0.7946 - val_loss: 0.5484 - val_accuracy: 0.7169\n",
            "Epoch 434/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5231 - accuracy: 0.7804 - val_loss: 0.5333 - val_accuracy: 0.7353\n",
            "Epoch 435/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4992 - accuracy: 0.8100 - val_loss: 0.5700 - val_accuracy: 0.7059\n",
            "Epoch 436/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5024 - accuracy: 0.8001 - val_loss: 0.5450 - val_accuracy: 0.7169\n",
            "Epoch 437/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5101 - accuracy: 0.7921 - val_loss: 0.5423 - val_accuracy: 0.7243\n",
            "Epoch 438/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5032 - accuracy: 0.7970 - val_loss: 0.6008 - val_accuracy: 0.7059\n",
            "Epoch 439/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.4979 - accuracy: 0.8093 - val_loss: 0.5546 - val_accuracy: 0.7169\n",
            "Epoch 440/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5081 - accuracy: 0.7970 - val_loss: 0.5242 - val_accuracy: 0.7426\n",
            "Epoch 441/500\n",
            "26/26 [==============================] - 2s 81ms/step - loss: 0.5113 - accuracy: 0.7927 - val_loss: 0.5347 - val_accuracy: 0.7243\n",
            "Epoch 442/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5045 - accuracy: 0.8026 - val_loss: 0.5788 - val_accuracy: 0.7022\n",
            "Epoch 443/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5183 - accuracy: 0.7811 - val_loss: 0.5748 - val_accuracy: 0.7022\n",
            "Epoch 444/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5121 - accuracy: 0.8038 - val_loss: 0.5753 - val_accuracy: 0.7243\n",
            "Epoch 445/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5076 - accuracy: 0.7921 - val_loss: 0.5438 - val_accuracy: 0.7316\n",
            "Epoch 446/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5050 - accuracy: 0.8081 - val_loss: 0.5606 - val_accuracy: 0.7059\n",
            "Epoch 447/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4982 - accuracy: 0.8038 - val_loss: 0.5419 - val_accuracy: 0.7206\n",
            "Epoch 448/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4876 - accuracy: 0.8137 - val_loss: 0.5390 - val_accuracy: 0.7243\n",
            "Epoch 449/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5241 - accuracy: 0.7897 - val_loss: 0.6077 - val_accuracy: 0.6949\n",
            "Epoch 450/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5266 - accuracy: 0.7934 - val_loss: 0.6189 - val_accuracy: 0.6949\n",
            "Epoch 451/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5174 - accuracy: 0.7909 - val_loss: 0.5341 - val_accuracy: 0.7426\n",
            "Epoch 452/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5208 - accuracy: 0.7952 - val_loss: 0.5348 - val_accuracy: 0.7243\n",
            "Epoch 453/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4889 - accuracy: 0.7940 - val_loss: 0.5461 - val_accuracy: 0.7316\n",
            "Epoch 454/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5034 - accuracy: 0.7964 - val_loss: 0.5611 - val_accuracy: 0.7096\n",
            "Epoch 455/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4898 - accuracy: 0.8001 - val_loss: 0.5764 - val_accuracy: 0.7169\n",
            "Epoch 456/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.4935 - accuracy: 0.8081 - val_loss: 0.5846 - val_accuracy: 0.6985\n",
            "Epoch 457/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5142 - accuracy: 0.7786 - val_loss: 0.5844 - val_accuracy: 0.7096\n",
            "Epoch 458/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5019 - accuracy: 0.7983 - val_loss: 0.5492 - val_accuracy: 0.7132\n",
            "Epoch 459/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5015 - accuracy: 0.7983 - val_loss: 0.5997 - val_accuracy: 0.7096\n",
            "Epoch 460/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4999 - accuracy: 0.8026 - val_loss: 0.6179 - val_accuracy: 0.7022\n",
            "Epoch 461/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5014 - accuracy: 0.7989 - val_loss: 0.5687 - val_accuracy: 0.7169\n",
            "Epoch 462/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5056 - accuracy: 0.8014 - val_loss: 0.5697 - val_accuracy: 0.7096\n",
            "Epoch 463/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5166 - accuracy: 0.7940 - val_loss: 0.5705 - val_accuracy: 0.7132\n",
            "Epoch 464/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5001 - accuracy: 0.7977 - val_loss: 0.5362 - val_accuracy: 0.7206\n",
            "Epoch 465/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5027 - accuracy: 0.7952 - val_loss: 0.5981 - val_accuracy: 0.6985\n",
            "Epoch 466/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4841 - accuracy: 0.7995 - val_loss: 0.5576 - val_accuracy: 0.7206\n",
            "Epoch 467/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5057 - accuracy: 0.7958 - val_loss: 0.5753 - val_accuracy: 0.7132\n",
            "Epoch 468/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4899 - accuracy: 0.7995 - val_loss: 0.5597 - val_accuracy: 0.7169\n",
            "Epoch 469/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4771 - accuracy: 0.8106 - val_loss: 0.5549 - val_accuracy: 0.7169\n",
            "Epoch 470/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4985 - accuracy: 0.7934 - val_loss: 0.5750 - val_accuracy: 0.7059\n",
            "Epoch 471/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4870 - accuracy: 0.8118 - val_loss: 0.5452 - val_accuracy: 0.7206\n",
            "Epoch 472/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4984 - accuracy: 0.7866 - val_loss: 0.5626 - val_accuracy: 0.7096\n",
            "Epoch 473/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5178 - accuracy: 0.7970 - val_loss: 0.5688 - val_accuracy: 0.7132\n",
            "Epoch 474/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4754 - accuracy: 0.8063 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
            "Epoch 475/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4949 - accuracy: 0.7884 - val_loss: 0.5510 - val_accuracy: 0.7279\n",
            "Epoch 476/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4874 - accuracy: 0.7989 - val_loss: 0.5651 - val_accuracy: 0.7279\n",
            "Epoch 477/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4991 - accuracy: 0.7977 - val_loss: 0.5955 - val_accuracy: 0.7096\n",
            "Epoch 478/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5087 - accuracy: 0.7921 - val_loss: 0.5471 - val_accuracy: 0.7132\n",
            "Epoch 479/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4904 - accuracy: 0.8001 - val_loss: 0.5680 - val_accuracy: 0.7022\n",
            "Epoch 480/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4970 - accuracy: 0.7934 - val_loss: 0.5461 - val_accuracy: 0.7206\n",
            "Epoch 481/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4876 - accuracy: 0.7903 - val_loss: 0.5534 - val_accuracy: 0.7316\n",
            "Epoch 482/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4931 - accuracy: 0.8075 - val_loss: 0.5282 - val_accuracy: 0.7390\n",
            "Epoch 483/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.4948 - accuracy: 0.8069 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
            "Epoch 484/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.4835 - accuracy: 0.7958 - val_loss: 0.5149 - val_accuracy: 0.7463\n",
            "Epoch 485/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5135 - accuracy: 0.7934 - val_loss: 0.5438 - val_accuracy: 0.7132\n",
            "Epoch 486/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5031 - accuracy: 0.8038 - val_loss: 0.5501 - val_accuracy: 0.7206\n",
            "Epoch 487/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4959 - accuracy: 0.8014 - val_loss: 0.5633 - val_accuracy: 0.7096\n",
            "Epoch 488/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4985 - accuracy: 0.8057 - val_loss: 0.5758 - val_accuracy: 0.7096\n",
            "Epoch 489/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.4930 - accuracy: 0.7977 - val_loss: 0.5363 - val_accuracy: 0.7390\n",
            "Epoch 490/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5101 - accuracy: 0.7934 - val_loss: 0.5556 - val_accuracy: 0.7169\n",
            "Epoch 491/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.4897 - accuracy: 0.8001 - val_loss: 0.5363 - val_accuracy: 0.7316\n",
            "Epoch 492/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4915 - accuracy: 0.7940 - val_loss: 0.5738 - val_accuracy: 0.7059\n",
            "Epoch 493/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5008 - accuracy: 0.7989 - val_loss: 0.5724 - val_accuracy: 0.7132\n",
            "Epoch 494/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4940 - accuracy: 0.8014 - val_loss: 0.5633 - val_accuracy: 0.7132\n",
            "Epoch 495/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.4954 - accuracy: 0.7989 - val_loss: 0.5537 - val_accuracy: 0.7132\n",
            "Epoch 496/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4865 - accuracy: 0.8106 - val_loss: 0.5760 - val_accuracy: 0.7022\n",
            "Epoch 497/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5048 - accuracy: 0.7977 - val_loss: 0.5464 - val_accuracy: 0.7169\n",
            "Epoch 498/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5016 - accuracy: 0.7940 - val_loss: 0.5758 - val_accuracy: 0.6985\n",
            "Epoch 499/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.4918 - accuracy: 0.8050 - val_loss: 0.5504 - val_accuracy: 0.7132\n",
            "Epoch 500/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4979 - accuracy: 0.7915 - val_loss: 0.5350 - val_accuracy: 0.7243\n"
          ]
        }
      ],
      "source": [
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer= keras.optimizers.Adam(0.001, decay=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "# Start training the model.\n",
        "cnn_3d_model_training_history = model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=500,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle = True,\n",
        "                                          validation_data = (features_valid, labels_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3vimsgjjbXvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d9a51d5-147b-47ce-9262-fdb1b2e63096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 21ms/step - loss: 0.6620 - accuracy: 0.7316\n",
            "\n",
            "\n",
            "Train accuracy: 80.689 % || Test accuracy: 73.162 % || Val accuracy: 72.426 %\n",
            "Train loss: 0.444 || Test loss: 0.662 || Val loss: 0.535\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ivmaK9BlbnRQ"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'3D_CNN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p cnn_3d_{current_date_time_string}\n",
        "# Save your Model.\n",
        "model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwU8TwPrbsKB"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cvKY05ncbwof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "955885e9-324c-496d-e7a8-075ffe036de5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o1iaaDHBb5i0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "1112b792-5cb3-499f-eb72-1086c595b118"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3D_CNN_No_Splint.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOF4WsaW9C05wiMd5RS5R01",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}