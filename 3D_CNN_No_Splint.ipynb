{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/3D_CNN_No_Splint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk7I8NauauE3"
      },
      "source": [
        "####**3D Convolutional Neural Network**\n",
        "######*I am using 3D Convolutional Neural Network to extract the temporal and spatial information which are merged slowly throughout the whole network.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8ibtd5HKtZk",
        "outputId": "10f53548-42c3-440b-da4d-d19bab5cffc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv3D, MaxPooling3D, Dropout\n",
        "from keras.layers import BatchNormalization, GlobalAveragePooling3D\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "f438fbae-439f-4eed-f357-ee38d8a90701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 96, 96\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Circle_Cropped_videos_labeled'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HUTeIqzpZc9J"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QRDbHG0TZkYJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(96, 96)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            # frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "7f46342a-f8bb-428b-9066-df3172a94b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "N-9ykP4ig7IW"
      },
      "outputs": [],
      "source": [
        "def create_3D_CNN_model():\n",
        "    sample_shape = (16, 96, 96, 3)\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv3D(8, (1,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4),\n",
        "                     input_shape=sample_shape))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv3D(16, (3,3,3), activation='relu', kernel_initializer='he_uniform',\n",
        "                     kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(MaxPooling3D(2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(GlobalAveragePooling3D())\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "\n",
        "    model.summary(line_length = 125)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_GxXZBcHlB",
        "outputId": "11396e94-3b4a-4ffb-ab6a-c6d25e4e31a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_____________________________________________________________________________________________________________________________\n",
            " Layer (type)                                           Output Shape                                      Param #            \n",
            "=============================================================================================================================\n",
            " conv3d (Conv3D)                                        (None, 16, 94, 94, 8)                             224                \n",
            "                                                                                                                             \n",
            " max_pooling3d (MaxPooling3D)                           (None, 8, 47, 47, 8)                              0                  \n",
            "                                                                                                                             \n",
            " dropout (Dropout)                                      (None, 8, 47, 47, 8)                              0                  \n",
            "                                                                                                                             \n",
            " conv3d_1 (Conv3D)                                      (None, 6, 45, 45, 16)                             3472               \n",
            "                                                                                                                             \n",
            " max_pooling3d_1 (MaxPooling3D)                         (None, 3, 22, 22, 16)                             0                  \n",
            "                                                                                                                             \n",
            " dropout_1 (Dropout)                                    (None, 3, 22, 22, 16)                             0                  \n",
            "                                                                                                                             \n",
            " global_average_pooling3d (GlobalAveragePooling3D)      (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dropout_2 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense (Dense)                                          (None, 16)                                        272                \n",
            "                                                                                                                             \n",
            " dropout_3 (Dropout)                                    (None, 16)                                        0                  \n",
            "                                                                                                                             \n",
            " dense_1 (Dense)                                        (None, 8)                                         136                \n",
            "                                                                                                                             \n",
            " dense_2 (Dense)                                        (None, 4)                                         36                 \n",
            "                                                                                                                             \n",
            "=============================================================================================================================\n",
            "Total params: 4,140\n",
            "Trainable params: 4,140\n",
            "Non-trainable params: 0\n",
            "_____________________________________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "model = create_3D_CNN_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYEkaYLoyb_",
        "outputId": "6c4075f2-dab1-4463-ae49-4a355903c1ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "26/26 [==============================] - 5s 105ms/step - loss: 1.5737 - accuracy: 0.1993 - val_loss: 1.3419 - val_accuracy: 0.3971\n",
            "Epoch 2/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.3341 - accuracy: 0.3776 - val_loss: 1.3023 - val_accuracy: 0.3971\n",
            "Epoch 3/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.2842 - accuracy: 0.4348 - val_loss: 1.2675 - val_accuracy: 0.3971\n",
            "Epoch 4/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.2423 - accuracy: 0.4496 - val_loss: 1.2403 - val_accuracy: 0.3971\n",
            "Epoch 5/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 1.2269 - accuracy: 0.4465 - val_loss: 1.2224 - val_accuracy: 0.3971\n",
            "Epoch 6/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.1933 - accuracy: 0.4446 - val_loss: 1.1799 - val_accuracy: 0.3971\n",
            "Epoch 7/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.1753 - accuracy: 0.4410 - val_loss: 1.1619 - val_accuracy: 0.3971\n",
            "Epoch 8/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.1423 - accuracy: 0.4563 - val_loss: 1.1349 - val_accuracy: 0.3971\n",
            "Epoch 9/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.1158 - accuracy: 0.4533 - val_loss: 1.0945 - val_accuracy: 0.3971\n",
            "Epoch 10/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 1.0921 - accuracy: 0.4840 - val_loss: 1.0655 - val_accuracy: 0.3971\n",
            "Epoch 11/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.0793 - accuracy: 0.4779 - val_loss: 1.0631 - val_accuracy: 0.5257\n",
            "Epoch 12/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 1.0382 - accuracy: 0.4772 - val_loss: 0.9799 - val_accuracy: 0.5221\n",
            "Epoch 13/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 1.0141 - accuracy: 0.4772 - val_loss: 0.9669 - val_accuracy: 0.5294\n",
            "Epoch 14/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9993 - accuracy: 0.5043 - val_loss: 0.9675 - val_accuracy: 0.5625\n",
            "Epoch 15/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9841 - accuracy: 0.5123 - val_loss: 0.9551 - val_accuracy: 0.5441\n",
            "Epoch 16/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9765 - accuracy: 0.5240 - val_loss: 0.9551 - val_accuracy: 0.5331\n",
            "Epoch 17/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9591 - accuracy: 0.5431 - val_loss: 0.9073 - val_accuracy: 0.5478\n",
            "Epoch 18/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9684 - accuracy: 0.5301 - val_loss: 0.8939 - val_accuracy: 0.6066\n",
            "Epoch 19/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9496 - accuracy: 0.5277 - val_loss: 0.8928 - val_accuracy: 0.5993\n",
            "Epoch 20/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9489 - accuracy: 0.5504 - val_loss: 0.8933 - val_accuracy: 0.6066\n",
            "Epoch 21/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9272 - accuracy: 0.5590 - val_loss: 0.8711 - val_accuracy: 0.6066\n",
            "Epoch 22/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.9241 - accuracy: 0.5412 - val_loss: 0.9114 - val_accuracy: 0.5551\n",
            "Epoch 23/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9323 - accuracy: 0.5443 - val_loss: 0.8819 - val_accuracy: 0.5993\n",
            "Epoch 24/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.9137 - accuracy: 0.5541 - val_loss: 0.8654 - val_accuracy: 0.6103\n",
            "Epoch 25/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.9042 - accuracy: 0.5713 - val_loss: 0.8526 - val_accuracy: 0.6140\n",
            "Epoch 26/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8902 - accuracy: 0.5720 - val_loss: 0.8432 - val_accuracy: 0.6213\n",
            "Epoch 27/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8996 - accuracy: 0.5800 - val_loss: 0.8291 - val_accuracy: 0.5956\n",
            "Epoch 28/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8907 - accuracy: 0.5923 - val_loss: 0.8473 - val_accuracy: 0.6103\n",
            "Epoch 29/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8980 - accuracy: 0.5720 - val_loss: 0.8347 - val_accuracy: 0.6066\n",
            "Epoch 30/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.8911 - accuracy: 0.5861 - val_loss: 0.8184 - val_accuracy: 0.5956\n",
            "Epoch 31/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.9028 - accuracy: 0.5566 - val_loss: 0.8175 - val_accuracy: 0.5956\n",
            "Epoch 32/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8660 - accuracy: 0.5861 - val_loss: 0.7973 - val_accuracy: 0.5772\n",
            "Epoch 33/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8581 - accuracy: 0.6015 - val_loss: 0.8004 - val_accuracy: 0.5956\n",
            "Epoch 34/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8627 - accuracy: 0.6039 - val_loss: 0.7941 - val_accuracy: 0.5809\n",
            "Epoch 35/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8555 - accuracy: 0.6039 - val_loss: 0.8049 - val_accuracy: 0.6103\n",
            "Epoch 36/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8570 - accuracy: 0.6082 - val_loss: 0.7787 - val_accuracy: 0.5809\n",
            "Epoch 37/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8530 - accuracy: 0.6002 - val_loss: 0.7850 - val_accuracy: 0.5956\n",
            "Epoch 38/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8481 - accuracy: 0.5996 - val_loss: 0.7937 - val_accuracy: 0.6213\n",
            "Epoch 39/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8459 - accuracy: 0.6175 - val_loss: 0.7748 - val_accuracy: 0.6029\n",
            "Epoch 40/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8498 - accuracy: 0.6039 - val_loss: 0.7833 - val_accuracy: 0.5882\n",
            "Epoch 41/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8413 - accuracy: 0.6261 - val_loss: 0.7789 - val_accuracy: 0.5846\n",
            "Epoch 42/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8448 - accuracy: 0.6113 - val_loss: 0.7790 - val_accuracy: 0.6140\n",
            "Epoch 43/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8452 - accuracy: 0.6107 - val_loss: 0.7777 - val_accuracy: 0.6029\n",
            "Epoch 44/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8277 - accuracy: 0.6193 - val_loss: 0.7965 - val_accuracy: 0.6287\n",
            "Epoch 45/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8337 - accuracy: 0.6298 - val_loss: 0.7709 - val_accuracy: 0.5919\n",
            "Epoch 46/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8220 - accuracy: 0.6316 - val_loss: 0.7633 - val_accuracy: 0.6029\n",
            "Epoch 47/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8383 - accuracy: 0.6181 - val_loss: 0.7678 - val_accuracy: 0.6287\n",
            "Epoch 48/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.8087 - accuracy: 0.6347 - val_loss: 0.7521 - val_accuracy: 0.6176\n",
            "Epoch 49/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8165 - accuracy: 0.6248 - val_loss: 0.7505 - val_accuracy: 0.6066\n",
            "Epoch 50/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8121 - accuracy: 0.6390 - val_loss: 0.7510 - val_accuracy: 0.6360\n",
            "Epoch 51/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.8007 - accuracy: 0.6464 - val_loss: 0.7370 - val_accuracy: 0.6360\n",
            "Epoch 52/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7972 - accuracy: 0.6341 - val_loss: 0.7260 - val_accuracy: 0.6397\n",
            "Epoch 53/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.8018 - accuracy: 0.6353 - val_loss: 0.7577 - val_accuracy: 0.6250\n",
            "Epoch 54/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.8037 - accuracy: 0.6439 - val_loss: 0.7291 - val_accuracy: 0.6360\n",
            "Epoch 55/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7884 - accuracy: 0.6531 - val_loss: 0.7407 - val_accuracy: 0.6728\n",
            "Epoch 56/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.8004 - accuracy: 0.6482 - val_loss: 0.7332 - val_accuracy: 0.6912\n",
            "Epoch 57/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7943 - accuracy: 0.6470 - val_loss: 0.7198 - val_accuracy: 0.6434\n",
            "Epoch 58/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7812 - accuracy: 0.6574 - val_loss: 0.7139 - val_accuracy: 0.6397\n",
            "Epoch 59/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7931 - accuracy: 0.6544 - val_loss: 0.7138 - val_accuracy: 0.6581\n",
            "Epoch 60/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7680 - accuracy: 0.6605 - val_loss: 0.7138 - val_accuracy: 0.6471\n",
            "Epoch 61/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7676 - accuracy: 0.6685 - val_loss: 0.7041 - val_accuracy: 0.6618\n",
            "Epoch 62/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7726 - accuracy: 0.6581 - val_loss: 0.6994 - val_accuracy: 0.6654\n",
            "Epoch 63/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7652 - accuracy: 0.6624 - val_loss: 0.6951 - val_accuracy: 0.7096\n",
            "Epoch 64/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7680 - accuracy: 0.6599 - val_loss: 0.6997 - val_accuracy: 0.6728\n",
            "Epoch 65/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7711 - accuracy: 0.6710 - val_loss: 0.6937 - val_accuracy: 0.6654\n",
            "Epoch 66/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7546 - accuracy: 0.6685 - val_loss: 0.6816 - val_accuracy: 0.6581\n",
            "Epoch 67/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7587 - accuracy: 0.6667 - val_loss: 0.6800 - val_accuracy: 0.6801\n",
            "Epoch 68/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7712 - accuracy: 0.6642 - val_loss: 0.6858 - val_accuracy: 0.6581\n",
            "Epoch 69/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7645 - accuracy: 0.6685 - val_loss: 0.6856 - val_accuracy: 0.6801\n",
            "Epoch 70/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7541 - accuracy: 0.6654 - val_loss: 0.6753 - val_accuracy: 0.6507\n",
            "Epoch 71/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7377 - accuracy: 0.6851 - val_loss: 0.6661 - val_accuracy: 0.6507\n",
            "Epoch 72/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7502 - accuracy: 0.6716 - val_loss: 0.6604 - val_accuracy: 0.6985\n",
            "Epoch 73/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7484 - accuracy: 0.6667 - val_loss: 0.6668 - val_accuracy: 0.6728\n",
            "Epoch 74/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.7653 - accuracy: 0.6617 - val_loss: 0.7049 - val_accuracy: 0.6581\n",
            "Epoch 75/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7423 - accuracy: 0.6802 - val_loss: 0.6629 - val_accuracy: 0.6507\n",
            "Epoch 76/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7531 - accuracy: 0.6679 - val_loss: 0.6939 - val_accuracy: 0.6618\n",
            "Epoch 77/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7336 - accuracy: 0.6962 - val_loss: 0.6550 - val_accuracy: 0.7206\n",
            "Epoch 78/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7328 - accuracy: 0.6827 - val_loss: 0.6550 - val_accuracy: 0.7353\n",
            "Epoch 79/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7514 - accuracy: 0.6833 - val_loss: 0.6680 - val_accuracy: 0.6691\n",
            "Epoch 80/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7417 - accuracy: 0.6716 - val_loss: 0.6586 - val_accuracy: 0.6912\n",
            "Epoch 81/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7307 - accuracy: 0.6913 - val_loss: 0.6615 - val_accuracy: 0.6691\n",
            "Epoch 82/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7447 - accuracy: 0.6814 - val_loss: 0.6587 - val_accuracy: 0.6875\n",
            "Epoch 83/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7387 - accuracy: 0.6808 - val_loss: 0.6519 - val_accuracy: 0.6544\n",
            "Epoch 84/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7258 - accuracy: 0.6888 - val_loss: 0.6762 - val_accuracy: 0.6581\n",
            "Epoch 85/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7404 - accuracy: 0.6728 - val_loss: 0.6529 - val_accuracy: 0.6691\n",
            "Epoch 86/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7180 - accuracy: 0.6925 - val_loss: 0.6661 - val_accuracy: 0.6765\n",
            "Epoch 87/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7051 - accuracy: 0.6999 - val_loss: 0.6242 - val_accuracy: 0.7353\n",
            "Epoch 88/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7336 - accuracy: 0.6820 - val_loss: 0.6810 - val_accuracy: 0.6618\n",
            "Epoch 89/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7127 - accuracy: 0.6974 - val_loss: 0.6395 - val_accuracy: 0.7353\n",
            "Epoch 90/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.7256 - accuracy: 0.6894 - val_loss: 0.6375 - val_accuracy: 0.6985\n",
            "Epoch 91/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.7171 - accuracy: 0.6857 - val_loss: 0.6418 - val_accuracy: 0.6949\n",
            "Epoch 92/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7166 - accuracy: 0.6913 - val_loss: 0.6534 - val_accuracy: 0.6912\n",
            "Epoch 93/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7058 - accuracy: 0.7023 - val_loss: 0.6254 - val_accuracy: 0.7096\n",
            "Epoch 94/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7162 - accuracy: 0.6999 - val_loss: 0.6269 - val_accuracy: 0.6949\n",
            "Epoch 95/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6960 - accuracy: 0.6980 - val_loss: 0.6344 - val_accuracy: 0.6912\n",
            "Epoch 96/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7108 - accuracy: 0.6980 - val_loss: 0.6215 - val_accuracy: 0.7059\n",
            "Epoch 97/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6913 - accuracy: 0.7134 - val_loss: 0.6076 - val_accuracy: 0.7132\n",
            "Epoch 98/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6915 - accuracy: 0.7005 - val_loss: 0.6037 - val_accuracy: 0.7132\n",
            "Epoch 99/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7283 - accuracy: 0.6943 - val_loss: 0.6303 - val_accuracy: 0.6875\n",
            "Epoch 100/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6881 - accuracy: 0.7048 - val_loss: 0.6147 - val_accuracy: 0.7279\n",
            "Epoch 101/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.7016 - accuracy: 0.6968 - val_loss: 0.6053 - val_accuracy: 0.7390\n",
            "Epoch 102/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6869 - accuracy: 0.7085 - val_loss: 0.6068 - val_accuracy: 0.7096\n",
            "Epoch 103/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6896 - accuracy: 0.7023 - val_loss: 0.6122 - val_accuracy: 0.7206\n",
            "Epoch 104/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6821 - accuracy: 0.7079 - val_loss: 0.6146 - val_accuracy: 0.7022\n",
            "Epoch 105/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6982 - accuracy: 0.7017 - val_loss: 0.6102 - val_accuracy: 0.7096\n",
            "Epoch 106/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.7057 - accuracy: 0.7023 - val_loss: 0.6020 - val_accuracy: 0.7390\n",
            "Epoch 107/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6948 - accuracy: 0.7042 - val_loss: 0.6073 - val_accuracy: 0.7096\n",
            "Epoch 108/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6787 - accuracy: 0.7122 - val_loss: 0.6025 - val_accuracy: 0.7169\n",
            "Epoch 109/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6789 - accuracy: 0.7202 - val_loss: 0.6554 - val_accuracy: 0.6838\n",
            "Epoch 110/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6871 - accuracy: 0.7091 - val_loss: 0.5941 - val_accuracy: 0.7243\n",
            "Epoch 111/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6937 - accuracy: 0.6925 - val_loss: 0.6307 - val_accuracy: 0.6949\n",
            "Epoch 112/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6690 - accuracy: 0.7140 - val_loss: 0.5991 - val_accuracy: 0.7206\n",
            "Epoch 113/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6908 - accuracy: 0.7079 - val_loss: 0.6005 - val_accuracy: 0.7463\n",
            "Epoch 114/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6781 - accuracy: 0.7066 - val_loss: 0.6255 - val_accuracy: 0.6912\n",
            "Epoch 115/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6652 - accuracy: 0.7288 - val_loss: 0.5957 - val_accuracy: 0.7206\n",
            "Epoch 116/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6647 - accuracy: 0.7245 - val_loss: 0.5934 - val_accuracy: 0.7316\n",
            "Epoch 117/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6976 - accuracy: 0.7060 - val_loss: 0.5888 - val_accuracy: 0.7243\n",
            "Epoch 118/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6852 - accuracy: 0.7134 - val_loss: 0.6025 - val_accuracy: 0.7243\n",
            "Epoch 119/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6676 - accuracy: 0.7226 - val_loss: 0.6331 - val_accuracy: 0.6838\n",
            "Epoch 120/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6682 - accuracy: 0.7171 - val_loss: 0.5760 - val_accuracy: 0.7353\n",
            "Epoch 121/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6730 - accuracy: 0.7109 - val_loss: 0.6292 - val_accuracy: 0.6985\n",
            "Epoch 122/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6650 - accuracy: 0.7196 - val_loss: 0.5845 - val_accuracy: 0.7279\n",
            "Epoch 123/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6579 - accuracy: 0.7269 - val_loss: 0.5872 - val_accuracy: 0.7390\n",
            "Epoch 124/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6724 - accuracy: 0.7208 - val_loss: 0.5841 - val_accuracy: 0.7537\n",
            "Epoch 125/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6651 - accuracy: 0.7282 - val_loss: 0.6286 - val_accuracy: 0.6838\n",
            "Epoch 126/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6670 - accuracy: 0.7208 - val_loss: 0.6117 - val_accuracy: 0.7059\n",
            "Epoch 127/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6710 - accuracy: 0.7251 - val_loss: 0.5751 - val_accuracy: 0.7353\n",
            "Epoch 128/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6514 - accuracy: 0.7251 - val_loss: 0.6007 - val_accuracy: 0.6949\n",
            "Epoch 129/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6632 - accuracy: 0.7232 - val_loss: 0.5823 - val_accuracy: 0.7353\n",
            "Epoch 130/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6416 - accuracy: 0.7337 - val_loss: 0.6094 - val_accuracy: 0.6912\n",
            "Epoch 131/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6559 - accuracy: 0.7146 - val_loss: 0.6058 - val_accuracy: 0.6949\n",
            "Epoch 132/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6549 - accuracy: 0.7257 - val_loss: 0.6309 - val_accuracy: 0.6875\n",
            "Epoch 133/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6465 - accuracy: 0.7153 - val_loss: 0.5947 - val_accuracy: 0.6949\n",
            "Epoch 134/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6528 - accuracy: 0.7288 - val_loss: 0.5928 - val_accuracy: 0.7059\n",
            "Epoch 135/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6575 - accuracy: 0.7306 - val_loss: 0.5975 - val_accuracy: 0.7169\n",
            "Epoch 136/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6540 - accuracy: 0.7245 - val_loss: 0.5853 - val_accuracy: 0.6912\n",
            "Epoch 137/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6636 - accuracy: 0.7171 - val_loss: 0.6134 - val_accuracy: 0.6912\n",
            "Epoch 138/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6441 - accuracy: 0.7374 - val_loss: 0.5792 - val_accuracy: 0.7279\n",
            "Epoch 139/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6408 - accuracy: 0.7325 - val_loss: 0.6084 - val_accuracy: 0.6912\n",
            "Epoch 140/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6466 - accuracy: 0.7263 - val_loss: 0.6331 - val_accuracy: 0.6875\n",
            "Epoch 141/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6451 - accuracy: 0.7276 - val_loss: 0.5929 - val_accuracy: 0.7243\n",
            "Epoch 142/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6425 - accuracy: 0.7288 - val_loss: 0.6157 - val_accuracy: 0.6985\n",
            "Epoch 143/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6389 - accuracy: 0.7355 - val_loss: 0.5732 - val_accuracy: 0.7279\n",
            "Epoch 144/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6529 - accuracy: 0.7294 - val_loss: 0.6112 - val_accuracy: 0.6801\n",
            "Epoch 145/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6374 - accuracy: 0.7294 - val_loss: 0.5879 - val_accuracy: 0.7279\n",
            "Epoch 146/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6347 - accuracy: 0.7368 - val_loss: 0.5828 - val_accuracy: 0.7206\n",
            "Epoch 147/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.6546 - accuracy: 0.7116 - val_loss: 0.5991 - val_accuracy: 0.7022\n",
            "Epoch 148/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6497 - accuracy: 0.7331 - val_loss: 0.5844 - val_accuracy: 0.7022\n",
            "Epoch 149/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6456 - accuracy: 0.7306 - val_loss: 0.6124 - val_accuracy: 0.6949\n",
            "Epoch 150/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6374 - accuracy: 0.7220 - val_loss: 0.5869 - val_accuracy: 0.6985\n",
            "Epoch 151/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6427 - accuracy: 0.7226 - val_loss: 0.6409 - val_accuracy: 0.6949\n",
            "Epoch 152/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6413 - accuracy: 0.7140 - val_loss: 0.5665 - val_accuracy: 0.7132\n",
            "Epoch 153/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6298 - accuracy: 0.7399 - val_loss: 0.5780 - val_accuracy: 0.7426\n",
            "Epoch 154/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6360 - accuracy: 0.7306 - val_loss: 0.5773 - val_accuracy: 0.7169\n",
            "Epoch 155/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6271 - accuracy: 0.7380 - val_loss: 0.5939 - val_accuracy: 0.6985\n",
            "Epoch 156/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6163 - accuracy: 0.7485 - val_loss: 0.5490 - val_accuracy: 0.7500\n",
            "Epoch 157/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6312 - accuracy: 0.7343 - val_loss: 0.5946 - val_accuracy: 0.7022\n",
            "Epoch 158/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6294 - accuracy: 0.7423 - val_loss: 0.6091 - val_accuracy: 0.6949\n",
            "Epoch 159/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6226 - accuracy: 0.7442 - val_loss: 0.6011 - val_accuracy: 0.6949\n",
            "Epoch 160/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6195 - accuracy: 0.7429 - val_loss: 0.6083 - val_accuracy: 0.6949\n",
            "Epoch 161/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6243 - accuracy: 0.7478 - val_loss: 0.5656 - val_accuracy: 0.7243\n",
            "Epoch 162/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6358 - accuracy: 0.7380 - val_loss: 0.5661 - val_accuracy: 0.7390\n",
            "Epoch 163/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6076 - accuracy: 0.7657 - val_loss: 0.6020 - val_accuracy: 0.6838\n",
            "Epoch 164/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6397 - accuracy: 0.7202 - val_loss: 0.6065 - val_accuracy: 0.6875\n",
            "Epoch 165/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6221 - accuracy: 0.7411 - val_loss: 0.6182 - val_accuracy: 0.6912\n",
            "Epoch 166/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6147 - accuracy: 0.7485 - val_loss: 0.6227 - val_accuracy: 0.6912\n",
            "Epoch 167/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6460 - accuracy: 0.7276 - val_loss: 0.5812 - val_accuracy: 0.7243\n",
            "Epoch 168/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6346 - accuracy: 0.7355 - val_loss: 0.5793 - val_accuracy: 0.7059\n",
            "Epoch 169/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6085 - accuracy: 0.7417 - val_loss: 0.5444 - val_accuracy: 0.7537\n",
            "Epoch 170/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6192 - accuracy: 0.7472 - val_loss: 0.5697 - val_accuracy: 0.7206\n",
            "Epoch 171/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6275 - accuracy: 0.7411 - val_loss: 0.5874 - val_accuracy: 0.7096\n",
            "Epoch 172/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6318 - accuracy: 0.7306 - val_loss: 0.6009 - val_accuracy: 0.6949\n",
            "Epoch 173/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6167 - accuracy: 0.7343 - val_loss: 0.5849 - val_accuracy: 0.7022\n",
            "Epoch 174/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6242 - accuracy: 0.7386 - val_loss: 0.5704 - val_accuracy: 0.6985\n",
            "Epoch 175/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6233 - accuracy: 0.7368 - val_loss: 0.6133 - val_accuracy: 0.7059\n",
            "Epoch 176/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6192 - accuracy: 0.7337 - val_loss: 0.5827 - val_accuracy: 0.6985\n",
            "Epoch 177/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6126 - accuracy: 0.7454 - val_loss: 0.5982 - val_accuracy: 0.6949\n",
            "Epoch 178/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6070 - accuracy: 0.7485 - val_loss: 0.5490 - val_accuracy: 0.7463\n",
            "Epoch 179/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6096 - accuracy: 0.7399 - val_loss: 0.5742 - val_accuracy: 0.6985\n",
            "Epoch 180/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6116 - accuracy: 0.7546 - val_loss: 0.5753 - val_accuracy: 0.7096\n",
            "Epoch 181/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6015 - accuracy: 0.7528 - val_loss: 0.5846 - val_accuracy: 0.7096\n",
            "Epoch 182/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6232 - accuracy: 0.7343 - val_loss: 0.5977 - val_accuracy: 0.6949\n",
            "Epoch 183/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6305 - accuracy: 0.7405 - val_loss: 0.5875 - val_accuracy: 0.7096\n",
            "Epoch 184/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6247 - accuracy: 0.7331 - val_loss: 0.5895 - val_accuracy: 0.7022\n",
            "Epoch 185/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6266 - accuracy: 0.7362 - val_loss: 0.5980 - val_accuracy: 0.7059\n",
            "Epoch 186/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6014 - accuracy: 0.7485 - val_loss: 0.5493 - val_accuracy: 0.7169\n",
            "Epoch 187/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6167 - accuracy: 0.7337 - val_loss: 0.6060 - val_accuracy: 0.7059\n",
            "Epoch 188/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6098 - accuracy: 0.7392 - val_loss: 0.5842 - val_accuracy: 0.6912\n",
            "Epoch 189/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6006 - accuracy: 0.7552 - val_loss: 0.5685 - val_accuracy: 0.6985\n",
            "Epoch 190/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6016 - accuracy: 0.7546 - val_loss: 0.6137 - val_accuracy: 0.6838\n",
            "Epoch 191/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6162 - accuracy: 0.7485 - val_loss: 0.5592 - val_accuracy: 0.7390\n",
            "Epoch 192/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5894 - accuracy: 0.7472 - val_loss: 0.6315 - val_accuracy: 0.6838\n",
            "Epoch 193/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6089 - accuracy: 0.7478 - val_loss: 0.5895 - val_accuracy: 0.6949\n",
            "Epoch 194/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5893 - accuracy: 0.7552 - val_loss: 0.5895 - val_accuracy: 0.7059\n",
            "Epoch 195/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5947 - accuracy: 0.7522 - val_loss: 0.6125 - val_accuracy: 0.7059\n",
            "Epoch 196/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6005 - accuracy: 0.7472 - val_loss: 0.5645 - val_accuracy: 0.6985\n",
            "Epoch 197/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5764 - accuracy: 0.7546 - val_loss: 0.5859 - val_accuracy: 0.7059\n",
            "Epoch 198/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5896 - accuracy: 0.7478 - val_loss: 0.5662 - val_accuracy: 0.6838\n",
            "Epoch 199/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6058 - accuracy: 0.7546 - val_loss: 0.6082 - val_accuracy: 0.7059\n",
            "Epoch 200/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6226 - accuracy: 0.7429 - val_loss: 0.5734 - val_accuracy: 0.7022\n",
            "Epoch 201/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5995 - accuracy: 0.7552 - val_loss: 0.5678 - val_accuracy: 0.6949\n",
            "Epoch 202/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5920 - accuracy: 0.7515 - val_loss: 0.5356 - val_accuracy: 0.7463\n",
            "Epoch 203/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6166 - accuracy: 0.7386 - val_loss: 0.5912 - val_accuracy: 0.6949\n",
            "Epoch 204/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5948 - accuracy: 0.7435 - val_loss: 0.5833 - val_accuracy: 0.6949\n",
            "Epoch 205/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5800 - accuracy: 0.7540 - val_loss: 0.5463 - val_accuracy: 0.7426\n",
            "Epoch 206/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6029 - accuracy: 0.7435 - val_loss: 0.6104 - val_accuracy: 0.6912\n",
            "Epoch 207/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5890 - accuracy: 0.7657 - val_loss: 0.5738 - val_accuracy: 0.6985\n",
            "Epoch 208/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6102 - accuracy: 0.7522 - val_loss: 0.5862 - val_accuracy: 0.6985\n",
            "Epoch 209/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5889 - accuracy: 0.7589 - val_loss: 0.5675 - val_accuracy: 0.7022\n",
            "Epoch 210/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.6000 - accuracy: 0.7503 - val_loss: 0.5624 - val_accuracy: 0.6838\n",
            "Epoch 211/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5843 - accuracy: 0.7724 - val_loss: 0.5495 - val_accuracy: 0.7390\n",
            "Epoch 212/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.6114 - accuracy: 0.7374 - val_loss: 0.6012 - val_accuracy: 0.6949\n",
            "Epoch 213/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5965 - accuracy: 0.7478 - val_loss: 0.6090 - val_accuracy: 0.6949\n",
            "Epoch 214/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5876 - accuracy: 0.7601 - val_loss: 0.5667 - val_accuracy: 0.6949\n",
            "Epoch 215/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5889 - accuracy: 0.7522 - val_loss: 0.5577 - val_accuracy: 0.7096\n",
            "Epoch 216/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5929 - accuracy: 0.7509 - val_loss: 0.5830 - val_accuracy: 0.6912\n",
            "Epoch 217/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5894 - accuracy: 0.7528 - val_loss: 0.5689 - val_accuracy: 0.7059\n",
            "Epoch 218/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5882 - accuracy: 0.7565 - val_loss: 0.5617 - val_accuracy: 0.6801\n",
            "Epoch 219/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5835 - accuracy: 0.7626 - val_loss: 0.6030 - val_accuracy: 0.7059\n",
            "Epoch 220/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5930 - accuracy: 0.7472 - val_loss: 0.6198 - val_accuracy: 0.6949\n",
            "Epoch 221/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5969 - accuracy: 0.7497 - val_loss: 0.5888 - val_accuracy: 0.6912\n",
            "Epoch 222/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5824 - accuracy: 0.7638 - val_loss: 0.5703 - val_accuracy: 0.6949\n",
            "Epoch 223/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5876 - accuracy: 0.7681 - val_loss: 0.5498 - val_accuracy: 0.7096\n",
            "Epoch 224/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6007 - accuracy: 0.7478 - val_loss: 0.5842 - val_accuracy: 0.6912\n",
            "Epoch 225/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5942 - accuracy: 0.7454 - val_loss: 0.5332 - val_accuracy: 0.7316\n",
            "Epoch 226/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.6032 - accuracy: 0.7454 - val_loss: 0.6112 - val_accuracy: 0.6912\n",
            "Epoch 227/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5743 - accuracy: 0.7645 - val_loss: 0.5885 - val_accuracy: 0.6949\n",
            "Epoch 228/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5804 - accuracy: 0.7663 - val_loss: 0.5596 - val_accuracy: 0.6949\n",
            "Epoch 229/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5815 - accuracy: 0.7626 - val_loss: 0.5905 - val_accuracy: 0.6912\n",
            "Epoch 230/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5839 - accuracy: 0.7534 - val_loss: 0.5777 - val_accuracy: 0.6912\n",
            "Epoch 231/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5753 - accuracy: 0.7571 - val_loss: 0.5550 - val_accuracy: 0.7022\n",
            "Epoch 232/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5759 - accuracy: 0.7571 - val_loss: 0.5858 - val_accuracy: 0.6912\n",
            "Epoch 233/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5734 - accuracy: 0.7694 - val_loss: 0.5529 - val_accuracy: 0.7206\n",
            "Epoch 234/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.6112 - accuracy: 0.7368 - val_loss: 0.5656 - val_accuracy: 0.6949\n",
            "Epoch 235/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5922 - accuracy: 0.7645 - val_loss: 0.5565 - val_accuracy: 0.7243\n",
            "Epoch 236/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5991 - accuracy: 0.7497 - val_loss: 0.5863 - val_accuracy: 0.6838\n",
            "Epoch 237/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5970 - accuracy: 0.7571 - val_loss: 0.5518 - val_accuracy: 0.7243\n",
            "Epoch 238/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5970 - accuracy: 0.7448 - val_loss: 0.5694 - val_accuracy: 0.6912\n",
            "Epoch 239/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5704 - accuracy: 0.7651 - val_loss: 0.5410 - val_accuracy: 0.7390\n",
            "Epoch 240/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5795 - accuracy: 0.7558 - val_loss: 0.6147 - val_accuracy: 0.6985\n",
            "Epoch 241/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5745 - accuracy: 0.7645 - val_loss: 0.5646 - val_accuracy: 0.6912\n",
            "Epoch 242/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5731 - accuracy: 0.7626 - val_loss: 0.5812 - val_accuracy: 0.6912\n",
            "Epoch 243/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5985 - accuracy: 0.7423 - val_loss: 0.6248 - val_accuracy: 0.6949\n",
            "Epoch 244/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5859 - accuracy: 0.7552 - val_loss: 0.5580 - val_accuracy: 0.6949\n",
            "Epoch 245/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5822 - accuracy: 0.7595 - val_loss: 0.5825 - val_accuracy: 0.6912\n",
            "Epoch 246/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5776 - accuracy: 0.7608 - val_loss: 0.5513 - val_accuracy: 0.6949\n",
            "Epoch 247/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5688 - accuracy: 0.7589 - val_loss: 0.5444 - val_accuracy: 0.7096\n",
            "Epoch 248/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5623 - accuracy: 0.7608 - val_loss: 0.5441 - val_accuracy: 0.7316\n",
            "Epoch 249/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5958 - accuracy: 0.7515 - val_loss: 0.5872 - val_accuracy: 0.6912\n",
            "Epoch 250/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5789 - accuracy: 0.7663 - val_loss: 0.5444 - val_accuracy: 0.6949\n",
            "Epoch 251/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5642 - accuracy: 0.7638 - val_loss: 0.5514 - val_accuracy: 0.6875\n",
            "Epoch 252/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5673 - accuracy: 0.7651 - val_loss: 0.5798 - val_accuracy: 0.6912\n",
            "Epoch 253/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5652 - accuracy: 0.7780 - val_loss: 0.5669 - val_accuracy: 0.6912\n",
            "Epoch 254/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5719 - accuracy: 0.7595 - val_loss: 0.5882 - val_accuracy: 0.6838\n",
            "Epoch 255/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5810 - accuracy: 0.7694 - val_loss: 0.5710 - val_accuracy: 0.6912\n",
            "Epoch 256/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5721 - accuracy: 0.7651 - val_loss: 0.5922 - val_accuracy: 0.6838\n",
            "Epoch 257/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5846 - accuracy: 0.7681 - val_loss: 0.5560 - val_accuracy: 0.6912\n",
            "Epoch 258/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5786 - accuracy: 0.7608 - val_loss: 0.5867 - val_accuracy: 0.6875\n",
            "Epoch 259/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5713 - accuracy: 0.7620 - val_loss: 0.5412 - val_accuracy: 0.6985\n",
            "Epoch 260/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5697 - accuracy: 0.7614 - val_loss: 0.5762 - val_accuracy: 0.6912\n",
            "Epoch 261/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5676 - accuracy: 0.7638 - val_loss: 0.5597 - val_accuracy: 0.6838\n",
            "Epoch 262/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5546 - accuracy: 0.7688 - val_loss: 0.5846 - val_accuracy: 0.6875\n",
            "Epoch 263/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5814 - accuracy: 0.7466 - val_loss: 0.5601 - val_accuracy: 0.6912\n",
            "Epoch 264/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5545 - accuracy: 0.7712 - val_loss: 0.5841 - val_accuracy: 0.6875\n",
            "Epoch 265/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5723 - accuracy: 0.7595 - val_loss: 0.6036 - val_accuracy: 0.6838\n",
            "Epoch 266/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5878 - accuracy: 0.7497 - val_loss: 0.5757 - val_accuracy: 0.6838\n",
            "Epoch 267/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5807 - accuracy: 0.7614 - val_loss: 0.6038 - val_accuracy: 0.6838\n",
            "Epoch 268/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5608 - accuracy: 0.7712 - val_loss: 0.5855 - val_accuracy: 0.6875\n",
            "Epoch 269/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5773 - accuracy: 0.7620 - val_loss: 0.5611 - val_accuracy: 0.6912\n",
            "Epoch 270/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5680 - accuracy: 0.7638 - val_loss: 0.5519 - val_accuracy: 0.6912\n",
            "Epoch 271/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5691 - accuracy: 0.7681 - val_loss: 0.5834 - val_accuracy: 0.6912\n",
            "Epoch 272/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5598 - accuracy: 0.7626 - val_loss: 0.5572 - val_accuracy: 0.6912\n",
            "Epoch 273/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5863 - accuracy: 0.7577 - val_loss: 0.5770 - val_accuracy: 0.6912\n",
            "Epoch 274/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5705 - accuracy: 0.7645 - val_loss: 0.5793 - val_accuracy: 0.6801\n",
            "Epoch 275/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5505 - accuracy: 0.7675 - val_loss: 0.5586 - val_accuracy: 0.6912\n",
            "Epoch 276/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5515 - accuracy: 0.7768 - val_loss: 0.5529 - val_accuracy: 0.6949\n",
            "Epoch 277/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5674 - accuracy: 0.7595 - val_loss: 0.5595 - val_accuracy: 0.7169\n",
            "Epoch 278/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5516 - accuracy: 0.7589 - val_loss: 0.5672 - val_accuracy: 0.6912\n",
            "Epoch 279/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5650 - accuracy: 0.7583 - val_loss: 0.5685 - val_accuracy: 0.7096\n",
            "Epoch 280/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5641 - accuracy: 0.7651 - val_loss: 0.5415 - val_accuracy: 0.6912\n",
            "Epoch 281/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5770 - accuracy: 0.7583 - val_loss: 0.5562 - val_accuracy: 0.6949\n",
            "Epoch 282/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5596 - accuracy: 0.7669 - val_loss: 0.6196 - val_accuracy: 0.6985\n",
            "Epoch 283/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5785 - accuracy: 0.7614 - val_loss: 0.5800 - val_accuracy: 0.6838\n",
            "Epoch 284/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5682 - accuracy: 0.7571 - val_loss: 0.5700 - val_accuracy: 0.6912\n",
            "Epoch 285/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5735 - accuracy: 0.7632 - val_loss: 0.5588 - val_accuracy: 0.6949\n",
            "Epoch 286/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5538 - accuracy: 0.7614 - val_loss: 0.5513 - val_accuracy: 0.6949\n",
            "Epoch 287/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5652 - accuracy: 0.7724 - val_loss: 0.5370 - val_accuracy: 0.7206\n",
            "Epoch 288/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5611 - accuracy: 0.7731 - val_loss: 0.5756 - val_accuracy: 0.6912\n",
            "Epoch 289/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5787 - accuracy: 0.7571 - val_loss: 0.5929 - val_accuracy: 0.6949\n",
            "Epoch 290/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5696 - accuracy: 0.7620 - val_loss: 0.5686 - val_accuracy: 0.6875\n",
            "Epoch 291/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5638 - accuracy: 0.7546 - val_loss: 0.5723 - val_accuracy: 0.6912\n",
            "Epoch 292/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5446 - accuracy: 0.7731 - val_loss: 0.5672 - val_accuracy: 0.6912\n",
            "Epoch 293/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5618 - accuracy: 0.7657 - val_loss: 0.5807 - val_accuracy: 0.6912\n",
            "Epoch 294/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5546 - accuracy: 0.7651 - val_loss: 0.5988 - val_accuracy: 0.6838\n",
            "Epoch 295/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5558 - accuracy: 0.7718 - val_loss: 0.5613 - val_accuracy: 0.6912\n",
            "Epoch 296/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5675 - accuracy: 0.7681 - val_loss: 0.5737 - val_accuracy: 0.6912\n",
            "Epoch 297/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5761 - accuracy: 0.7571 - val_loss: 0.5809 - val_accuracy: 0.6875\n",
            "Epoch 298/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5504 - accuracy: 0.7768 - val_loss: 0.5728 - val_accuracy: 0.6949\n",
            "Epoch 299/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5578 - accuracy: 0.7601 - val_loss: 0.5821 - val_accuracy: 0.6875\n",
            "Epoch 300/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5530 - accuracy: 0.7712 - val_loss: 0.5419 - val_accuracy: 0.7022\n",
            "Epoch 301/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5672 - accuracy: 0.7706 - val_loss: 0.5674 - val_accuracy: 0.6838\n",
            "Epoch 302/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5650 - accuracy: 0.7626 - val_loss: 0.6075 - val_accuracy: 0.6838\n",
            "Epoch 303/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5638 - accuracy: 0.7681 - val_loss: 0.5544 - val_accuracy: 0.6949\n",
            "Epoch 304/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5693 - accuracy: 0.7700 - val_loss: 0.5915 - val_accuracy: 0.6875\n",
            "Epoch 305/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5517 - accuracy: 0.7675 - val_loss: 0.5768 - val_accuracy: 0.6838\n",
            "Epoch 306/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5659 - accuracy: 0.7663 - val_loss: 0.5572 - val_accuracy: 0.6875\n",
            "Epoch 307/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5362 - accuracy: 0.7847 - val_loss: 0.5666 - val_accuracy: 0.6875\n",
            "Epoch 308/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5636 - accuracy: 0.7608 - val_loss: 0.5898 - val_accuracy: 0.6875\n",
            "Epoch 309/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5453 - accuracy: 0.7743 - val_loss: 0.5841 - val_accuracy: 0.6912\n",
            "Epoch 310/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5530 - accuracy: 0.7645 - val_loss: 0.5805 - val_accuracy: 0.6912\n",
            "Epoch 311/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5629 - accuracy: 0.7645 - val_loss: 0.5785 - val_accuracy: 0.6985\n",
            "Epoch 312/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5500 - accuracy: 0.7749 - val_loss: 0.5704 - val_accuracy: 0.6985\n",
            "Epoch 313/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5469 - accuracy: 0.7712 - val_loss: 0.5520 - val_accuracy: 0.6985\n",
            "Epoch 314/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5450 - accuracy: 0.7700 - val_loss: 0.5584 - val_accuracy: 0.6912\n",
            "Epoch 315/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5587 - accuracy: 0.7768 - val_loss: 0.5719 - val_accuracy: 0.6949\n",
            "Epoch 316/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5465 - accuracy: 0.7780 - val_loss: 0.5710 - val_accuracy: 0.6985\n",
            "Epoch 317/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5542 - accuracy: 0.7638 - val_loss: 0.5527 - val_accuracy: 0.7059\n",
            "Epoch 318/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5465 - accuracy: 0.7718 - val_loss: 0.5751 - val_accuracy: 0.6949\n",
            "Epoch 319/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5643 - accuracy: 0.7688 - val_loss: 0.5424 - val_accuracy: 0.7022\n",
            "Epoch 320/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5485 - accuracy: 0.7651 - val_loss: 0.5862 - val_accuracy: 0.6838\n",
            "Epoch 321/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5401 - accuracy: 0.7774 - val_loss: 0.5875 - val_accuracy: 0.6875\n",
            "Epoch 322/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5511 - accuracy: 0.7737 - val_loss: 0.5584 - val_accuracy: 0.7022\n",
            "Epoch 323/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5480 - accuracy: 0.7774 - val_loss: 0.5506 - val_accuracy: 0.6949\n",
            "Epoch 324/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5508 - accuracy: 0.7675 - val_loss: 0.5593 - val_accuracy: 0.6949\n",
            "Epoch 325/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5425 - accuracy: 0.7829 - val_loss: 0.5579 - val_accuracy: 0.6838\n",
            "Epoch 326/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.5434 - accuracy: 0.7645 - val_loss: 0.5718 - val_accuracy: 0.6949\n",
            "Epoch 327/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5409 - accuracy: 0.7755 - val_loss: 0.5550 - val_accuracy: 0.6838\n",
            "Epoch 328/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5599 - accuracy: 0.7595 - val_loss: 0.5728 - val_accuracy: 0.6949\n",
            "Epoch 329/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5457 - accuracy: 0.7724 - val_loss: 0.5764 - val_accuracy: 0.6985\n",
            "Epoch 330/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5569 - accuracy: 0.7675 - val_loss: 0.5737 - val_accuracy: 0.6912\n",
            "Epoch 331/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5621 - accuracy: 0.7651 - val_loss: 0.5782 - val_accuracy: 0.6985\n",
            "Epoch 332/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5653 - accuracy: 0.7601 - val_loss: 0.5654 - val_accuracy: 0.6875\n",
            "Epoch 333/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5513 - accuracy: 0.7700 - val_loss: 0.5519 - val_accuracy: 0.6838\n",
            "Epoch 334/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5415 - accuracy: 0.7681 - val_loss: 0.5726 - val_accuracy: 0.6949\n",
            "Epoch 335/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5370 - accuracy: 0.7891 - val_loss: 0.5665 - val_accuracy: 0.6985\n",
            "Epoch 336/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5380 - accuracy: 0.7718 - val_loss: 0.5605 - val_accuracy: 0.6949\n",
            "Epoch 337/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5470 - accuracy: 0.7632 - val_loss: 0.5592 - val_accuracy: 0.6985\n",
            "Epoch 338/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5508 - accuracy: 0.7743 - val_loss: 0.5621 - val_accuracy: 0.6985\n",
            "Epoch 339/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5456 - accuracy: 0.7712 - val_loss: 0.5824 - val_accuracy: 0.6875\n",
            "Epoch 340/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5488 - accuracy: 0.7737 - val_loss: 0.5770 - val_accuracy: 0.6949\n",
            "Epoch 341/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5435 - accuracy: 0.7706 - val_loss: 0.5828 - val_accuracy: 0.6838\n",
            "Epoch 342/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5434 - accuracy: 0.7724 - val_loss: 0.5709 - val_accuracy: 0.6912\n",
            "Epoch 343/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5418 - accuracy: 0.7835 - val_loss: 0.5886 - val_accuracy: 0.6838\n",
            "Epoch 344/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5324 - accuracy: 0.7817 - val_loss: 0.5752 - val_accuracy: 0.6912\n",
            "Epoch 345/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5549 - accuracy: 0.7645 - val_loss: 0.5423 - val_accuracy: 0.7059\n",
            "Epoch 346/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5380 - accuracy: 0.7761 - val_loss: 0.5767 - val_accuracy: 0.7096\n",
            "Epoch 347/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5538 - accuracy: 0.7645 - val_loss: 0.5741 - val_accuracy: 0.6875\n",
            "Epoch 348/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5401 - accuracy: 0.7891 - val_loss: 0.5688 - val_accuracy: 0.7059\n",
            "Epoch 349/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5355 - accuracy: 0.7786 - val_loss: 0.5469 - val_accuracy: 0.7022\n",
            "Epoch 350/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5514 - accuracy: 0.7651 - val_loss: 0.5825 - val_accuracy: 0.6985\n",
            "Epoch 351/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5337 - accuracy: 0.7712 - val_loss: 0.5458 - val_accuracy: 0.6801\n",
            "Epoch 352/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5558 - accuracy: 0.7657 - val_loss: 0.5832 - val_accuracy: 0.6949\n",
            "Epoch 353/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5606 - accuracy: 0.7515 - val_loss: 0.5930 - val_accuracy: 0.6838\n",
            "Epoch 354/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5429 - accuracy: 0.7688 - val_loss: 0.5867 - val_accuracy: 0.6949\n",
            "Epoch 355/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5300 - accuracy: 0.7872 - val_loss: 0.5745 - val_accuracy: 0.6985\n",
            "Epoch 356/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5538 - accuracy: 0.7681 - val_loss: 0.5521 - val_accuracy: 0.6875\n",
            "Epoch 357/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5204 - accuracy: 0.7866 - val_loss: 0.5542 - val_accuracy: 0.7059\n",
            "Epoch 358/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5415 - accuracy: 0.7601 - val_loss: 0.5491 - val_accuracy: 0.7059\n",
            "Epoch 359/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5293 - accuracy: 0.7811 - val_loss: 0.5657 - val_accuracy: 0.6875\n",
            "Epoch 360/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5511 - accuracy: 0.7700 - val_loss: 0.5530 - val_accuracy: 0.6875\n",
            "Epoch 361/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5533 - accuracy: 0.7688 - val_loss: 0.5686 - val_accuracy: 0.7132\n",
            "Epoch 362/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5333 - accuracy: 0.7768 - val_loss: 0.5533 - val_accuracy: 0.7022\n",
            "Epoch 363/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5267 - accuracy: 0.7835 - val_loss: 0.5710 - val_accuracy: 0.6875\n",
            "Epoch 364/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5416 - accuracy: 0.7866 - val_loss: 0.5687 - val_accuracy: 0.7096\n",
            "Epoch 365/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5377 - accuracy: 0.7798 - val_loss: 0.5676 - val_accuracy: 0.6985\n",
            "Epoch 366/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5436 - accuracy: 0.7731 - val_loss: 0.5741 - val_accuracy: 0.6985\n",
            "Epoch 367/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5306 - accuracy: 0.7811 - val_loss: 0.5588 - val_accuracy: 0.6875\n",
            "Epoch 368/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5450 - accuracy: 0.7798 - val_loss: 0.5665 - val_accuracy: 0.6838\n",
            "Epoch 369/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5230 - accuracy: 0.8020 - val_loss: 0.5748 - val_accuracy: 0.7132\n",
            "Epoch 370/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5549 - accuracy: 0.7620 - val_loss: 0.5842 - val_accuracy: 0.6985\n",
            "Epoch 371/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5258 - accuracy: 0.7891 - val_loss: 0.5937 - val_accuracy: 0.6875\n",
            "Epoch 372/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5481 - accuracy: 0.7817 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
            "Epoch 373/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5277 - accuracy: 0.7872 - val_loss: 0.5660 - val_accuracy: 0.7096\n",
            "Epoch 374/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5429 - accuracy: 0.7657 - val_loss: 0.5585 - val_accuracy: 0.6985\n",
            "Epoch 375/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5321 - accuracy: 0.7878 - val_loss: 0.5670 - val_accuracy: 0.6875\n",
            "Epoch 376/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5313 - accuracy: 0.7706 - val_loss: 0.5506 - val_accuracy: 0.7022\n",
            "Epoch 377/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5330 - accuracy: 0.7774 - val_loss: 0.5911 - val_accuracy: 0.6875\n",
            "Epoch 378/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5456 - accuracy: 0.7675 - val_loss: 0.5713 - val_accuracy: 0.7022\n",
            "Epoch 379/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5323 - accuracy: 0.7835 - val_loss: 0.5456 - val_accuracy: 0.7169\n",
            "Epoch 380/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5378 - accuracy: 0.7946 - val_loss: 0.5768 - val_accuracy: 0.7096\n",
            "Epoch 381/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5289 - accuracy: 0.7792 - val_loss: 0.5695 - val_accuracy: 0.7169\n",
            "Epoch 382/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5330 - accuracy: 0.7817 - val_loss: 0.5551 - val_accuracy: 0.6985\n",
            "Epoch 383/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5387 - accuracy: 0.7786 - val_loss: 0.5847 - val_accuracy: 0.7096\n",
            "Epoch 384/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5518 - accuracy: 0.7792 - val_loss: 0.6005 - val_accuracy: 0.6985\n",
            "Epoch 385/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5453 - accuracy: 0.7774 - val_loss: 0.5849 - val_accuracy: 0.6912\n",
            "Epoch 386/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5174 - accuracy: 0.7952 - val_loss: 0.5517 - val_accuracy: 0.7132\n",
            "Epoch 387/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5314 - accuracy: 0.7804 - val_loss: 0.5500 - val_accuracy: 0.6949\n",
            "Epoch 388/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5448 - accuracy: 0.7823 - val_loss: 0.5624 - val_accuracy: 0.7059\n",
            "Epoch 389/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5317 - accuracy: 0.7829 - val_loss: 0.5529 - val_accuracy: 0.6875\n",
            "Epoch 390/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5339 - accuracy: 0.7811 - val_loss: 0.5839 - val_accuracy: 0.7096\n",
            "Epoch 391/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5330 - accuracy: 0.7891 - val_loss: 0.5685 - val_accuracy: 0.6875\n",
            "Epoch 392/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5299 - accuracy: 0.7847 - val_loss: 0.5507 - val_accuracy: 0.7206\n",
            "Epoch 393/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5472 - accuracy: 0.7860 - val_loss: 0.5743 - val_accuracy: 0.6912\n",
            "Epoch 394/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5438 - accuracy: 0.7798 - val_loss: 0.5735 - val_accuracy: 0.6875\n",
            "Epoch 395/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5248 - accuracy: 0.7841 - val_loss: 0.5596 - val_accuracy: 0.7059\n",
            "Epoch 396/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5371 - accuracy: 0.7817 - val_loss: 0.5706 - val_accuracy: 0.6875\n",
            "Epoch 397/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5211 - accuracy: 0.7829 - val_loss: 0.5725 - val_accuracy: 0.7132\n",
            "Epoch 398/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5275 - accuracy: 0.7983 - val_loss: 0.5727 - val_accuracy: 0.6912\n",
            "Epoch 399/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5076 - accuracy: 0.8050 - val_loss: 0.5586 - val_accuracy: 0.7132\n",
            "Epoch 400/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5343 - accuracy: 0.7811 - val_loss: 0.5500 - val_accuracy: 0.7022\n",
            "Epoch 401/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5306 - accuracy: 0.7749 - val_loss: 0.5557 - val_accuracy: 0.6985\n",
            "Epoch 402/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5270 - accuracy: 0.7755 - val_loss: 0.5987 - val_accuracy: 0.7096\n",
            "Epoch 403/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5243 - accuracy: 0.7860 - val_loss: 0.5694 - val_accuracy: 0.6875\n",
            "Epoch 404/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5433 - accuracy: 0.7811 - val_loss: 0.5662 - val_accuracy: 0.6875\n",
            "Epoch 405/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5240 - accuracy: 0.7718 - val_loss: 0.5909 - val_accuracy: 0.6875\n",
            "Epoch 406/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5344 - accuracy: 0.7829 - val_loss: 0.5736 - val_accuracy: 0.7169\n",
            "Epoch 407/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5449 - accuracy: 0.7774 - val_loss: 0.5819 - val_accuracy: 0.6875\n",
            "Epoch 408/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5391 - accuracy: 0.7749 - val_loss: 0.5845 - val_accuracy: 0.7132\n",
            "Epoch 409/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5309 - accuracy: 0.7872 - val_loss: 0.5671 - val_accuracy: 0.7206\n",
            "Epoch 410/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5357 - accuracy: 0.7786 - val_loss: 0.5650 - val_accuracy: 0.7096\n",
            "Epoch 411/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5336 - accuracy: 0.7811 - val_loss: 0.5856 - val_accuracy: 0.6875\n",
            "Epoch 412/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5271 - accuracy: 0.7872 - val_loss: 0.5576 - val_accuracy: 0.7243\n",
            "Epoch 413/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5217 - accuracy: 0.7823 - val_loss: 0.5493 - val_accuracy: 0.7096\n",
            "Epoch 414/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5326 - accuracy: 0.7768 - val_loss: 0.5794 - val_accuracy: 0.6912\n",
            "Epoch 415/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5165 - accuracy: 0.8001 - val_loss: 0.5586 - val_accuracy: 0.7059\n",
            "Epoch 416/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5307 - accuracy: 0.7811 - val_loss: 0.5567 - val_accuracy: 0.7096\n",
            "Epoch 417/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5294 - accuracy: 0.7921 - val_loss: 0.5599 - val_accuracy: 0.7059\n",
            "Epoch 418/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5282 - accuracy: 0.7847 - val_loss: 0.5410 - val_accuracy: 0.7537\n",
            "Epoch 419/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5186 - accuracy: 0.7909 - val_loss: 0.5726 - val_accuracy: 0.7022\n",
            "Epoch 420/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5204 - accuracy: 0.7841 - val_loss: 0.5691 - val_accuracy: 0.7169\n",
            "Epoch 421/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5427 - accuracy: 0.7755 - val_loss: 0.5601 - val_accuracy: 0.7059\n",
            "Epoch 422/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5299 - accuracy: 0.7872 - val_loss: 0.5764 - val_accuracy: 0.7059\n",
            "Epoch 423/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5227 - accuracy: 0.7743 - val_loss: 0.5635 - val_accuracy: 0.7022\n",
            "Epoch 424/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5246 - accuracy: 0.7817 - val_loss: 0.5586 - val_accuracy: 0.7169\n",
            "Epoch 425/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5213 - accuracy: 0.7854 - val_loss: 0.5630 - val_accuracy: 0.7059\n",
            "Epoch 426/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5223 - accuracy: 0.7847 - val_loss: 0.5766 - val_accuracy: 0.7096\n",
            "Epoch 427/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5190 - accuracy: 0.7835 - val_loss: 0.5608 - val_accuracy: 0.7022\n",
            "Epoch 428/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5290 - accuracy: 0.7934 - val_loss: 0.5639 - val_accuracy: 0.7132\n",
            "Epoch 429/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5310 - accuracy: 0.7841 - val_loss: 0.5625 - val_accuracy: 0.7059\n",
            "Epoch 430/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5249 - accuracy: 0.7872 - val_loss: 0.5705 - val_accuracy: 0.7022\n",
            "Epoch 431/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5261 - accuracy: 0.7774 - val_loss: 0.5951 - val_accuracy: 0.7206\n",
            "Epoch 432/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5191 - accuracy: 0.7841 - val_loss: 0.5663 - val_accuracy: 0.7022\n",
            "Epoch 433/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5337 - accuracy: 0.7774 - val_loss: 0.5674 - val_accuracy: 0.7096\n",
            "Epoch 434/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5330 - accuracy: 0.7847 - val_loss: 0.5766 - val_accuracy: 0.7132\n",
            "Epoch 435/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5226 - accuracy: 0.7964 - val_loss: 0.5765 - val_accuracy: 0.7132\n",
            "Epoch 436/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5224 - accuracy: 0.7780 - val_loss: 0.5675 - val_accuracy: 0.6912\n",
            "Epoch 437/500\n",
            "26/26 [==============================] - 2s 75ms/step - loss: 0.5258 - accuracy: 0.7958 - val_loss: 0.5667 - val_accuracy: 0.6949\n",
            "Epoch 438/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5232 - accuracy: 0.7946 - val_loss: 0.5733 - val_accuracy: 0.7022\n",
            "Epoch 439/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5173 - accuracy: 0.7915 - val_loss: 0.5635 - val_accuracy: 0.7169\n",
            "Epoch 440/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5375 - accuracy: 0.7817 - val_loss: 0.5563 - val_accuracy: 0.7059\n",
            "Epoch 441/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5415 - accuracy: 0.7811 - val_loss: 0.5603 - val_accuracy: 0.7132\n",
            "Epoch 442/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5230 - accuracy: 0.7903 - val_loss: 0.5817 - val_accuracy: 0.7022\n",
            "Epoch 443/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5282 - accuracy: 0.7737 - val_loss: 0.5681 - val_accuracy: 0.7022\n",
            "Epoch 444/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5290 - accuracy: 0.7970 - val_loss: 0.5834 - val_accuracy: 0.7206\n",
            "Epoch 445/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5358 - accuracy: 0.7854 - val_loss: 0.5507 - val_accuracy: 0.7096\n",
            "Epoch 446/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5282 - accuracy: 0.7995 - val_loss: 0.5503 - val_accuracy: 0.7059\n",
            "Epoch 447/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5126 - accuracy: 0.7897 - val_loss: 0.5487 - val_accuracy: 0.7096\n",
            "Epoch 448/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5112 - accuracy: 0.8069 - val_loss: 0.5476 - val_accuracy: 0.7279\n",
            "Epoch 449/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5464 - accuracy: 0.7755 - val_loss: 0.5896 - val_accuracy: 0.7059\n",
            "Epoch 450/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5367 - accuracy: 0.7792 - val_loss: 0.6149 - val_accuracy: 0.6875\n",
            "Epoch 451/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5421 - accuracy: 0.7743 - val_loss: 0.5646 - val_accuracy: 0.7169\n",
            "Epoch 452/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5491 - accuracy: 0.7681 - val_loss: 0.5647 - val_accuracy: 0.7132\n",
            "Epoch 453/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5134 - accuracy: 0.7878 - val_loss: 0.5621 - val_accuracy: 0.7206\n",
            "Epoch 454/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5264 - accuracy: 0.7841 - val_loss: 0.5741 - val_accuracy: 0.7096\n",
            "Epoch 455/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5037 - accuracy: 0.7847 - val_loss: 0.5791 - val_accuracy: 0.7132\n",
            "Epoch 456/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5144 - accuracy: 0.7897 - val_loss: 0.5714 - val_accuracy: 0.7096\n",
            "Epoch 457/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5221 - accuracy: 0.7823 - val_loss: 0.5753 - val_accuracy: 0.7169\n",
            "Epoch 458/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5232 - accuracy: 0.7903 - val_loss: 0.5579 - val_accuracy: 0.7206\n",
            "Epoch 459/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5202 - accuracy: 0.7823 - val_loss: 0.5917 - val_accuracy: 0.7059\n",
            "Epoch 460/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5080 - accuracy: 0.7884 - val_loss: 0.5925 - val_accuracy: 0.7096\n",
            "Epoch 461/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5181 - accuracy: 0.7884 - val_loss: 0.5682 - val_accuracy: 0.7096\n",
            "Epoch 462/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5333 - accuracy: 0.7872 - val_loss: 0.5474 - val_accuracy: 0.7132\n",
            "Epoch 463/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5410 - accuracy: 0.7786 - val_loss: 0.5749 - val_accuracy: 0.7169\n",
            "Epoch 464/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5129 - accuracy: 0.7927 - val_loss: 0.5556 - val_accuracy: 0.7059\n",
            "Epoch 465/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5260 - accuracy: 0.7854 - val_loss: 0.6040 - val_accuracy: 0.7132\n",
            "Epoch 466/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5027 - accuracy: 0.7860 - val_loss: 0.5487 - val_accuracy: 0.7206\n",
            "Epoch 467/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5231 - accuracy: 0.7823 - val_loss: 0.5667 - val_accuracy: 0.7206\n",
            "Epoch 468/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5238 - accuracy: 0.7829 - val_loss: 0.5607 - val_accuracy: 0.7059\n",
            "Epoch 469/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5013 - accuracy: 0.8014 - val_loss: 0.5787 - val_accuracy: 0.7096\n",
            "Epoch 470/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5272 - accuracy: 0.7897 - val_loss: 0.5857 - val_accuracy: 0.7059\n",
            "Epoch 471/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5181 - accuracy: 0.7927 - val_loss: 0.5592 - val_accuracy: 0.7059\n",
            "Epoch 472/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5211 - accuracy: 0.7743 - val_loss: 0.5629 - val_accuracy: 0.7059\n",
            "Epoch 473/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5423 - accuracy: 0.7835 - val_loss: 0.5672 - val_accuracy: 0.7206\n",
            "Epoch 474/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.4989 - accuracy: 0.8057 - val_loss: 0.5418 - val_accuracy: 0.7206\n",
            "Epoch 475/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5215 - accuracy: 0.7786 - val_loss: 0.5504 - val_accuracy: 0.7059\n",
            "Epoch 476/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5059 - accuracy: 0.7934 - val_loss: 0.5598 - val_accuracy: 0.7206\n",
            "Epoch 477/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5272 - accuracy: 0.7878 - val_loss: 0.5850 - val_accuracy: 0.7206\n",
            "Epoch 478/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5412 - accuracy: 0.7823 - val_loss: 0.5655 - val_accuracy: 0.7059\n",
            "Epoch 479/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5100 - accuracy: 0.7927 - val_loss: 0.5881 - val_accuracy: 0.7022\n",
            "Epoch 480/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5258 - accuracy: 0.7749 - val_loss: 0.5494 - val_accuracy: 0.7096\n",
            "Epoch 481/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5124 - accuracy: 0.7841 - val_loss: 0.5563 - val_accuracy: 0.7132\n",
            "Epoch 482/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5173 - accuracy: 0.7995 - val_loss: 0.5406 - val_accuracy: 0.7096\n",
            "Epoch 483/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5276 - accuracy: 0.7823 - val_loss: 0.5466 - val_accuracy: 0.7279\n",
            "Epoch 484/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5164 - accuracy: 0.7786 - val_loss: 0.5524 - val_accuracy: 0.7169\n",
            "Epoch 485/500\n",
            "26/26 [==============================] - 2s 80ms/step - loss: 0.5278 - accuracy: 0.7977 - val_loss: 0.5599 - val_accuracy: 0.7059\n",
            "Epoch 486/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5122 - accuracy: 0.7952 - val_loss: 0.5695 - val_accuracy: 0.7206\n",
            "Epoch 487/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5217 - accuracy: 0.7878 - val_loss: 0.5502 - val_accuracy: 0.7096\n",
            "Epoch 488/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5158 - accuracy: 0.7958 - val_loss: 0.5765 - val_accuracy: 0.7059\n",
            "Epoch 489/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5146 - accuracy: 0.7774 - val_loss: 0.5634 - val_accuracy: 0.7169\n",
            "Epoch 490/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5256 - accuracy: 0.7798 - val_loss: 0.5621 - val_accuracy: 0.7096\n",
            "Epoch 491/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5129 - accuracy: 0.7891 - val_loss: 0.5476 - val_accuracy: 0.7132\n",
            "Epoch 492/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5115 - accuracy: 0.7909 - val_loss: 0.5794 - val_accuracy: 0.7096\n",
            "Epoch 493/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5156 - accuracy: 0.7872 - val_loss: 0.5571 - val_accuracy: 0.7096\n",
            "Epoch 494/500\n",
            "26/26 [==============================] - 2s 79ms/step - loss: 0.5168 - accuracy: 0.7983 - val_loss: 0.5721 - val_accuracy: 0.7206\n",
            "Epoch 495/500\n",
            "26/26 [==============================] - 2s 76ms/step - loss: 0.5181 - accuracy: 0.7811 - val_loss: 0.5527 - val_accuracy: 0.7096\n",
            "Epoch 496/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5155 - accuracy: 0.7989 - val_loss: 0.5872 - val_accuracy: 0.7096\n",
            "Epoch 497/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5193 - accuracy: 0.7847 - val_loss: 0.5689 - val_accuracy: 0.7096\n",
            "Epoch 498/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5122 - accuracy: 0.7866 - val_loss: 0.6036 - val_accuracy: 0.7206\n",
            "Epoch 499/500\n",
            "26/26 [==============================] - 2s 77ms/step - loss: 0.5204 - accuracy: 0.7884 - val_loss: 0.5792 - val_accuracy: 0.7096\n",
            "Epoch 500/500\n",
            "26/26 [==============================] - 2s 78ms/step - loss: 0.5227 - accuracy: 0.7817 - val_loss: 0.5730 - val_accuracy: 0.7096\n"
          ]
        }
      ],
      "source": [
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer= keras.optimizers.Adam(0.001, decay=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "# Start training the model.\n",
        "cnn_3d_model_training_history = model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=500,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle = True,\n",
        "                                          validation_data = (features_valid, labels_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3vimsgjjbXvL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6da5000d-81e3-4e6a-af99-f703924c9b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 21ms/step - loss: 0.6576 - accuracy: 0.7243\n",
            "\n",
            "\n",
            "Train accuracy: 76.691 % || Test accuracy: 72.426 % || Val accuracy: 70.956 %\n",
            "Train loss: 0.480 || Test loss: 0.658 || Val loss: 0.573\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ivmaK9BlbnRQ"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'3D_CNN_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p cnn_3d_{current_date_time_string}\n",
        "# Save your Model.\n",
        "model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OwU8TwPrbsKB"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "cvKY05ncbwof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "2714c12f-a3bd-4d21-f53c-b797053baed8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o1iaaDHBb5i0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ceeaf074-8452-4a0c-e7e3-1a6781f63cee"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(cnn_3d_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3D_CNN_No_Splint.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOooD4+LIs1bl53wwIiZqVo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}