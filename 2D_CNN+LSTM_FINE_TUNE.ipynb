{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/2D_CNN%2BLSTM_FINE_TUNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8TLrPiv-ab"
      },
      "source": [
        "####**Convolutional Neural Network + Long Short Term Memory**\n",
        "######*I am using a Convolution Neural Network (CNN) + Long Short Term Memory (LSTM) Network to extract general representation while utilizing the Spatial-temporal aspect of the videos.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8ibtd5HKtZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf7f169-c983-47e9-8076-112b538297a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)\n",
        "# https://bleedai.com/human-activity-recognition-using-tensorflow-cnn-lstm/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ],
      "metadata": {
        "id": "LQG5OyCvdrEp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yJblbgIBdthN",
        "outputId": "bf24f039-f4d8-4897-951e-4f42c5128a2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 120, 120\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ],
      "metadata": {
        "id": "z6J-CWMspHtX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ],
      "metadata": {
        "id": "BdVrDyPxpKIU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/analytics-vidhya/video-preprocessor-and-augmentation-for-deep-learning-tasks-12dd3fcce868\n",
        "def load_video(path, resize=(120, 120)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            black_frame = frame\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ],
      "metadata": {
        "id": "ah7C52S1pOAf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ],
      "metadata": {
        "id": "y7e3nTHcpQ6a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Do0iTsopUN4",
        "outputId": "b361d7a5-4b85-4c55-c773-ab7636db3019"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one_hot_encoded_labels\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ],
      "metadata": {
        "id": "eypY9qHnpWye"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yXe59rJMsrAz",
        "outputId": "b8ee1193-1ad9-4728-e63d-e2dd86c108ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247/Saved_models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_Model = tf.keras.models.load_model('convlstm_2022_04_28__02_44_17/convlstm_model___Date_Time_2022_04_28__02_44_17___Loss_0.7613360285758972___Accuracy_0.7242646813392639.h5')\n",
        "trained_Model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4u8TCKucsvX",
        "outputId": "35ccd408-3b78-4613-dc25-7e361bc95191"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d (ConvLSTM2D)    (None, 16, 116, 116, 4)   2816      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 16, 58, 58, 4)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 16, 58, 58, 4)    0         \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " conv_lstm2d_1 (ConvLSTM2D)  (None, 16, 54, 54, 8)     9632      \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 16, 27, 27, 8)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 16, 27, 27, 8)    0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv_lstm2d_2 (ConvLSTM2D)  (None, 16, 23, 23, 14)    30856     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 16, 12, 12, 14)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 16, 12, 12, 14)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv_lstm2d_3 (ConvLSTM2D)  (None, 16, 8, 8, 16)      48064     \n",
            "                                                                 \n",
            " max_pooling3d_3 (MaxPooling  (None, 16, 4, 4, 16)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4)                 16388     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,756\n",
            "Trainable params: 107,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = trained_Model.evaluate(features_test, labels_test, verbose=2)\n",
        "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
        "print(trained_Model.predict(features_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1IRGR4_r_Fy",
        "outputId": "8acefa5e-4344-4752-a9e8-b3d043ca8297"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 - 10s - loss: 0.7613 - accuracy: 0.7243 - 10s/epoch - 1s/step\n",
            "Restored model, accuracy: 72.43%\n",
            "(272, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the base model\n",
        "trained_Model.trainable = True\n",
        "\n",
        "# Create an Instance of Early Stopping Callback\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                                        patience = 10,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "# to the `trainable` attribute of any inner layer, so that your changes\n",
        "# are take into account\n",
        "trained_Model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "              metrics = [\"accuracy\"])\n",
        "              # loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              # metrics=[keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "# Train end-to-end. Be careful to stop before you overfit!\n",
        "cnn_3d_fine_tuned_model_training_history = trained_Model.fit(x = features_train,\n",
        "                                          y = labels_train,\n",
        "                                          epochs=50,\n",
        "                                          batch_size=4,\n",
        "                                          validation_data = (features_valid, labels_valid),\n",
        "                                          callbacks = [early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQUc88gWvROI",
        "outputId": "b7b2811d-c6ef-4ffd-b9e8-9eec703bea36"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "404/404 [==============================] - 116s 266ms/step - loss: 0.3715 - accuracy: 0.8422 - val_loss: 0.6156 - val_accuracy: 0.7794\n",
            "Epoch 2/50\n",
            "404/404 [==============================] - 106s 262ms/step - loss: 0.3296 - accuracy: 0.8577 - val_loss: 0.6194 - val_accuracy: 0.7868\n",
            "Epoch 3/50\n",
            "404/404 [==============================] - 106s 262ms/step - loss: 0.3111 - accuracy: 0.8663 - val_loss: 0.6243 - val_accuracy: 0.7941\n",
            "Epoch 4/50\n",
            "404/404 [==============================] - 105s 261ms/step - loss: 0.3027 - accuracy: 0.8639 - val_loss: 0.6303 - val_accuracy: 0.7904\n",
            "Epoch 5/50\n",
            "404/404 [==============================] - 105s 260ms/step - loss: 0.2938 - accuracy: 0.8744 - val_loss: 0.6357 - val_accuracy: 0.7904\n",
            "Epoch 6/50\n",
            "404/404 [==============================] - 105s 260ms/step - loss: 0.2798 - accuracy: 0.8812 - val_loss: 0.6426 - val_accuracy: 0.7868\n",
            "Epoch 7/50\n",
            "404/404 [==============================] - 105s 259ms/step - loss: 0.2821 - accuracy: 0.8793 - val_loss: 0.6485 - val_accuracy: 0.7831\n",
            "Epoch 8/50\n",
            "404/404 [==============================] - 104s 258ms/step - loss: 0.2763 - accuracy: 0.8750 - val_loss: 0.6554 - val_accuracy: 0.7831\n",
            "Epoch 9/50\n",
            "404/404 [==============================] - 104s 258ms/step - loss: 0.2763 - accuracy: 0.8769 - val_loss: 0.6636 - val_accuracy: 0.7721\n",
            "Epoch 10/50\n",
            "404/404 [==============================] - 104s 258ms/step - loss: 0.2720 - accuracy: 0.8731 - val_loss: 0.6720 - val_accuracy: 0.7610\n",
            "Epoch 11/50\n",
            "404/404 [==============================] - 104s 258ms/step - loss: 0.2607 - accuracy: 0.8843 - val_loss: 0.6849 - val_accuracy: 0.7574\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation_history = trained_Model.evaluate(features_test, labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KUEISfZxScL",
        "outputId": "df8437ae-b0f1-401f-ae51-df8350a234d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 2s 122ms/step - loss: 0.7711 - accuracy: 0.7610\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'fine_tuned_convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        " \n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/convlstm_2022_04_28__02_44_17/'\n",
        "os.chdir(gdrive_path)\n",
        "# Save your Model.\n",
        "trained_Model.save('fine_tuned_convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "trained_Model.save_weights('fine_tuned_convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ],
      "metadata": {
        "id": "dScBXaAdyGqd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history.history[metric_name_1]\n",
        "    metric_value_2 = model_training_history.history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "PFXKaQB50WOJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(convlstm_fine_tuned_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "UfPhZKuH0ZGP",
        "outputId": "419a10d1-1df8-45a7-dd99-171371ae2003"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4891e09c9795>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvlstm_fine_tuned_model_training_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Total Loss vs Total Validation Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'convlstm_fine_tuned_model_training_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(convlstm_fine_tuned_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ],
      "metadata": {
        "id": "w9qJdAOo0odX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "2D_CNN+LSTM_FINE_TUNE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVJs+GiDrQUASs+ENu/V9k",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}