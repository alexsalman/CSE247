{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexsalman/CSE247/blob/main/2D_CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8TLrPiv-ab"
      },
      "source": [
        "####**Convolutional Neural Network + Long Short Term Memory**\n",
        "######*I am using a Convolution Neural Network (CNN) + Long Short Term Memory (LSTM) Network to extract general representation while utilizing the Spatial-temporal aspect of the videos.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8ibtd5HKtZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5de478-3bb5-4511-f0f1-d5af2f006283"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# required libraries\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import TimeDistributed, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras import regularizers\n",
        "%matplotlib inline\n",
        "print(tf.version.VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iffdFOf1CEAN"
      },
      "outputs": [],
      "source": [
        "# set Numpy, Python, and Tensorflow seeds to get consistent results on every execution\n",
        "seed_constant = 27\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mcLh22LiOHyn",
        "outputId": "665b1fbd-f470-4f81-d4b6-370cf6ac59fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/247'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# mount dataset from google drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/'\n",
        "os.chdir(gdrive_path)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oeDK8SzumZ1Q"
      },
      "outputs": [],
      "source": [
        "# frame dimention\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 128, 128\n",
        "# frame number for each video (depth)\n",
        "SEQUENCE_LENGTH = 16\n",
        "# video dir path\n",
        "DATASET_DIR = gdrive_path + 'Cropped_videos'\n",
        "# labels of classes\n",
        "CLASSES_LIST = ['hemostasis', 'inflammatory', 'proliferative', 'maturation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3mFB5qD6b3Kd"
      },
      "outputs": [],
      "source": [
        "# image cropping\n",
        "def crop_center_square(frame):\n",
        "    y, x = frame.shape[0:2]\n",
        "    min_dim = min(y, x)\n",
        "    start_x = (x // 2) - (min_dim // 2)\n",
        "    start_y = (y // 2) - (min_dim // 2)\n",
        "    return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sqeexMUjaLzJ"
      },
      "outputs": [],
      "source": [
        "def load_video(path, resize=(128, 128)):\n",
        "    video_reader = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "    try:\n",
        "        while True:\n",
        "            ret, frame = video_reader.read()\n",
        "            if not ret:\n",
        "                  break\n",
        "            frame = crop_center_square(frame)\n",
        "            frame = cv2.resize(frame, resize)\n",
        "            frame = frame[:, :, [2, 1, 0]]\n",
        "            frames.append(frame)\n",
        "    finally:\n",
        "        video_reader.release()\n",
        "    return np.array(frames) / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ljUWHW6Jqzu-"
      },
      "outputs": [],
      "source": [
        "def create_dataset(state):\n",
        "    # Declared Empty Lists to store the features, labels and video file path values.\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    # Iterating through all the classes mentioned in the classes list\n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "        # Display the name of the class whose data is being extracted.\n",
        "        print(f'Extracting Data of Class: {class_name} {state}')\n",
        "        # Get the list of video files present in the specific class name directory.\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        # Iterate through all the files present in the files list.\n",
        "        for file_name in files_list:\n",
        "            # Get the complete video path.\n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # create testing data\n",
        "            if state == 'test':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'L':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create validation data\n",
        "            elif state == 'valid':\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                # get the mouse side (L or R)\n",
        "                mouse_side = video_file_path.split(' ')[2].split('_')[1].split('-')[2]\n",
        "                if mouse_number == 4 and mouse_side == 'R':\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "            # create training data\n",
        "            else:\n",
        "                # get the mouse number\n",
        "                mouse_number = int(video_file_path.split(' ')[2].split('_')[1].split('-')[1])\n",
        "                if mouse_number != 4:\n",
        "                    frames = load_video(video_file_path)\n",
        "                    features.append(frames)\n",
        "                    labels.append(class_index)\n",
        "                    video_files_paths.append(video_file_path)\n",
        "    # Converting the list to numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    # print(features)\n",
        "    labels = np.array(labels)\n",
        "    # Return the frames, class index, and video file path.\n",
        "    return features, labels, video_files_paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8rpanz9rASe",
        "outputId": "92f532dc-23fb-4570-d601-99178d2d5a18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Data of Class: hemostasis train\n",
            "Extracting Data of Class: inflammatory train\n",
            "Extracting Data of Class: proliferative train\n",
            "Extracting Data of Class: maturation train\n",
            "Extracting Data of Class: hemostasis test\n",
            "Extracting Data of Class: inflammatory test\n",
            "Extracting Data of Class: proliferative test\n",
            "Extracting Data of Class: maturation test\n",
            "Extracting Data of Class: hemostasis valid\n",
            "Extracting Data of Class: inflammatory valid\n",
            "Extracting Data of Class: proliferative valid\n",
            "Extracting Data of Class: maturation valid\n"
          ]
        }
      ],
      "source": [
        "# 6 mice for training, 2 mice for test and validation (one wound on each mice for test one for validation)\n",
        "features_train, labels_train, video_files_paths_train = create_dataset('train')\n",
        "features_test, labels_test, video_files_paths_test = create_dataset('test')\n",
        "features_valid, labels_valid, video_files_paths_valid = create_dataset('valid')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dtJkK4qTAulC"
      },
      "outputs": [],
      "source": [
        "# labels to catogorical\n",
        "labels_train = keras.utils.to_categorical(labels_train)\n",
        "labels_test = keras.utils.to_categorical(labels_test)\n",
        "labels_valid = keras.utils.to_categorical(labels_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bi-NDol3DHRV"
      },
      "outputs": [],
      "source": [
        "def create_convlstm_model():\n",
        "    # TimeDistributed is a wrapper to handle input of size five to maintain frames number for LSTM\n",
        "    # A Conv2D layer requires four dimensions: (batch_size, height, width, channels)\n",
        "    # TimeDistributed will require an additional dimension: (batch_size, frames, height, width, channels)\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(8, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4)),\n",
        "                              input_shape=(16, 128, 128, 3)))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(16, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(TimeDistributed(Conv2D(64, (3,3), activation='relu',\n",
        "                                     kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # model.add(TimeDistributed(BatchNormalization()))\n",
        "    model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # model.add(TimeDistributed(Conv2D(32, (3,3), activation='relu',\n",
        "    #                                  kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # # model.add(TimeDistributed(BatchNormalization()))\n",
        "    # model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    # model.add(Dropout(0.25))\n",
        "\n",
        "    # model.add(TimeDistributed(Conv2D(40, (3,3), activation='relu',\n",
        "    #                                  kernel_regularizer=regularizers.L2(l2=1e-4))))\n",
        "    # # model.add(TimeDistributed(BatchNormalization()))\n",
        "    # model.add(TimeDistributed(MaxPooling2D((2,2), strides=(2,2))))\n",
        "    # model.add(Dropout(0.25))\n",
        "  \n",
        "    model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "    model.add(Dropout(0.35))\n",
        "\n",
        "    model.add(LSTM(4, activation='relu', return_sequences=False))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(16, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    # model.add(Dense(8, activation='relu', kernel_initializer='he_uniform',\n",
        "    #                 kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Dense(4, activation='relu', kernel_initializer='he_uniform',\n",
        "                    kernel_regularizer=regularizers.L2(l2=1e-4)))\n",
        "    # model.add(Dropout(0.3))\n",
        "    model.add(Dense(len(CLASSES_LIST), activation='softmax'))\n",
        "    model.summary(line_length = 100)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FbjNYI-0DY_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9a041fa-a91a-4803-f80a-96aab8469a02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "____________________________________________________________________________________________________\n",
            " Layer (type)                                Output Shape                            Param #        \n",
            "====================================================================================================\n",
            " time_distributed (TimeDistributed)          (None, 16, 126, 126, 8)                 224            \n",
            "                                                                                                    \n",
            " time_distributed_1 (TimeDistributed)        (None, 16, 63, 63, 8)                   0              \n",
            "                                                                                                    \n",
            " dropout (Dropout)                           (None, 16, 63, 63, 8)                   0              \n",
            "                                                                                                    \n",
            " time_distributed_2 (TimeDistributed)        (None, 16, 61, 61, 16)                  1168           \n",
            "                                                                                                    \n",
            " time_distributed_3 (TimeDistributed)        (None, 16, 30, 30, 16)                  0              \n",
            "                                                                                                    \n",
            " dropout_1 (Dropout)                         (None, 16, 30, 30, 16)                  0              \n",
            "                                                                                                    \n",
            " time_distributed_4 (TimeDistributed)        (None, 16, 28, 28, 32)                  4640           \n",
            "                                                                                                    \n",
            " time_distributed_5 (TimeDistributed)        (None, 16, 14, 14, 32)                  0              \n",
            "                                                                                                    \n",
            " dropout_2 (Dropout)                         (None, 16, 14, 14, 32)                  0              \n",
            "                                                                                                    \n",
            " time_distributed_6 (TimeDistributed)        (None, 16, 12, 12, 64)                  18496          \n",
            "                                                                                                    \n",
            " time_distributed_7 (TimeDistributed)        (None, 16, 6, 6, 64)                    0              \n",
            "                                                                                                    \n",
            " dropout_3 (Dropout)                         (None, 16, 6, 6, 64)                    0              \n",
            "                                                                                                    \n",
            " time_distributed_8 (TimeDistributed)        (None, 16, 64)                          0              \n",
            "                                                                                                    \n",
            " dropout_4 (Dropout)                         (None, 16, 64)                          0              \n",
            "                                                                                                    \n",
            " lstm (LSTM)                                 (None, 4)                               1104           \n",
            "                                                                                                    \n",
            " dropout_5 (Dropout)                         (None, 4)                               0              \n",
            "                                                                                                    \n",
            " dense (Dense)                               (None, 16)                              80             \n",
            "                                                                                                    \n",
            " dropout_6 (Dropout)                         (None, 16)                              0              \n",
            "                                                                                                    \n",
            " dense_1 (Dense)                             (None, 8)                               136            \n",
            "                                                                                                    \n",
            " dropout_7 (Dropout)                         (None, 8)                               0              \n",
            "                                                                                                    \n",
            " dense_2 (Dense)                             (None, 4)                               36             \n",
            "                                                                                                    \n",
            " dense_3 (Dense)                             (None, 4)                               20             \n",
            "                                                                                                    \n",
            "====================================================================================================\n",
            "Total params: 25,904\n",
            "Trainable params: 25,904\n",
            "Non-trainable params: 0\n",
            "____________________________________________________________________________________________________\n",
            "Model Created Successfully!\n"
          ]
        }
      ],
      "source": [
        "# Construct the required convlstm model.\n",
        "convlstm_model = create_convlstm_model()\n",
        " \n",
        "# Display the success message. \n",
        "print(\"Model Created Successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SCB3R7so-wHz"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(convlstm_model, to_file = 'convlstm_model_structure_plot.png', show_shapes = True, show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nMYwQOwyF3bd"
      },
      "outputs": [],
      "source": [
        "# keras.utils.plot_model(convlstm_model,\n",
        "#                          to_file = 'convlstm_model_structure_plot.png',\n",
        "#                          show_shapes = True,\n",
        "#                          show_layer_names = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYC_6H0uGqW9",
        "outputId": "949f1257-6299-4f81-cd2c-bf90bb71de26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "51/51 [==============================] - 12s 132ms/step - loss: 1.3468 - accuracy: 0.3769 - val_loss: 1.3675 - val_accuracy: 0.3566\n",
            "Epoch 2/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.3090 - accuracy: 0.3713 - val_loss: 1.3583 - val_accuracy: 0.3566\n",
            "Epoch 3/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.2943 - accuracy: 0.3849 - val_loss: 1.3328 - val_accuracy: 0.3640\n",
            "Epoch 4/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.2455 - accuracy: 0.4047 - val_loss: 1.3082 - val_accuracy: 0.5294\n",
            "Epoch 5/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.2332 - accuracy: 0.4208 - val_loss: 1.2672 - val_accuracy: 0.5515\n",
            "Epoch 6/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.2246 - accuracy: 0.4468 - val_loss: 1.2468 - val_accuracy: 0.5662\n",
            "Epoch 7/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.1894 - accuracy: 0.4598 - val_loss: 1.2069 - val_accuracy: 0.5478\n",
            "Epoch 8/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.1697 - accuracy: 0.4740 - val_loss: 1.1739 - val_accuracy: 0.5515\n",
            "Epoch 9/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.1602 - accuracy: 0.4969 - val_loss: 1.1263 - val_accuracy: 0.5110\n",
            "Epoch 10/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.1439 - accuracy: 0.4932 - val_loss: 1.1215 - val_accuracy: 0.5735\n",
            "Epoch 11/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.1107 - accuracy: 0.5217 - val_loss: 1.0744 - val_accuracy: 0.5551\n",
            "Epoch 12/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.0945 - accuracy: 0.5421 - val_loss: 1.0505 - val_accuracy: 0.5404\n",
            "Epoch 13/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 1.0672 - accuracy: 0.5371 - val_loss: 1.0543 - val_accuracy: 0.6066\n",
            "Epoch 14/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.0664 - accuracy: 0.5656 - val_loss: 0.9940 - val_accuracy: 0.5993\n",
            "Epoch 15/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.0480 - accuracy: 0.5681 - val_loss: 0.9879 - val_accuracy: 0.6176\n",
            "Epoch 16/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.0279 - accuracy: 0.5681 - val_loss: 0.9505 - val_accuracy: 0.6066\n",
            "Epoch 17/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 1.0227 - accuracy: 0.5613 - val_loss: 0.9688 - val_accuracy: 0.6250\n",
            "Epoch 18/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 1.0144 - accuracy: 0.5835 - val_loss: 0.9564 - val_accuracy: 0.6176\n",
            "Epoch 19/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.0174 - accuracy: 0.5854 - val_loss: 0.9181 - val_accuracy: 0.6507\n",
            "Epoch 20/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.9911 - accuracy: 0.5879 - val_loss: 0.9046 - val_accuracy: 0.6434\n",
            "Epoch 21/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.9776 - accuracy: 0.6009 - val_loss: 0.8675 - val_accuracy: 0.6103\n",
            "Epoch 22/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9854 - accuracy: 0.5835 - val_loss: 0.8732 - val_accuracy: 0.6360\n",
            "Epoch 23/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.9481 - accuracy: 0.6027 - val_loss: 0.8759 - val_accuracy: 0.6544\n",
            "Epoch 24/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9446 - accuracy: 0.5934 - val_loss: 0.8576 - val_accuracy: 0.6728\n",
            "Epoch 25/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.9403 - accuracy: 0.6095 - val_loss: 0.8397 - val_accuracy: 0.6618\n",
            "Epoch 26/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.9396 - accuracy: 0.5965 - val_loss: 0.8461 - val_accuracy: 0.6618\n",
            "Epoch 27/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9382 - accuracy: 0.5897 - val_loss: 0.7980 - val_accuracy: 0.6875\n",
            "Epoch 28/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.9160 - accuracy: 0.6089 - val_loss: 0.7801 - val_accuracy: 0.6544\n",
            "Epoch 29/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9145 - accuracy: 0.6021 - val_loss: 0.8395 - val_accuracy: 0.6838\n",
            "Epoch 30/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.8960 - accuracy: 0.6207 - val_loss: 0.7794 - val_accuracy: 0.6949\n",
            "Epoch 31/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.9969 - accuracy: 0.5545 - val_loss: 0.8029 - val_accuracy: 0.6654\n",
            "Epoch 32/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8933 - accuracy: 0.6015 - val_loss: 0.7595 - val_accuracy: 0.6912\n",
            "Epoch 33/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8701 - accuracy: 0.6275 - val_loss: 0.7388 - val_accuracy: 0.7096\n",
            "Epoch 34/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.8737 - accuracy: 0.6250 - val_loss: 0.7681 - val_accuracy: 0.7206\n",
            "Epoch 35/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.8892 - accuracy: 0.6213 - val_loss: 0.7914 - val_accuracy: 0.7206\n",
            "Epoch 36/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8883 - accuracy: 0.6071 - val_loss: 0.7669 - val_accuracy: 0.7169\n",
            "Epoch 37/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8596 - accuracy: 0.6231 - val_loss: 0.7272 - val_accuracy: 0.7096\n",
            "Epoch 38/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8773 - accuracy: 0.6170 - val_loss: 0.7489 - val_accuracy: 0.7463\n",
            "Epoch 39/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8782 - accuracy: 0.6207 - val_loss: 0.7420 - val_accuracy: 0.7169\n",
            "Epoch 40/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8486 - accuracy: 0.6330 - val_loss: 0.7244 - val_accuracy: 0.7169\n",
            "Epoch 41/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8495 - accuracy: 0.6312 - val_loss: 0.7162 - val_accuracy: 0.7169\n",
            "Epoch 42/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8294 - accuracy: 0.6535 - val_loss: 0.7157 - val_accuracy: 0.7316\n",
            "Epoch 43/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8255 - accuracy: 0.6349 - val_loss: 0.6970 - val_accuracy: 0.7169\n",
            "Epoch 44/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8849 - accuracy: 0.6132 - val_loss: 0.8023 - val_accuracy: 0.7206\n",
            "Epoch 45/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8220 - accuracy: 0.6374 - val_loss: 0.6946 - val_accuracy: 0.7316\n",
            "Epoch 46/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8369 - accuracy: 0.6355 - val_loss: 0.7166 - val_accuracy: 0.7647\n",
            "Epoch 47/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8100 - accuracy: 0.6448 - val_loss: 0.7167 - val_accuracy: 0.7721\n",
            "Epoch 48/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8225 - accuracy: 0.6355 - val_loss: 0.6785 - val_accuracy: 0.7426\n",
            "Epoch 49/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.8101 - accuracy: 0.6485 - val_loss: 0.6773 - val_accuracy: 0.7831\n",
            "Epoch 50/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8076 - accuracy: 0.6467 - val_loss: 0.7191 - val_accuracy: 0.7684\n",
            "Epoch 51/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8063 - accuracy: 0.6516 - val_loss: 0.7103 - val_accuracy: 0.7757\n",
            "Epoch 52/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7931 - accuracy: 0.6498 - val_loss: 0.6594 - val_accuracy: 0.7831\n",
            "Epoch 53/500\n",
            "51/51 [==============================] - 6s 108ms/step - loss: 0.7852 - accuracy: 0.6522 - val_loss: 0.7092 - val_accuracy: 0.7757\n",
            "Epoch 54/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.7993 - accuracy: 0.6429 - val_loss: 0.6666 - val_accuracy: 0.7831\n",
            "Epoch 55/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8097 - accuracy: 0.6498 - val_loss: 0.7330 - val_accuracy: 0.7390\n",
            "Epoch 56/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8738 - accuracy: 0.6064 - val_loss: 0.6819 - val_accuracy: 0.7647\n",
            "Epoch 57/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.7756 - accuracy: 0.6621 - val_loss: 0.6463 - val_accuracy: 0.7831\n",
            "Epoch 58/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.7784 - accuracy: 0.6627 - val_loss: 0.6856 - val_accuracy: 0.7757\n",
            "Epoch 59/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7877 - accuracy: 0.6553 - val_loss: 0.6414 - val_accuracy: 0.7757\n",
            "Epoch 60/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7754 - accuracy: 0.6578 - val_loss: 0.6310 - val_accuracy: 0.7941\n",
            "Epoch 61/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7942 - accuracy: 0.6473 - val_loss: 0.6455 - val_accuracy: 0.7831\n",
            "Epoch 62/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7853 - accuracy: 0.6603 - val_loss: 0.6295 - val_accuracy: 0.7831\n",
            "Epoch 63/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7622 - accuracy: 0.6627 - val_loss: 0.6382 - val_accuracy: 0.7831\n",
            "Epoch 64/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7576 - accuracy: 0.6739 - val_loss: 0.6330 - val_accuracy: 0.7868\n",
            "Epoch 65/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7652 - accuracy: 0.6584 - val_loss: 0.6251 - val_accuracy: 0.7831\n",
            "Epoch 66/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7600 - accuracy: 0.6634 - val_loss: 0.6269 - val_accuracy: 0.7831\n",
            "Epoch 67/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7475 - accuracy: 0.6788 - val_loss: 0.6170 - val_accuracy: 0.7868\n",
            "Epoch 68/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7444 - accuracy: 0.6745 - val_loss: 0.6951 - val_accuracy: 0.7574\n",
            "Epoch 69/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7402 - accuracy: 0.6739 - val_loss: 0.6255 - val_accuracy: 0.7831\n",
            "Epoch 70/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7427 - accuracy: 0.6714 - val_loss: 0.6179 - val_accuracy: 0.7831\n",
            "Epoch 71/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7442 - accuracy: 0.6714 - val_loss: 0.6113 - val_accuracy: 0.7868\n",
            "Epoch 72/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7427 - accuracy: 0.6658 - val_loss: 0.6094 - val_accuracy: 0.7868\n",
            "Epoch 73/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.7431 - accuracy: 0.6751 - val_loss: 0.6714 - val_accuracy: 0.7684\n",
            "Epoch 74/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9334 - accuracy: 0.5755 - val_loss: 1.0850 - val_accuracy: 0.4816\n",
            "Epoch 75/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 1.0767 - accuracy: 0.4623 - val_loss: 0.9733 - val_accuracy: 0.4816\n",
            "Epoch 76/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 1.0326 - accuracy: 0.4604 - val_loss: 0.9616 - val_accuracy: 0.4816\n",
            "Epoch 77/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 1.0118 - accuracy: 0.4796 - val_loss: 0.9212 - val_accuracy: 0.5404\n",
            "Epoch 78/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.9805 - accuracy: 0.4944 - val_loss: 0.9117 - val_accuracy: 0.5588\n",
            "Epoch 79/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.9588 - accuracy: 0.5266 - val_loss: 0.9117 - val_accuracy: 0.5625\n",
            "Epoch 80/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.9286 - accuracy: 0.5285 - val_loss: 0.8839 - val_accuracy: 0.5662\n",
            "Epoch 81/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.9280 - accuracy: 0.5353 - val_loss: 0.8733 - val_accuracy: 0.5735\n",
            "Epoch 82/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.9129 - accuracy: 0.5507 - val_loss: 0.8548 - val_accuracy: 0.5809\n",
            "Epoch 83/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8988 - accuracy: 0.5588 - val_loss: 0.8383 - val_accuracy: 0.6029\n",
            "Epoch 84/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8984 - accuracy: 0.5575 - val_loss: 0.8210 - val_accuracy: 0.5993\n",
            "Epoch 85/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.8760 - accuracy: 0.5644 - val_loss: 0.8040 - val_accuracy: 0.6176\n",
            "Epoch 86/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.8724 - accuracy: 0.5619 - val_loss: 0.8047 - val_accuracy: 0.6213\n",
            "Epoch 87/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8561 - accuracy: 0.5637 - val_loss: 0.7777 - val_accuracy: 0.6360\n",
            "Epoch 88/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8386 - accuracy: 0.5984 - val_loss: 0.7666 - val_accuracy: 0.6471\n",
            "Epoch 89/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8559 - accuracy: 0.5854 - val_loss: 0.7514 - val_accuracy: 0.6471\n",
            "Epoch 90/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.8395 - accuracy: 0.6002 - val_loss: 0.7816 - val_accuracy: 0.6691\n",
            "Epoch 91/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8326 - accuracy: 0.5984 - val_loss: 0.7237 - val_accuracy: 0.6875\n",
            "Epoch 92/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.8190 - accuracy: 0.6040 - val_loss: 0.7320 - val_accuracy: 0.7316\n",
            "Epoch 93/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.8023 - accuracy: 0.6275 - val_loss: 0.7019 - val_accuracy: 0.7316\n",
            "Epoch 94/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7745 - accuracy: 0.6386 - val_loss: 0.6755 - val_accuracy: 0.7132\n",
            "Epoch 95/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7881 - accuracy: 0.6300 - val_loss: 0.6717 - val_accuracy: 0.7684\n",
            "Epoch 96/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7606 - accuracy: 0.6559 - val_loss: 0.6568 - val_accuracy: 0.7721\n",
            "Epoch 97/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7520 - accuracy: 0.6423 - val_loss: 0.6376 - val_accuracy: 0.7794\n",
            "Epoch 98/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7573 - accuracy: 0.6467 - val_loss: 0.6437 - val_accuracy: 0.7721\n",
            "Epoch 99/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7552 - accuracy: 0.6510 - val_loss: 0.6388 - val_accuracy: 0.7757\n",
            "Epoch 100/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7419 - accuracy: 0.6547 - val_loss: 0.6251 - val_accuracy: 0.7794\n",
            "Epoch 101/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.7398 - accuracy: 0.6597 - val_loss: 0.6271 - val_accuracy: 0.7757\n",
            "Epoch 102/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7348 - accuracy: 0.6547 - val_loss: 0.6240 - val_accuracy: 0.7757\n",
            "Epoch 103/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7337 - accuracy: 0.6640 - val_loss: 0.6523 - val_accuracy: 0.7684\n",
            "Epoch 104/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7201 - accuracy: 0.6720 - val_loss: 0.6350 - val_accuracy: 0.7721\n",
            "Epoch 105/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7138 - accuracy: 0.6702 - val_loss: 0.6470 - val_accuracy: 0.7721\n",
            "Epoch 106/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7158 - accuracy: 0.6733 - val_loss: 0.6022 - val_accuracy: 0.7794\n",
            "Epoch 107/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7001 - accuracy: 0.6807 - val_loss: 0.6159 - val_accuracy: 0.7757\n",
            "Epoch 108/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.7145 - accuracy: 0.6801 - val_loss: 0.5871 - val_accuracy: 0.7831\n",
            "Epoch 109/500\n",
            "51/51 [==============================] - 6s 109ms/step - loss: 0.6957 - accuracy: 0.6869 - val_loss: 0.6589 - val_accuracy: 0.7647\n",
            "Epoch 110/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.7121 - accuracy: 0.6782 - val_loss: 0.6100 - val_accuracy: 0.7757\n",
            "Epoch 111/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6909 - accuracy: 0.6838 - val_loss: 0.6101 - val_accuracy: 0.7757\n",
            "Epoch 112/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6927 - accuracy: 0.6912 - val_loss: 0.5999 - val_accuracy: 0.7757\n",
            "Epoch 113/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6906 - accuracy: 0.6875 - val_loss: 0.6098 - val_accuracy: 0.7757\n",
            "Epoch 114/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.7214 - accuracy: 0.6745 - val_loss: 0.5983 - val_accuracy: 0.7757\n",
            "Epoch 115/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6840 - accuracy: 0.6881 - val_loss: 0.5932 - val_accuracy: 0.7794\n",
            "Epoch 116/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.6920 - accuracy: 0.6819 - val_loss: 0.6428 - val_accuracy: 0.7684\n",
            "Epoch 117/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6981 - accuracy: 0.6894 - val_loss: 0.5803 - val_accuracy: 0.7757\n",
            "Epoch 118/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7040 - accuracy: 0.6782 - val_loss: 0.5974 - val_accuracy: 0.7757\n",
            "Epoch 119/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.7000 - accuracy: 0.6776 - val_loss: 0.5972 - val_accuracy: 0.7757\n",
            "Epoch 120/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6852 - accuracy: 0.6881 - val_loss: 0.5947 - val_accuracy: 0.7757\n",
            "Epoch 121/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6821 - accuracy: 0.6819 - val_loss: 0.5727 - val_accuracy: 0.7831\n",
            "Epoch 122/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6970 - accuracy: 0.6757 - val_loss: 0.5801 - val_accuracy: 0.7831\n",
            "Epoch 123/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6988 - accuracy: 0.6856 - val_loss: 0.5900 - val_accuracy: 0.7757\n",
            "Epoch 124/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.7137 - accuracy: 0.6770 - val_loss: 0.6631 - val_accuracy: 0.7353\n",
            "Epoch 125/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6819 - accuracy: 0.6838 - val_loss: 0.5933 - val_accuracy: 0.7757\n",
            "Epoch 126/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.6825 - accuracy: 0.6949 - val_loss: 0.5595 - val_accuracy: 0.7904\n",
            "Epoch 127/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6959 - accuracy: 0.6739 - val_loss: 0.6323 - val_accuracy: 0.7684\n",
            "Epoch 128/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6942 - accuracy: 0.6776 - val_loss: 0.6035 - val_accuracy: 0.7721\n",
            "Epoch 129/500\n",
            "51/51 [==============================] - 5s 102ms/step - loss: 0.6844 - accuracy: 0.6906 - val_loss: 0.5760 - val_accuracy: 0.7868\n",
            "Epoch 130/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6808 - accuracy: 0.6887 - val_loss: 0.5956 - val_accuracy: 0.7757\n",
            "Epoch 131/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.7054 - accuracy: 0.6714 - val_loss: 0.5831 - val_accuracy: 0.7757\n",
            "Epoch 132/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6830 - accuracy: 0.6832 - val_loss: 0.5807 - val_accuracy: 0.7757\n",
            "Epoch 133/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6778 - accuracy: 0.6850 - val_loss: 0.5522 - val_accuracy: 0.7831\n",
            "Epoch 134/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6830 - accuracy: 0.6801 - val_loss: 0.5698 - val_accuracy: 0.7757\n",
            "Epoch 135/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6734 - accuracy: 0.6869 - val_loss: 0.6001 - val_accuracy: 0.7721\n",
            "Epoch 136/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6852 - accuracy: 0.6894 - val_loss: 0.5750 - val_accuracy: 0.7757\n",
            "Epoch 137/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6607 - accuracy: 0.6825 - val_loss: 0.5666 - val_accuracy: 0.7794\n",
            "Epoch 138/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.6732 - accuracy: 0.6776 - val_loss: 0.5704 - val_accuracy: 0.7794\n",
            "Epoch 139/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6738 - accuracy: 0.6819 - val_loss: 0.5660 - val_accuracy: 0.7794\n",
            "Epoch 140/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6846 - accuracy: 0.6720 - val_loss: 0.5843 - val_accuracy: 0.7757\n",
            "Epoch 141/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6863 - accuracy: 0.6708 - val_loss: 0.6193 - val_accuracy: 0.7610\n",
            "Epoch 142/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6719 - accuracy: 0.6813 - val_loss: 0.5835 - val_accuracy: 0.7794\n",
            "Epoch 143/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6734 - accuracy: 0.6782 - val_loss: 0.5676 - val_accuracy: 0.7831\n",
            "Epoch 144/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6549 - accuracy: 0.6875 - val_loss: 0.5953 - val_accuracy: 0.7757\n",
            "Epoch 145/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6814 - accuracy: 0.6813 - val_loss: 0.6189 - val_accuracy: 0.7684\n",
            "Epoch 146/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.6690 - accuracy: 0.6887 - val_loss: 0.5799 - val_accuracy: 0.7757\n",
            "Epoch 147/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6590 - accuracy: 0.6949 - val_loss: 0.6317 - val_accuracy: 0.7684\n",
            "Epoch 148/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6609 - accuracy: 0.6807 - val_loss: 0.5535 - val_accuracy: 0.7831\n",
            "Epoch 149/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6658 - accuracy: 0.6894 - val_loss: 0.6018 - val_accuracy: 0.7721\n",
            "Epoch 150/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6588 - accuracy: 0.6949 - val_loss: 0.5690 - val_accuracy: 0.7794\n",
            "Epoch 151/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.6723 - accuracy: 0.6869 - val_loss: 0.5752 - val_accuracy: 0.7757\n",
            "Epoch 152/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6585 - accuracy: 0.6887 - val_loss: 0.6015 - val_accuracy: 0.7721\n",
            "Epoch 153/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6445 - accuracy: 0.6968 - val_loss: 0.5656 - val_accuracy: 0.7794\n",
            "Epoch 154/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6417 - accuracy: 0.6955 - val_loss: 0.5283 - val_accuracy: 0.8125\n",
            "Epoch 155/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6636 - accuracy: 0.6887 - val_loss: 0.5776 - val_accuracy: 0.7757\n",
            "Epoch 156/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6529 - accuracy: 0.6931 - val_loss: 0.5684 - val_accuracy: 0.7757\n",
            "Epoch 157/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6614 - accuracy: 0.6869 - val_loss: 0.5850 - val_accuracy: 0.7757\n",
            "Epoch 158/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.6506 - accuracy: 0.6993 - val_loss: 0.5662 - val_accuracy: 0.7831\n",
            "Epoch 159/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6641 - accuracy: 0.6850 - val_loss: 0.5618 - val_accuracy: 0.7794\n",
            "Epoch 160/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6693 - accuracy: 0.6838 - val_loss: 0.5750 - val_accuracy: 0.7757\n",
            "Epoch 161/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6544 - accuracy: 0.6838 - val_loss: 0.5843 - val_accuracy: 0.7721\n",
            "Epoch 162/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6352 - accuracy: 0.6980 - val_loss: 0.5345 - val_accuracy: 0.7904\n",
            "Epoch 163/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6385 - accuracy: 0.6974 - val_loss: 0.5421 - val_accuracy: 0.7904\n",
            "Epoch 164/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6555 - accuracy: 0.6912 - val_loss: 0.5591 - val_accuracy: 0.7868\n",
            "Epoch 165/500\n",
            "51/51 [==============================] - 6s 110ms/step - loss: 0.6439 - accuracy: 0.6949 - val_loss: 0.5442 - val_accuracy: 0.7868\n",
            "Epoch 166/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6458 - accuracy: 0.6931 - val_loss: 0.5734 - val_accuracy: 0.7794\n",
            "Epoch 167/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6247 - accuracy: 0.7036 - val_loss: 0.5651 - val_accuracy: 0.7831\n",
            "Epoch 168/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6549 - accuracy: 0.6900 - val_loss: 0.5650 - val_accuracy: 0.7904\n",
            "Epoch 169/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6408 - accuracy: 0.7005 - val_loss: 0.6195 - val_accuracy: 0.7684\n",
            "Epoch 170/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6209 - accuracy: 0.7073 - val_loss: 0.5520 - val_accuracy: 0.7904\n",
            "Epoch 171/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6580 - accuracy: 0.6875 - val_loss: 0.5664 - val_accuracy: 0.7831\n",
            "Epoch 172/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6615 - accuracy: 0.6825 - val_loss: 0.5572 - val_accuracy: 0.7757\n",
            "Epoch 173/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6456 - accuracy: 0.6918 - val_loss: 0.5810 - val_accuracy: 0.7757\n",
            "Epoch 174/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6473 - accuracy: 0.7085 - val_loss: 0.6433 - val_accuracy: 0.7500\n",
            "Epoch 175/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6515 - accuracy: 0.7104 - val_loss: 0.5421 - val_accuracy: 0.8015\n",
            "Epoch 176/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6484 - accuracy: 0.7184 - val_loss: 0.5560 - val_accuracy: 0.7978\n",
            "Epoch 177/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6393 - accuracy: 0.7321 - val_loss: 0.5656 - val_accuracy: 0.7904\n",
            "Epoch 178/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6432 - accuracy: 0.7234 - val_loss: 0.5425 - val_accuracy: 0.7978\n",
            "Epoch 179/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6390 - accuracy: 0.7345 - val_loss: 0.5402 - val_accuracy: 0.8088\n",
            "Epoch 180/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6315 - accuracy: 0.7382 - val_loss: 0.5415 - val_accuracy: 0.8015\n",
            "Epoch 181/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6193 - accuracy: 0.7469 - val_loss: 0.5408 - val_accuracy: 0.8015\n",
            "Epoch 182/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6446 - accuracy: 0.7327 - val_loss: 0.5332 - val_accuracy: 0.8051\n",
            "Epoch 183/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6351 - accuracy: 0.7265 - val_loss: 0.5593 - val_accuracy: 0.7978\n",
            "Epoch 184/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6268 - accuracy: 0.7283 - val_loss: 0.5441 - val_accuracy: 0.8015\n",
            "Epoch 185/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6290 - accuracy: 0.7519 - val_loss: 0.5862 - val_accuracy: 0.7794\n",
            "Epoch 186/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6243 - accuracy: 0.7376 - val_loss: 0.5503 - val_accuracy: 0.7978\n",
            "Epoch 187/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6177 - accuracy: 0.7364 - val_loss: 0.5307 - val_accuracy: 0.7978\n",
            "Epoch 188/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6273 - accuracy: 0.7543 - val_loss: 0.5392 - val_accuracy: 0.7904\n",
            "Epoch 189/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.6412 - accuracy: 0.7382 - val_loss: 0.5340 - val_accuracy: 0.8015\n",
            "Epoch 190/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6386 - accuracy: 0.7370 - val_loss: 0.5615 - val_accuracy: 0.7794\n",
            "Epoch 191/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6392 - accuracy: 0.7457 - val_loss: 0.6076 - val_accuracy: 0.7794\n",
            "Epoch 192/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6346 - accuracy: 0.7376 - val_loss: 0.5395 - val_accuracy: 0.7978\n",
            "Epoch 193/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6188 - accuracy: 0.7494 - val_loss: 0.5417 - val_accuracy: 0.7978\n",
            "Epoch 194/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6221 - accuracy: 0.7358 - val_loss: 0.5593 - val_accuracy: 0.7831\n",
            "Epoch 195/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6119 - accuracy: 0.7432 - val_loss: 0.5628 - val_accuracy: 0.7794\n",
            "Epoch 196/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6374 - accuracy: 0.7420 - val_loss: 0.5597 - val_accuracy: 0.7794\n",
            "Epoch 197/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6099 - accuracy: 0.7512 - val_loss: 0.5462 - val_accuracy: 0.7904\n",
            "Epoch 198/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6040 - accuracy: 0.7605 - val_loss: 0.5225 - val_accuracy: 0.7941\n",
            "Epoch 199/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6266 - accuracy: 0.7488 - val_loss: 0.5168 - val_accuracy: 0.8125\n",
            "Epoch 200/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6275 - accuracy: 0.7475 - val_loss: 0.5570 - val_accuracy: 0.7904\n",
            "Epoch 201/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6271 - accuracy: 0.7351 - val_loss: 0.5264 - val_accuracy: 0.7941\n",
            "Epoch 202/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6282 - accuracy: 0.7506 - val_loss: 0.5444 - val_accuracy: 0.7868\n",
            "Epoch 203/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6202 - accuracy: 0.7494 - val_loss: 0.4991 - val_accuracy: 0.8235\n",
            "Epoch 204/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6126 - accuracy: 0.7432 - val_loss: 0.5202 - val_accuracy: 0.7868\n",
            "Epoch 205/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6068 - accuracy: 0.7463 - val_loss: 0.5187 - val_accuracy: 0.7941\n",
            "Epoch 206/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5969 - accuracy: 0.7599 - val_loss: 0.5139 - val_accuracy: 0.8162\n",
            "Epoch 207/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6317 - accuracy: 0.7401 - val_loss: 0.5136 - val_accuracy: 0.8015\n",
            "Epoch 208/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6167 - accuracy: 0.7550 - val_loss: 0.4941 - val_accuracy: 0.8272\n",
            "Epoch 209/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6267 - accuracy: 0.7370 - val_loss: 0.5275 - val_accuracy: 0.7978\n",
            "Epoch 210/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5986 - accuracy: 0.7512 - val_loss: 0.4968 - val_accuracy: 0.8235\n",
            "Epoch 211/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6107 - accuracy: 0.7580 - val_loss: 0.5032 - val_accuracy: 0.8199\n",
            "Epoch 212/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6291 - accuracy: 0.7537 - val_loss: 0.5663 - val_accuracy: 0.7794\n",
            "Epoch 213/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6154 - accuracy: 0.7531 - val_loss: 0.5203 - val_accuracy: 0.7831\n",
            "Epoch 214/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6161 - accuracy: 0.7599 - val_loss: 0.5162 - val_accuracy: 0.7978\n",
            "Epoch 215/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.6015 - accuracy: 0.7679 - val_loss: 0.5007 - val_accuracy: 0.8162\n",
            "Epoch 216/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6169 - accuracy: 0.7481 - val_loss: 0.5144 - val_accuracy: 0.8125\n",
            "Epoch 217/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6334 - accuracy: 0.7494 - val_loss: 0.5349 - val_accuracy: 0.8015\n",
            "Epoch 218/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6155 - accuracy: 0.7519 - val_loss: 0.5114 - val_accuracy: 0.8162\n",
            "Epoch 219/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5885 - accuracy: 0.7618 - val_loss: 0.4942 - val_accuracy: 0.8272\n",
            "Epoch 220/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6010 - accuracy: 0.7574 - val_loss: 0.4915 - val_accuracy: 0.8199\n",
            "Epoch 221/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.6226 - accuracy: 0.7556 - val_loss: 0.4979 - val_accuracy: 0.8235\n",
            "Epoch 222/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5967 - accuracy: 0.7642 - val_loss: 0.5317 - val_accuracy: 0.7941\n",
            "Epoch 223/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5963 - accuracy: 0.7661 - val_loss: 0.5207 - val_accuracy: 0.7941\n",
            "Epoch 224/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5988 - accuracy: 0.7587 - val_loss: 0.4969 - val_accuracy: 0.8125\n",
            "Epoch 225/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6041 - accuracy: 0.7618 - val_loss: 0.4993 - val_accuracy: 0.8235\n",
            "Epoch 226/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6148 - accuracy: 0.7469 - val_loss: 0.5106 - val_accuracy: 0.8125\n",
            "Epoch 227/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6131 - accuracy: 0.7519 - val_loss: 0.5182 - val_accuracy: 0.7904\n",
            "Epoch 228/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5958 - accuracy: 0.7661 - val_loss: 0.4892 - val_accuracy: 0.8199\n",
            "Epoch 229/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6071 - accuracy: 0.7587 - val_loss: 0.4862 - val_accuracy: 0.8272\n",
            "Epoch 230/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5992 - accuracy: 0.7605 - val_loss: 0.4857 - val_accuracy: 0.8272\n",
            "Epoch 231/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6225 - accuracy: 0.7463 - val_loss: 0.5377 - val_accuracy: 0.7831\n",
            "Epoch 232/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6112 - accuracy: 0.7457 - val_loss: 0.4886 - val_accuracy: 0.8309\n",
            "Epoch 233/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.6145 - accuracy: 0.7580 - val_loss: 0.4907 - val_accuracy: 0.8235\n",
            "Epoch 234/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6027 - accuracy: 0.7568 - val_loss: 0.5220 - val_accuracy: 0.7868\n",
            "Epoch 235/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6105 - accuracy: 0.7475 - val_loss: 0.5025 - val_accuracy: 0.8162\n",
            "Epoch 236/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5860 - accuracy: 0.7618 - val_loss: 0.5228 - val_accuracy: 0.7794\n",
            "Epoch 237/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5874 - accuracy: 0.7679 - val_loss: 0.4908 - val_accuracy: 0.8272\n",
            "Epoch 238/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5945 - accuracy: 0.7686 - val_loss: 0.4891 - val_accuracy: 0.8272\n",
            "Epoch 239/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6113 - accuracy: 0.7525 - val_loss: 0.5343 - val_accuracy: 0.7868\n",
            "Epoch 240/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5888 - accuracy: 0.7649 - val_loss: 0.4811 - val_accuracy: 0.8051\n",
            "Epoch 241/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6002 - accuracy: 0.7673 - val_loss: 0.5147 - val_accuracy: 0.7941\n",
            "Epoch 242/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6144 - accuracy: 0.7469 - val_loss: 0.5345 - val_accuracy: 0.7941\n",
            "Epoch 243/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6095 - accuracy: 0.7636 - val_loss: 0.5034 - val_accuracy: 0.8162\n",
            "Epoch 244/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5922 - accuracy: 0.7525 - val_loss: 0.4987 - val_accuracy: 0.8199\n",
            "Epoch 245/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.6055 - accuracy: 0.7624 - val_loss: 0.4895 - val_accuracy: 0.8199\n",
            "Epoch 246/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5974 - accuracy: 0.7630 - val_loss: 0.5237 - val_accuracy: 0.7941\n",
            "Epoch 247/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6032 - accuracy: 0.7611 - val_loss: 0.5182 - val_accuracy: 0.7941\n",
            "Epoch 248/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5933 - accuracy: 0.7636 - val_loss: 0.4949 - val_accuracy: 0.8162\n",
            "Epoch 249/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5758 - accuracy: 0.7698 - val_loss: 0.4818 - val_accuracy: 0.8088\n",
            "Epoch 250/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5858 - accuracy: 0.7661 - val_loss: 0.5220 - val_accuracy: 0.7868\n",
            "Epoch 251/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6114 - accuracy: 0.7512 - val_loss: 0.4812 - val_accuracy: 0.8235\n",
            "Epoch 252/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5922 - accuracy: 0.7605 - val_loss: 0.4871 - val_accuracy: 0.8235\n",
            "Epoch 253/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.6044 - accuracy: 0.7698 - val_loss: 0.5835 - val_accuracy: 0.7610\n",
            "Epoch 254/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6165 - accuracy: 0.7438 - val_loss: 0.4819 - val_accuracy: 0.8051\n",
            "Epoch 255/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5876 - accuracy: 0.7710 - val_loss: 0.4899 - val_accuracy: 0.8235\n",
            "Epoch 256/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.5969 - accuracy: 0.7655 - val_loss: 0.4917 - val_accuracy: 0.7978\n",
            "Epoch 257/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6075 - accuracy: 0.7587 - val_loss: 0.4847 - val_accuracy: 0.8235\n",
            "Epoch 258/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5880 - accuracy: 0.7704 - val_loss: 0.4992 - val_accuracy: 0.8051\n",
            "Epoch 259/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5755 - accuracy: 0.7717 - val_loss: 0.4842 - val_accuracy: 0.8051\n",
            "Epoch 260/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5817 - accuracy: 0.7698 - val_loss: 0.4847 - val_accuracy: 0.8272\n",
            "Epoch 261/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5720 - accuracy: 0.7624 - val_loss: 0.4866 - val_accuracy: 0.8199\n",
            "Epoch 262/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5924 - accuracy: 0.7673 - val_loss: 0.5033 - val_accuracy: 0.7941\n",
            "Epoch 263/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5808 - accuracy: 0.7649 - val_loss: 0.4951 - val_accuracy: 0.7868\n",
            "Epoch 264/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6521 - accuracy: 0.7339 - val_loss: 0.5631 - val_accuracy: 0.7610\n",
            "Epoch 265/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5805 - accuracy: 0.7599 - val_loss: 0.5113 - val_accuracy: 0.7904\n",
            "Epoch 266/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5909 - accuracy: 0.7642 - val_loss: 0.5006 - val_accuracy: 0.7904\n",
            "Epoch 267/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5959 - accuracy: 0.7717 - val_loss: 0.5057 - val_accuracy: 0.8051\n",
            "Epoch 268/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5929 - accuracy: 0.7618 - val_loss: 0.4892 - val_accuracy: 0.8162\n",
            "Epoch 269/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5730 - accuracy: 0.7803 - val_loss: 0.4929 - val_accuracy: 0.7978\n",
            "Epoch 270/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5748 - accuracy: 0.7717 - val_loss: 0.5310 - val_accuracy: 0.8051\n",
            "Epoch 271/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5907 - accuracy: 0.7710 - val_loss: 0.4891 - val_accuracy: 0.7868\n",
            "Epoch 272/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5817 - accuracy: 0.7605 - val_loss: 0.4950 - val_accuracy: 0.7978\n",
            "Epoch 273/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5922 - accuracy: 0.7642 - val_loss: 0.4857 - val_accuracy: 0.8162\n",
            "Epoch 274/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5737 - accuracy: 0.7748 - val_loss: 0.4779 - val_accuracy: 0.8125\n",
            "Epoch 275/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5694 - accuracy: 0.7766 - val_loss: 0.4758 - val_accuracy: 0.8051\n",
            "Epoch 276/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5783 - accuracy: 0.7704 - val_loss: 0.4792 - val_accuracy: 0.8088\n",
            "Epoch 277/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.5747 - accuracy: 0.7642 - val_loss: 0.4767 - val_accuracy: 0.8272\n",
            "Epoch 278/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5760 - accuracy: 0.7618 - val_loss: 0.4773 - val_accuracy: 0.8272\n",
            "Epoch 279/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.6009 - accuracy: 0.7593 - val_loss: 0.4913 - val_accuracy: 0.8051\n",
            "Epoch 280/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5776 - accuracy: 0.7803 - val_loss: 0.4886 - val_accuracy: 0.7941\n",
            "Epoch 281/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5741 - accuracy: 0.7760 - val_loss: 0.4829 - val_accuracy: 0.8088\n",
            "Epoch 282/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5702 - accuracy: 0.7760 - val_loss: 0.4832 - val_accuracy: 0.7978\n",
            "Epoch 283/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6042 - accuracy: 0.7543 - val_loss: 0.4710 - val_accuracy: 0.8125\n",
            "Epoch 284/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5759 - accuracy: 0.7748 - val_loss: 0.4820 - val_accuracy: 0.7978\n",
            "Epoch 285/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5739 - accuracy: 0.7778 - val_loss: 0.4820 - val_accuracy: 0.7978\n",
            "Epoch 286/500\n",
            "51/51 [==============================] - 6s 114ms/step - loss: 0.5787 - accuracy: 0.7679 - val_loss: 0.4795 - val_accuracy: 0.8015\n",
            "Epoch 287/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5869 - accuracy: 0.7686 - val_loss: 0.4832 - val_accuracy: 0.8125\n",
            "Epoch 288/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5816 - accuracy: 0.7636 - val_loss: 0.4958 - val_accuracy: 0.8051\n",
            "Epoch 289/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5783 - accuracy: 0.7679 - val_loss: 0.4755 - val_accuracy: 0.8088\n",
            "Epoch 290/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5650 - accuracy: 0.7729 - val_loss: 0.4888 - val_accuracy: 0.7978\n",
            "Epoch 291/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5687 - accuracy: 0.7760 - val_loss: 0.5041 - val_accuracy: 0.7941\n",
            "Epoch 292/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5852 - accuracy: 0.7642 - val_loss: 0.4799 - val_accuracy: 0.7978\n",
            "Epoch 293/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5856 - accuracy: 0.7735 - val_loss: 0.4726 - val_accuracy: 0.8051\n",
            "Epoch 294/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5615 - accuracy: 0.7797 - val_loss: 0.4996 - val_accuracy: 0.8051\n",
            "Epoch 295/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5754 - accuracy: 0.7748 - val_loss: 0.5330 - val_accuracy: 0.7721\n",
            "Epoch 296/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5947 - accuracy: 0.7599 - val_loss: 0.4914 - val_accuracy: 0.8051\n",
            "Epoch 297/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5709 - accuracy: 0.7840 - val_loss: 0.5031 - val_accuracy: 0.7978\n",
            "Epoch 298/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5645 - accuracy: 0.7754 - val_loss: 0.5073 - val_accuracy: 0.7794\n",
            "Epoch 299/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5666 - accuracy: 0.7809 - val_loss: 0.4774 - val_accuracy: 0.8125\n",
            "Epoch 300/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5702 - accuracy: 0.7754 - val_loss: 0.4885 - val_accuracy: 0.7941\n",
            "Epoch 301/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5563 - accuracy: 0.7809 - val_loss: 0.5089 - val_accuracy: 0.7941\n",
            "Epoch 302/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5672 - accuracy: 0.7766 - val_loss: 0.5093 - val_accuracy: 0.7794\n",
            "Epoch 303/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5682 - accuracy: 0.7735 - val_loss: 0.4940 - val_accuracy: 0.7647\n",
            "Epoch 304/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5782 - accuracy: 0.7754 - val_loss: 0.4875 - val_accuracy: 0.7684\n",
            "Epoch 305/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5679 - accuracy: 0.7692 - val_loss: 0.5143 - val_accuracy: 0.7831\n",
            "Epoch 306/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5717 - accuracy: 0.7772 - val_loss: 0.5224 - val_accuracy: 0.7757\n",
            "Epoch 307/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5613 - accuracy: 0.7785 - val_loss: 0.4984 - val_accuracy: 0.8015\n",
            "Epoch 308/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5606 - accuracy: 0.7748 - val_loss: 0.4745 - val_accuracy: 0.8125\n",
            "Epoch 309/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5540 - accuracy: 0.7741 - val_loss: 0.4776 - val_accuracy: 0.8088\n",
            "Epoch 310/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5752 - accuracy: 0.7760 - val_loss: 0.5209 - val_accuracy: 0.8051\n",
            "Epoch 311/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5572 - accuracy: 0.7748 - val_loss: 0.4952 - val_accuracy: 0.8015\n",
            "Epoch 312/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5813 - accuracy: 0.7667 - val_loss: 0.4926 - val_accuracy: 0.7794\n",
            "Epoch 313/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5901 - accuracy: 0.7642 - val_loss: 0.4912 - val_accuracy: 0.7868\n",
            "Epoch 314/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5747 - accuracy: 0.7679 - val_loss: 0.4965 - val_accuracy: 0.7794\n",
            "Epoch 315/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5605 - accuracy: 0.7766 - val_loss: 0.4766 - val_accuracy: 0.7868\n",
            "Epoch 316/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5550 - accuracy: 0.7754 - val_loss: 0.4897 - val_accuracy: 0.7721\n",
            "Epoch 317/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5742 - accuracy: 0.7760 - val_loss: 0.4857 - val_accuracy: 0.7904\n",
            "Epoch 318/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5686 - accuracy: 0.7723 - val_loss: 0.5905 - val_accuracy: 0.7941\n",
            "Epoch 319/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5631 - accuracy: 0.7791 - val_loss: 0.4884 - val_accuracy: 0.8015\n",
            "Epoch 320/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5491 - accuracy: 0.7785 - val_loss: 0.4940 - val_accuracy: 0.7941\n",
            "Epoch 321/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5520 - accuracy: 0.7853 - val_loss: 0.5059 - val_accuracy: 0.7757\n",
            "Epoch 322/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5573 - accuracy: 0.7791 - val_loss: 0.5255 - val_accuracy: 0.7978\n",
            "Epoch 323/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5592 - accuracy: 0.7785 - val_loss: 0.5007 - val_accuracy: 0.7941\n",
            "Epoch 324/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.6050 - accuracy: 0.7543 - val_loss: 0.4767 - val_accuracy: 0.7978\n",
            "Epoch 325/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5618 - accuracy: 0.7865 - val_loss: 0.4720 - val_accuracy: 0.7978\n",
            "Epoch 326/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5578 - accuracy: 0.7785 - val_loss: 0.5094 - val_accuracy: 0.7904\n",
            "Epoch 327/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5564 - accuracy: 0.7847 - val_loss: 0.4713 - val_accuracy: 0.8088\n",
            "Epoch 328/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5758 - accuracy: 0.7754 - val_loss: 0.5463 - val_accuracy: 0.8051\n",
            "Epoch 329/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5625 - accuracy: 0.7840 - val_loss: 0.5128 - val_accuracy: 0.8051\n",
            "Epoch 330/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5549 - accuracy: 0.7797 - val_loss: 0.5393 - val_accuracy: 0.7831\n",
            "Epoch 331/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5502 - accuracy: 0.7834 - val_loss: 0.4721 - val_accuracy: 0.8015\n",
            "Epoch 332/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5579 - accuracy: 0.7778 - val_loss: 0.5344 - val_accuracy: 0.7978\n",
            "Epoch 333/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.5643 - accuracy: 0.7772 - val_loss: 0.5451 - val_accuracy: 0.7831\n",
            "Epoch 334/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5635 - accuracy: 0.7840 - val_loss: 0.4762 - val_accuracy: 0.7978\n",
            "Epoch 335/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5988 - accuracy: 0.7580 - val_loss: 0.4740 - val_accuracy: 0.8162\n",
            "Epoch 336/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5836 - accuracy: 0.7624 - val_loss: 0.4969 - val_accuracy: 0.8015\n",
            "Epoch 337/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5532 - accuracy: 0.7853 - val_loss: 0.5286 - val_accuracy: 0.7794\n",
            "Epoch 338/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5509 - accuracy: 0.7834 - val_loss: 0.5122 - val_accuracy: 0.7831\n",
            "Epoch 339/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5619 - accuracy: 0.7698 - val_loss: 0.5096 - val_accuracy: 0.7463\n",
            "Epoch 340/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5491 - accuracy: 0.7853 - val_loss: 0.5602 - val_accuracy: 0.7757\n",
            "Epoch 341/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5545 - accuracy: 0.7803 - val_loss: 0.4988 - val_accuracy: 0.7794\n",
            "Epoch 342/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5498 - accuracy: 0.7717 - val_loss: 0.5678 - val_accuracy: 0.7868\n",
            "Epoch 343/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5538 - accuracy: 0.7772 - val_loss: 0.4915 - val_accuracy: 0.7868\n",
            "Epoch 344/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5494 - accuracy: 0.7847 - val_loss: 0.5767 - val_accuracy: 0.7978\n",
            "Epoch 345/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5466 - accuracy: 0.7859 - val_loss: 0.5451 - val_accuracy: 0.7941\n",
            "Epoch 346/500\n",
            "51/51 [==============================] - 5s 108ms/step - loss: 0.5557 - accuracy: 0.7778 - val_loss: 0.4873 - val_accuracy: 0.7684\n",
            "Epoch 347/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5699 - accuracy: 0.7809 - val_loss: 0.5028 - val_accuracy: 0.7978\n",
            "Epoch 348/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5564 - accuracy: 0.7871 - val_loss: 0.4958 - val_accuracy: 0.7904\n",
            "Epoch 349/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5477 - accuracy: 0.7877 - val_loss: 0.4829 - val_accuracy: 0.7721\n",
            "Epoch 350/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5397 - accuracy: 0.7760 - val_loss: 0.5635 - val_accuracy: 0.7978\n",
            "Epoch 351/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5457 - accuracy: 0.7772 - val_loss: 0.5194 - val_accuracy: 0.7721\n",
            "Epoch 352/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5580 - accuracy: 0.7760 - val_loss: 0.4753 - val_accuracy: 0.7831\n",
            "Epoch 353/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5513 - accuracy: 0.7710 - val_loss: 0.5932 - val_accuracy: 0.7831\n",
            "Epoch 354/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5318 - accuracy: 0.7902 - val_loss: 0.5342 - val_accuracy: 0.8015\n",
            "Epoch 355/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5449 - accuracy: 0.7828 - val_loss: 0.5168 - val_accuracy: 0.7941\n",
            "Epoch 356/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5473 - accuracy: 0.7877 - val_loss: 0.5009 - val_accuracy: 0.7941\n",
            "Epoch 357/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5589 - accuracy: 0.7816 - val_loss: 0.5179 - val_accuracy: 0.7868\n",
            "Epoch 358/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5311 - accuracy: 0.7908 - val_loss: 0.5348 - val_accuracy: 0.7794\n",
            "Epoch 359/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5496 - accuracy: 0.7797 - val_loss: 0.5325 - val_accuracy: 0.7904\n",
            "Epoch 360/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5288 - accuracy: 0.7933 - val_loss: 0.5594 - val_accuracy: 0.7904\n",
            "Epoch 361/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5455 - accuracy: 0.7921 - val_loss: 0.4831 - val_accuracy: 0.7794\n",
            "Epoch 362/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5804 - accuracy: 0.7587 - val_loss: 0.5266 - val_accuracy: 0.7537\n",
            "Epoch 363/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5699 - accuracy: 0.7809 - val_loss: 0.5181 - val_accuracy: 0.7463\n",
            "Epoch 364/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5777 - accuracy: 0.7574 - val_loss: 0.4797 - val_accuracy: 0.7684\n",
            "Epoch 365/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5552 - accuracy: 0.7797 - val_loss: 0.5120 - val_accuracy: 0.7537\n",
            "Epoch 366/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5494 - accuracy: 0.7778 - val_loss: 0.4755 - val_accuracy: 0.7868\n",
            "Epoch 367/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5582 - accuracy: 0.7791 - val_loss: 0.4735 - val_accuracy: 0.7757\n",
            "Epoch 368/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5465 - accuracy: 0.7865 - val_loss: 0.4824 - val_accuracy: 0.7794\n",
            "Epoch 369/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5407 - accuracy: 0.7853 - val_loss: 0.4761 - val_accuracy: 0.7794\n",
            "Epoch 370/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5428 - accuracy: 0.7933 - val_loss: 0.5051 - val_accuracy: 0.7757\n",
            "Epoch 371/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5486 - accuracy: 0.7809 - val_loss: 0.4765 - val_accuracy: 0.7941\n",
            "Epoch 372/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5558 - accuracy: 0.7853 - val_loss: 0.4785 - val_accuracy: 0.7831\n",
            "Epoch 373/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5560 - accuracy: 0.7748 - val_loss: 0.4931 - val_accuracy: 0.7831\n",
            "Epoch 374/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5488 - accuracy: 0.7822 - val_loss: 0.4817 - val_accuracy: 0.7941\n",
            "Epoch 375/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5727 - accuracy: 0.7698 - val_loss: 0.4666 - val_accuracy: 0.8125\n",
            "Epoch 376/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5543 - accuracy: 0.7853 - val_loss: 0.5188 - val_accuracy: 0.7904\n",
            "Epoch 377/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5445 - accuracy: 0.7772 - val_loss: 0.5027 - val_accuracy: 0.7757\n",
            "Epoch 378/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5334 - accuracy: 0.7915 - val_loss: 0.4760 - val_accuracy: 0.7978\n",
            "Epoch 379/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5650 - accuracy: 0.7778 - val_loss: 0.5020 - val_accuracy: 0.7610\n",
            "Epoch 380/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5837 - accuracy: 0.7599 - val_loss: 0.4709 - val_accuracy: 0.8015\n",
            "Epoch 381/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5691 - accuracy: 0.7735 - val_loss: 0.5242 - val_accuracy: 0.7316\n",
            "Epoch 382/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5610 - accuracy: 0.7748 - val_loss: 0.4791 - val_accuracy: 0.7794\n",
            "Epoch 383/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5415 - accuracy: 0.7741 - val_loss: 0.5121 - val_accuracy: 0.7757\n",
            "Epoch 384/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5433 - accuracy: 0.7871 - val_loss: 0.4765 - val_accuracy: 0.7757\n",
            "Epoch 385/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5425 - accuracy: 0.7871 - val_loss: 0.5417 - val_accuracy: 0.7794\n",
            "Epoch 386/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5444 - accuracy: 0.7859 - val_loss: 0.5150 - val_accuracy: 0.7794\n",
            "Epoch 387/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5406 - accuracy: 0.7890 - val_loss: 0.4876 - val_accuracy: 0.7904\n",
            "Epoch 388/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5532 - accuracy: 0.7778 - val_loss: 0.4737 - val_accuracy: 0.7978\n",
            "Epoch 389/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5442 - accuracy: 0.7877 - val_loss: 0.5299 - val_accuracy: 0.8015\n",
            "Epoch 390/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5536 - accuracy: 0.7853 - val_loss: 0.5040 - val_accuracy: 0.7904\n",
            "Epoch 391/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5465 - accuracy: 0.7927 - val_loss: 0.4964 - val_accuracy: 0.7721\n",
            "Epoch 392/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5667 - accuracy: 0.7673 - val_loss: 0.4876 - val_accuracy: 0.7757\n",
            "Epoch 393/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5206 - accuracy: 0.7877 - val_loss: 0.5958 - val_accuracy: 0.7978\n",
            "Epoch 394/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5472 - accuracy: 0.7729 - val_loss: 0.5173 - val_accuracy: 0.7757\n",
            "Epoch 395/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5227 - accuracy: 0.7946 - val_loss: 0.5826 - val_accuracy: 0.7794\n",
            "Epoch 396/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5301 - accuracy: 0.8001 - val_loss: 0.5068 - val_accuracy: 0.7721\n",
            "Epoch 397/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5606 - accuracy: 0.7772 - val_loss: 0.5070 - val_accuracy: 0.7757\n",
            "Epoch 398/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5412 - accuracy: 0.7896 - val_loss: 0.6013 - val_accuracy: 0.7941\n",
            "Epoch 399/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5390 - accuracy: 0.7908 - val_loss: 0.5442 - val_accuracy: 0.7978\n",
            "Epoch 400/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5394 - accuracy: 0.7847 - val_loss: 0.5576 - val_accuracy: 0.7978\n",
            "Epoch 401/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5506 - accuracy: 0.7828 - val_loss: 0.4805 - val_accuracy: 0.7757\n",
            "Epoch 402/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5334 - accuracy: 0.7877 - val_loss: 0.5095 - val_accuracy: 0.7941\n",
            "Epoch 403/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5306 - accuracy: 0.7840 - val_loss: 0.5517 - val_accuracy: 0.7978\n",
            "Epoch 404/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5406 - accuracy: 0.7877 - val_loss: 0.5535 - val_accuracy: 0.7978\n",
            "Epoch 405/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5443 - accuracy: 0.7859 - val_loss: 0.5810 - val_accuracy: 0.7978\n",
            "Epoch 406/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5518 - accuracy: 0.7772 - val_loss: 0.4643 - val_accuracy: 0.7978\n",
            "Epoch 407/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5327 - accuracy: 0.7927 - val_loss: 0.6239 - val_accuracy: 0.7978\n",
            "Epoch 408/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5503 - accuracy: 0.7834 - val_loss: 0.5910 - val_accuracy: 0.7941\n",
            "Epoch 409/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5439 - accuracy: 0.7729 - val_loss: 0.7047 - val_accuracy: 0.7978\n",
            "Epoch 410/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5420 - accuracy: 0.7908 - val_loss: 0.6069 - val_accuracy: 0.7978\n",
            "Epoch 411/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5478 - accuracy: 0.7834 - val_loss: 0.5230 - val_accuracy: 0.7904\n",
            "Epoch 412/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5267 - accuracy: 0.7896 - val_loss: 0.6310 - val_accuracy: 0.7978\n",
            "Epoch 413/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5250 - accuracy: 0.7952 - val_loss: 0.5868 - val_accuracy: 0.7941\n",
            "Epoch 414/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5532 - accuracy: 0.7816 - val_loss: 0.5833 - val_accuracy: 0.7941\n",
            "Epoch 415/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5407 - accuracy: 0.7958 - val_loss: 0.5301 - val_accuracy: 0.7684\n",
            "Epoch 416/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5484 - accuracy: 0.7803 - val_loss: 0.5558 - val_accuracy: 0.7757\n",
            "Epoch 417/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5225 - accuracy: 0.7896 - val_loss: 0.4677 - val_accuracy: 0.7757\n",
            "Epoch 418/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5278 - accuracy: 0.7939 - val_loss: 0.4977 - val_accuracy: 0.7757\n",
            "Epoch 419/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5422 - accuracy: 0.7791 - val_loss: 0.4682 - val_accuracy: 0.7904\n",
            "Epoch 420/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5622 - accuracy: 0.7723 - val_loss: 0.5410 - val_accuracy: 0.7904\n",
            "Epoch 421/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5378 - accuracy: 0.7921 - val_loss: 0.6586 - val_accuracy: 0.7757\n",
            "Epoch 422/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5357 - accuracy: 0.7853 - val_loss: 0.5097 - val_accuracy: 0.7684\n",
            "Epoch 423/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5427 - accuracy: 0.7834 - val_loss: 0.5068 - val_accuracy: 0.7721\n",
            "Epoch 424/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5329 - accuracy: 0.7939 - val_loss: 0.5683 - val_accuracy: 0.7831\n",
            "Epoch 425/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5258 - accuracy: 0.7902 - val_loss: 0.6178 - val_accuracy: 0.7941\n",
            "Epoch 426/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5294 - accuracy: 0.7847 - val_loss: 0.5608 - val_accuracy: 0.7794\n",
            "Epoch 427/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5463 - accuracy: 0.7859 - val_loss: 0.4890 - val_accuracy: 0.7831\n",
            "Epoch 428/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5321 - accuracy: 0.7853 - val_loss: 0.5182 - val_accuracy: 0.7757\n",
            "Epoch 429/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5382 - accuracy: 0.7822 - val_loss: 0.5740 - val_accuracy: 0.7941\n",
            "Epoch 430/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5559 - accuracy: 0.7741 - val_loss: 0.4779 - val_accuracy: 0.7904\n",
            "Epoch 431/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5194 - accuracy: 0.7921 - val_loss: 0.8452 - val_accuracy: 0.7904\n",
            "Epoch 432/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5682 - accuracy: 0.7778 - val_loss: 0.5528 - val_accuracy: 0.7941\n",
            "Epoch 433/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5500 - accuracy: 0.7803 - val_loss: 0.5394 - val_accuracy: 0.7721\n",
            "Epoch 434/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5460 - accuracy: 0.7853 - val_loss: 0.6854 - val_accuracy: 0.7757\n",
            "Epoch 435/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5293 - accuracy: 0.7958 - val_loss: 0.5497 - val_accuracy: 0.7757\n",
            "Epoch 436/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5448 - accuracy: 0.7772 - val_loss: 0.5030 - val_accuracy: 0.7721\n",
            "Epoch 437/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5274 - accuracy: 0.7902 - val_loss: 0.5435 - val_accuracy: 0.7941\n",
            "Epoch 438/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5166 - accuracy: 0.8020 - val_loss: 0.4971 - val_accuracy: 0.7757\n",
            "Epoch 439/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5323 - accuracy: 0.7902 - val_loss: 0.6156 - val_accuracy: 0.7794\n",
            "Epoch 440/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5107 - accuracy: 0.7964 - val_loss: 0.5301 - val_accuracy: 0.7941\n",
            "Epoch 441/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5730 - accuracy: 0.7630 - val_loss: 0.4819 - val_accuracy: 0.7757\n",
            "Epoch 442/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5407 - accuracy: 0.7791 - val_loss: 0.5442 - val_accuracy: 0.7757\n",
            "Epoch 443/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5211 - accuracy: 0.7890 - val_loss: 0.5950 - val_accuracy: 0.7794\n",
            "Epoch 444/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5417 - accuracy: 0.7803 - val_loss: 0.5240 - val_accuracy: 0.7721\n",
            "Epoch 445/500\n",
            "51/51 [==============================] - 6s 109ms/step - loss: 0.5561 - accuracy: 0.7729 - val_loss: 0.5598 - val_accuracy: 0.7941\n",
            "Epoch 446/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5109 - accuracy: 0.7915 - val_loss: 0.6466 - val_accuracy: 0.7941\n",
            "Epoch 447/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5293 - accuracy: 0.8001 - val_loss: 0.5122 - val_accuracy: 0.7904\n",
            "Epoch 448/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5203 - accuracy: 0.7964 - val_loss: 0.5612 - val_accuracy: 0.7831\n",
            "Epoch 449/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5374 - accuracy: 0.7816 - val_loss: 0.5699 - val_accuracy: 0.7794\n",
            "Epoch 450/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5543 - accuracy: 0.7809 - val_loss: 0.4753 - val_accuracy: 0.7868\n",
            "Epoch 451/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5433 - accuracy: 0.7816 - val_loss: 0.5901 - val_accuracy: 0.7794\n",
            "Epoch 452/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5269 - accuracy: 0.7921 - val_loss: 0.7147 - val_accuracy: 0.7941\n",
            "Epoch 453/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5393 - accuracy: 0.7964 - val_loss: 0.5840 - val_accuracy: 0.7794\n",
            "Epoch 454/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5203 - accuracy: 0.7939 - val_loss: 0.5638 - val_accuracy: 0.7794\n",
            "Epoch 455/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5284 - accuracy: 0.7915 - val_loss: 0.5584 - val_accuracy: 0.7794\n",
            "Epoch 456/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5416 - accuracy: 0.7915 - val_loss: 0.5907 - val_accuracy: 0.7794\n",
            "Epoch 457/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5428 - accuracy: 0.7834 - val_loss: 0.5555 - val_accuracy: 0.7941\n",
            "Epoch 458/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5202 - accuracy: 0.7927 - val_loss: 0.4651 - val_accuracy: 0.7941\n",
            "Epoch 459/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5213 - accuracy: 0.7896 - val_loss: 0.7643 - val_accuracy: 0.7794\n",
            "Epoch 460/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5291 - accuracy: 0.7933 - val_loss: 0.6457 - val_accuracy: 0.7794\n",
            "Epoch 461/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5317 - accuracy: 0.7884 - val_loss: 0.5790 - val_accuracy: 0.7941\n",
            "Epoch 462/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5299 - accuracy: 0.7921 - val_loss: 0.6795 - val_accuracy: 0.8051\n",
            "Epoch 463/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5183 - accuracy: 0.7958 - val_loss: 0.6040 - val_accuracy: 0.7904\n",
            "Epoch 464/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5329 - accuracy: 0.7847 - val_loss: 0.6585 - val_accuracy: 0.7978\n",
            "Epoch 465/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5575 - accuracy: 0.7853 - val_loss: 0.4762 - val_accuracy: 0.7868\n",
            "Epoch 466/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5422 - accuracy: 0.7939 - val_loss: 0.7907 - val_accuracy: 0.7941\n",
            "Epoch 467/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5236 - accuracy: 0.7927 - val_loss: 0.8251 - val_accuracy: 0.8125\n",
            "Epoch 468/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5222 - accuracy: 0.7989 - val_loss: 0.6331 - val_accuracy: 0.7941\n",
            "Epoch 469/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5179 - accuracy: 0.7933 - val_loss: 0.7355 - val_accuracy: 0.7794\n",
            "Epoch 470/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5425 - accuracy: 0.7939 - val_loss: 0.6632 - val_accuracy: 0.7941\n",
            "Epoch 471/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5167 - accuracy: 0.8045 - val_loss: 0.6616 - val_accuracy: 0.7941\n",
            "Epoch 472/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5200 - accuracy: 0.7865 - val_loss: 0.7028 - val_accuracy: 0.7831\n",
            "Epoch 473/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5249 - accuracy: 0.7915 - val_loss: 0.6849 - val_accuracy: 0.7978\n",
            "Epoch 474/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5198 - accuracy: 0.7908 - val_loss: 0.6605 - val_accuracy: 0.7941\n",
            "Epoch 475/500\n",
            "51/51 [==============================] - 5s 103ms/step - loss: 0.5249 - accuracy: 0.7908 - val_loss: 0.8172 - val_accuracy: 0.7941\n",
            "Epoch 476/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5015 - accuracy: 0.8032 - val_loss: 0.6094 - val_accuracy: 0.7978\n",
            "Epoch 477/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5300 - accuracy: 0.7902 - val_loss: 0.7009 - val_accuracy: 0.7941\n",
            "Epoch 478/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5255 - accuracy: 0.7983 - val_loss: 0.6601 - val_accuracy: 0.7941\n",
            "Epoch 479/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5015 - accuracy: 0.8038 - val_loss: 0.6152 - val_accuracy: 0.7978\n",
            "Epoch 480/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5477 - accuracy: 0.7834 - val_loss: 0.5545 - val_accuracy: 0.7757\n",
            "Epoch 481/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5275 - accuracy: 0.7809 - val_loss: 0.6082 - val_accuracy: 0.7978\n",
            "Epoch 482/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5107 - accuracy: 0.8106 - val_loss: 0.6046 - val_accuracy: 0.7978\n",
            "Epoch 483/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5134 - accuracy: 0.7964 - val_loss: 0.6141 - val_accuracy: 0.7794\n",
            "Epoch 484/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5201 - accuracy: 0.7970 - val_loss: 0.6712 - val_accuracy: 0.7757\n",
            "Epoch 485/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5209 - accuracy: 0.7908 - val_loss: 0.7391 - val_accuracy: 0.7941\n",
            "Epoch 486/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5254 - accuracy: 0.7927 - val_loss: 0.6472 - val_accuracy: 0.7794\n",
            "Epoch 487/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.4990 - accuracy: 0.8069 - val_loss: 0.6709 - val_accuracy: 0.7941\n",
            "Epoch 488/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5360 - accuracy: 0.7970 - val_loss: 0.7787 - val_accuracy: 0.7941\n",
            "Epoch 489/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5421 - accuracy: 0.7958 - val_loss: 0.4958 - val_accuracy: 0.7684\n",
            "Epoch 490/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5117 - accuracy: 0.7989 - val_loss: 0.5516 - val_accuracy: 0.7757\n",
            "Epoch 491/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5209 - accuracy: 0.7840 - val_loss: 0.6331 - val_accuracy: 0.7868\n",
            "Epoch 492/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5096 - accuracy: 0.8045 - val_loss: 0.6682 - val_accuracy: 0.7978\n",
            "Epoch 493/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5128 - accuracy: 0.7983 - val_loss: 0.5603 - val_accuracy: 0.7941\n",
            "Epoch 494/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5195 - accuracy: 0.8007 - val_loss: 0.6601 - val_accuracy: 0.7941\n",
            "Epoch 495/500\n",
            "51/51 [==============================] - 5s 107ms/step - loss: 0.5270 - accuracy: 0.7995 - val_loss: 0.7655 - val_accuracy: 0.7978\n",
            "Epoch 496/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5354 - accuracy: 0.7859 - val_loss: 0.4823 - val_accuracy: 0.7757\n",
            "Epoch 497/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5484 - accuracy: 0.7809 - val_loss: 0.8011 - val_accuracy: 0.7941\n",
            "Epoch 498/500\n",
            "51/51 [==============================] - 5s 105ms/step - loss: 0.5274 - accuracy: 0.7964 - val_loss: 0.6174 - val_accuracy: 0.7941\n",
            "Epoch 499/500\n",
            "51/51 [==============================] - 5s 104ms/step - loss: 0.5152 - accuracy: 0.7952 - val_loss: 0.7790 - val_accuracy: 0.7941\n",
            "Epoch 500/500\n",
            "51/51 [==============================] - 5s 106ms/step - loss: 0.5198 - accuracy: 0.8001 - val_loss: 0.8887 - val_accuracy: 0.8015\n"
          ]
        }
      ],
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "\n",
        "# https://stackoverflow.com/questions/53479007/how-to-setup-adaptive-learning-rate-in-keras\n",
        "# def adapt_learning_rate(epoch):\n",
        "#     print(0.0001 * epoch)\n",
        "#     return 0.0001 * epoch\n",
        "# my_lr_scheduler = keras.callbacks.LearningRateScheduler(adapt_learning_rate)\n",
        "\n",
        "early_stopping_callback = keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                                        patience = 10,\n",
        "                                                        mode = 'min',\n",
        "                                                        restore_best_weights = True)\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "convlstm_model.compile(loss = 'categorical_crossentropy',\n",
        "                       optimizer= keras.optimizers.Adam(0.0003, decay=1e-4),\n",
        "                       metrics = [\"accuracy\"])\n",
        "# Start training the model.\n",
        "convlstm_model_training_history = convlstm_model.fit(x = features_train,\n",
        "                                                     y = labels_train,\n",
        "                                                     epochs = 500,\n",
        "                                                     batch_size = 32,\n",
        "                                                     shuffle = True,\n",
        "                                                     validation_data = (features_valid, labels_valid)),\n",
        "                                                    #  callbacks = [early_stopping_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcpKhGqvIenv",
        "outputId": "97ecfa03-2764-4b59-e1ed-bc1e6e4df2cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 43ms/step - loss: 0.7630 - accuracy: 0.7491\n",
            "\n",
            "\n",
            "Train accuracy: 78.403 % || Test accuracy: 74.908 % || Val accuracy: 80.147 %\n",
            "\n",
            "\n",
            "Train loss: 0.510 || Test loss: 0.763 || Val loss: 0.889\n"
          ]
        }
      ],
      "source": [
        "model_evaluation_history = convlstm_model.evaluate(features_test, labels_test)\n",
        "print('\\n')\n",
        "train_loss, train_acc = convlstm_model.evaluate(features_train, labels_train, verbose=0)\n",
        "test_loss, test_acc = convlstm_model.evaluate(features_test, labels_test, verbose=0)\n",
        "val_loss, val_acc = convlstm_model.evaluate(features_valid, labels_valid, verbose=0)\n",
        "\n",
        "print(f'Train accuracy: {train_acc*100:.3f} % || Test accuracy: {test_acc*100:.3f} % || Val accuracy: {val_acc*100:.3f} %')\n",
        "print('\\n')\n",
        "print(f'Train loss: {train_loss:.3f} || Test loss: {test_loss:.3f} || Val loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qsFw5KIzIum9"
      },
      "outputs": [],
      "source": [
        "# Get the loss and accuracy from model_evaluation_history.\n",
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        " \n",
        "# Define the string date format.\n",
        "# Get the current Date and Time in a DateTime Object.\n",
        "# Convert the DateTime object to string according to the style mentioned in date_time_format string.\n",
        "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
        "current_date_time_dt = dt.datetime.now()\n",
        "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
        " \n",
        "# Define a useful name for our model to make it easy for us while navigating through multiple saved models.\n",
        "model_file_name = f'convlstm_model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
        " \n",
        "# Change dir\n",
        "gdrive_path = '/content/gdrive' + '/My Drive/247/Saved_models/'\n",
        "os.chdir(gdrive_path)\n",
        "# Create a floder for the model files\n",
        "!mkdir -p convlstm_{current_date_time_string}\n",
        "# Save your Model.\n",
        "convlstm_model.save('convlstm_' + str(current_date_time_string) + '/' + model_file_name)\n",
        "# Save model weights\n",
        "convlstm_model.save_weights('convlstm_' + str(current_date_time_string) + '/' + 'weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z0eAobhSIz_P"
      },
      "outputs": [],
      "source": [
        "def plot_metric(model_training_history, metric_name_1, metric_name_2, plot_name):\n",
        "    '''\n",
        "    This function will plot the metrics passed to it in a graph.\n",
        "    Args:\n",
        "        model_training_history: A history object containing a record of training and validation \n",
        "                                loss values and metrics values at successive epochs\n",
        "        metric_name_1:          The name of the first metric that needs to be plotted in the graph.\n",
        "        metric_name_2:          The name of the second metric that needs to be plotted in the graph.\n",
        "        plot_name:              The title of the graph.\n",
        "    '''\n",
        "    \n",
        "    # Get metric values using metric names as identifiers.\n",
        "    metric_value_1 = model_training_history[0].history[metric_name_1]\n",
        "    metric_value_2 = model_training_history[0].history[metric_name_2]\n",
        "    \n",
        "    # Construct a range object which will be used as x-axis (horizontal plane) of the graph.\n",
        "    epochs = range(len(metric_value_1))\n",
        "\n",
        "    # Plot the Graph.\n",
        "    plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
        "    plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
        "\n",
        "    # Add title to the plot.\n",
        "    plt.title(str(plot_name))\n",
        "\n",
        "    # Add legend to the plot.\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "18RtBjI9I5lE",
        "outputId": "81b38a5a-eea2-49df-cbe5-4fe56865de94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(convlstm_model_training_history, 'loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "02amk7TXI_OS",
        "outputId": "683d3f02-3732-4642-b1d3-789679f6308d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_metric(convlstm_model_training_history, 'accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "2D_CNN+LSTM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPIn5kGoB+/9REj5cRqFsA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}